ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 19.5 Synchronisation Bidirectionnelle

## Introduction

La synchronisation bidirectionnelle reprÃ©sente l'un des dÃ©fis les plus complexes en migration de donnÃ©es. Contrairement Ã  la synchronisation unidirectionnelle (CDC simple), elle permet des modifications concurrentes dans deux systÃ¨mes hÃ©tÃ©rogÃ¨nes (SQL et MongoDB) avec rÃ©conciliation automatique des conflits. Cette approche est essentielle pour les migrations incrÃ©mentales nÃ©cessitant une pÃ©riode de coexistence prolongÃ©e avec zÃ©ro perte de donnÃ©es.

Cette section explore les architectures, algorithmes et patterns Ã©prouvÃ©s pour implÃ©menter une synchronisation bidirectionnelle fiable Ã  l'Ã©chelle production.

---

## ğŸ¯ Principes et DÃ©fis

### Le problÃ¨me fondamental

**ScÃ©nario typique**
```
T0 : [Record A v1] existe dans SQL et MongoDB (sync)

T1 : User1 modifie A â†’ v2 dans SQL
T1 : User2 modifie A â†’ v2' dans MongoDB (concurrent)

T2 : Sync SQL â†’ MongoDB dÃ©tecte conflit (v2 vs v2')
T2 : Sync MongoDB â†’ SQL dÃ©tecte conflit (v2' vs v2)

Question : Quelle version prÃ©valoir ? Comment rÃ©concilier ?
```

### PropriÃ©tÃ©s dÃ©sirÃ©es (thÃ©orÃ¨me CAP)

**Consistency (CohÃ©rence)**
- Les deux systÃ¨mes doivent converger vers le mÃªme Ã©tat
- Ordre des opÃ©rations respectÃ© (causalitÃ©)

**Availability (DisponibilitÃ©)**
- Chaque systÃ¨me accepte des writes mÃªme en cas de partition
- Pas de blocking sur synchronisation

**Partition Tolerance (TolÃ©rance aux partitions)**
- SystÃ¨mes fonctionnent mÃªme si rÃ©seau coupÃ© temporairement
- RÃ©conciliation automatique aprÃ¨s reconnexion

**Compromis inÃ©vitables (thÃ©orÃ¨me CAP)**
```
Dans un systÃ¨me distribuÃ©, impossible d'avoir simultanÃ©ment :
- Consistency forte
- Availability totale
- Partition tolerance

Choix typique pour sync bidirectionnelle :
â†’ AP (Available + Partition tolerant)
â†’ Eventually Consistent (cohÃ©rence Ã  terme)
```

### Types de conflits

**1. Conflits d'Ã©criture (Write-Write)**
```
SQL:     [user.name = "Alice"]  (T1)
MongoDB: [user.name = "Alicia"] (T1)

â†’ Conflit : Deux modifications concurrentes du mÃªme champ
```

**2. Conflits d'insertion (Insert-Insert)**
```
SQL:     INSERT user (id=123, name="Bob")    (T1)
MongoDB: INSERT user (id=123, name="Bobby")  (T1)

â†’ Conflit : MÃªme clÃ©, donnÃ©es diffÃ©rentes
```

**3. Conflits de suppression (Delete-Update)**
```
SQL:     DELETE user WHERE id=123  (T1)
MongoDB: UPDATE user SET age=30 WHERE id=123  (T1)

â†’ Conflit : Un systÃ¨me supprime, l'autre modifie
```

**4. Conflits de type (Type Mismatch)**
```
SQL:     [user.phone = "1234567890"] (STRING)
MongoDB: [user.phone = 1234567890]   (NUMBER)

â†’ Conflit : IncompatibilitÃ© de types
```

**5. Conflits structurels (Schema Evolution)**
```
SQL:     [user.address = "123 Main St"] (denormalized)
MongoDB: [user.address = {street: "123 Main St", city: "Paris"}] (object)

â†’ Conflit : Structure incompatible
```

---

## ğŸ—ï¸ Patterns de RÃ©solution de Conflits

### 1. Last-Write-Wins (LWW)

**Principe**
La derniÃ¨re Ã©criture (timestamp le plus rÃ©cent) l'emporte.

**ImplÃ©mentation**

```typescript
// lww-resolver.ts
interface VersionedRecord {
  id: string;
  data: any;
  version: number;
  timestamp: Date;
  source: 'sql' | 'mongodb';
}

class LWWResolver {
  resolve(
    sqlRecord: VersionedRecord,
    mongoRecord: VersionedRecord
  ): VersionedRecord {

    // Comparer timestamps
    if (sqlRecord.timestamp > mongoRecord.timestamp) {
      return {
        ...sqlRecord,
        resolvedBy: 'lww',
        winner: 'sql',
        timestamp: new Date()
      };
    } else if (mongoRecord.timestamp > sqlRecord.timestamp) {
      return {
        ...mongoRecord,
        resolvedBy: 'lww',
        winner: 'mongodb',
        timestamp: new Date()
      };
    } else {
      // Timestamps Ã©gaux â†’ tiebreaker par source
      // (rÃ¨gle arbitraire : SQL gagne)
      return {
        ...sqlRecord,
        resolvedBy: 'lww-tiebreaker',
        winner: 'sql',
        timestamp: new Date()
      };
    }
  }
}
```

**Avantages**
- âœ… Simple Ã  implÃ©menter
- âœ… DÃ©terministe (mÃªme rÃ©sultat partout)
- âœ… Performance Ã©levÃ©e

**InconvÃ©nients**
- âŒ Perte possible de donnÃ©es (Ã©criture Ã©crasÃ©e)
- âŒ Pas de prise en compte de la sÃ©mantique mÃ©tier
- âŒ ProblÃ¨me si clocks non synchronisÃ©es

**Quand utiliser ?**
- DonnÃ©es oÃ¹ la derniÃ¨re valeur est la bonne (tempÃ©rature, statut)
- SystÃ¨mes avec clock sync parfait (NTP)
- Taux de conflits faible

---

### 2. Version Vector

**Principe**
Chaque systÃ¨me maintient un vecteur de versions pour dÃ©tecter causalitÃ© et conflits rÃ©els.

**ImplÃ©mentation**

```typescript
// version-vector.ts
type VersionVector = {
  [systemId: string]: number;
};

interface VectoredRecord {
  id: string;
  data: any;
  versionVector: VersionVector;
}

class VersionVectorResolver {

  /**
   * Compare deux vecteurs de version
   *
   * Returns:
   * - 'before' : v1 happened before v2 (v1 < v2)
   * - 'after'  : v1 happened after v2 (v1 > v2)
   * - 'concurrent' : v1 and v2 are concurrent (conflict)
   * - 'equal' : v1 == v2 (no conflict)
   */
  compare(v1: VersionVector, v2: VersionVector): 'before' | 'after' | 'concurrent' | 'equal' {
    let v1Greater = false;
    let v2Greater = false;

    // Union de toutes les clÃ©s
    const allKeys = new Set([
      ...Object.keys(v1),
      ...Object.keys(v2)
    ]);

    for (const key of allKeys) {
      const val1 = v1[key] || 0;
      const val2 = v2[key] || 0;

      if (val1 > val2) v1Greater = true;
      if (val2 > val1) v2Greater = true;
    }

    if (!v1Greater && !v2Greater) return 'equal';
    if (v1Greater && !v2Greater) return 'after';
    if (!v1Greater && v2Greater) return 'before';
    return 'concurrent';  // Conflict rÃ©el !
  }

  resolve(
    sqlRecord: VectoredRecord,
    mongoRecord: VectoredRecord
  ): {
    action: 'use_sql' | 'use_mongo' | 'merge' | 'manual';
    resolved?: VectoredRecord;
  } {

    const comparison = this.compare(
      sqlRecord.versionVector,
      mongoRecord.versionVector
    );

    switch (comparison) {
      case 'equal':
        return { action: 'use_sql', resolved: sqlRecord };

      case 'after':
        // SQL is more recent
        return { action: 'use_sql', resolved: sqlRecord };

      case 'before':
        // MongoDB is more recent
        return { action: 'use_mongo', resolved: mongoRecord };

      case 'concurrent':
        // Vrai conflit â†’ nÃ©cessite merge ou rÃ©solution manuelle
        return {
          action: 'merge',
          resolved: this.merge(sqlRecord, mongoRecord)
        };
    }
  }

  merge(
    sqlRecord: VectoredRecord,
    mongoRecord: VectoredRecord
  ): VectoredRecord {

    // Merge champ par champ avec stratÃ©gie customizable
    const mergedData: any = {};

    const allKeys = new Set([
      ...Object.keys(sqlRecord.data),
      ...Object.keys(mongoRecord.data)
    ]);

    for (const key of allKeys) {
      const sqlValue = sqlRecord.data[key];
      const mongoValue = mongoRecord.data[key];

      if (sqlValue === mongoValue) {
        mergedData[key] = sqlValue;
      } else if (sqlValue === undefined) {
        mergedData[key] = mongoValue;
      } else if (mongoValue === undefined) {
        mergedData[key] = sqlValue;
      } else {
        // Conflit sur ce champ â†’ appliquer stratÃ©gie
        mergedData[key] = this.resolveFieldConflict(key, sqlValue, mongoValue);
      }
    }

    // Merge version vectors
    const mergedVector: VersionVector = {};
    const allSystems = new Set([
      ...Object.keys(sqlRecord.versionVector),
      ...Object.keys(mongoRecord.versionVector)
    ]);

    for (const system of allSystems) {
      mergedVector[system] = Math.max(
        sqlRecord.versionVector[system] || 0,
        mongoRecord.versionVector[system] || 0
      );
    }

    return {
      id: sqlRecord.id,
      data: mergedData,
      versionVector: mergedVector
    };
  }

  private resolveFieldConflict(field: string, sqlValue: any, mongoValue: any): any {
    // StratÃ©gie par champ (configurable)
    const strategy = this.getFieldStrategy(field);

    switch (strategy) {
      case 'prefer_sql':
        return sqlValue;
      case 'prefer_mongo':
        return mongoValue;
      case 'prefer_non_null':
        return sqlValue !== null ? sqlValue : mongoValue;
      case 'merge_array':
        if (Array.isArray(sqlValue) && Array.isArray(mongoValue)) {
          return [...new Set([...sqlValue, ...mongoValue])];
        }
        return sqlValue;
      case 'merge_object':
        if (typeof sqlValue === 'object' && typeof mongoValue === 'object') {
          return { ...sqlValue, ...mongoValue };
        }
        return sqlValue;
      default:
        return sqlValue;
    }
  }

  private getFieldStrategy(field: string): string {
    // Configuration par champ
    const strategies: Record<string, string> = {
      'email': 'prefer_non_null',
      'tags': 'merge_array',
      'metadata': 'merge_object',
      'status': 'prefer_sql',
      'preferences': 'prefer_mongo'
    };

    return strategies[field] || 'prefer_sql';
  }
}

// Exemple d'utilisation
const resolver = new VersionVectorResolver();

const sqlRecord: VectoredRecord = {
  id: "user_123",
  data: {
    name: "Alice",
    email: "alice@example.com",
    age: 30
  },
  versionVector: {
    sql: 5,
    mongodb: 3
  }
};

const mongoRecord: VectoredRecord = {
  id: "user_123",
  data: {
    name: "Alice Smith",
    email: "alice@example.com",
    age: 30
  },
  versionVector: {
    sql: 4,
    mongodb: 6
  }
};

const result = resolver.resolve(sqlRecord, mongoRecord);
// result.action = 'concurrent'
// â†’ Merge nÃ©cessaire
```

**Avantages**
- âœ… DÃ©tection prÃ©cise des conflits rÃ©els
- âœ… Pas de perte de donnÃ©es causales
- âœ… IdÃ©al pour systÃ¨mes distribuÃ©s

**InconvÃ©nients**
- âŒ ComplexitÃ© implÃ©mentation
- âŒ Overhead stockage (vecteurs)
- âŒ Merge complexe si conflit

---

### 3. Operational Transformation (OT)

**Principe**
Transforme opÃ©rations concurrentes pour prÃ©server intention utilisateur.

**ImplÃ©mentation (texte collaboratif)**

```typescript
// operational-transformation.ts
interface Operation {
  type: 'insert' | 'delete' | 'retain';
  position: number;
  text?: string;
  length?: number;
}

class OTResolver {

  /**
   * Transform operation A against operation B
   * Used when both operations were applied to the same base state
   */
  transform(opA: Operation, opB: Operation): Operation {

    if (opA.type === 'insert' && opB.type === 'insert') {
      if (opA.position < opB.position) {
        return opA;  // A remains unchanged
      } else if (opA.position > opB.position) {
        return {
          ...opA,
          position: opA.position + (opB.text?.length || 0)
        };
      } else {
        // Same position â†’ tiebreaker (arbitrary)
        return {
          ...opA,
          position: opA.position + (opB.text?.length || 0)
        };
      }
    }

    if (opA.type === 'insert' && opB.type === 'delete') {
      if (opA.position <= opB.position) {
        return opA;
      } else if (opA.position > opB.position + (opB.length || 0)) {
        return {
          ...opA,
          position: opA.position - (opB.length || 0)
        };
      } else {
        // Insert inside delete range
        return {
          ...opA,
          position: opB.position
        };
      }
    }

    if (opA.type === 'delete' && opB.type === 'insert') {
      if (opA.position < opB.position) {
        return opA;
      } else {
        return {
          ...opA,
          position: opA.position + (opB.text?.length || 0)
        };
      }
    }

    if (opA.type === 'delete' && opB.type === 'delete') {
      if (opA.position + (opA.length || 0) <= opB.position) {
        return opA;
      } else if (opA.position >= opB.position + (opB.length || 0)) {
        return {
          ...opA,
          position: opA.position - (opB.length || 0)
        };
      } else {
        // Overlapping deletes â†’ adjust
        const newLength = Math.max(
          0,
          (opA.length || 0) - (opB.length || 0)
        );
        return {
          ...opA,
          position: Math.min(opA.position, opB.position),
          length: newLength
        };
      }
    }

    return opA;
  }

  /**
   * Apply transformation to document field
   */
  applyOT(
    baseValue: string,
    sqlOp: Operation,
    mongoOp: Operation
  ): string {

    // Transform operations
    const transformedSqlOp = this.transform(sqlOp, mongoOp);
    const transformedMongoOp = this.transform(mongoOp, sqlOp);

    // Apply both operations in sequence
    let result = baseValue;
    result = this.applyOperation(result, transformedSqlOp);
    result = this.applyOperation(result, transformedMongoOp);

    return result;
  }

  private applyOperation(text: string, op: Operation): string {
    switch (op.type) {
      case 'insert':
        return (
          text.slice(0, op.position) +
          (op.text || '') +
          text.slice(op.position)
        );

      case 'delete':
        return (
          text.slice(0, op.position) +
          text.slice(op.position + (op.length || 0))
        );

      default:
        return text;
    }
  }
}

// Exemple
const ot = new OTResolver();

const baseText = "Hello world";

const sqlOp: Operation = {
  type: 'insert',
  position: 6,
  text: 'beautiful '
};

const mongoOp: Operation = {
  type: 'delete',
  position: 0,
  length: 6
};

const result = ot.applyOT(baseText, sqlOp, mongoOp);
// Result: "beautiful world"
// (SQL insert + Mongo delete reconciled)
```

**Avantages**
- âœ… PrÃ©serve intention utilisateur
- âœ… IdÃ©al pour Ã©dition collaborative (Google Docs style)
- âœ… Convergence garantie

**InconvÃ©nients**
- âŒ ComplexitÃ© algorithmique Ã©levÃ©e
- âŒ LimitÃ© aux types sÃ©quentiels (texte)
- âŒ Performance sur grandes opÃ©rations

**Quand utiliser ?**
- Ã‰dition collaborative de texte
- Synchronisation documents riches
- SystÃ¨mes avec OT natif (MongoDB Realm Sync utilise OT)

---

### 4. CRDT (Conflict-free Replicated Data Types)

**Principe**
Types de donnÃ©es conÃ§us mathÃ©matiquement pour converger automatiquement sans conflit.

**ImplÃ©mentation G-Counter (Grow-only Counter)**

```typescript
// crdt-gcounter.ts
interface GCounter {
  id: string;
  counts: Map<string, number>;  // nodeId â†’ count
}

class GCounterCRDT {

  increment(counter: GCounter, nodeId: string, amount: number = 1): GCounter {
    const newCounts = new Map(counter.counts);
    const current = newCounts.get(nodeId) || 0;
    newCounts.set(nodeId, current + amount);

    return {
      id: counter.id,
      counts: newCounts
    };
  }

  merge(counter1: GCounter, counter2: GCounter): GCounter {
    const mergedCounts = new Map<string, number>();

    // Union de tous les nodeIds
    const allNodes = new Set([
      ...counter1.counts.keys(),
      ...counter2.counts.keys()
    ]);

    for (const nodeId of allNodes) {
      const count1 = counter1.counts.get(nodeId) || 0;
      const count2 = counter2.counts.get(nodeId) || 0;

      // Prendre le max pour chaque node (monotonic increase)
      mergedCounts.set(nodeId, Math.max(count1, count2));
    }

    return {
      id: counter1.id,
      counts: mergedCounts
    };
  }

  value(counter: GCounter): number {
    let total = 0;
    for (const count of counter.counts.values()) {
      total += count;
    }
    return total;
  }
}

// PN-Counter (Positive-Negative Counter) - supports decrement
interface PNCounter {
  id: string;
  positive: Map<string, number>;
  negative: Map<string, number>;
}

class PNCounterCRDT {

  increment(counter: PNCounter, nodeId: string, amount: number = 1): PNCounter {
    const newPositive = new Map(counter.positive);
    const current = newPositive.get(nodeId) || 0;
    newPositive.set(nodeId, current + amount);

    return {
      ...counter,
      positive: newPositive
    };
  }

  decrement(counter: PNCounter, nodeId: string, amount: number = 1): PNCounter {
    const newNegative = new Map(counter.negative);
    const current = newNegative.get(nodeId) || 0;
    newNegative.set(nodeId, current + amount);

    return {
      ...counter,
      negative: newNegative
    };
  }

  merge(counter1: PNCounter, counter2: PNCounter): PNCounter {
    const mergedPositive = this.mergeMaps(counter1.positive, counter2.positive);
    const mergedNegative = this.mergeMaps(counter1.negative, counter2.negative);

    return {
      id: counter1.id,
      positive: mergedPositive,
      negative: mergedNegative
    };
  }

  private mergeMaps(
    map1: Map<string, number>,
    map2: Map<string, number>
  ): Map<string, number> {
    const merged = new Map<string, number>();
    const allKeys = new Set([...map1.keys(), ...map2.keys()]);

    for (const key of allKeys) {
      merged.set(key, Math.max(map1.get(key) || 0, map2.get(key) || 0));
    }

    return merged;
  }

  value(counter: PNCounter): number {
    let positive = 0;
    for (const count of counter.positive.values()) {
      positive += count;
    }

    let negative = 0;
    for (const count of counter.negative.values()) {
      negative += count;
    }

    return positive - negative;
  }
}

// LWW-Element-Set (Last-Write-Wins Set)
interface LWWElement<T> {
  value: T;
  timestamp: Date;
  tombstone: boolean;  // true if deleted
}

class LWWSetCRDT<T> {
  private elements: Map<string, LWWElement<T>>;

  constructor() {
    this.elements = new Map();
  }

  add(value: T, timestamp: Date = new Date()): void {
    const key = this.hash(value);
    const existing = this.elements.get(key);

    if (!existing || timestamp > existing.timestamp) {
      this.elements.set(key, {
        value,
        timestamp,
        tombstone: false
      });
    }
  }

  remove(value: T, timestamp: Date = new Date()): void {
    const key = this.hash(value);
    const existing = this.elements.get(key);

    if (!existing || timestamp > existing.timestamp) {
      this.elements.set(key, {
        value,
        timestamp,
        tombstone: true
      });
    }
  }

  merge(other: LWWSetCRDT<T>): LWWSetCRDT<T> {
    const merged = new LWWSetCRDT<T>();

    // Merge this elements
    for (const [key, element] of this.elements) {
      merged.elements.set(key, element);
    }

    // Merge other elements (keeping latest)
    for (const [key, otherElement] of other.elements) {
      const existing = merged.elements.get(key);

      if (!existing || otherElement.timestamp > existing.timestamp) {
        merged.elements.set(key, otherElement);
      }
    }

    return merged;
  }

  values(): T[] {
    const result: T[] = [];

    for (const element of this.elements.values()) {
      if (!element.tombstone) {
        result.push(element.value);
      }
    }

    return result;
  }

  private hash(value: T): string {
    return JSON.stringify(value);
  }
}
```

**Application pratique : Synchronisation tags**

```typescript
// Exemple : Tags utilisateur synchronisÃ©s SQL â†” MongoDB
class UserTagsSyncService {
  private sqlTags: LWWSetCRDT<string>;
  private mongoTags: LWWSetCRDT<string>;

  async syncTags(userId: string): Promise<void> {
    // RÃ©cupÃ©rer tags SQL
    const sqlTagsData = await this.fetchSQLTags(userId);
    this.sqlTags = this.buildLWWSet(sqlTagsData);

    // RÃ©cupÃ©rer tags MongoDB
    const mongoTagsData = await this.fetchMongoTags(userId);
    this.mongoTags = this.buildLWWSet(mongoTagsData);

    // Merge automatique (pas de conflit !)
    const mergedTags = this.sqlTags.merge(this.mongoTags);

    // Ã‰crire rÃ©sultat dans les deux systÃ¨mes
    await Promise.all([
      this.writeSQLTags(userId, mergedTags.values()),
      this.writeMongoTags(userId, mergedTags.values())
    ]);
  }
}
```

**Avantages**
- âœ… Convergence automatique garantie
- âœ… Pas de rÃ©solution de conflit nÃ©cessaire
- âœ… Performance Ã©levÃ©e

**InconvÃ©nients**
- âŒ Types limitÃ©s (compteurs, sets, registres)
- âŒ Overhead mÃ©moire (mÃ©tadonnÃ©es)
- âŒ Pas applicable Ã  toutes les donnÃ©es

**Quand utiliser ?**
- Compteurs distribuÃ©s (vues, likes)
- Sets collaboratifs (tags, labels)
- DonnÃ©es oÃ¹ merge mathÃ©matique possible

---

## ğŸ”„ Architectures de Synchronisation Bidirectionnelle

### Architecture 1 : Event-Driven avec Kafka

**Principe**
Chaque systÃ¨me publie ses changements dans Kafka. Un orchestrateur rÃ©concilie et propage.

**Architecture complÃ¨te**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Event-Driven Bidirectional Sync Architecture        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  [Application] â”€â”€writesâ”€â”€â–¶ [PostgreSQL]                     â”‚
â”‚                                  â”‚                          â”‚
â”‚                                  â”‚ CDC (Debezium)           â”‚
â”‚                                  â†“                          â”‚
â”‚                          [Kafka Topic: sql_changes]         â”‚
â”‚                                  â†“                          â”‚
â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚                          â”‚ Reconciliation â”‚                 â”‚
â”‚                          â”‚  Orchestrator  â”‚                 â”‚
â”‚                          â”‚                â”‚                 â”‚
â”‚  [MongoDB] â”€â”€changesâ”€â”€â”€â–¶ â”‚  â€¢ Detect      â”‚                 â”‚
â”‚      â†‘                   â”‚    conflicts   â”‚                 â”‚
â”‚      â”‚                   â”‚  â€¢ Resolve     â”‚                 â”‚
â”‚      â”‚                   â”‚  â€¢ Propagate   â”‚                 â”‚
â”‚      â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚      â”‚                           â”‚                          â”‚
â”‚      â”‚                           â†“                          â”‚
â”‚      â”‚                   [Kafka Topic: mongo_changes]       â”‚
â”‚      â”‚                           â”‚                          â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                    (bidirectional sync)                     â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Conflict Resolution Store (MongoDB)                   â”‚ â”‚
â”‚  â”‚  â€¢ Conflict log                                        â”‚ â”‚
â”‚  â”‚  â€¢ Resolution history                                  â”‚ â”‚
â”‚  â”‚  â€¢ Metrics & analytics                                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ImplÃ©mentation Orchestrateur**

```typescript
// reconciliation-orchestrator.ts
import { Kafka, Consumer, Producer } from 'kafkajs';
import { MongoClient } from 'mongodb';
import { Client as PgClient } from 'pg';

interface ChangeEvent {
  source: 'sql' | 'mongodb';
  operation: 'insert' | 'update' | 'delete';
  table: string;
  key: any;
  before?: any;
  after?: any;
  timestamp: Date;
  version?: number;
}

interface ConflictResolution {
  conflictId: string;
  sqlEvent: ChangeEvent;
  mongoEvent: ChangeEvent;
  resolution: 'sql_wins' | 'mongo_wins' | 'merged';
  resolvedData: any;
  resolvedAt: Date;
  strategy: string;
}

class ReconciliationOrchestrator {
  private kafka: Kafka;
  private sqlConsumer: Consumer;
  private mongoConsumer: Consumer;
  private producer: Producer;
  private mongoClient: MongoClient;
  private pgClient: PgClient;

  // Buffer des Ã©vÃ©nements rÃ©cents pour dÃ©tection conflits
  private eventBuffer: Map<string, ChangeEvent[]>;
  private conflictWindow: number = 5000;  // 5 secondes

  async start(): Promise<void> {
    // Setup Kafka
    this.kafka = new Kafka({
      brokers: ['kafka1:9092', 'kafka2:9092', 'kafka3:9092']
    });

    this.sqlConsumer = this.kafka.consumer({ groupId: 'sql-sync' });
    this.mongoConsumer = this.kafka.consumer({ groupId: 'mongo-sync' });
    this.producer = this.kafka.producer();

    await this.sqlConsumer.connect();
    await this.mongoConsumer.connect();
    await this.producer.connect();

    // Subscribe topics
    await this.sqlConsumer.subscribe({ topic: 'sql_changes' });
    await this.mongoConsumer.subscribe({ topic: 'mongo_changes' });

    // Setup databases
    this.mongoClient = new MongoClient(process.env.MONGODB_URI);
    await this.mongoClient.connect();

    this.pgClient = new PgClient(/* config */);
    await this.pgClient.connect();

    // Start consuming
    this.eventBuffer = new Map();

    await Promise.all([
      this.consumeSQLChanges(),
      this.consumeMongoChanges()
    ]);
  }

  private async consumeSQLChanges(): Promise<void> {
    await this.sqlConsumer.run({
      eachMessage: async ({ message }) => {
        const event: ChangeEvent = JSON.parse(message.value.toString());
        event.source = 'sql';

        await this.processEvent(event);
      }
    });
  }

  private async consumeMongoChanges(): Promise<void> {
    await this.mongoConsumer.run({
      eachMessage: async ({ message }) => {
        const event: ChangeEvent = JSON.parse(message.value.toString());
        event.source = 'mongodb';

        await this.processEvent(event);
      }
    });
  }

  private async processEvent(event: ChangeEvent): Promise<void> {
    const eventKey = this.getEventKey(event);

    // Ajouter Ã  buffer
    if (!this.eventBuffer.has(eventKey)) {
      this.eventBuffer.set(eventKey, []);
    }
    this.eventBuffer.get(eventKey).push(event);

    // Nettoyer buffer ancien
    this.cleanBuffer(eventKey);

    // DÃ©tecter conflits
    const conflictingEvents = this.detectConflicts(eventKey);

    if (conflictingEvents.length > 1) {
      // Conflit dÃ©tectÃ© !
      await this.resolveConflict(conflictingEvents);
    } else {
      // Pas de conflit â†’ propager
      await this.propagateEvent(event);
    }
  }

  private detectConflicts(eventKey: string): ChangeEvent[] {
    const events = this.eventBuffer.get(eventKey) || [];

    // Grouper par source
    const sqlEvents = events.filter(e => e.source === 'sql');
    const mongoEvents = events.filter(e => e.source === 'mongodb');

    // Conflit si Ã©vÃ©nements des deux sources dans la fenÃªtre
    if (sqlEvents.length > 0 && mongoEvents.length > 0) {
      const latestSql = sqlEvents[sqlEvents.length - 1];
      const latestMongo = mongoEvents[mongoEvents.length - 1];

      // VÃ©rifier si vraiment concurrent (pas causal)
      const timeDiff = Math.abs(
        latestSql.timestamp.getTime() - latestMongo.timestamp.getTime()
      );

      if (timeDiff < this.conflictWindow) {
        return [latestSql, latestMongo];
      }
    }

    return events.slice(-1);  // Pas de conflit, retourner le dernier
  }

  private async resolveConflict(events: ChangeEvent[]): Promise<void> {
    const [sqlEvent, mongoEvent] = events;

    console.log('Conflict detected:', {
      key: this.getEventKey(sqlEvent),
      sqlTimestamp: sqlEvent.timestamp,
      mongoTimestamp: mongoEvent.timestamp
    });

    // Appliquer stratÃ©gie de rÃ©solution
    const resolution = await this.applyResolutionStrategy(sqlEvent, mongoEvent);

    // Logger conflit
    await this.logConflict(resolution);

    // Propager rÃ©solution
    await this.propagateResolution(resolution);

    // MÃ©triques
    this.recordConflictMetric(resolution);
  }

  private async applyResolutionStrategy(
    sqlEvent: ChangeEvent,
    mongoEvent: ChangeEvent
  ): Promise<ConflictResolution> {

    const strategy = this.getStrategyForTable(sqlEvent.table);

    switch (strategy) {
      case 'lww':
        return this.resolveLWW(sqlEvent, mongoEvent);

      case 'version_vector':
        return this.resolveVersionVector(sqlEvent, mongoEvent);

      case 'merge':
        return this.resolveMerge(sqlEvent, mongoEvent);

      case 'manual':
        return this.queueForManualResolution(sqlEvent, mongoEvent);

      default:
        return this.resolveLWW(sqlEvent, mongoEvent);
    }
  }

  private resolveLWW(
    sqlEvent: ChangeEvent,
    mongoEvent: ChangeEvent
  ): ConflictResolution {

    const sqlWins = sqlEvent.timestamp > mongoEvent.timestamp;

    return {
      conflictId: this.generateConflictId(),
      sqlEvent,
      mongoEvent,
      resolution: sqlWins ? 'sql_wins' : 'mongo_wins',
      resolvedData: sqlWins ? sqlEvent.after : mongoEvent.after,
      resolvedAt: new Date(),
      strategy: 'lww'
    };
  }

  private async resolveMerge(
    sqlEvent: ChangeEvent,
    mongoEvent: ChangeEvent
  ): Promise<ConflictResolution> {

    // Merge champ par champ
    const merged = {
      ...sqlEvent.after,
      ...mongoEvent.after
    };

    // Appliquer rÃ¨gles mÃ©tier spÃ©cifiques
    merged.name = mongoEvent.after?.name || sqlEvent.after?.name;
    merged.email = sqlEvent.after?.email || mongoEvent.after?.email;
    merged.updated_at = new Date();

    return {
      conflictId: this.generateConflictId(),
      sqlEvent,
      mongoEvent,
      resolution: 'merged',
      resolvedData: merged,
      resolvedAt: new Date(),
      strategy: 'merge'
    };
  }

  private async propagateResolution(resolution: ConflictResolution): Promise<void> {
    // Ã‰crire dans SQL
    if (resolution.resolution !== 'sql_wins') {
      await this.writeSQLWithRetry(
        resolution.sqlEvent.table,
        resolution.sqlEvent.key,
        resolution.resolvedData
      );
    }

    // Ã‰crire dans MongoDB
    if (resolution.resolution !== 'mongo_wins') {
      await this.writeMongoWithRetry(
        resolution.mongoEvent.table,
        resolution.mongoEvent.key,
        resolution.resolvedData
      );
    }
  }

  private async propagateEvent(event: ChangeEvent): Promise<void> {
    // Propager vers l'autre systÃ¨me
    if (event.source === 'sql') {
      await this.writeMongoWithRetry(event.table, event.key, event.after);
    } else {
      await this.writeSQLWithRetry(event.table, event.key, event.after);
    }
  }

  private async logConflict(resolution: ConflictResolution): Promise<void> {
    await this.mongoClient
      .db('sync_metadata')
      .collection('conflicts')
      .insertOne({
        ...resolution,
        created_at: new Date()
      });
  }

  private getEventKey(event: ChangeEvent): string {
    return `${event.table}:${JSON.stringify(event.key)}`;
  }

  private cleanBuffer(eventKey: string): void {
    const events = this.eventBuffer.get(eventKey) || [];
    const now = Date.now();

    const filtered = events.filter(
      e => now - e.timestamp.getTime() < this.conflictWindow * 2
    );

    this.eventBuffer.set(eventKey, filtered);
  }

  private getStrategyForTable(table: string): string {
    const strategies: Record<string, string> = {
      'users': 'merge',
      'orders': 'lww',
      'products': 'version_vector',
      'settings': 'manual'
    };

    return strategies[table] || 'lww';
  }

  private generateConflictId(): string {
    return `conflict_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
  }

  private async writeSQLWithRetry(table: string, key: any, data: any): Promise<void> {
    // ImplÃ©mentation avec retry logic
  }

  private async writeMongoWithRetry(collection: string, key: any, data: any): Promise<void> {
    // ImplÃ©mentation avec retry logic
  }
}
```

**Monitoring des conflits**

```typescript
// conflict-dashboard.ts
interface ConflictMetrics {
  totalConflicts: number;
  conflictsLast24h: number;
  conflictsByTable: Record<string, number>;
  resolutionStrategies: Record<string, number>;
  avgResolutionTime: number;
  pendingManualResolutions: number;
}

class ConflictMonitor {
  async getMetrics(timeRange: string = '24h'): Promise<ConflictMetrics> {
    const db = this.mongoClient.db('sync_metadata');

    const startTime = this.getStartTime(timeRange);

    const conflicts = await db
      .collection('conflicts')
      .find({ created_at: { $gte: startTime } })
      .toArray();

    const totalConflicts = conflicts.length;

    // Group by table
    const conflictsByTable: Record<string, number> = {};
    for (const conflict of conflicts) {
      const table = conflict.sqlEvent.table;
      conflictsByTable[table] = (conflictsByTable[table] || 0) + 1;
    }

    // Group by resolution strategy
    const resolutionStrategies: Record<string, number> = {};
    for (const conflict of conflicts) {
      const strategy = conflict.strategy;
      resolutionStrategies[strategy] = (resolutionStrategies[strategy] || 0) + 1;
    }

    // Average resolution time
    const resolutionTimes = conflicts.map(c =>
      c.resolvedAt.getTime() - c.created_at.getTime()
    );
    const avgResolutionTime = resolutionTimes.reduce((a, b) => a + b, 0) / resolutionTimes.length;

    // Pending manual resolutions
    const pendingManual = await db
      .collection('conflicts')
      .countDocuments({
        strategy: 'manual',
        resolved: false
      });

    return {
      totalConflicts,
      conflictsLast24h: totalConflicts,
      conflictsByTable,
      resolutionStrategies,
      avgResolutionTime,
      pendingManualResolutions: pendingManual
    };
  }
}
```

---

## ğŸ“Š ScÃ©nario RÃ©el : E-commerce Global (Sync Bidirectionnelle 9 mois)

**Contexte**
- E-commerce international, 50M produits
- SystÃ¨me legacy : Oracle 19c (5 To)
- Cible : MongoDB Atlas (multi-rÃ©gion)
- Contrainte : Zero downtime, sync bidirectionnelle pendant migration (6 mois)
- Ã‰quipe : 12 devs, 3 DBAs, 2 architectes

### Architecture implÃ©mentÃ©e

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Production Architecture                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  [Web App] â”€â”€â”¬â”€â”€â–¶ [API Gateway (Kong)]                      â”‚
â”‚              â”‚         â”‚                                    â”‚
â”‚              â”‚         â”œâ”€â”€â–¶ [Products Service]              â”‚
â”‚              â”‚         â”‚      â†“                             â”‚
â”‚              â”‚         â”‚   [Oracle] (writes)                â”‚
â”‚              â”‚         â”‚      â†“                             â”‚
â”‚              â”‚         â”‚   [Debezium CDC]                   â”‚
â”‚              â”‚         â”‚      â†“                             â”‚
â”‚              â”‚         â”‚   [Kafka Cluster]                  â”‚
â”‚              â”‚         â”‚      â†“                             â”‚
â”‚              â”‚         â”‚   [Reconciliation Orchestrator]    â”‚
â”‚              â”‚         â”‚      â†“                             â”‚
â”‚              â”‚         â”‚   [MongoDB Atlas]                  â”‚
â”‚              â”‚         â”‚      â†‘                             â”‚
â”‚              â”‚         â”‚   [Change Streams]                 â”‚
â”‚              â”‚         â”‚      â†‘                             â”‚
â”‚              â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚              â”‚                                              â”‚
â”‚              â””â”€â”€â–¶ [Search Service]                          â”‚
â”‚                         â†“                                   â”‚
â”‚                      [MongoDB Atlas] (reads)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Timeline

**Mois 1-2 : Setup Infrastructure**
- Kafka cluster (9 brokers, 3 AZs)
- Debezium Oracle connector
- MongoDB Atlas M80 clusters (3 rÃ©gions)
- Reconciliation orchestrator (custom)

**Mois 3-4 : Migration Initiale + CDC**
- Snapshot 50M produits â†’ MongoDB (72h)
- Activation CDC Oracle â†’ Kafka â†’ MongoDB
- Validation : 100% donnÃ©es synchronisÃ©es
- Lag CDC : < 500ms P95

**Mois 5-6 : Phase Dual-Read**
- API Gateway route 10% reads â†’ MongoDB
- Comparaison automatisÃ©e (1M queries/jour)
- DÃ©tection divergences : 0.02% (fixÃ©es)
- Performance MongoDB : +45% vs Oracle

**Mois 7 : Bascule Reads 100% MongoDB**
- Rollout progressif : 10% â†’ 50% â†’ 100%
- Oracle devient read-only (fallback uniquement)
- Monitoring intensif

**Mois 8 : Phase Dual-Write Bidirectionnelle**
- Writes vont vers Oracle ET MongoDB
- Sync bidirectionnelle active
- Conflits dÃ©tectÃ©s : 234 en 1 mois
  - LWW : 180 (77%)
  - Merge : 45 (19%)
  - Manual : 9 (4%)

**Mois 9 : MongoDB devient Primary**
- ArrÃªt dual-write
- MongoDB = source de vÃ©ritÃ©
- Oracle = archive (6 mois retention)

### RÃ©sultats

**Performance**
- Latence lecture : 180ms â†’ 45ms (P95)
- Throughput : 8K â†’ 25K req/sec
- Query complexes : 5s â†’ 800ms

**FiabilitÃ©**
- Uptime : 99.98% (objectif 99.95%)
- Zero data loss
- 234 conflits automatiquement rÃ©solus
- 9 rÃ©solutions manuelles (< 24h chacune)

**Business**
- Recherche produits 5x plus rapide
- Support multi-rÃ©gion natif
- CoÃ»ts infra : -35%

### Challenges et Solutions

**Challenge 1 : CDC lag spikes Oracle**
- **SymptÃ´me** : Lag monte Ã  30 secondes lors des imports bulk (nuit)
- **Cause** : Bulk updates gÃ©nÃ¨rent des millions d'events
- **Solution** :
  - Batch processing avec throttling
  - Augmentation partitions Kafka (12 â†’ 24)
  - Buffer size optimisÃ©

**Challenge 2 : Conflits sur prix produits**
- **SymptÃ´me** : 120 conflits/jour sur champ `price`
- **Cause** : Mise Ã  jour manuelle Oracle + automatique MongoDB (algorithmes pricing)
- **Solution** :
  - Oracle = source vÃ©ritÃ© pour prix manuels
  - MongoDB = source pour prix calculÃ©s
  - Flag `price_source` pour arbitrage

**Challenge 3 : Performance MongoDB dÃ©gradÃ©e (1 query)**
- **SymptÃ´me** : Query "products by category" 10x plus lente MongoDB
- **Cause** : $lookup sur 3 collections (over-normalisÃ©)
- **Solution** : Refactoring modÃ¨le avec embedded categories

**Challenge 4 : Divergence images produits**
- **SymptÃ´me** : 0.5% divergence URLs images
- **Cause** : Race condition dual-write + CDN cache
- **Solution** :
  - Versioning URLs images
  - Cache invalidation synchronisÃ©e
  - Reconciliation asynchrone

---

## ğŸ¯ Bonnes Pratiques

### 1. Choisir la bonne stratÃ©gie de rÃ©solution

```typescript
// DÃ©cision tree pour stratÃ©gie de rÃ©solution
function chooseResolutionStrategy(
  dataType: string,
  conflictRate: number,
  criticalityLevel: 'low' | 'medium' | 'high'
): string {

  // DonnÃ©es critiques â†’ Manual review
  if (criticalityLevel === 'high' && conflictRate > 0.001) {
    return 'manual';
  }

  // Texte collaboratif â†’ OT/CRDT
  if (dataType === 'text' || dataType === 'document') {
    return 'ot';
  }

  // Compteurs, sets â†’ CRDT
  if (dataType === 'counter' || dataType === 'set') {
    return 'crdt';
  }

  // DonnÃ©es avec sÃ©mantique mÃ©tier forte â†’ Merge
  if (dataType === 'user_profile' || dataType === 'settings') {
    return 'merge';
  }

  // DÃ©faut â†’ LWW
  return 'lww';
}
```

### 2. Monitoring exhaustif

```typescript
// MÃ©triques essentielles Ã  surveiller
interface SyncMetrics {
  // Performance
  syncLatency: {
    p50: number;
    p95: number;
    p99: number;
  };
  throughput: number;

  // QualitÃ©
  conflictRate: number;
  divergenceRate: number;
  autoResolutionRate: number;
  manualResolutionPending: number;

  // FiabilitÃ©
  errorRate: number;
  retryRate: number;
  dlqMessages: number;

  // Lag
  cdcLag: number;
  kafkaLag: number;
  replicationLag: number;
}

// Alertes critiques
const ALERT_THRESHOLDS = {
  conflictRate: 0.01,       // > 1%
  divergenceRate: 0.001,    // > 0.1%
  syncLatency: 5000,        // > 5s
  cdcLag: 60000,           // > 1 minute
  errorRate: 0.05          // > 5%
};
```

### 3. Testing de synchronisation

```typescript
// Test de synchronisation bidirectionnelle
describe('Bidirectional Sync', () => {

  test('should handle concurrent updates', async () => {
    const userId = 'test_user_123';

    // Write concurrently to both systems
    await Promise.all([
      sqlClient.query(
        'UPDATE users SET name = $1 WHERE id = $2',
        ['Alice SQL', userId]
      ),
      mongoDb.collection('users').updateOne(
        { _id: userId },
        { $set: { name: 'Alice Mongo' } }
      )
    ]);

    // Wait for sync
    await sleep(5000);

    // Both should converge to same value
    const sqlUser = await sqlClient.query(
      'SELECT * FROM users WHERE id = $1',
      [userId]
    );
    const mongoUser = await mongoDb.collection('users').findOne({
      _id: userId
    });

    expect(sqlUser.name).toBe(mongoUser.name);
  });

  test('should handle delete-update conflict', async () => {
    const userId = 'test_user_456';

    // Delete in SQL, Update in MongoDB
    await Promise.all([
      sqlClient.query('DELETE FROM users WHERE id = $1', [userId]),
      mongoDb.collection('users').updateOne(
        { _id: userId },
        { $set: { age: 30 } }
      )
    ]);

    await sleep(5000);

    // Verify resolution (delete should win)
    const sqlExists = await sqlClient.query(
      'SELECT COUNT(*) FROM users WHERE id = $1',
      [userId]
    );
    const mongoExists = await mongoDb.collection('users').countDocuments({
      _id: userId
    });

    expect(sqlExists.count).toBe(0);
    expect(mongoExists).toBe(0);
  });
});
```

### 4. Plan de rollback

```yaml
# Rollback plan par niveau de criticitÃ©

level_1_minor_divergence:
  trigger: divergence_rate < 0.1%
  action:
    - Continue sync
    - Monitor closely
    - Log for analysis

level_2_moderate_divergence:
  trigger: divergence_rate 0.1% - 1%
  action:
    - Alert on-call
    - Increase reconciliation frequency
    - Manual review of divergent records

level_3_major_divergence:
  trigger: divergence_rate > 1%
  action:
    - Pause sync
    - Full reconciliation
    - Root cause analysis
    - Resume after fix

level_4_critical_failure:
  trigger: sync completely broken
  action:
    - Immediate rollback to single source
    - Activate fallback (SQL or MongoDB)
    - Emergency fix
    - Phased restart
```

---

## ğŸ“š Checklist Synchronisation Bidirectionnelle

**Avant de commencer**
- [ ] Architecture de rÃ©solution de conflits dÃ©finie
- [ ] StratÃ©gies par type de donnÃ©es documentÃ©es
- [ ] Infrastructure Kafka provisionnÃ©e
- [ ] Monitoring et alerting configurÃ©s
- [ ] Plan de rollback testÃ©
- [ ] Ã‰quipe formÃ©e sur rÃ©solution conflits

**Pendant la synchronisation**
- [ ] Lag CDC < 1 seconde (P95)
- [ ] Taux de conflits < 1%
- [ ] Taux de divergence < 0.1%
- [ ] Taux de rÃ©solution auto > 95%
- [ ] RÃ©solutions manuelles < 24h
- [ ] Monitoring temps rÃ©el actif

**Validation continue**
- [ ] Comparaison automatisÃ©e quotidienne
- [ ] Tests fonctionnels end-to-end
- [ ] Audit des conflits rÃ©solus
- [ ] Performance acceptable (latence, throughput)
- [ ] Aucune perte de donnÃ©es dÃ©tectÃ©e

**Post-synchronisation**
- [ ] Analyse des conflits (patterns, causes)
- [ ] Documentation des cas edge
- [ ] Optimisation stratÃ©gies rÃ©solution
- [ ] Formation Ã©quipe sur leÃ§ons apprises
- [ ] Post-mortem et amÃ©lioration continue

---

## ğŸ“ Conclusion

La synchronisation bidirectionnelle est **complexe** mais **nÃ©cessaire** pour les migrations zero-downtime de systÃ¨mes critiques. Les points clÃ©s :

**Choix de la stratÃ©gie**
- LWW : Simple, perte de donnÃ©es possible
- Version Vector : DÃ©tection prÃ©cise, merge complexe
- OT : IdÃ©al pour texte collaboratif
- CRDT : Convergence automatique, types limitÃ©s

**Architecture**
- Event-driven avec Kafka recommandÃ©
- Orchestrateur centralisÃ© pour rÃ©conciliation
- Monitoring exhaustif essentiel

**Gestion des conflits**
- 95%+ rÃ©solution automatique possible
- Plan pour rÃ©solutions manuelles nÃ©cessaire
- Tests exhaustifs critiques

**RÃ©alisme**
- PrÃ©voir 6-12 mois pour production
- Budget consÃ©quent (infrastructure double)
- Expertise distribuÃ©e requise

La synchronisation bidirectionnelle n'est pas une solution long-terme mais une **phase transitoire** vers MongoDB. Objectif : Converger vers source unique dÃ¨s que possible.

---

**Prochaine section** : 19.6 MongoDB Connector for BI - IntÃ©gration de MongoDB avec outils BI traditionnels.

â­ï¸ [MongoDB Connector for BI](/19-migration-integration/06-mongodb-connector-bi.md)
