üîù Retour au [Sommaire](/SOMMAIRE.md)

# 16.1 Change Streams

## Introduction

Les **Change Streams** constituent l'une des fonctionnalit√©s les plus puissantes de MongoDB pour construire des architectures modernes r√©actives et √©v√©nementielles. Introduits dans MongoDB 3.6, les Change Streams permettent aux applications d'√©couter en temps r√©el les modifications (insertions, mises √† jour, suppressions) effectu√©es sur les collections, bases de donn√©es ou m√™me l'ensemble d'un cluster.

Cette capacit√© transforme MongoDB d'une base de donn√©es traditionnelle en une source d'√©v√©nements distribu√©e, ouvrant la voie √† des patterns architecturaux comme Event Sourcing, CQRS, et Event-Driven Architecture.

---

## Qu'est-ce qu'un Change Stream ?

Un Change Stream est un **flux de notifications push** qui diffuse les √©v√©nements de modification de donn√©es en temps quasi-r√©el. Contrairement au polling traditionnel (interrogation p√©riodique de la base), les Change Streams utilisent une approche r√©active o√π MongoDB pousse activement les changements vers les clients abonn√©s.

### Architecture conceptuelle

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    MongoDB Replica Set                      ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îÇ
‚îÇ  ‚îÇ   Primary    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ    Oplog     ‚îÇ                  ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ  writes ‚îÇ (Operations  ‚îÇ                  ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ         ‚îÇ    Log)      ‚îÇ                  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îÇ
‚îÇ                                   ‚îÇ                         ‚îÇ
‚îÇ                                   ‚îÇ Tail & Transform        ‚îÇ
‚îÇ                                   ‚ñº                         ‚îÇ
‚îÇ                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ
‚îÇ                          ‚îÇ Change Streams ‚îÇ                 ‚îÇ
‚îÇ                          ‚îÇ    Engine      ‚îÇ                 ‚îÇ
‚îÇ                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                                    ‚îÇ Push Events
                                    ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   Subscribed Applications     ‚îÇ
                    ‚îÇ                               ‚îÇ
                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
                    ‚îÇ  ‚îÇ  App 1  ‚îÇ  ‚îÇ  App 2  ‚îÇ     ‚îÇ
                    ‚îÇ  ‚îÇ(Node.js)‚îÇ  ‚îÇ(Python) ‚îÇ     ‚îÇ
                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Flux de donn√©es :**
1. Les op√©rations d'√©criture sont enregistr√©es dans l'**Oplog** (Operations Log)
2. Le moteur Change Streams **surveille** l'Oplog en continu
3. Les √©v√©nements sont **transform√©s** en documents normalis√©s
4. Les √©v√©nements sont **pouss√©s** vers les clients abonn√©s
5. Les clients **r√©agissent** aux changements en temps r√©el

---

## Caract√©ristiques fondamentales

### 1. Temps r√©el avec latence minimale

Les Change Streams offrent une latence typique de **50-200 millisecondes** entre l'√©criture et la notification, selon la charge du syst√®me et la configuration r√©seau.

```javascript
// Exemple de latence mesur√©e
const startTime = Date.now();

// Insertion
await collection.insertOne({ status: "pending", timestamp: new Date() });

// Notification re√ßue dans le Change Stream
changeStream.on('change', (change) => {
  const latency = Date.now() - change.fullDocument.timestamp.getTime();
  console.log(`Latency: ${latency}ms`); // Typiquement 50-200ms
});
```

### 2. Garanties de livraison

Les Change Streams garantissent :
- **Au moins une fois (at-least-once delivery)** : Chaque √©v√©nement est livr√© au moins une fois
- **Ordre total** : Les √©v√©nements sont livr√©s dans l'ordre exact des op√©rations sur l'Oplog
- **Durabilit√©** : Les √©v√©nements sont bas√©s sur l'Oplog r√©pliqu√© (pas de perte en cas de failover)

### 3. Reprise automatique (Resumability)

En cas de d√©connexion, les Change Streams peuvent reprendre exactement o√π ils s'√©taient arr√™t√©s gr√¢ce aux **resume tokens**.

```javascript
let resumeToken;

const changeStream = collection.watch();

changeStream.on('change', (change) => {
  // Sauvegarder le token pour reprise ult√©rieure
  resumeToken = change._id;
  processChange(change);
});

// En cas de reconnexion
const resumedStream = collection.watch([], {
  resumeAfter: resumeToken
});
```

### 4. Filtrage c√¥t√© serveur

Les Change Streams supportent des pipelines d'agr√©gation pour filtrer les √©v√©nements directement sur le serveur, r√©duisant la bande passante et la charge client.

```javascript
// Filtrer uniquement les insertions de commandes > 1000‚Ç¨
const pipeline = [
  {
    $match: {
      operationType: 'insert',
      'fullDocument.amount': { $gt: 1000 }
    }
  }
];

const changeStream = collection.watch(pipeline);
```

---

## Types d'√©v√©nements

Un Change Stream peut √©mettre plusieurs types d'√©v√©nements, chacun correspondant √† une op√©ration diff√©rente :

| Type d'√©v√©nement | Description | Disponibilit√© |
|------------------|-------------|---------------|
| `insert` | Nouveau document ins√©r√© | Toujours |
| `update` | Document modifi√© | Toujours |
| `replace` | Document remplac√© enti√®rement | Toujours |
| `delete` | Document supprim√© | Toujours |
| `drop` | Collection supprim√©e | Toujours |
| `rename` | Collection renomm√©e | Toujours |
| `dropDatabase` | Base de donn√©es supprim√©e | Toujours |
| `invalidate` | Stream invalid√© (ex: collection dropp√©e) | Toujours |

### Structure d'un √©v√©nement Change Stream

```javascript
{
  _id: {
    // Resume token (opaque, utilis√© pour reprise)
    _data: "8264F3A123000000012B022C0100296E5A1004..."
  },
  operationType: "insert",
  clusterTime: Timestamp(1, 1643723456),
  wallTime: ISODate("2024-02-01T14:30:56.123Z"),
  fullDocument: {
    _id: ObjectId("6472a5b3c8f9e2d45a1b3c4d"),
    orderId: "ORD-2024-001",
    customerId: "CUST-5678",
    amount: 1250.00,
    status: "pending",
    items: [/* ... */]
  },
  ns: {
    db: "ecommerce",
    coll: "orders"
  },
  documentKey: {
    _id: ObjectId("6472a5b3c8f9e2d45a1b3c4d")
  }
}
```

**Champs cl√©s :**
- `_id` : Token de reprise unique pour cet √©v√©nement
- `operationType` : Type d'op√©ration (insert, update, delete, etc.)
- `clusterTime` : Timestamp Oplog (ordre global)
- `wallTime` : Horodatage r√©el (wall-clock time)
- `fullDocument` : Document complet (selon configuration)
- `ns` : Namespace (base de donn√©es + collection)
- `documentKey` : Identifiant du document concern√©

---

## Niveaux de granularit√©

Les Change Streams peuvent √™tre ouverts √† trois niveaux diff√©rents :

### 1. Collection unique

```javascript
// Surveiller une collection sp√©cifique
const changeStream = db.collection('orders').watch();

changeStream.on('change', (change) => {
  console.log('Changement dans orders:', change.operationType);
});
```

**Cas d'usage :** Synchronisation cache, invalidation, notifications m√©tier sp√©cifiques

### 2. Base de donn√©es compl√®te

```javascript
// Surveiller toutes les collections d'une base
const changeStream = db.watch();

changeStream.on('change', (change) => {
  console.log(`Changement dans ${change.ns.coll}:`, change.operationType);
});
```

**Cas d'usage :** Audit global, r√©plication vers data warehouse, CDC complet

### 3. Cluster entier (deployment)

```javascript
// Surveiller toutes les bases de donn√©es du cluster
const changeStream = client.watch();

changeStream.on('change', (change) => {
  console.log(`Changement dans ${change.ns.db}.${change.ns.coll}`);
});
```

**Cas d'usage :** Monitoring centralis√©, r√©plication multi-tenant, observabilit√©

---

## Exemple complet : Syst√®me de notification en temps r√©el

Voici un exemple d'impl√©mentation production-ready d'un syst√®me de notification bas√© sur Change Streams :

```javascript
const { MongoClient } = require('mongodb');
const WebSocket = require('ws');

class RealtimeNotificationService {
  constructor(mongoUri, wsPort = 8080) {
    this.mongoUri = mongoUri;
    this.wsPort = wsPort;
    this.wss = null;
    this.changeStream = null;
    this.resumeToken = null;
  }

  async start() {
    // Connexion MongoDB
    this.client = await MongoClient.connect(this.mongoUri, {
      useUnifiedTopology: true,
      retryWrites: true
    });

    const db = this.client.db('myapp');
    const collection = db.collection('notifications');

    // Configuration du Change Stream avec pipeline
    const pipeline = [
      {
        $match: {
          operationType: 'insert',
          'fullDocument.read': false  // Seulement notifications non lues
        }
      },
      {
        $project: {
          _id: 1,
          operationType: 1,
          fullDocument: 1,
          'fullDocument.userId': 1,
          'fullDocument.type': 1,
          'fullDocument.message': 1,
          'fullDocument.timestamp': 1
        }
      }
    ];

    // D√©marrer le Change Stream
    this.changeStream = collection.watch(pipeline, {
      fullDocument: 'updateLookup',
      resumeAfter: this.resumeToken  // Reprise si disponible
    });

    // Gestion des √©v√©nements
    this.changeStream.on('change', (change) => {
      this.handleChange(change);
    });

    this.changeStream.on('error', (error) => {
      console.error('Change Stream error:', error);
      this.reconnect();
    });

    // Serveur WebSocket
    this.wss = new WebSocket.Server({ port: this.wsPort });

    this.wss.on('connection', (ws, req) => {
      console.log('Client WebSocket connect√©');

      // Authentification du client (userId depuis token JWT)
      const userId = this.authenticateClient(req);
      ws.userId = userId;

      ws.on('close', () => {
        console.log(`Client ${userId} d√©connect√©`);
      });
    });

    console.log(`Service d√©marr√© sur port ${this.wsPort}`);
  }

  handleChange(change) {
    // Sauvegarder le resume token
    this.resumeToken = change._id;

    const notification = change.fullDocument;
    const userId = notification.userId;

    // Diffuser vers le client WebSocket appropri√©
    this.wss.clients.forEach((client) => {
      if (client.userId === userId && client.readyState === WebSocket.OPEN) {
        client.send(JSON.stringify({
          type: 'notification',
          data: {
            id: notification._id,
            type: notification.type,
            message: notification.message,
            timestamp: notification.timestamp
          }
        }));
      }
    });

    // Logging pour analytics
    console.log(`Notification envoy√©e √† user ${userId}: ${notification.type}`);
  }

  authenticateClient(req) {
    // Extraction et validation du JWT (simplifi√©)
    const token = req.headers['sec-websocket-protocol'];
    // Validation r√©elle ici...
    return 'user123'; // ID extrait du token
  }

  async reconnect() {
    console.log('Reconnexion au Change Stream...');

    // Attendre avant de reconnecter
    await new Promise(resolve => setTimeout(resolve, 5000));

    // Fermer proprement
    if (this.changeStream) {
      await this.changeStream.close();
    }

    // Red√©marrer avec resume token
    await this.start();
  }

  async stop() {
    if (this.changeStream) {
      await this.changeStream.close();
    }
    if (this.client) {
      await this.client.close();
    }
    if (this.wss) {
      this.wss.close();
    }
  }
}

// Utilisation
const service = new RealtimeNotificationService(
  'mongodb://localhost:27017/?replicaSet=rs0'
);

service.start().catch(console.error);

// Gestion propre de l'arr√™t
process.on('SIGINT', async () => {
  console.log('Arr√™t du service...');
  await service.stop();
  process.exit(0);
});
```

### C√¥t√© client (JavaScript)

```javascript
// Connexion WebSocket c√¥t√© frontend
class NotificationClient {
  constructor(wsUrl, jwtToken) {
    this.wsUrl = wsUrl;
    this.jwtToken = jwtToken;
    this.ws = null;
    this.reconnectDelay = 1000;
  }

  connect() {
    // Connexion avec authentification
    this.ws = new WebSocket(this.wsUrl, this.jwtToken);

    this.ws.onopen = () => {
      console.log('Connect√© au service de notifications');
      this.reconnectDelay = 1000; // Reset du d√©lai
    };

    this.ws.onmessage = (event) => {
      const message = JSON.parse(event.data);

      if (message.type === 'notification') {
        this.displayNotification(message.data);
      }
    };

    this.ws.onerror = (error) => {
      console.error('WebSocket error:', error);
    };

    this.ws.onclose = () => {
      console.log('Connexion ferm√©e, reconnexion...');
      setTimeout(() => this.connect(), this.reconnectDelay);
      this.reconnectDelay = Math.min(this.reconnectDelay * 2, 30000);
    };
  }

  displayNotification(data) {
    // Affichage de la notification (browser notification API)
    if (Notification.permission === 'granted') {
      new Notification(data.type, {
        body: data.message,
        icon: '/icon.png',
        timestamp: new Date(data.timestamp)
      });
    }

    // Mise √† jour de l'UI
    this.updateNotificationBadge();
  }

  updateNotificationBadge() {
    // Incr√©menter le compteur de notifications
    const badge = document.getElementById('notification-badge');
    const count = parseInt(badge.textContent) || 0;
    badge.textContent = count + 1;
    badge.style.display = 'block';
  }
}

// Utilisation
const client = new NotificationClient(
  'ws://localhost:8080',
  localStorage.getItem('jwt_token')
);

client.connect();
```

---

## Architecture d'entreprise avec Change Streams

### Pattern 1 : Event Bus distribu√©

```javascript
// Hub central qui redistribue les √©v√©nements
class EventBusHub {
  constructor() {
    this.subscribers = new Map();
  }

  async initialize(mongoUri) {
    this.client = await MongoClient.connect(mongoUri);
    const db = this.client.db('main');

    // Surveiller toutes les collections critiques
    const collections = ['orders', 'payments', 'inventory', 'users'];

    collections.forEach(collName => {
      const changeStream = db.collection(collName).watch();

      changeStream.on('change', (change) => {
        this.broadcast({
          source: collName,
          event: change.operationType,
          data: change.fullDocument,
          timestamp: change.wallTime
        });
      });
    });
  }

  subscribe(eventType, callback) {
    if (!this.subscribers.has(eventType)) {
      this.subscribers.set(eventType, []);
    }
    this.subscribers.get(eventType).push(callback);
  }

  broadcast(event) {
    const eventType = `${event.source}.${event.event}`;
    const handlers = this.subscribers.get(eventType) || [];

    handlers.forEach(handler => {
      try {
        handler(event);
      } catch (error) {
        console.error(`Error in handler for ${eventType}:`, error);
      }
    });
  }
}

// Services qui s'abonnent
const eventBus = new EventBusHub();
await eventBus.initialize('mongodb://localhost:27017/?replicaSet=rs0');

// Service de cache
eventBus.subscribe('orders.insert', (event) => {
  cache.set(`order:${event.data._id}`, event.data);
});

eventBus.subscribe('orders.update', (event) => {
  cache.invalidate(`order:${event.data._id}`);
});

// Service d'email
eventBus.subscribe('orders.insert', async (event) => {
  await emailService.sendOrderConfirmation(event.data);
});

// Service d'analytics
eventBus.subscribe('payments.insert', (event) => {
  analytics.track('payment_completed', {
    amount: event.data.amount,
    currency: event.data.currency
  });
});
```

### Pattern 2 : CDC (Change Data Capture) vers Data Warehouse

```javascript
// R√©plication vers Snowflake/BigQuery
class CDCPipeline {
  constructor(mongoUri, warehouseConfig) {
    this.mongoUri = mongoUri;
    this.warehouse = warehouseConfig;
    this.buffer = [];
    this.flushInterval = 5000; // 5 secondes
    this.batchSize = 1000;
  }

  async start() {
    const client = await MongoClient.connect(this.mongoUri);
    const db = client.db('production');

    // Pipeline de transformation
    const pipeline = [
      {
        $match: {
          operationType: { $in: ['insert', 'update', 'delete'] }
        }
      },
      {
        $project: {
          operation: '$operationType',
          table: '$ns.coll',
          data: '$fullDocument',
          timestamp: '$wallTime',
          key: '$documentKey._id'
        }
      }
    ];

    const changeStream = db.watch(pipeline);

    changeStream.on('change', (change) => {
      this.buffer.push(change);

      if (this.buffer.length >= this.batchSize) {
        this.flush();
      }
    });

    // Flush p√©riodique
    setInterval(() => this.flush(), this.flushInterval);
  }

  async flush() {
    if (this.buffer.length === 0) return;

    const batch = [...this.buffer];
    this.buffer = [];

    try {
      // Insertion batch vers data warehouse
      await this.warehouse.insertBatch(batch);
      console.log(`${batch.length} √©v√©nements r√©pliqu√©s vers warehouse`);
    } catch (error) {
      console.error('Erreur r√©plication:', error);
      // R√©ins√©rer dans le buffer pour retry
      this.buffer.unshift(...batch);
    }
  }
}
```

### Pattern 3 : Cache invalidation intelligente

```javascript
// Synchronisation automatique Redis <-> MongoDB
class SmartCacheSync {
  constructor(mongoUri, redisClient) {
    this.redisClient = redisClient;
    this.mongoUri = mongoUri;
  }

  async initialize() {
    const client = await MongoClient.connect(this.mongoUri);
    const db = client.db('myapp');

    // Surveiller uniquement les updates de documents mis en cache
    const pipeline = [
      {
        $match: {
          $or: [
            { operationType: 'update' },
            { operationType: 'replace' },
            { operationType: 'delete' }
          ]
        }
      }
    ];

    const changeStream = db.watch(pipeline);

    changeStream.on('change', async (change) => {
      const cacheKey = this.buildCacheKey(
        change.ns.coll,
        change.documentKey._id
      );

      if (change.operationType === 'delete') {
        // Supprimer du cache
        await this.redisClient.del(cacheKey);
        console.log(`Cache invalidated: ${cacheKey}`);
      } else {
        // Mettre √† jour le cache avec nouvelles donn√©es
        const freshData = change.fullDocument;
        await this.redisClient.setex(
          cacheKey,
          3600, // TTL 1h
          JSON.stringify(freshData)
        );
        console.log(`Cache updated: ${cacheKey}`);
      }
    });
  }

  buildCacheKey(collection, id) {
    return `${collection}:${id}`;
  }
}

// Utilisation
const redis = require('redis').createClient();
const cacheSync = new SmartCacheSync(
  'mongodb://localhost:27017/?replicaSet=rs0',
  redis
);

await cacheSync.initialize();
```

---

## Consid√©rations de performance

### Overhead et impact

Les Change Streams introduisent un overhead minimal :
- **CPU** : ~2-5% suppl√©mentaire sur le Primary
- **M√©moire** : ~10-50 Mo par stream actif
- **R√©seau** : Proportionnel au volume de changements
- **Oplog** : Aucun impact (lecture en lecture seule)

### Limites et quotas

| Param√®tre | Limite | Notes |
|-----------|--------|-------|
| Change Streams simultan√©s | 1000 par mongos | Limite soft, ajustable |
| Taille d'√©v√©nement | 16 Mo | Limite BSON |
| Dur√©e de vie resume token | Taille de l'Oplog | Variable selon config |
| Latency P50 | < 100 ms | R√©seau optimal |
| Latency P99 | < 500 ms | Charge normale |

### Optimisations recommand√©es

```javascript
// 1. Filtrer t√¥t dans le pipeline
const optimizedPipeline = [
  {
    $match: {
      operationType: 'insert',
      'fullDocument.status': 'pending'
    }
  },
  // Transformation apr√®s filtrage
  { $project: { /* ... */ } }
];

// 2. Utiliser fullDocument: 'updateLookup' uniquement si n√©cessaire
const changeStream = collection.watch(pipeline, {
  fullDocument: 'default'  // Plus performant si on n'a pas besoin du doc complet
});

// 3. Batch processing pour r√©duire la charge
const eventBuffer = [];
changeStream.on('change', (change) => {
  eventBuffer.push(change);

  if (eventBuffer.length >= 100) {
    processEventsBatch(eventBuffer);
    eventBuffer.length = 0;
  }
});
```

---

## Pr√©requis et limitations

### Pr√©requis techniques

‚úÖ **Obligatoire :**
- MongoDB ‚â• 3.6
- **Replica Set** ou **Sharded Cluster** (standalone non support√©)
- Driver compatible (Node.js ‚â• 3.1, Python ‚â• 3.6, Java ‚â• 3.6, etc.)

‚ö†Ô∏è **Recommand√© :**
- MongoDB ‚â• 4.0 (meilleure gestion des transactions)
- Replica Set avec au moins 3 membres
- Oplog dimensionn√© (‚â• 5% de la taille des donn√©es)

### Limitations importantes

‚ùå **Ne peut pas :**
- Fonctionner sur un MongoDB standalone (n√©cessite replica set minimum)
- Garantir l'ordre entre shards diff√©rents dans un cluster shard√©
- Capturer les changements avant l'ouverture du stream (pas de replay historique)
- Capturer les op√©rations administratives (createCollection, dropCollection sauf via √©v√©nements sp√©ciaux)

‚úÖ **Peut :**
- Reprendre apr√®s interruption (via resume tokens)
- Filtrer sur plusieurs crit√®res complexes
- Transformer les √©v√©nements via pipelines d'agr√©gation
- Fonctionner sur collection, database ou cluster entier

---

## Monitoring et observabilit√©

### M√©triques cl√©s √† surveiller

```javascript
// Monitoring d'un Change Stream
class MonitoredChangeStream {
  constructor(collection) {
    this.collection = collection;
    this.metrics = {
      eventsReceived: 0,
      eventsProcessed: 0,
      errors: 0,
      latencySum: 0,
      latencyCount: 0
    };
  }

  async start() {
    const changeStream = this.collection.watch();

    changeStream.on('change', async (change) => {
      const startTime = Date.now();
      this.metrics.eventsReceived++;

      try {
        await this.processChange(change);
        this.metrics.eventsProcessed++;

        // Latence
        const latency = Date.now() - startTime;
        this.metrics.latencySum += latency;
        this.metrics.latencyCount++;
      } catch (error) {
        this.metrics.errors++;
        console.error('Processing error:', error);
      }
    });

    // M√©triques p√©riodiques
    setInterval(() => this.logMetrics(), 60000);
  }

  logMetrics() {
    const avgLatency = this.metrics.latencyCount > 0
      ? this.metrics.latencySum / this.metrics.latencyCount
      : 0;

    console.log({
      eventsReceived: this.metrics.eventsReceived,
      eventsProcessed: this.metrics.eventsProcessed,
      errors: this.metrics.errors,
      avgLatency: `${avgLatency.toFixed(2)}ms`,
      successRate: `${((this.metrics.eventsProcessed / this.metrics.eventsReceived) * 100).toFixed(2)}%`
    });
  }
}
```

---

## S√©curit√© et bonnes pratiques

### 1. Contr√¥le d'acc√®s

```javascript
// L'utilisateur doit avoir les privil√®ges appropri√©s
{
  role: "customChangeStreamRole",
  privileges: [
    {
      resource: { db: "mydb", collection: "mycollection" },
      actions: ["find", "changeStream"]
    }
  ]
}
```

### 2. Gestion des secrets

```javascript
// Ne jamais hardcoder les credentials
const mongoUri = process.env.MONGODB_URI;
const changeStream = client.watch();

// Chiffrement TLS obligatoire en production
const secureClient = new MongoClient(mongoUri, {
  tls: true,
  tlsCAFile: '/path/to/ca.pem',
  tlsCertificateKeyFile: '/path/to/client.pem'
});
```

### 3. Idempotence

```javascript
// Traiter les √©v√©nements de mani√®re idempotente
changeStream.on('change', async (change) => {
  const eventId = change._id._data;

  // V√©rifier si d√©j√† trait√©
  const processed = await redis.get(`processed:${eventId}`);
  if (processed) {
    console.log(`Event ${eventId} already processed, skipping`);
    return;
  }

  // Traiter
  await processEvent(change);

  // Marquer comme trait√©
  await redis.setex(`processed:${eventId}`, 86400, '1'); // 24h TTL
});
```

---

## Comparaison avec d'autres approches

| Approche | Latence | Overhead | Fiabilit√© | Complexit√© | Cas d'usage |
|----------|---------|----------|-----------|------------|-------------|
| **Change Streams** | 50-200ms | Faible | √âlev√©e | Moyenne | Production, temps r√©el |
| **Polling** | 1-60s | √âlev√© | Moyenne | Faible | Dev, non critique |
| **Triggers** | < 100ms | Moyen | √âlev√©e | Faible | Atlas uniquement |
| **Oplog Tailing** | < 50ms | Tr√®s faible | Moyenne | √âlev√©e | Cas avanc√©s sp√©cifiques |
| **Message Queue** | Variable | √âlev√© | √âlev√©e | √âlev√©e | Architecture distribu√©e |

### Quand utiliser Change Streams ?

‚úÖ **Utiliser quand :**
- Besoin de r√©activit√© temps r√©el (< 1s)
- Architecture √©v√©nementielle / Event-Driven
- Synchronisation de syst√®mes externes
- Invalidation de cache automatique
- Notifications push utilisateur
- CDC (Change Data Capture) vers data warehouse

‚ùå **Ne pas utiliser quand :**
- MongoDB standalone (pas de replica set)
- Latence > 5 secondes acceptable (polling suffit)
- Transformation complexe requise (pr√©f√©rer ETL batch)
- Oplog trop petit ou instable

---

## Prochaines sections

Cette introduction aux Change Streams a couvert les concepts fondamentaux, l'architecture, et des exemples d'impl√©mentation avanc√©s. Les sections suivantes approfondiront :

- **16.1.1 Principes et cas d'usage** : Patterns architecturaux d√©taill√©s, Event Sourcing, CQRS
- **16.1.2 Configuration et filtres** : Pipelines avanc√©s, optimisations, options
- **16.1.3 Resume tokens** : Gestion de la r√©silience, reprise apr√®s panne, persistance

---

## Ressources compl√©mentaires

- [Documentation officielle MongoDB Change Streams](https://www.mongodb.com/docs/manual/changeStreams/)
- [Blog MongoDB : Building with Change Streams](https://www.mongodb.com/blog)
- [Driver Specifications : Change Streams](https://github.com/mongodb/specifications/blob/master/source/change-streams)

---


‚è≠Ô∏è [Principes et cas d'usage](/16-fonctionnalites-avancees/01.1-principes-cas-usage.md)
