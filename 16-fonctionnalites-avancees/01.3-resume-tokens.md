üîù Retour au [Sommaire](/SOMMAIRE.md)

# 16.1.3 Resume tokens

## Introduction

Les **resume tokens** sont l'un des m√©canismes les plus puissants des Change Streams, permettant de reprendre l'√©coute des √©v√©nements exactement o√π elle s'√©tait arr√™t√©e apr√®s une interruption. Cette fonctionnalit√© est essentielle pour construire des syst√®mes r√©silients en production, garantissant qu'aucun √©v√©nement n'est perdu m√™me en cas de crash, de red√©marrage ou de d√©connexion r√©seau.

Cette section explore en profondeur les resume tokens, leur fonctionnement interne, les strat√©gies de persistance, et les patterns avanc√©s pour une r√©silience maximale.

---

## Qu'est-ce qu'un resume token ?

Un resume token est un **identifiant opaque** qui marque une position pr√©cise dans l'Oplog de MongoDB. Chaque √©v√©nement Change Stream contient un resume token unique qui peut √™tre utilis√© pour reprendre le stream √† partir de cet √©v√©nement exact.

### Structure d'un resume token

```javascript
// Exemple d'√©v√©nement Change Stream
{
  _id: {
    _data: "826475A1E7000000012B022C0100296E5A1004D5F9E8B4C8F9E2D45A1B3C4D5E46736800"
  },
  operationType: "insert",
  clusterTime: Timestamp(1701234567, 1),
  wallTime: ISODate("2024-12-08T14:30:45.123Z"),
  fullDocument: { /* ... */ },
  ns: { db: "mydb", coll: "mycollection" },
  documentKey: { _id: ObjectId("...") }
}

// Le resume token est dans _id._data
const resumeToken = change._id;
```

### Composition du resume token

Le resume token encode plusieurs informations :
- **Timestamp du cluster** (clusterTime)
- **Identifiant de transaction** (si applicable)
- **Position dans l'Oplog**
- **M√©tadonn√©es internes MongoDB**

**‚ö†Ô∏è Important :** Le format est opaque et peut changer entre versions. Ne jamais essayer de parser ou modifier un resume token.

---

## resumeAfter vs startAfter vs startAtOperationTime

MongoDB propose trois m√©canismes pour reprendre ou d√©marrer un Change Stream √† une position sp√©cifique.

### 1. resumeAfter

```javascript
// Reprendre APR√àS un √©v√©nement sp√©cifique
const changeStream = collection.watch(pipeline, {
  resumeAfter: lastResumeToken
});

// Sc√©nario typique
let lastToken;

const stream = collection.watch();
stream.on('change', (change) => {
  lastToken = change._id;
  processChange(change);
});

// En cas de reconnexion
const resumedStream = collection.watch([], {
  resumeAfter: lastToken
});
```

**Caract√©ristiques :**
- ‚úÖ Reprend exactement apr√®s l'√©v√©nement du token
- ‚úÖ Garantit qu'aucun √©v√©nement n'est manqu√©
- ‚ùå √âchoue si le token n'est plus dans l'Oplog
- ‚ùå √âchoue si le stream a √©t√© invalid√© (ex: collection dropp√©e)

### 2. startAfter (MongoDB 4.2+)

```javascript
// D√©marrer APR√àS un √©v√©nement, m√™me si invalid√©
const changeStream = collection.watch(pipeline, {
  startAfter: lastResumeToken
});
```

**Diff√©rence cl√© avec resumeAfter :**

| Crit√®re | resumeAfter | startAfter |
|---------|-------------|------------|
| Invalidation du stream | ‚ùå √âchoue avec erreur | ‚úÖ Continue apr√®s invalidation |
| Collection dropp√©e puis recr√©√©e | ‚ùå √âchoue | ‚úÖ Reprend sur nouvelle collection |
| Cas d'usage | Reprise normale | Reprise apr√®s √©v√©nements administratifs |

**Exemple d'usage :**

```javascript
class ResilientChangeStream {
  constructor(collection) {
    this.collection = collection;
    this.lastToken = null;
    this.useStartAfter = false;
  }

  async start() {
    const options = {};

    if (this.lastToken) {
      if (this.useStartAfter) {
        options.startAfter = this.lastToken;
      } else {
        options.resumeAfter = this.lastToken;
      }
    }

    const changeStream = this.collection.watch([], options);

    changeStream.on('change', (change) => {
      this.lastToken = change._id;

      // D√©tection d'invalidation
      if (change.operationType === 'invalidate') {
        console.log('Stream invalidated, switching to startAfter mode');
        this.useStartAfter = true;
      }

      this.processChange(change);
    });

    changeStream.on('error', async (error) => {
      if (error.code === 286) { // Resume token not found
        console.log('Resume token expired, using startAfter');
        this.useStartAfter = true;
      }
      await this.reconnect();
    });
  }

  async reconnect() {
    await new Promise(resolve => setTimeout(resolve, 5000));
    await this.start();
  }

  processChange(change) {
    console.log('Processing:', change.operationType);
  }
}

// Utilisation
const stream = new ResilientChangeStream(collection);
await stream.start();
```

### 3. startAtOperationTime

```javascript
// D√©marrer √† un timestamp cluster sp√©cifique
const operationTime = await db.command({ ping: 1 }).then(
  result => result.$clusterTime.clusterTime
);

const changeStream = collection.watch([], {
  startAtOperationTime: operationTime
});
```

**Cas d'usage :**
- D√©marrer un nouveau stream √† un point dans le temps connu
- Synchronisation initiale de syst√®mes
- Tests et replay d'√©v√©nements historiques

**‚ö†Ô∏è Attention :** Le timestamp doit √™tre dans la fen√™tre de l'Oplog, sinon erreur.

---

## Persistance des resume tokens

### Strat√©gie 1 : Persistance en base de donn√©es

La strat√©gie la plus robuste consiste √† sauvegarder les resume tokens dans MongoDB lui-m√™me.

```javascript
class PersistentChangeStream {
  constructor(db, collectionName, streamName) {
    this.collection = db.collection(collectionName);
    this.checkpoints = db.collection('changestream_checkpoints');
    this.streamName = streamName;
  }

  async initialize() {
    // Cr√©er l'index unique sur le nom du stream
    await this.checkpoints.createIndex(
      { streamName: 1 },
      { unique: true }
    );

    // Charger le dernier token sauvegard√©
    const checkpoint = await this.checkpoints.findOne({
      streamName: this.streamName
    });

    const options = {};
    if (checkpoint?.resumeToken) {
      options.resumeAfter = checkpoint.resumeToken;
      console.log('Resuming from saved token');
    }

    const changeStream = this.collection.watch([], options);

    changeStream.on('change', async (change) => {
      await this.handleChange(change);
    });

    changeStream.on('error', async (error) => {
      console.error('Stream error:', error);
      await this.handleError(error);
    });
  }

  async handleChange(change) {
    const session = this.collection.client.startSession();

    try {
      await session.withTransaction(async () => {
        // 1. Traiter l'√©v√©nement
        await this.processChange(change, { session });

        // 2. Sauvegarder le resume token (dans la m√™me transaction)
        await this.checkpoints.updateOne(
          { streamName: this.streamName },
          {
            $set: {
              resumeToken: change._id,
              lastEventTime: change.wallTime,
              lastOperationType: change.operationType,
              updatedAt: new Date()
            }
          },
          { upsert: true, session }
        );
      });

      console.log('Event processed and token saved atomically');
    } catch (error) {
      console.error('Transaction failed:', error);
      // La transaction rollback automatiquement
      throw error;
    } finally {
      await session.endSession();
    }
  }

  async processChange(change, options) {
    // Traitement m√©tier avec session pour atomicit√©
    console.log('Processing:', change.operationType);

    // Exemple: mise √† jour d'une vue mat√©rialis√©e
    if (change.operationType === 'insert') {
      await this.collection.db
        .collection('materialized_view')
        .insertOne(change.fullDocument, options);
    }
  }

  async handleError(error) {
    if (error.code === 286) { // Resume token not found in oplog
      console.warn('Resume token expired, resetting stream');

      // Supprimer le checkpoint invalide
      await this.checkpoints.deleteOne({
        streamName: this.streamName
      });

      // Red√©marrer sans resume token
      await this.initialize();
    } else {
      // Attendre et r√©essayer
      await new Promise(resolve => setTimeout(resolve, 5000));
      await this.initialize();
    }
  }
}

// Utilisation
const persistentStream = new PersistentChangeStream(
  db,
  'orders',
  'orders-to-warehouse-sync'
);

await persistentStream.initialize();
```

**Avantages :**
- ‚úÖ R√©sistant aux crashs de l'application
- ‚úÖ Atomicit√© garantie (transaction)
- ‚úÖ Partageable entre instances (clustering)
- ‚úÖ Tra√ßabilit√© compl√®te

### Strat√©gie 2 : Persistance multi-niveaux (cache + DB)

```javascript
class MultiLevelCheckpointManager {
  constructor(db, redisClient, streamName) {
    this.db = db;
    this.redis = redisClient;
    this.streamName = streamName;
    this.memoryToken = null;
    this.saveInterval = 1000; // Sauvegarder toutes les secondes
    this.lastSaveTime = 0;
  }

  async getLastToken() {
    // 1. M√©moire (le plus rapide)
    if (this.memoryToken) {
      return this.memoryToken;
    }

    // 2. Redis (rapide, partag√©)
    const redisToken = await this.redis.get(
      `checkpoint:${this.streamName}`
    );
    if (redisToken) {
      this.memoryToken = JSON.parse(redisToken);
      return this.memoryToken;
    }

    // 3. MongoDB (persistent, source of truth)
    const checkpoint = await this.db
      .collection('changestream_checkpoints')
      .findOne({ streamName: this.streamName });

    if (checkpoint?.resumeToken) {
      this.memoryToken = checkpoint.resumeToken;
      return this.memoryToken;
    }

    return null;
  }

  async saveToken(token) {
    // Toujours sauvegarder en m√©moire (instantan√©)
    this.memoryToken = token;

    const now = Date.now();

    // Throttle les √©critures pour performance
    if (now - this.lastSaveTime < this.saveInterval) {
      return;
    }

    this.lastSaveTime = now;

    // Sauvegarder en parall√®le dans Redis et MongoDB
    await Promise.all([
      // Redis : rapide, pour failover rapide
      this.redis.setex(
        `checkpoint:${this.streamName}`,
        3600, // TTL 1h
        JSON.stringify(token)
      ),

      // MongoDB : persistent, source of truth
      this.db.collection('changestream_checkpoints').updateOne(
        { streamName: this.streamName },
        {
          $set: {
            resumeToken: token,
            updatedAt: new Date()
          }
        },
        { upsert: true }
      )
    ]);
  }

  async flush() {
    // Force la sauvegarde imm√©diate (ex: avant shutdown)
    if (this.memoryToken) {
      await this.saveToken(this.memoryToken);
    }
  }
}

// Utilisation
const checkpointManager = new MultiLevelCheckpointManager(
  db,
  redisClient,
  'critical-stream'
);

const lastToken = await checkpointManager.getLastToken();

const changeStream = collection.watch([], {
  resumeAfter: lastToken
});

changeStream.on('change', async (change) => {
  await processChange(change);
  await checkpointManager.saveToken(change._id);
});

// Graceful shutdown
process.on('SIGTERM', async () => {
  await checkpointManager.flush();
  await changeStream.close();
  process.exit(0);
});
```

### Strat√©gie 3 : Persistance avec fen√™tre glissante

```javascript
class SlidingWindowCheckpoint {
  constructor(db, streamName, windowSize = 100) {
    this.db = db;
    this.streamName = streamName;
    this.windowSize = windowSize;
    this.window = [];
  }

  async initialize() {
    const checkpoint = await this.db
      .collection('changestream_checkpoints')
      .findOne({ streamName: this.streamName });

    const options = {};
    if (checkpoint?.resumeToken) {
      options.resumeAfter = checkpoint.resumeToken;
    }

    const changeStream = this.db.collection('orders').watch([], options);

    changeStream.on('change', async (change) => {
      await this.handleChange(change);
    });
  }

  async handleChange(change) {
    // Ajouter √† la fen√™tre
    this.window.push({
      token: change._id,
      timestamp: change.wallTime,
      operationType: change.operationType
    });

    // Maintenir la taille de la fen√™tre
    if (this.window.length > this.windowSize) {
      this.window.shift();
    }

    // Traiter l'√©v√©nement
    try {
      await this.processChange(change);

      // Sauvegarder le token le plus ancien de la fen√™tre (safe point)
      // Garantit qu'on peut replay les N derniers √©v√©nements si n√©cessaire
      const safeToken = this.window[0].token;

      await this.db.collection('changestream_checkpoints').updateOne(
        { streamName: this.streamName },
        {
          $set: {
            resumeToken: safeToken,
            safeWindow: this.window.length,
            updatedAt: new Date()
          }
        },
        { upsert: true }
      );

    } catch (error) {
      console.error('Processing failed, can replay from safe point');
      throw error;
    }
  }

  async processChange(change) {
    // Traitement m√©tier
    console.log('Processing:', change.operationType);
  }

  getReplayWindow() {
    return [...this.window];
  }
}

// Utilisation avec replay capability
const stream = new SlidingWindowCheckpoint(db, 'orders-stream', 100);
await stream.initialize();

// En cas d'erreur, possibilit√© de replay les 100 derniers √©v√©nements
const replayEvents = stream.getReplayWindow();
```

---

## Cas d'usage avanc√©s

### Cas 1 : Distributed Change Stream avec leader election

Pour des applications distribu√©es avec plusieurs instances, une seule doit consommer le Change Stream.

```javascript
class DistributedChangeStream {
  constructor(db, collectionName, streamName) {
    this.db = db;
    this.collection = db.collection(collectionName);
    this.streamName = streamName;
    this.instanceId = `instance-${process.pid}-${Date.now()}`;
    this.leaseCollection = db.collection('changestream_leases');
    this.isLeader = false;
    this.leaseInterval = null;
  }

  async initialize() {
    // Cr√©er l'index pour les leases
    await this.leaseCollection.createIndex({ streamName: 1 }, { unique: true });
    await this.leaseCollection.createIndex({ expiresAt: 1 }, { expireAfterSeconds: 0 });

    // Tenter d'acqu√©rir le lease
    await this.tryAcquireLease();

    // V√©rifier/renouveler le lease toutes les 10 secondes
    this.leaseInterval = setInterval(
      () => this.maintainLease(),
      10000
    );
  }

  async tryAcquireLease() {
    const now = new Date();
    const expiresAt = new Date(now.getTime() + 30000); // 30 secondes

    try {
      // Essayer d'acqu√©rir ou renouveler le lease
      const result = await this.leaseCollection.updateOne(
        {
          streamName: this.streamName,
          $or: [
            { expiresAt: { $lt: now } }, // Lease expir√©
            { instanceId: this.instanceId } // Notre lease
          ]
        },
        {
          $set: {
            instanceId: this.instanceId,
            expiresAt: expiresAt,
            acquiredAt: now
          }
        },
        { upsert: true }
      );

      if (result.modifiedCount > 0 || result.upsertedCount > 0) {
        if (!this.isLeader) {
          console.log(`${this.instanceId} acquired leadership`);
          this.isLeader = true;
          await this.startChangeStream();
        }
      } else {
        if (this.isLeader) {
          console.log(`${this.instanceId} lost leadership`);
          this.isLeader = false;
          await this.stopChangeStream();
        }
      }
    } catch (error) {
      console.error('Lease acquisition failed:', error);
    }
  }

  async maintainLease() {
    if (this.isLeader) {
      await this.tryAcquireLease();
    } else {
      // Follower : tenter d'acqu√©rir si leader est mort
      await this.tryAcquireLease();
    }
  }

  async startChangeStream() {
    // Charger le resume token partag√©
    const checkpoint = await this.db
      .collection('changestream_checkpoints')
      .findOne({ streamName: this.streamName });

    const options = {};
    if (checkpoint?.resumeToken) {
      options.resumeAfter = checkpoint.resumeToken;
    }

    this.changeStream = this.collection.watch([], options);

    this.changeStream.on('change', async (change) => {
      if (this.isLeader) {
        await this.handleChange(change);
      }
    });

    this.changeStream.on('error', async (error) => {
      console.error('Stream error:', error);
      if (this.isLeader) {
        await this.handleError(error);
      }
    });

    console.log(`${this.instanceId} started Change Stream`);
  }

  async stopChangeStream() {
    if (this.changeStream) {
      await this.changeStream.close();
      this.changeStream = null;
      console.log(`${this.instanceId} stopped Change Stream`);
    }
  }

  async handleChange(change) {
    // V√©rifier qu'on est toujours leader avant de traiter
    if (!this.isLeader) {
      return;
    }

    // Traitement + sauvegarde du token
    await this.processChange(change);

    await this.db.collection('changestream_checkpoints').updateOne(
      { streamName: this.streamName },
      {
        $set: {
          resumeToken: change._id,
          processedBy: this.instanceId,
          updatedAt: new Date()
        }
      },
      { upsert: true }
    );
  }

  async processChange(change) {
    console.log(`${this.instanceId} processing:`, change.operationType);
  }

  async handleError(error) {
    // Lib√©rer le lease en cas d'erreur
    this.isLeader = false;
    await this.stopChangeStream();

    // Un autre instance reprendra
    console.log(`${this.instanceId} released leadership due to error`);
  }

  async shutdown() {
    // Cleanup
    if (this.leaseInterval) {
      clearInterval(this.leaseInterval);
    }

    if (this.isLeader) {
      await this.stopChangeStream();

      // Lib√©rer le lease
      await this.leaseCollection.deleteOne({
        streamName: this.streamName,
        instanceId: this.instanceId
      });
    }
  }
}

// D√©ployer sur plusieurs instances
const distributedStream = new DistributedChangeStream(
  db,
  'orders',
  'orders-processor'
);

await distributedStream.initialize();

// Graceful shutdown
process.on('SIGTERM', async () => {
  await distributedStream.shutdown();
  process.exit(0);
});
```

### Cas 2 : Resume token avec compression et rotation

Pour des syst√®mes traitant des milliards d'√©v√©nements, la taille des checkpoints peut devenir probl√©matique.

```javascript
const zlib = require('zlib');
const { promisify } = require('util');

const gzip = promisify(zlib.gzip);
const gunzip = promisify(zlib.gunzip);

class CompressedCheckpointManager {
  constructor(db, streamName, maxHistorySize = 1000) {
    this.db = db;
    this.streamName = streamName;
    this.maxHistorySize = maxHistorySize;
    this.checkpoints = db.collection('changestream_checkpoints_compressed');
  }

  async initialize() {
    // Index pour rotation automatique
    await this.checkpoints.createIndex(
      { streamName: 1, createdAt: -1 }
    );
  }

  async saveCheckpoint(token, metadata = {}) {
    // S√©rialiser le token
    const tokenString = JSON.stringify(token);

    // Compresser (r√©duit ~70% la taille)
    const compressed = await gzip(tokenString);
    const base64 = compressed.toString('base64');

    // Sauvegarder
    await this.checkpoints.insertOne({
      streamName: this.streamName,
      resumeTokenCompressed: base64,
      metadata: {
        ...metadata,
        originalSize: tokenString.length,
        compressedSize: base64.length,
        compressionRatio: (1 - base64.length / tokenString.length).toFixed(2)
      },
      createdAt: new Date()
    });

    // Rotation : garder seulement les N derniers
    await this.rotateOldCheckpoints();
  }

  async getLatestCheckpoint() {
    const checkpoint = await this.checkpoints
      .find({ streamName: this.streamName })
      .sort({ createdAt: -1 })
      .limit(1)
      .toArray();

    if (checkpoint.length === 0) {
      return null;
    }

    // D√©compresser
    const compressed = Buffer.from(
      checkpoint[0].resumeTokenCompressed,
      'base64'
    );
    const decompressed = await gunzip(compressed);
    const token = JSON.parse(decompressed.toString());

    return {
      token,
      metadata: checkpoint[0].metadata,
      createdAt: checkpoint[0].createdAt
    };
  }

  async rotateOldCheckpoints() {
    // Compter les checkpoints
    const count = await this.checkpoints.countDocuments({
      streamName: this.streamName
    });

    if (count > this.maxHistorySize) {
      // Garder seulement les N plus r√©cents
      const toKeep = await this.checkpoints
        .find({ streamName: this.streamName })
        .sort({ createdAt: -1 })
        .limit(this.maxHistorySize)
        .toArray();

      const idsToKeep = toKeep.map(doc => doc._id);

      await this.checkpoints.deleteMany({
        streamName: this.streamName,
        _id: { $nin: idsToKeep }
      });

      console.log(`Rotated checkpoints, kept ${this.maxHistorySize} most recent`);
    }
  }

  async getCheckpointHistory(limit = 10) {
    const history = await this.checkpoints
      .find({ streamName: this.streamName })
      .sort({ createdAt: -1 })
      .limit(limit)
      .project({ metadata: 1, createdAt: 1 })
      .toArray();

    return history;
  }
}

// Utilisation
const checkpointManager = new CompressedCheckpointManager(
  db,
  'high-volume-stream',
  1000 // Garder les 1000 derniers checkpoints
);

await checkpointManager.initialize();

// R√©cup√©rer le dernier checkpoint
const checkpoint = await checkpointManager.getLatestCheckpoint();

const changeStream = collection.watch([], {
  resumeAfter: checkpoint?.token
});

changeStream.on('change', async (change) => {
  await processChange(change);

  // Sauvegarder avec m√©tadonn√©es
  await checkpointManager.saveCheckpoint(change._id, {
    operationType: change.operationType,
    eventCount: eventCounter++
  });
});

// Voir l'historique
const history = await checkpointManager.getCheckpointHistory(20);
console.log('Recent checkpoints:', history);
```

### Cas 3 : Failover automatique avec validation

```javascript
class FailoverAwareChangeStream {
  constructor(primaryDb, replicaDbs, streamName) {
    this.primaryDb = primaryDb;
    this.replicaDbs = replicaDbs; // Array de connexions replicas
    this.streamName = streamName;
    this.currentDb = primaryDb;
    this.failoverCount = 0;
  }

  async initialize() {
    await this.startChangeStream();
  }

  async startChangeStream() {
    // Charger et valider le resume token
    const checkpoint = await this.loadAndValidateCheckpoint();

    const options = {};
    if (checkpoint?.resumeToken) {
      options.resumeAfter = checkpoint.resumeToken;
    }

    try {
      this.changeStream = this.currentDb
        .collection('orders')
        .watch([], options);

      this.changeStream.on('change', async (change) => {
        await this.handleChange(change);
      });

      this.changeStream.on('error', async (error) => {
        await this.handleError(error);
      });

      console.log('Change Stream started successfully');
    } catch (error) {
      console.error('Failed to start Change Stream:', error);
      await this.attemptFailover();
    }
  }

  async loadAndValidateCheckpoint() {
    try {
      const checkpoint = await this.currentDb
        .collection('changestream_checkpoints')
        .findOne({ streamName: this.streamName });

      if (!checkpoint) {
        return null;
      }

      // Valider que le token est toujours valide
      const isValid = await this.validateResumeToken(
        checkpoint.resumeToken
      );

      if (!isValid) {
        console.warn('Resume token no longer valid, starting fresh');
        return null;
      }

      return checkpoint;
    } catch (error) {
      console.error('Failed to load checkpoint:', error);
      return null;
    }
  }

  async validateResumeToken(token) {
    try {
      // Essayer d'ouvrir un stream avec le token
      const testStream = this.currentDb
        .collection('orders')
        .watch([], { resumeAfter: token });

      // Attendre le premier √©v√©nement ou timeout
      const result = await Promise.race([
        new Promise((resolve) => {
          testStream.on('change', () => resolve(true));
        }),
        new Promise((resolve) => setTimeout(() => resolve(true), 1000))
      ]);

      await testStream.close();
      return true;
    } catch (error) {
      if (error.code === 286) { // Token not in oplog
        return false;
      }
      throw error;
    }
  }

  async handleChange(change) {
    const session = this.currentDb.client.startSession();

    try {
      await session.withTransaction(async () => {
        // Traiter
        await this.processChange(change, { session });

        // Sauvegarder avec validation
        await this.currentDb
          .collection('changestream_checkpoints')
          .updateOne(
            { streamName: this.streamName },
            {
              $set: {
                resumeToken: change._id,
                lastEventTime: change.wallTime,
                processedAt: new Date(),
                failoverCount: this.failoverCount
              }
            },
            { upsert: true, session }
          );

        // Reset failover count apr√®s succ√®s
        this.failoverCount = 0;
      });
    } catch (error) {
      console.error('Transaction failed:', error);
      throw error;
    } finally {
      await session.endSession();
    }
  }

  async handleError(error) {
    console.error('Change Stream error:', error);

    if (error.code === 286) {
      // Resume token expir√©
      console.log('Resume token expired');
      await this.currentDb
        .collection('changestream_checkpoints')
        .deleteOne({ streamName: this.streamName });
    }

    await this.attemptFailover();
  }

  async attemptFailover() {
    this.failoverCount++;

    if (this.failoverCount > 5) {
      console.error('Too many failover attempts, stopping');
      throw new Error('Failover limit exceeded');
    }

    // Essayer le primary d'abord
    const connections = [this.primaryDb, ...this.replicaDbs];

    for (const db of connections) {
      try {
        console.log(`Attempting failover to ${db.databaseName}`);

        // Tester la connexion
        await db.admin().ping();

        // Changer la connexion
        this.currentDb = db;

        // Red√©marrer le stream
        if (this.changeStream) {
          await this.changeStream.close();
        }

        await new Promise(resolve => setTimeout(resolve, 2000));
        await this.startChangeStream();

        console.log('Failover successful');
        return;
      } catch (error) {
        console.error(`Failover to ${db.databaseName} failed:`, error);
      }
    }

    // Si tous les failovers √©chouent
    throw new Error('All failover attempts failed');
  }

  async processChange(change, options) {
    console.log('Processing:', change.operationType);
  }

  async shutdown() {
    if (this.changeStream) {
      await this.changeStream.close();
    }
  }
}

// Utilisation avec multiple replicas
const primaryConnection = await MongoClient.connect(primaryUri);
const replicaConnections = await Promise.all([
  MongoClient.connect(replica1Uri),
  MongoClient.connect(replica2Uri)
]);

const failoverStream = new FailoverAwareChangeStream(
  primaryConnection.db('mydb'),
  replicaConnections.map(c => c.db('mydb')),
  'critical-stream'
);

await failoverStream.initialize();
```

---

## Gestion des erreurs et limites

### Erreurs courantes li√©es aux resume tokens

```javascript
class ResumeTokenErrorHandler {
  static async handleError(error, changeStream, checkpointManager) {
    switch (error.code) {
      case 286: // Resume token not found in oplog
        console.error('Resume token expired - oplog too small or too old');

        // Solution 1 : Augmenter la taille de l'Oplog
        // Solution 2 : Checkpoint plus fr√©quent
        // Solution 3 : Red√©marrer sans token (perte de donn√©es possible)

        await checkpointManager.markAsInvalid();

        // D√©cider de la strat√©gie
        const shouldRestart = await this.confirmDataLossAcceptable();
        if (shouldRestart) {
          return { action: 'restart', resumeAfter: null };
        } else {
          return { action: 'alert', message: 'Manual intervention required' };
        }

      case 280: // Invalid resume token
        console.error('Resume token is invalid or corrupted');

        // Token corrompu en DB
        await checkpointManager.delete();
        return { action: 'restart', resumeAfter: null };

      case 11602: // Cursor killed
        console.error('Change Stream cursor was killed');

        // Red√©marrer avec le dernier token sauvegard√©
        const lastToken = await checkpointManager.getLatest();
        return { action: 'restart', resumeAfter: lastToken };

      case 40573: // Invalidate event
        console.error('Stream invalidated (collection dropped/renamed)');

        // Utiliser startAfter au lieu de resumeAfter
        const lastToken = await checkpointManager.getLatest();
        return { action: 'restart', startAfter: lastToken };

      default:
        console.error('Unhandled Change Stream error:', error);
        return { action: 'retry', delay: 5000 };
    }
  }

  static async confirmDataLossAcceptable() {
    // Logique m√©tier pour confirmer si la perte de donn√©es est acceptable
    // Par exemple: envoyer une alerte et attendre confirmation manuelle
    return false; // Par d√©faut : ne pas accepter la perte
  }
}

// Utilisation
changeStream.on('error', async (error) => {
  const resolution = await ResumeTokenErrorHandler.handleError(
    error,
    changeStream,
    checkpointManager
  );

  switch (resolution.action) {
    case 'restart':
      await changeStream.close();
      await restartStream(resolution.resumeAfter, resolution.startAfter);
      break;

    case 'alert':
      await sendAlert(resolution.message);
      break;

    case 'retry':
      await new Promise(resolve => setTimeout(resolve, resolution.delay));
      await restartStream();
      break;
  }
});
```

### Limites de l'Oplog et dimensionnement

```javascript
class OplogSizeMonitor {
  constructor(db) {
    this.db = db;
  }

  async checkOplogSize() {
    const oplogStats = await this.db
      .admin()
      .command({ replSetGetStatus: 1 });

    const oplogInfo = await this.db
      .db('local')
      .collection('oplog.rs')
      .stats();

    return {
      size: oplogInfo.size,
      maxSize: oplogInfo.maxSize,
      usagePercent: (oplogInfo.size / oplogInfo.maxSize) * 100,
      firstTimestamp: await this.getFirstOplogTimestamp(),
      lastTimestamp: await this.getLastOplogTimestamp()
    };
  }

  async getFirstOplogTimestamp() {
    const first = await this.db
      .db('local')
      .collection('oplog.rs')
      .find()
      .sort({ ts: 1 })
      .limit(1)
      .toArray();

    return first[0]?.ts;
  }

  async getLastOplogTimestamp() {
    const last = await this.db
      .db('local')
      .collection('oplog.rs')
      .find()
      .sort({ ts: -1 })
      .limit(1)
      .toArray();

    return last[0]?.ts;
  }

  async getOplogWindow() {
    const first = await this.getFirstOplogTimestamp();
    const last = await this.getLastOplogTimestamp();

    if (!first || !last) {
      return null;
    }

    const windowSeconds = last.getHighBits() - first.getHighBits();
    const windowHours = windowSeconds / 3600;

    return {
      seconds: windowSeconds,
      hours: windowHours,
      days: windowHours / 24
    };
  }

  async calculateRecommendedCheckpointInterval() {
    const window = await this.getOplogWindow();

    if (!window) {
      return null;
    }

    // Recommandation : checkpoint au moins toutes les 10% de la fen√™tre Oplog
    const recommendedInterval = (window.hours * 0.1) * 3600 * 1000; // ms

    return {
      intervalMs: recommendedInterval,
      intervalMinutes: recommendedInterval / 60000,
      intervalHours: recommendedInterval / 3600000,
      oplogWindow: window
    };
  }

  async monitorAndAlert() {
    const stats = await this.checkOplogSize();
    const window = await this.getOplogWindow();
    const recommendation = await this.calculateRecommendedCheckpointInterval();

    console.log('Oplog Statistics:', {
      usage: `${stats.usagePercent.toFixed(2)}%`,
      window: `${window.days.toFixed(2)} days`,
      recommendedCheckpointInterval: `${recommendation.intervalHours.toFixed(2)} hours`
    });

    // Alerter si fen√™tre trop courte
    if (window.hours < 24) {
      console.warn('‚ö†Ô∏è  Oplog window is less than 24 hours!');
      console.warn('   Consider increasing oplog size to avoid resume token expiration');
    }

    // Alerter si usage √©lev√©
    if (stats.usagePercent > 80) {
      console.warn('‚ö†Ô∏è  Oplog usage above 80%!');
    }

    return { stats, window, recommendation };
  }
}

// Utilisation
const oplogMonitor = new OplogSizeMonitor(db);

// V√©rification p√©riodique
setInterval(async () => {
  await oplogMonitor.monitorAndAlert();
}, 3600000); // Toutes les heures

// V√©rification initiale pour dimensionner les checkpoints
const recommendation = await oplogMonitor.calculateRecommendedCheckpointInterval();
console.log('Use checkpoint interval:', recommendation.intervalMinutes, 'minutes');
```

---

## Bonnes pratiques de production

### ‚úÖ DO (√Ä faire)

```javascript
// 1. Toujours sauvegarder le resume token de mani√®re durable
const session = db.client.startSession();
await session.withTransaction(async () => {
  await processEvent(change, { session });
  await saveResumeToken(change._id, { session });
});

// 2. G√©rer les erreurs sp√©cifiques aux resume tokens
changeStream.on('error', async (error) => {
  if (error.code === 286) {
    // Token expir√© - d√©cision m√©tier n√©cessaire
    await handleTokenExpiration();
  }
});

// 3. Monitorer la fen√™tre de l'Oplog
const window = await getOplogWindow();
if (window.hours < 24) {
  console.warn('Oplog window too short for reliable resume');
}

// 4. Utiliser startAfter apr√®s invalidation
if (change.operationType === 'invalidate') {
  useStartAfterForNextResume = true;
}

// 5. Impl√©menter un graceful shutdown
process.on('SIGTERM', async () => {
  await saveCurrentResumeToken();
  await changeStream.close();
});
```

### ‚ùå DON'T (√Ä √©viter)

```javascript
// 1. Ne jamais sauvegarder le token seulement en m√©moire
let resumeToken; // ‚ùå Perdu au crash
changeStream.on('change', (change) => {
  resumeToken = change._id; // Pas sauvegard√©
});

// 2. Ne pas ignorer les erreurs de resume token
changeStream.on('error', () => {
  // ‚ùå Ignorer l'erreur
});

// 3. Ne pas sauvegarder le token apr√®s traitement sans transaction
await processEvent(change); // ‚ùå Peut √©chouer
await saveResumeToken(change._id); // Si √ßa √©choue, inconsistance

// 4. Ne pas utiliser le m√™me resume token pour plusieurs streams
const token = await loadToken();
stream1.watch([], { resumeAfter: token }); // ‚ùå
stream2.watch([], { resumeAfter: token }); // ‚ùå Chaque stream doit avoir son token

// 5. Ne pas supposer que le token est toujours valide
const token = await loadToken();
const stream = collection.watch([], { resumeAfter: token }); // ‚ùå Peut √©chouer
// ‚úÖ Toujours valider ou g√©rer l'erreur
```

---

## Conclusion

Les resume tokens sont un m√©canisme puissant mais exigeant qui requiert une attention particuli√®re en production :

**Points cl√©s √† retenir :**
1. ‚úÖ **Persistance durable** : Sauvegarder dans une base de donn√©es, id√©alement dans une transaction
2. ‚úÖ **Gestion d'erreurs robuste** : Code 286 (token expir√©) n√©cessite une d√©cision m√©tier
3. ‚úÖ **Monitoring de l'Oplog** : S'assurer que la fen√™tre est suffisante (>24h recommand√©)
4. ‚úÖ **Strat√©gie de failover** : Pr√©voir plusieurs niveaux de sauvegarde (DB, Redis, etc.)
5. ‚úÖ **Leader election** : Pour syst√®mes distribu√©s, une seule instance doit consommer
6. ‚úÖ **Validation** : Toujours valider qu'un resume token est encore utilisable

**M√©triques √† surveiller :**
- Taille et fen√™tre de l'Oplog
- Fr√©quence de sauvegarde des tokens
- Taux d'erreurs 286 (token expiration)
- Dur√©e entre checkpoint et traitement

**En cas de doute :**
- P√©cher par exc√®s de pr√©caution dans la sauvegarde
- Tester les sc√©narios de failover en staging
- Documenter la strat√©gie de reprise apr√®s incident

---


‚è≠Ô∏è [GridFS (stockage de fichiers volumineux)](/16-fonctionnalites-avancees/02-gridfs.md)
