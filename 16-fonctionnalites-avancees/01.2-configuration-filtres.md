üîù Retour au [Sommaire](/SOMMAIRE.md)

# 16.1.2 Configuration et filtres des Change Streams

## Introduction

La configuration et le filtrage des Change Streams sont essentiels pour optimiser les performances et r√©duire la bande passante r√©seau. Cette section explore en profondeur les options de configuration disponibles, les pipelines d'agr√©gation pour filtrer les √©v√©nements c√¥t√© serveur, et les strat√©gies d'optimisation pour des d√©ploiements √† grande √©chelle.

Une configuration appropri√©e peut r√©duire de 90% le trafic r√©seau et am√©liorer consid√©rablement les performances globales de votre architecture √©v√©nementielle.

---

## Options de configuration

### Vue d'ensemble des options disponibles

```javascript
const changeStream = collection.watch(pipeline, {
  // Options de document
  fullDocument: 'default',              // 'default', 'updateLookup', 'whenAvailable', 'required'
  fullDocumentBeforeChange: 'off',      // 'off', 'whenAvailable', 'required'

  // Options de reprise
  resumeAfter: resumeToken,             // Resume token pour reprise
  startAfter: startToken,               // Start after token (ignore invalidate)
  startAtOperationTime: timestamp,      // Timestamp MongoDB pour d√©marrage

  // Options de comportement
  maxAwaitTimeMS: 1000,                 // Timeout max pour getMore
  batchSize: 100,                       // Nombre de documents par batch

  // Options de collation
  collation: { locale: 'fr' },          // R√®gles de tri et comparaison

  // Options avanc√©es
  showExpandedEvents: false             // Inclure √©v√©nements √©tendus (MongoDB 6.0+)
});
```

---

## 1. Options de document (fullDocument)

### 1.1 fullDocument: 'default' (par d√©faut)

```javascript
// Comportement par d√©faut
const changeStream = collection.watch([], {
  fullDocument: 'default'
});

changeStream.on('change', (change) => {
  console.log(change);
  /*
    Pour insert/replace: fullDocument contient le document complet
    Pour update: fullDocument n'est PAS inclus, seulement updateDescription
    Pour delete: fullDocument est null
  */
});

// Exemple de sortie pour un UPDATE avec 'default':
{
  operationType: 'update',
  documentKey: { _id: ObjectId('...') },
  updateDescription: {
    updatedFields: { status: 'shipped', shippedAt: ISODate(...) },
    removedFields: [],
    truncatedArrays: []
  }
  // Pas de fullDocument !
}
```

**Cas d'usage :** √âconomie de bande passante quand seuls les champs modifi√©s sont n√©cessaires.

### 1.2 fullDocument: 'updateLookup'

```javascript
// R√©cup√©rer le document complet apr√®s update
const changeStream = collection.watch([], {
  fullDocument: 'updateLookup'
});

changeStream.on('change', (change) => {
  if (change.operationType === 'update') {
    console.log('Document complet apr√®s update:', change.fullDocument);
    /*
      fullDocument contient l'√©tat APR√àS la modification
      N√©cessite une lecture suppl√©mentaire dans MongoDB
    */
  }
});

// Exemple de sortie pour un UPDATE avec 'updateLookup':
{
  operationType: 'update',
  documentKey: { _id: ObjectId('...') },
  fullDocument: {
    _id: ObjectId('...'),
    name: 'Product A',
    status: 'shipped',      // Valeur mise √† jour
    shippedAt: ISODate(...), // Valeur mise √† jour
    price: 29.99,
    stock: 100
  },
  updateDescription: {
    updatedFields: { status: 'shipped', shippedAt: ISODate(...) },
    removedFields: []
  }
}
```

**Cas d'usage :** Synchronisation de cache, r√©plication compl√®te, besoin du document entier.

**‚ö†Ô∏è Attention :** Impact sur les performances (lecture suppl√©mentaire). Le document peut avoir √©t√© modifi√© entre l'update et le lookup.

### 1.3 fullDocument: 'whenAvailable' et 'required' (MongoDB 6.0+)

```javascript
// whenAvailable : inclut le document si disponible
const changeStream = collection.watch([], {
  fullDocument: 'whenAvailable'
});

// required : erreur si document non disponible
const strictChangeStream = collection.watch([], {
  fullDocument: 'required'
});

// Cas o√π le document n'est pas disponible:
// - Document supprim√© entre l'√©v√©nement et le lookup
// - Permissions insuffisantes
// - Document dans une autre shard (cas edge)
```

**Comparaison :**

| Option | Insert | Update | Delete | Lecture suppl√©mentaire | Erreur si non disponible |
|--------|--------|--------|--------|------------------------|--------------------------|
| `default` | ‚úÖ Complet | ‚ùå Non | ‚ùå Non | Non | Non |
| `updateLookup` | ‚úÖ Complet | ‚úÖ Complet | ‚ùå Non | Oui (update) | Non |
| `whenAvailable` | ‚úÖ Complet | ‚úÖ Si dispo | ‚ùå Non | Oui (update) | Non |
| `required` | ‚úÖ Complet | ‚úÖ Obligatoire | ‚ùå Non | Oui (update) | Oui |

---

## 2. Options de document avant changement (fullDocumentBeforeChange)

Disponible depuis **MongoDB 6.0**, permet d'obtenir l'√©tat du document **AVANT** la modification.

### 2.1 Configuration et cas d'usage

```javascript
// Activer la capture de l'√©tat avant modification
const changeStream = collection.watch([], {
  fullDocumentBeforeChange: 'whenAvailable'
  // ou 'required' pour erreur si non disponible
});

changeStream.on('change', (change) => {
  if (change.operationType === 'update' || change.operationType === 'replace') {
    console.log('Avant:', change.fullDocumentBeforeChange);
    console.log('Apr√®s:', change.fullDocument); // Avec fullDocument: 'updateLookup'

    // Calculer le delta
    const delta = calculateDelta(
      change.fullDocumentBeforeChange,
      change.fullDocument
    );
  }
});
```

**‚ö†Ô∏è Pr√©requis :** N√©cessite `changeStreamPreAndPostImages` activ√© sur la collection.

```javascript
// Activer la fonctionnalit√© sur une collection
await db.createCollection('orders', {
  changeStreamPreAndPostImages: { enabled: true }
});

// Ou sur une collection existante
await db.runCommand({
  collMod: 'orders',
  changeStreamPreAndPostImages: { enabled: true }
});
```

### 2.2 Exemple d'audit trail complet

```javascript
class AuditTrailWithDelta {
  constructor(collection, auditCollection) {
    this.collection = collection;
    this.auditCollection = auditCollection;
  }

  async initialize() {
    // Activer pre/post images
    await db.runCommand({
      collMod: this.collection.collectionName,
      changeStreamPreAndPostImages: { enabled: true }
    });

    // Change Stream avec avant/apr√®s
    const changeStream = this.collection.watch([], {
      fullDocument: 'updateLookup',
      fullDocumentBeforeChange: 'whenAvailable'
    });

    changeStream.on('change', async (change) => {
      await this.createAuditEntry(change);
    });
  }

  async createAuditEntry(change) {
    const auditEntry = {
      timestamp: new Date(),
      operationType: change.operationType,
      documentId: change.documentKey._id,
      user: change.clusterTime // √Ä remplacer par auth info r√©elle
    };

    switch (change.operationType) {
      case 'insert':
        auditEntry.action = 'created';
        auditEntry.newValue = change.fullDocument;
        break;

      case 'update':
      case 'replace':
        auditEntry.action = 'modified';
        auditEntry.oldValue = change.fullDocumentBeforeChange;
        auditEntry.newValue = change.fullDocument;
        auditEntry.changes = this.computeChanges(
          change.fullDocumentBeforeChange,
          change.fullDocument
        );
        break;

      case 'delete':
        auditEntry.action = 'deleted';
        auditEntry.oldValue = change.fullDocumentBeforeChange;
        break;
    }

    await this.auditCollection.insertOne(auditEntry);
  }

  computeChanges(oldDoc, newDoc) {
    const changes = [];

    // Parcourir tous les champs
    const allKeys = new Set([
      ...Object.keys(oldDoc || {}),
      ...Object.keys(newDoc || {})
    ]);

    for (const key of allKeys) {
      if (key === '_id') continue;

      const oldValue = oldDoc?.[key];
      const newValue = newDoc?.[key];

      if (JSON.stringify(oldValue) !== JSON.stringify(newValue)) {
        changes.push({
          field: key,
          oldValue: oldValue,
          newValue: newValue
        });
      }
    }

    return changes;
  }
}

// Utilisation
const auditTrail = new AuditTrailWithDelta(
  db.collection('sensitive_data'),
  db.collection('audit_log')
);

await auditTrail.initialize();

// Les modifications sont maintenant audit√©es avec d√©tails complets
await db.collection('sensitive_data').updateOne(
  { _id: docId },
  { $set: { status: 'approved', approvedBy: 'admin' } }
);

// Audit log contiendra:
// {
//   timestamp: ISODate(...),
//   operationType: 'update',
//   documentId: ObjectId(...),
//   action: 'modified',
//   oldValue: { status: 'pending', ... },
//   newValue: { status: 'approved', approvedBy: 'admin', ... },
//   changes: [
//     { field: 'status', oldValue: 'pending', newValue: 'approved' },
//     { field: 'approvedBy', oldValue: undefined, newValue: 'admin' }
//   ]
// }
```

**‚ö†Ô∏è Impact performance :**
- Stockage suppl√©mentaire pour pre-images
- Augmentation de la taille de l'Oplog (~2x)
- Recommand√© uniquement pour collections critiques n√©cessitant audit

---

## 3. Pipelines d'agr√©gation pour filtrage

Les Change Streams acceptent des pipelines d'agr√©gation pour filtrer et transformer les √©v√©nements **c√¥t√© serveur**, r√©duisant drastiquement le trafic r√©seau.

### 3.1 Filtrage basique avec $match

```javascript
// Filtrer uniquement les insertions
const pipeline = [
  { $match: { operationType: 'insert' } }
];

// Filtrer par type d'op√©ration et champ sp√©cifique
const pipeline = [
  {
    $match: {
      operationType: { $in: ['insert', 'update'] },
      'fullDocument.status': 'pending'
    }
  }
];

// Filtrer par namespace (collection)
const pipeline = [
  {
    $match: {
      'ns.coll': 'orders',
      operationType: 'update'
    }
  }
];
```

### 3.2 Filtrage avanc√© multi-conditions

```javascript
// Filtrage complexe avec op√©rateurs logiques
const pipeline = [
  {
    $match: {
      $or: [
        // Toutes les insertions
        { operationType: 'insert' },
        // Updates sur commandes > 1000‚Ç¨
        {
          operationType: 'update',
          'fullDocument.totalAmount': { $gt: 1000 }
        },
        // Suppressions de commandes confirm√©es
        {
          operationType: 'delete',
          'fullDocumentBeforeChange.status': 'confirmed'
        }
      ]
    }
  }
];

const changeStream = collection.watch(pipeline, {
  fullDocument: 'updateLookup',
  fullDocumentBeforeChange: 'whenAvailable'
});
```

### 3.3 Filtrage sur champs imbriqu√©s et tableaux

```javascript
// Filtrer sur documents imbriqu√©s
const pipeline = [
  {
    $match: {
      operationType: 'update',
      'fullDocument.address.country': 'France',
      'fullDocument.preferences.notifications': true
    }
  }
];

// Filtrer sur tableaux avec $elemMatch
const pipeline = [
  {
    $match: {
      operationType: 'insert',
      'fullDocument.items': {
        $elemMatch: {
          category: 'electronics',
          price: { $gt: 500 }
        }
      }
    }
  }
];

// Filtrer sur taille de tableau
const pipeline = [
  {
    $match: {
      'fullDocument.tags': { $size: { $gte: 3 } }
    }
  }
];
```

### 3.4 Filtrage sur champs modifi√©s (updateDescription)

```javascript
// Surveiller uniquement les changements de statut
const pipeline = [
  {
    $match: {
      operationType: 'update',
      'updateDescription.updatedFields.status': { $exists: true }
    }
  }
];

// Surveiller les modifications de plusieurs champs sp√©cifiques
const pipeline = [
  {
    $match: {
      operationType: 'update',
      $or: [
        { 'updateDescription.updatedFields.price': { $exists: true } },
        { 'updateDescription.updatedFields.stock': { $exists: true } },
        { 'updateDescription.updatedFields.availability': { $exists: true } }
      ]
    }
  }
];

// Exclure les modifications de certains champs (ex: lastModified)
const pipeline = [
  {
    $match: {
      operationType: 'update',
      'updateDescription.updatedFields.lastModified': { $exists: false }
    }
  }
];
```

---

## 4. Transformation avec $project

### 4.1 R√©duire la taille des √©v√©nements

```javascript
// Projeter uniquement les champs n√©cessaires
const pipeline = [
  {
    $match: { operationType: 'insert' }
  },
  {
    $project: {
      _id: 1,
      operationType: 1,
      // Seulement quelques champs du document
      'fullDocument._id': 1,
      'fullDocument.orderId': 1,
      'fullDocument.totalAmount': 1,
      'fullDocument.status': 1,
      'fullDocument.createdAt': 1
      // Exclure tous les autres champs volumineux
    }
  }
];

changeStream.on('change', (change) => {
  // change.fullDocument ne contient que les champs projet√©s
  // √âconomie significative de bande passante
});
```

### 4.2 Transformation et enrichissement

```javascript
// Ajouter des champs calcul√©s
const pipeline = [
  {
    $match: { operationType: 'insert' }
  },
  {
    $project: {
      operationType: 1,
      documentId: '$documentKey._id',
      // Champs calcul√©s
      totalItems: { $size: { $ifNull: ['$fullDocument.items', []] } },
      avgItemPrice: {
        $avg: '$fullDocument.items.price'
      },
      orderYear: { $year: '$fullDocument.createdAt' },
      orderMonth: { $month: '$fullDocument.createdAt' },
      // Simplification de structure
      customer: {
        id: '$fullDocument.customerId',
        name: '$fullDocument.customerName',
        tier: '$fullDocument.customerTier'
      }
    }
  }
];

// √âv√©nement transform√© re√ßu par le client
{
  operationType: 'insert',
  documentId: ObjectId('...'),
  totalItems: 3,
  avgItemPrice: 45.67,
  orderYear: 2024,
  orderMonth: 12,
  customer: {
    id: 'CUST-123',
    name: 'John Doe',
    tier: 'gold'
  }
}
```

### 4.3 Renommage et restructuration

```javascript
const pipeline = [
  {
    $match: { operationType: 'update' }
  },
  {
    $project: {
      // Renommer des champs pour compatibilit√©
      event_type: '$operationType',
      entity_id: '$documentKey._id',
      timestamp: '$clusterTime',
      // Aplatir la structure
      updated_status: '$updateDescription.updatedFields.status',
      updated_amount: '$updateDescription.updatedFields.totalAmount',
      // Cr√©er un objet simplifi√©
      metadata: {
        db: '$ns.db',
        collection: '$ns.coll',
        version: { $literal: '1.0' }
      }
    }
  }
];
```

---

## 5. Cas d'usage avanc√©s de filtrage

### Cas 1 : Surveillance s√©lective par environnement

```javascript
// Surveiller uniquement les modifications en production
class EnvironmentAwareChangeStream {
  constructor(db, environment) {
    this.db = db;
    this.environment = environment;
  }

  async initialize() {
    // Pipeline adapt√© √† l'environnement
    const pipeline = this.buildEnvironmentPipeline();

    const changeStream = this.db.watch(pipeline, {
      fullDocument: 'updateLookup'
    });

    changeStream.on('change', (change) => {
      this.handleChange(change);
    });
  }

  buildEnvironmentPipeline() {
    const basePipeline = [];

    switch (this.environment) {
      case 'production':
        // En prod : surveiller tout sauf les op√©rations syst√®me
        basePipeline.push({
          $match: {
            'ns.coll': { $not: { $regex: /^system\./ } },
            operationType: { $in: ['insert', 'update', 'delete'] }
          }
        });
        break;

      case 'staging':
        // En staging : surveiller uniquement collections critiques
        basePipeline.push({
          $match: {
            'ns.coll': { $in: ['orders', 'payments', 'users'] },
            operationType: { $ne: 'delete' }
          }
        });
        break;

      case 'development':
        // En dev : surveiller uniquement insertions pour debug
        basePipeline.push({
          $match: {
            operationType: 'insert'
          }
        });
        break;
    }

    // Toujours exclure les collections de monitoring
    basePipeline.push({
      $match: {
        'ns.coll': { $nin: ['logs', 'metrics', 'events'] }
      }
    });

    return basePipeline;
  }

  handleChange(change) {
    console.log(`[${this.environment}] Change detected:`, {
      type: change.operationType,
      collection: change.ns.coll,
      id: change.documentKey._id
    });
  }
}

// Utilisation
const prodMonitor = new EnvironmentAwareChangeStream(db, 'production');
await prodMonitor.initialize();
```

### Cas 2 : Filtrage par priorit√© m√©tier

```javascript
// Syst√®me de priorit√©s pour traitement diff√©renci√©
class PriorityBasedChangeStream {
  constructor(db) {
    this.db = db;
    this.handlers = {
      critical: [],
      high: [],
      normal: [],
      low: []
    };
  }

  async initialize() {
    // Pipeline pour √©v√©nements critiques
    this.watchCriticalEvents();

    // Pipeline pour √©v√©nements haute priorit√©
    this.watchHighPriorityEvents();

    // Pipeline pour √©v√©nements normaux
    this.watchNormalEvents();
  }

  watchCriticalEvents() {
    const pipeline = [
      {
        $match: {
          $or: [
            // Commandes > 10000‚Ç¨
            {
              operationType: 'insert',
              'fullDocument.type': 'order',
              'fullDocument.amount': { $gt: 10000 }
            },
            // √âchecs de paiement
            {
              operationType: 'update',
              'fullDocument.type': 'payment',
              'fullDocument.status': 'failed'
            },
            // Comptes suspendus
            {
              operationType: 'update',
              'fullDocument.type': 'account',
              'updateDescription.updatedFields.suspended': true
            }
          ]
        }
      },
      {
        $project: {
          priority: { $literal: 'critical' },
          operationType: 1,
          documentId: '$documentKey._id',
          details: '$fullDocument'
        }
      }
    ];

    const stream = this.db.watch(pipeline, {
      fullDocument: 'updateLookup'
    });

    stream.on('change', (change) => {
      // Traitement imm√©diat pour √©v√©nements critiques
      this.processCritical(change);
    });
  }

  watchHighPriorityEvents() {
    const pipeline = [
      {
        $match: {
          $or: [
            // Nouvelles commandes normales
            {
              operationType: 'insert',
              'fullDocument.type': 'order',
              'fullDocument.amount': { $lte: 10000, $gt: 1000 }
            },
            // Changements de statut importants
            {
              operationType: 'update',
              'updateDescription.updatedFields.status': {
                $in: ['shipped', 'delivered', 'cancelled']
              }
            }
          ]
        }
      },
      {
        $project: {
          priority: { $literal: 'high' },
          operationType: 1,
          documentId: '$documentKey._id',
          details: '$fullDocument'
        }
      }
    ];

    const stream = this.db.watch(pipeline);

    stream.on('change', (change) => {
      // Queue avec priorit√© haute
      this.queueForProcessing('high', change);
    });
  }

  watchNormalEvents() {
    const pipeline = [
      {
        $match: {
          // Tout le reste
          operationType: { $in: ['insert', 'update'] }
        }
      },
      {
        $project: {
          priority: { $literal: 'normal' },
          operationType: 1,
          documentId: '$documentKey._id'
        }
      }
    ];

    const stream = this.db.watch(pipeline);

    stream.on('change', (change) => {
      this.queueForProcessing('normal', change);
    });
  }

  processCritical(change) {
    // Traitement imm√©diat + alerte
    console.log('üö® CRITICAL EVENT:', change);
    this.sendAlert(change);
    this.processImmediately(change);
  }

  queueForProcessing(priority, change) {
    // Ajouter √† la queue appropri√©e
    this.handlers[priority].push(change);
  }

  async sendAlert(change) {
    // Int√©gration avec syst√®me d'alerting
    console.error('Alert sent for critical event');
  }

  async processImmediately(change) {
    // Traitement synchrone pour √©v√©nements critiques
    console.log('Processing immediately...');
  }
}
```

### Cas 3 : Filtrage g√©ographique et compliance

```javascript
// Filtrage bas√© sur la g√©olocalisation pour RGPD/compliance
class GDPRCompliantChangeStream {
  constructor(db, region) {
    this.db = db;
    this.region = region; // 'EU', 'US', 'APAC', etc.
  }

  async initialize() {
    const pipeline = this.buildCompliancePipeline();

    const changeStream = this.db.watch(pipeline, {
      fullDocument: 'updateLookup'
    });

    changeStream.on('change', async (change) => {
      await this.handleCompliantChange(change);
    });
  }

  buildCompliancePipeline() {
    const pipeline = [];

    // Filtrer par r√©gion pour donn√©es utilisateur
    if (this.region === 'EU') {
      pipeline.push({
        $match: {
          $or: [
            // Utilisateurs EU uniquement
            {
              'ns.coll': 'users',
              'fullDocument.region': 'EU'
            },
            // Ou collections non-sensibles (tout le monde)
            {
              'ns.coll': { $in: ['products', 'categories', 'articles'] }
            }
          ]
        }
      });

      // Masquer les donn√©es sensibles
      pipeline.push({
        $project: {
          operationType: 1,
          documentKey: 1,
          ns: 1,
          // Pour les users, masquer les PII
          'fullDocument._id': 1,
          'fullDocument.userId': 1,
          'fullDocument.region': 1,
          'fullDocument.createdAt': 1,
          // NE PAS inclure: email, phone, address, etc.
          // Ou les hash
          'fullDocument.emailHash': {
            $cond: {
              if: { $eq: ['$ns.coll', 'users'] },
              then: { $substr: [{ $toString: '$fullDocument.email' }, 0, 8] },
              else: '$$REMOVE'
            }
          }
        }
      });
    }

    return pipeline;
  }

  async handleCompliantChange(change) {
    // Log d'audit pour compliance
    await this.db.collection('compliance_audit').insertOne({
      timestamp: new Date(),
      region: this.region,
      operationType: change.operationType,
      collection: change.ns.coll,
      documentId: change.documentKey._id,
      // Ne pas logger les donn√©es sensibles
      dataAccessed: false
    });

    // Traitement m√©tier
    await this.processChange(change);
  }

  async processChange(change) {
    console.log('Processing compliant change:', {
      type: change.operationType,
      collection: change.ns.coll,
      region: this.region
    });
  }
}

// Utilisation multi-r√©gion
const euStream = new GDPRCompliantChangeStream(euDb, 'EU');
const usStream = new GDPRCompliantChangeStream(usDb, 'US');

await Promise.all([
  euStream.initialize(),
  usStream.initialize()
]);
```

### Cas 4 : Filtrage par fen√™tre temporelle

```javascript
// Surveiller uniquement pendant certaines plages horaires
class TimeWindowedChangeStream {
  constructor(collection, timeWindow) {
    this.collection = collection;
    this.timeWindow = timeWindow; // { start: '09:00', end: '18:00' }
    this.changeStream = null;
  }

  async initialize() {
    this.scheduleActivation();
  }

  scheduleActivation() {
    // V√©rifier toutes les minutes
    setInterval(() => {
      const now = new Date();
      const currentTime = `${now.getHours().toString().padStart(2, '0')}:${now.getMinutes().toString().padStart(2, '0')}`;

      const shouldBeActive =
        currentTime >= this.timeWindow.start &&
        currentTime <= this.timeWindow.end;

      if (shouldBeActive && !this.changeStream) {
        this.activate();
      } else if (!shouldBeActive && this.changeStream) {
        this.deactivate();
      }
    }, 60000);

    // Activer imm√©diatement si dans la fen√™tre
    this.scheduleActivation();
  }

  async activate() {
    console.log('Activating Change Stream for business hours');

    const pipeline = [
      {
        $match: {
          operationType: { $in: ['insert', 'update'] }
        }
      }
    ];

    this.changeStream = this.collection.watch(pipeline);

    this.changeStream.on('change', (change) => {
      this.handleChange(change);
    });
  }

  async deactivate() {
    console.log('Deactivating Change Stream outside business hours');

    if (this.changeStream) {
      await this.changeStream.close();
      this.changeStream = null;
    }
  }

  handleChange(change) {
    console.log('Business hours event:', {
      type: change.operationType,
      id: change.documentKey._id,
      timestamp: new Date()
    });
  }
}

// Utilisation
const businessHoursStream = new TimeWindowedChangeStream(
  db.collection('transactions'),
  { start: '09:00', end: '18:00' }
);

await businessHoursStream.initialize();
```

---

## 6. Optimisations avanc√©es

### 6.1 Index pour am√©liorer les performances de filtrage

```javascript
// Si vous filtrez sur fullDocument.status fr√©quemment
await collection.createIndex({ status: 1 });

// Si vous filtrez sur des champs imbriqu√©s
await collection.createIndex({ 'address.country': 1 });

// Index compos√© pour filtres complexes
await collection.createIndex({
  status: 1,
  totalAmount: 1,
  createdAt: -1
});

// Avec fullDocument: 'updateLookup', les index am√©liorent le lookup
```

### 6.2 Batch processing pour r√©duire la charge

```javascript
class BatchedChangeStreamProcessor {
  constructor(collection, batchSize = 100, intervalMs = 1000) {
    this.collection = collection;
    this.batchSize = batchSize;
    this.intervalMs = intervalMs;
    this.buffer = [];
  }

  async initialize() {
    const changeStream = this.collection.watch([], {
      batchSize: this.batchSize // Taille des batches MongoDB
    });

    changeStream.on('change', (change) => {
      this.buffer.push(change);

      // Traiter imm√©diatement si buffer plein
      if (this.buffer.length >= this.batchSize) {
        this.processBatch();
      }
    });

    // Traiter p√©riodiquement m√™me si buffer pas plein
    setInterval(() => {
      if (this.buffer.length > 0) {
        this.processBatch();
      }
    }, this.intervalMs);
  }

  async processBatch() {
    const batch = [...this.buffer];
    this.buffer = [];

    console.log(`Processing batch of ${batch.length} events`);

    // Traitement parall√®le
    await Promise.all(
      batch.map(change => this.processChange(change))
    );
  }

  async processChange(change) {
    // Traitement individuel
    // ...
  }
}
```

### 6.3 Pipeline optimization order

```javascript
// ‚ùå MAUVAIS : $project avant $match (traite tous les docs)
const badPipeline = [
  {
    $project: {
      operationType: 1,
      'fullDocument.status': 1,
      'fullDocument.amount': 1
    }
  },
  {
    $match: {
      operationType: 'insert',
      'fullDocument.status': 'pending'
    }
  }
];

// ‚úÖ BON : $match en premier (filtre d'abord)
const goodPipeline = [
  {
    $match: {
      operationType: 'insert',
      'fullDocument.status': 'pending'
    }
  },
  {
    $project: {
      operationType: 1,
      'fullDocument.status': 1,
      'fullDocument.amount': 1
    }
  }
];

// ‚úÖ OPTIMAL : Match le plus s√©lectif d'abord
const optimalPipeline = [
  {
    $match: {
      operationType: 'insert' // Tr√®s s√©lectif
    }
  },
  {
    $match: {
      'fullDocument.status': 'pending', // Moins s√©lectif
      'fullDocument.amount': { $gt: 1000 }
    }
  },
  {
    $project: {
      // Projection en dernier
      operationType: 1,
      'fullDocument.status': 1,
      'fullDocument.amount': 1
    }
  }
];
```

### 6.4 R√©utilisation de pipelines

```javascript
class PipelineFactory {
  static getOrdersPipeline(options = {}) {
    const pipeline = [
      { $match: { 'ns.coll': 'orders' } }
    ];

    if (options.minAmount) {
      pipeline.push({
        $match: {
          'fullDocument.totalAmount': { $gte: options.minAmount }
        }
      });
    }

    if (options.status) {
      pipeline.push({
        $match: {
          'fullDocument.status': options.status
        }
      });
    }

    if (options.lightweight) {
      pipeline.push({
        $project: {
          operationType: 1,
          'fullDocument._id': 1,
          'fullDocument.orderId': 1,
          'fullDocument.status': 1
        }
      });
    }

    return pipeline;
  }

  static getPaymentsPipeline(options = {}) {
    return [
      { $match: { 'ns.coll': 'payments' } },
      {
        $match: {
          'fullDocument.status': options.status || 'completed'
        }
      }
    ];
  }
}

// Utilisation
const pipeline = PipelineFactory.getOrdersPipeline({
  minAmount: 1000,
  status: 'pending',
  lightweight: true
});

const changeStream = collection.watch(pipeline);
```

---

## 7. Monitoring et debugging des pipelines

### 7.1 Logging des √©v√©nements filtr√©s

```javascript
class MonitoredChangeStream {
  constructor(collection, pipeline) {
    this.collection = collection;
    this.pipeline = pipeline;
    this.stats = {
      received: 0,
      processed: 0,
      filtered: 0,
      errors: 0
    };
  }

  async initialize() {
    // Change Stream sans pipeline pour compter tous les √©v√©nements
    const rawStream = this.collection.watch();
    rawStream.on('change', () => {
      this.stats.received++;
    });

    // Change Stream avec pipeline
    const filteredStream = this.collection.watch(this.pipeline);

    filteredStream.on('change', async (change) => {
      this.stats.processed++;

      try {
        await this.processChange(change);
      } catch (error) {
        this.stats.errors++;
        console.error('Processing error:', error);
      }
    });

    // Rapports p√©riodiques
    setInterval(() => {
      this.stats.filtered = this.stats.received - this.stats.processed;

      console.log('Change Stream Stats:', {
        ...this.stats,
        filterRate: `${((this.stats.filtered / this.stats.received) * 100).toFixed(2)}%`,
        errorRate: `${((this.stats.errors / this.stats.processed) * 100).toFixed(2)}%`
      });
    }, 60000);
  }

  async processChange(change) {
    // Traitement m√©tier
  }
}
```

### 7.2 Test de pipelines

```javascript
// Utilitaire pour tester les pipelines
class PipelineTester {
  static async testPipeline(collection, pipeline, testDocs) {
    console.log('Testing pipeline:', JSON.stringify(pipeline, null, 2));

    // Ins√©rer des documents de test
    for (const doc of testDocs) {
      await collection.insertOne(doc);
    }

    // √âcouter pendant 5 secondes
    const changeStream = collection.watch(pipeline);
    const receivedEvents = [];

    changeStream.on('change', (change) => {
      receivedEvents.push(change);
      console.log('Event received:', {
        operationType: change.operationType,
        documentId: change.documentKey._id
      });
    });

    await new Promise(resolve => setTimeout(resolve, 5000));
    await changeStream.close();

    // Nettoyage
    await collection.deleteMany({
      _id: { $in: testDocs.map(d => d._id) }
    });

    console.log(`Test complete: ${receivedEvents.length} events matched`);
    return receivedEvents;
  }
}

// Utilisation
const testDocs = [
  { _id: new ObjectId(), status: 'pending', amount: 100 },
  { _id: new ObjectId(), status: 'pending', amount: 2000 },
  { _id: new ObjectId(), status: 'completed', amount: 1500 }
];

const pipeline = [
  {
    $match: {
      operationType: 'insert',
      'fullDocument.status': 'pending',
      'fullDocument.amount': { $gt: 1000 }
    }
  }
];

const events = await PipelineTester.testPipeline(
  db.collection('test_orders'),
  pipeline,
  testDocs
);

// Devrait recevoir 1 √©v√©nement (amount: 2000, status: pending)
```

---

## 8. Bonnes pratiques de configuration

### ‚úÖ DO (√Ä faire)

```javascript
// 1. Filtrer t√¥t et pr√©cis√©ment
const pipeline = [
  {
    $match: {
      operationType: 'insert',
      'fullDocument.critical': true
    }
  }
];

// 2. Utiliser fullDocument: 'default' si possible (√©conomie de bande passante)
const changeStream = collection.watch(pipeline, {
  fullDocument: 'default'
});

// 3. Projeter uniquement les champs n√©cessaires
const pipeline = [
  { $match: { operationType: 'insert' } },
  {
    $project: {
      'fullDocument._id': 1,
      'fullDocument.essentialField': 1
    }
  }
];

// 4. Configurer batchSize appropri√©
const changeStream = collection.watch(pipeline, {
  batchSize: 100 // Ajuster selon volum√©trie
});

// 5. Sauvegarder les resume tokens
let resumeToken;
changeStream.on('change', (change) => {
  resumeToken = change._id;
  // Sauvegarder p√©riodiquement dans DB
});
```

### ‚ùå DON'T (√Ä √©viter)

```javascript
// 1. Ne pas utiliser fullDocument: 'updateLookup' sans raison
// Impact performance significatif
const changeStream = collection.watch([], {
  fullDocument: 'updateLookup' // ‚ùå Seulement si vraiment n√©cessaire
});

// 2. Ne pas filtrer c√¥t√© client ce qui peut l'√™tre c√¥t√© serveur
// ‚ùå MAUVAIS
const changeStream = collection.watch();
changeStream.on('change', (change) => {
  if (change.operationType === 'insert') { // Filtrage client
    // ...
  }
});

// ‚úÖ BON
const pipeline = [{ $match: { operationType: 'insert' } }];
const changeStream = collection.watch(pipeline); // Filtrage serveur

// 3. Ne pas oublier la gestion d'erreur
// ‚ùå MAUVAIS
const changeStream = collection.watch(pipeline);

// ‚úÖ BON
const changeStream = collection.watch(pipeline);
changeStream.on('error', async (error) => {
  console.error('Stream error:', error);
  await handleError(error);
});

// 4. Ne pas activer pre/post images sur toutes les collections
// Impact stockage et performance significatif
```

---

## Conclusion

La configuration et le filtrage appropri√©s des Change Streams sont essentiels pour :
- ‚úÖ **R√©duire la bande passante** : Filtrage serveur et projection
- ‚úÖ **Am√©liorer les performances** : Index appropri√©s, batch processing
- ‚úÖ **Optimiser les co√ªts** : Moins de donn√©es transf√©r√©es et stock√©es
- ‚úÖ **Simplifier le code client** : Transformation c√¥t√© serveur

**Points cl√©s √† retenir :**
1. Toujours filtrer avec `$match` en premier dans le pipeline
2. Utiliser `fullDocument: 'default'` sauf si n√©cessaire
3. Projeter uniquement les champs n√©cessaires
4. Activer `pre/post images` uniquement pour collections critiques
5. Tester les pipelines avant d√©ploiement en production
6. Monitorer les m√©triques de filtrage (taux de filtrage, erreurs)

---


‚è≠Ô∏è [Resume tokens](/16-fonctionnalites-avancees/01.3-resume-tokens.md)
