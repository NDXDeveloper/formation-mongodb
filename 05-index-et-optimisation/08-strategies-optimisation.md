ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 5.8 StratÃ©gies d'optimisation des requÃªtes

## Introduction

Maintenant que vous comprenez les index et le Query Planner, il est temps d'apprendre les **stratÃ©gies concrÃ¨tes** pour optimiser vos requÃªtes MongoDB. L'optimisation n'est pas une science exacte, mais plutÃ´t un ensemble de techniques et de bonnes pratiques Ã  appliquer selon votre contexte.

Dans ce chapitre, nous allons explorer :
- ğŸ¯ Les **principes fondamentaux** d'optimisation
- ğŸ”§ Les **techniques pratiques** Ã©prouvÃ©es
- ğŸ“Š Les **patterns** d'optimisation courants
- âš¡ Les **anti-patterns** Ã  Ã©viter
- ğŸš€ Des **exemples concrets** avant/aprÃ¨s

L'objectif : rendre vos requÃªtes MongoDB rapides, efficaces et scalables.

---

## Les 10 principes fondamentaux d'optimisation

### Principe 1 : Mesurer avant d'optimiser

```
"On ne peut pas amÃ©liorer ce qu'on ne mesure pas"

Le cycle d'optimisation :
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. MESURER
   â””â”€ Utiliser explain("executionStats")
   â””â”€ Noter les mÃ©triques actuelles

2. IDENTIFIER
   â””â”€ Trouver le goulot d'Ã©tranglement
   â””â”€ Comprendre le problÃ¨me

3. OPTIMISER
   â””â”€ Appliquer une technique
   â””â”€ Modifier un index

4. VALIDER
   â””â”€ Re-mesurer avec explain()
   â””â”€ Comparer avant/aprÃ¨s

5. DOCUMENTER
   â””â”€ Noter l'amÃ©lioration
   â””â”€ Expliquer le changement
```

**Exemple** :

```javascript
// 1. MESURER (avant)
const before = db.orders.find({ status: "pending" })
  .explain("executionStats")
console.log(`Avant : ${before.executionStats.executionTimeMillis}ms`)

// 2. IDENTIFIER le problÃ¨me
// â†’ COLLSCAN sur 1M documents

// 3. OPTIMISER
db.orders.createIndex({ status: 1 })

// 4. VALIDER (aprÃ¨s)
const after = db.orders.find({ status: "pending" })
  .explain("executionStats")
console.log(`AprÃ¨s : ${after.executionStats.executionTimeMillis}ms`)
console.log(`AmÃ©lioration : ${before.executionStats.executionTimeMillis / after.executionStats.executionTimeMillis}x`)

// 5. DOCUMENTER
// Index crÃ©Ã© le 2024-12-01
// AmÃ©lioration : 3500ms â†’ 15ms (233x plus rapide)
// Raison : Ã‰limination du COLLSCAN sur 1M documents
```

### Principe 2 : L'index appropriÃ© avant tout

```
Un bon index > Tout autre optimisation

PrioritÃ© des optimisations :
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. Index appropriÃ©         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ Impact : 100x - 1000x
2. Index composÃ© optimal   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   Impact : 10x - 100x
3. Index avec options      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     Impact : 5x - 20x
4. Optimisation requÃªte    â–ˆâ–ˆâ–ˆâ–ˆ         Impact : 2x - 5x
5. ParamÃ¨tres serveur      â–ˆâ–ˆ           Impact : 1.1x - 2x
```

### Principe 3 : La rÃ¨gle ESR

Pour les index composÃ©s, suivez toujours la rÃ¨gle **ESR** :

```
E = Equality (Ã‰galitÃ©)
S = Sort (Tri)
R = Range (Plage)

Ordre optimal dans l'index :
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. EQUALITY - Les filtres d'Ã©galitÃ© exacte
   { status: "pending" }
   { userId: 12345 }

2. SORT - Les champs de tri
   .sort({ createdAt: -1 })

3. RANGE - Les filtres de plage
   { price: { $gte: 10, $lte: 100 } }
   { age: { $gt: 18 } }
```

**Exemple** :

```javascript
// RequÃªte
db.orders.find({
  userId: 12345,              // E - Equality
  status: "pending",          // E - Equality
  amount: { $gte: 100 }       // R - Range
}).sort({
  createdAt: -1               // S - Sort
})

// Index optimal selon ESR
db.orders.createIndex({
  userId: 1,        // E - Equality en premier
  status: 1,        // E - Equality en second
  createdAt: -1,    // S - Sort en troisiÃ¨me
  amount: 1         // R - Range en dernier
})
```

### Principe 4 : Viser un ratio de 100%

```
Ratio d'efficacitÃ© = nReturned / totalDocsExamined

Objectifs :
â•â•â•â•â•â•â•â•â•â•â•

100%     â˜…â˜…â˜…â˜…â˜… PARFAIT - Chaque document examinÃ© est retournÃ©
80-99%   â˜…â˜…â˜…â˜…  EXCELLENT
50-79%   â˜…â˜…â˜…   BON
20-49%   â˜…â˜…    ACCEPTABLE
< 20%    â˜…     MAUVAIS - Beaucoup de gaspillage
< 5%           CRITIQUE - Optimisation urgente
```

### Principe 5 : PrivilÃ©gier la lecture sur l'Ã©criture

```
Les index accÃ©lÃ¨rent les lectures mais ralentissent les Ã©critures

Ã‰quation d'optimisation :
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

BÃ©nÃ©fice index = (Lectures Ã— Gain lecture) - (Ã‰critures Ã— CoÃ»t Ã©criture)

Si Lectures >> Ã‰critures :
â””â”€ âœ… Index trÃ¨s bÃ©nÃ©fique

Si Lectures â‰ˆ Ã‰critures :
â””â”€ âš ï¸ Ã‰valuer le compromis

Si Ã‰critures >> Lectures :
â””â”€ âŒ Peut-Ãªtre Ã©viter l'index
```

### Principe 6 : Ã‰viter les requÃªtes sur tableaux quand possible

```javascript
// âŒ LENT : RequÃªte sur tableau
{
  tags: ["mongodb", "database", "nosql"]  // Tableau
}
db.articles.find({ tags: "mongodb" })
// â†’ Index multikey, moins efficace

// âœ… RAPIDE : Champ dÃ©dupliquÃ©
{
  tags: ["mongodb", "database", "nosql"],
  primaryTag: "mongodb"                    // Champ simple
}
db.articles.createIndex({ primaryTag: 1 })
db.articles.find({ primaryTag: "mongodb" })
// â†’ Index simple, plus efficace
```

### Principe 7 : Limiter les rÃ©sultats tÃ´t

```javascript
// âŒ MAUVAIS : Limite appliquÃ©e tard
db.posts.find()
  .sort({ publishedAt: -1 })
  .skip(100)
  .limit(10)
// â†’ Trie TOUS les documents puis skip

// âœ… BON : Index pour tri + limite
db.posts.createIndex({ publishedAt: -1 })
db.posts.find()
  .sort({ publishedAt: -1 })
  .skip(100)
  .limit(10)
// â†’ Parcourt l'index directement, s'arrÃªte Ã  110
```

### Principe 8 : Projections pour rÃ©duire les donnÃ©es

```javascript
// âŒ LENT : RÃ©cupÃ¨re tous les champs
db.users.find({ city: "Paris" })
// â†’ TransfÃ¨re beaucoup de donnÃ©es

// âœ… RAPIDE : Ne rÃ©cupÃ¨re que le nÃ©cessaire
db.users.find(
  { city: "Paris" },
  { name: 1, email: 1, _id: 0 }
)
// â†’ TransfÃ¨re moins de donnÃ©es
// â†’ Peut Ãªtre une covered query
```

### Principe 9 : Ã‰viter les expressions coÃ»teuses

```javascript
// âŒ TRÃˆS LENT : $where avec JavaScript
db.users.find({
  $where: function() {
    return this.age > 18 && this.status === "active"
  }
})
// â†’ ExÃ©cute JavaScript pour chaque document
// â†’ Ne peut pas utiliser d'index

// âœ… RAPIDE : OpÃ©rateurs natifs
db.users.find({
  age: { $gt: 18 },
  status: "active"
})
// â†’ Peut utiliser un index
```

### Principe 10 : Penser en termes de batch

```javascript
// âŒ LENT : Une requÃªte par document
for (let userId of userIds) {
  db.users.findOne({ _id: userId })
}
// â†’ 1000 requÃªtes pour 1000 utilisateurs

// âœ… RAPIDE : Batch avec $in
db.users.find({
  _id: { $in: userIds }
})
// â†’ 1 requÃªte pour 1000 utilisateurs
```

---

## StratÃ©gies d'optimisation par scÃ©nario

### ScÃ©nario 1 : Recherche simple lente

**ProblÃ¨me** :

```javascript
// RequÃªte lente
db.products.find({ sku: "PROD-12345" })

// explain() montre :
{
  "stage": "COLLSCAN",
  "executionTimeMillis": 3500,
  "totalDocsExamined": 5000000
}
```

**Solution** :

```javascript
// CrÃ©er un index unique sur SKU
db.products.createIndex({ sku: 1 }, { unique: true })

// RÃ©sultat :
{
  "stage": "IXSCAN",
  "indexName": "sku_1",
  "executionTimeMillis": 2,
  "totalDocsExamined": 1
}

// AmÃ©lioration : 3500ms â†’ 2ms (1750x plus rapide)
```

### ScÃ©nario 2 : Filtres multiples

**ProblÃ¨me** :

```javascript
// RequÃªte avec plusieurs filtres
db.orders.find({
  userId: 12345,
  status: "pending",
  amount: { $gte: 100 }
})

// Avec index simple sur userId
{
  "stage": "FETCH",
  "inputStage": { "stage": "IXSCAN", "indexName": "userId_1" },
  "executionTimeMillis": 145,
  "totalDocsExamined": 5000,
  "nReturned": 50
}
// Ratio : 50/5000 = 1% (mauvais)
```

**Solution** :

```javascript
// Index composÃ© selon ESR
db.orders.createIndex({
  userId: 1,      // E - Equality
  status: 1,      // E - Equality
  amount: 1       // R - Range
})

// RÃ©sultat :
{
  "stage": "IXSCAN",
  "indexName": "userId_1_status_1_amount_1",
  "executionTimeMillis": 8,
  "totalDocsExamined": 50,
  "nReturned": 50
}
// Ratio : 50/50 = 100% (parfait)
// AmÃ©lioration : 145ms â†’ 8ms (18x plus rapide)
```

### ScÃ©nario 3 : Tri sans index

**ProblÃ¨me** :

```javascript
// Tri sur grande collection
db.posts.find({ status: "published" })
  .sort({ publishedAt: -1 })
  .limit(20)

// explain() montre :
{
  "stage": "LIMIT",
  "inputStage": {
    "stage": "SORT",              // âš ï¸ Tri en mÃ©moire !
    "sortPattern": { "publishedAt": -1 },
    "inputStage": {
      "stage": "IXSCAN",
      "indexName": "status_1"
    }
  },
  "executionTimeMillis": 1250
}
```

**Solution** :

```javascript
// Index composÃ© incluant le champ de tri
db.posts.createIndex({
  status: 1,        // E - Equality
  publishedAt: -1   // S - Sort
})

// RÃ©sultat :
{
  "stage": "LIMIT",
  "inputStage": {
    "stage": "IXSCAN",            // Tri via l'index !
    "indexName": "status_1_publishedAt_-1"
  },
  "executionTimeMillis": 5
}
// AmÃ©lioration : 1250ms â†’ 5ms (250x plus rapide)
```

### ScÃ©nario 4 : RequÃªtes OR inefficaces

**ProblÃ¨me** :

```javascript
// OR sur champs diffÃ©rents
db.users.find({
  $or: [
    { email: "user@example.com" },
    { username: "user123" }
  ]
})

// Sans index : COLLSCAN
// Avec index sur email seulement : Inefficace
```

**Solution A : Deux index** :

```javascript
// CrÃ©er un index sur chaque champ
db.users.createIndex({ email: 1 })
db.users.createIndex({ username: 1 })

// MongoDB utilisera les deux index et fusionnera les rÃ©sultats
// explain() montre :
{
  "stage": "SUBPLAN",
  "inputStage": {
    "stage": "OR",
    "inputStages": [
      { "stage": "IXSCAN", "indexName": "email_1" },
      { "stage": "IXSCAN", "indexName": "username_1" }
    ]
  }
}
```

**Solution B : DÃ©normalisation** (si applicable) :

```javascript
// Si les requÃªtes OR sont trÃ¨s frÃ©quentes,
// considÃ©rer une dÃ©normalisation

// Document Ã©tendu
{
  _id: ObjectId("..."),
  email: "user@example.com",
  username: "user123",
  loginIdentifiers: [          // â† Tableau combinÃ©
    "user@example.com",
    "user123"
  ]
}

// Index multikey
db.users.createIndex({ loginIdentifiers: 1 })

// RequÃªte simplifiÃ©e
db.users.find({ loginIdentifiers: "user123" })
```

### ScÃ©nario 5 : Comptage lent

**ProblÃ¨me** :

```javascript
// Comptage sur grande collection
db.orders.countDocuments({ status: "pending" })

// Sans index : TrÃ¨s lent (COLLSCAN sur millions de docs)
```

**Solution** :

```javascript
// Index sur le champ de filtre
db.orders.createIndex({ status: 1 })

// Ou utiliser estimatedDocumentCount() si prÃ©cision pas critique
db.orders.estimatedDocumentCount()
// â†’ Utilise les mÃ©tadonnÃ©es, instantanÃ©
// â†’ Mais compte TOUS les documents (pas de filtre)
```

### ScÃ©nario 6 : Pagination inefficace

**ProblÃ¨me** :

```javascript
// Pagination avec skip/limit
// Page 1000 : skip(50000).limit(50)
db.posts.find()
  .sort({ createdAt: -1 })
  .skip(50000)      // âš ï¸ Parcourt 50000 docs !
  .limit(50)

// TrÃ¨s lent sur les pages Ã©loignÃ©es
```

**Solution A : Pagination par curseur** :

```javascript
// PremiÃ¨re page
const page1 = db.posts.find()
  .sort({ createdAt: -1 })
  .limit(50)

const lastDoc = page1[page1.length - 1]

// Page suivante (avec curseur)
const page2 = db.posts.find({
  createdAt: { $lt: lastDoc.createdAt }
})
  .sort({ createdAt: -1 })
  .limit(50)

// Toujours rapide, mÃªme pour page 1000
// Car ne parcourt que 50 documents
```

**Solution B : Index avec _id** (si tri naturel) :

```javascript
// Utiliser _id pour pagination
// _id contient un timestamp

// Page suivante
db.posts.find({
  _id: { $lt: lastSeenId }
})
  .sort({ _id: -1 })
  .limit(50)

// L'index _id est automatique et toujours triÃ©
```

### ScÃ©nario 7 : Regex non optimisÃ©

**ProblÃ¨me** :

```javascript
// Regex qui ne peut pas utiliser d'index
db.users.find({
  email: { $regex: /example.com$/ }    // âš ï¸ Fin de chaÃ®ne
})

// OU
db.users.find({
  name: { $regex: /.*john.*/i }        // âš ï¸ Wildcard au dÃ©but
})

// Ne peut pas utiliser l'index â†’ COLLSCAN
```

**Solution** :

```javascript
// Pour prÃ©fixes : Regex optimisÃ©
db.users.find({
  email: { $regex: /^john/ }           // âœ… DÃ©but de chaÃ®ne
})
// Peut utiliser l'index email_1

// Pour recherche full-text : Index texte
db.users.createIndex({ name: "text" })
db.users.find({
  $text: { $search: "john" }
})

// Pour suffixes : DÃ©normalisation
{
  email: "john@example.com",
  emailDomain: "example.com"           // â† Champ dÃ©diÃ©
}
db.users.createIndex({ emailDomain: 1 })
db.users.find({ emailDomain: "example.com" })
```

### ScÃ©nario 8 : AgrÃ©gations lentes

**ProblÃ¨me** :

```javascript
// AgrÃ©gation sans optimisation
db.orders.aggregate([
  { $match: { status: "completed" } },
  { $group: {
      _id: "$userId",
      total: { $sum: "$amount" }
  }},
  { $sort: { total: -1 } },
  { $limit: 10 }
])

// Lent si pas d'index
```

**Solution** :

```javascript
// Index pour le $match
db.orders.createIndex({ status: 1 })

// RÃ©organiser le pipeline (MongoDB le fait automatiquement, mais...)
db.orders.aggregate([
  { $match: { status: "completed" } },     // Filtrage en premier
  { $sort: { amount: -1 } },               // Tri avant group si possible
  { $group: {
      _id: "$userId",
      total: { $sum: "$amount" }
  }},
  { $limit: 10 }                           // Limite aprÃ¨s group
])

// Index composÃ© pour $match + champs du $group
db.orders.createIndex({ status: 1, userId: 1, amount: 1 })
```

---

## Patterns d'optimisation avancÃ©s

### Pattern 1 : Covered Query (requÃªte couverte)

**Objectif** : RÃ©pondre Ã  la requÃªte uniquement avec l'index, sans lire les documents.

```javascript
// CrÃ©er un index avec tous les champs nÃ©cessaires
db.users.createIndex({ email: 1, name: 1, age: 1 })

// RequÃªte qui utilise UNIQUEMENT les champs indexÃ©s
db.users.find(
  { email: "user@example.com" },
  { _id: 0, email: 1, name: 1, age: 1 }   // Projection sur index
)

// explain() montre :
{
  "stage": "PROJECTION_COVERED",          // âœ… Covered query !
  "totalDocsExamined": 0                  // âœ… 0 documents lus !
}

// Encore plus rapide qu'une requÃªte normale avec index
```

### Pattern 2 : Index partiel pour cas spÃ©cifiques

**Objectif** : Indexer seulement les documents pertinents.

```javascript
// ProblÃ¨me : 95% des commandes sont "completed"
// Seules les "pending" sont souvent recherchÃ©es

// Solution : Index partiel
db.orders.createIndex(
  { status: 1, createdAt: -1 },
  {
    partialFilterExpression: {
      status: { $in: ["pending", "processing"] }
    }
  }
)

// Avantages :
// - Index 20x plus petit
// - Ã‰critures plus rapides
// - Toujours performant pour les requÃªtes pertinentes
```

### Pattern 3 : Index composÃ© avec unique

**Objectif** : Garantir l'unicitÃ© d'une combinaison de champs.

```javascript
// Un user peut avoir plusieurs emails
// Mais chaque email doit Ãªtre unique globalement

db.userEmails.createIndex(
  { userId: 1, email: 1 },
  { unique: true }
)

// Permet :
// - userId: 1, email: "a@ex.com" âœ…
// - userId: 1, email: "b@ex.com" âœ…
// - userId: 2, email: "a@ex.com" âœ…

// Interdit :
// - userId: 1, email: "a@ex.com" (doublon) âŒ
```

### Pattern 4 : DÃ©normalisation calculÃ©e

**Objectif** : PrÃ©-calculer et stocker des valeurs souvent utilisÃ©es.

```javascript
// Au lieu de calculer Ã  chaque requÃªte
db.orders.find({
  $expr: {
    $gt: [{ $multiply: ["$quantity", "$price"] }, 1000]
  }
})
// â†’ Calcul sur chaque document, lent

// Stocker la valeur calculÃ©e
{
  quantity: 10,
  price: 150,
  totalAmount: 1500           // â† CalculÃ© Ã  l'insertion
}

// Index sur la valeur calculÃ©e
db.orders.createIndex({ totalAmount: 1 })

// RequÃªte rapide
db.orders.find({ totalAmount: { $gt: 1000 } })
```

### Pattern 5 : Index pour lookups frÃ©quents

**Objectif** : Optimiser les jointures (agrÃ©gation $lookup).

```javascript
// AgrÃ©gation avec $lookup
db.orders.aggregate([
  { $lookup: {
      from: "users",
      localField: "userId",
      foreignField: "_id",
      as: "user"
  }}
])

// Optimisation : Index sur le foreignField
db.users.createIndex({ _id: 1 })  // DÃ©jÃ  prÃ©sent
// Mais pour autres cas :
db.products.createIndex({ categoryId: 1 })  // Pour lookups sur category
```

### Pattern 6 : Index sparse pour champs optionnels

**Objectif** : Ã‰conomiser de l'espace pour champs peu remplis.

```javascript
// Seulement 5% des users ont un phoneNumber
// 95% n'en ont pas (null ou absent)

// Index sparse
db.users.createIndex(
  { phoneNumber: 1 },
  { sparse: true }
)

// Ã‰conomie : Index 95% plus petit
// Les requÃªtes sur phoneNumber restent rapides
// Les autres requÃªtes ne sont pas affectÃ©es
```

---

## Techniques d'optimisation applicative

### 1. Caching intelligent

```javascript
// Cache applicatif pour donnÃ©es rarement modifiÃ©es
const cache = new Map()

async function getUser(userId) {
  // VÃ©rifier le cache
  if (cache.has(userId)) {
    return cache.get(userId)
  }

  // Sinon, requÃªte DB
  const user = await db.users.findOne({ _id: userId })

  // Mettre en cache (avec TTL)
  cache.set(userId, user)
  setTimeout(() => cache.delete(userId), 60000)  // 1 minute

  return user
}
```

### 2. Batch processing

```javascript
// Au lieu de requÃªtes individuelles
for (const orderId of orderIds) {
  const order = await db.orders.findOne({ _id: orderId })
  // Traiter...
}

// Batch avec $in
const orders = await db.orders.find({
  _id: { $in: orderIds }
}).toArray()
```

### 3. Projection minimale

```javascript
// Ne charger que les champs nÃ©cessaires

// âŒ Charge tout (peut-Ãªtre 50 champs)
const users = db.users.find({ city: "Paris" })

// âœ… Charge seulement ce qui est nÃ©cessaire
const users = db.users.find(
  { city: "Paris" },
  { name: 1, email: 1, _id: 0 }
)

// Ã‰conomie de bande passante et mÃ©moire
```

### 4. Ã‰viter les grandes transactions

```javascript
// âŒ Transaction Ã©norme
const session = client.startSession()
session.startTransaction()
for (let i = 0; i < 100000; i++) {
  await db.collection.insertOne({ ... }, { session })
}
await session.commitTransaction()
// â†’ TrÃ¨s lent, risque de timeout

// âœ… Batches plus petits
for (let i = 0; i < 100000; i += 1000) {
  const batch = data.slice(i, i + 1000)
  await db.collection.insertMany(batch)
}
```

### 5. Utiliser allowDiskUse pour agrÃ©gations

```javascript
// AgrÃ©gation qui dÃ©passe la limite mÃ©moire

// âŒ Erreur si > 100 Mo
db.orders.aggregate([
  { $group: { ... } },
  { $sort: { ... } }
])

// âœ… Autorise l'utilisation du disque
db.orders.aggregate(
  [
    { $group: { ... } },
    { $sort: { ... } }
  ],
  { allowDiskUse: true }
)
```

---

## Anti-patterns Ã  Ã©viter

### Anti-pattern 1 : Index sur chaque champ

```javascript
// âŒ MAUVAIS : Trop d'index
db.users.createIndex({ email: 1 })
db.users.createIndex({ username: 1 })
db.users.createIndex({ firstName: 1 })
db.users.createIndex({ lastName: 1 })
db.users.createIndex({ city: 1 })
db.users.createIndex({ country: 1 })
db.users.createIndex({ age: 1 })
db.users.createIndex({ status: 1 })
// â†’ 9 index ! (avec _id)
// â†’ Ã‰critures trÃ¨s lentes
// â†’ Beaucoup d'espace disque

// âœ… BON : Index ciblÃ©s sur requÃªtes rÃ©elles
db.users.createIndex({ email: 1 }, { unique: true })
db.users.createIndex({ city: 1, age: 1 })
db.users.createIndex({ status: 1, lastLoginAt: -1 })
// â†’ 4 index (avec _id)
// â†’ Couvre les requÃªtes importantes
```

### Anti-pattern 2 : Index redondants

```javascript
// âŒ MAUVAIS : Index redondants
db.products.createIndex({ category: 1 })
db.products.createIndex({ category: 1, price: 1 })
// â†’ L'index composÃ© rend le premier inutile

// âœ… BON : Supprimer le redondant
db.products.dropIndex("category_1")
// Garder seulement : category_1_price_1
// Il peut servir pour :
// - { category: "X" }
// - { category: "X", price: { ... } }
```

### Anti-pattern 3 : Pagination avec skip() profond

```javascript
// âŒ MAUVAIS : skip() avec grande valeur
// Page 1000
db.posts.find()
  .sort({ _id: -1 })
  .skip(50000)
  .limit(50)
// â†’ Parcourt et ignore 50,000 documents !

// âœ… BON : Pagination par curseur
const lastId = previousPage.lastId
db.posts.find({ _id: { $lt: lastId } })
  .sort({ _id: -1 })
  .limit(50)
```

### Anti-pattern 4 : $where pour logique simple

```javascript
// âŒ MAUVAIS : $where avec JavaScript
db.users.find({
  $where: "this.age > 18"
})
// â†’ Ne peut pas utiliser d'index
// â†’ ExÃ©cute JS pour chaque document

// âœ… BON : OpÃ©rateurs natifs
db.users.find({
  age: { $gt: 18 }
})
```

### Anti-pattern 5 : RequÃªtes dans des boucles

```javascript
// âŒ MAUVAIS : N+1 queries
const orders = await db.orders.find({ userId: 123 }).toArray()
for (const order of orders) {
  const product = await db.products.findOne({ _id: order.productId })
  // Traiter...
}
// â†’ Si 100 orders : 101 requÃªtes !

// âœ… BON : AgrÃ©gation ou lookup
const orders = await db.orders.aggregate([
  { $match: { userId: 123 } },
  { $lookup: {
      from: "products",
      localField: "productId",
      foreignField: "_id",
      as: "product"
  }},
  { $unwind: "$product" }
]).toArray()
// â†’ 1 seule requÃªte
```

### Anti-pattern 6 : Tri sans index sur grande collection

```javascript
// âŒ MAUVAIS : Tri en mÃ©moire
db.logs.find()
  .sort({ timestamp: -1 })
  .limit(100)
// â†’ Charge et trie TOUS les documents
// â†’ Peut Ã©chouer si > 100 Mo

// âœ… BON : Index sur le champ de tri
db.logs.createIndex({ timestamp: -1 })
```

### Anti-pattern 7 : Faible cardinalitÃ© comme seul index

```javascript
// âŒ MAUVAIS : Index sur champ boolean seul
db.users.createIndex({ isActive: 1 })
// â†’ Seulement 2 valeurs (true/false)
// â†’ Peut Ãªtre un COLLSCAN serait plus rapide

// âœ… BON : Index composÃ©
db.users.createIndex({ isActive: 1, lastLoginAt: -1 })
// â†’ Plus sÃ©lectif
// â†’ Supporte aussi le tri
```

---

## Checklist d'optimisation

### âœ… Avant de crÃ©er un index

```
â–¡ J'ai identifiÃ© une requÃªte lente avec explain()
â–¡ J'ai calculÃ© le ratio actuel (< 80%)
â–¡ J'ai vÃ©rifiÃ© qu'un index similaire n'existe pas
â–¡ J'ai dÃ©terminÃ© les champs nÃ©cessaires (ESR)
â–¡ J'ai estimÃ© la taille de l'index
â–¡ J'ai vÃ©rifiÃ© la frÃ©quence de la requÃªte
â–¡ J'ai comparÃ© avec le coÃ»t des Ã©critures
â–¡ J'ai testÃ© en environnement de dev/staging
â–¡ J'ai documentÃ© la raison de l'index
```

### âœ… AprÃ¨s optimisation

```
â–¡ J'ai re-testÃ© avec explain("executionStats")
â–¡ Le ratio est maintenant > 80%
â–¡ Le stage est IXSCAN (pas COLLSCAN)
â–¡ Le temps d'exÃ©cution est acceptable (< 100ms)
â–¡ Il n'y a plus de SORT en mÃ©moire si applicable
â–¡ J'ai documentÃ© l'amÃ©lioration (avant/aprÃ¨s)
â–¡ J'ai vÃ©rifiÃ© l'impact sur les Ã©critures
â–¡ J'ai surveillÃ© en production pendant quelques jours
```

### âœ… Maintenance rÃ©guliÃ¨re

```
â–¡ Analyser $indexStats pour identifier les index inutilisÃ©s
â–¡ VÃ©rifier les requÃªtes lentes (profiler)
â–¡ Supprimer les index redondants
â–¡ Mettre Ã  jour les index selon l'Ã©volution des requÃªtes
â–¡ Surveiller la taille totale des index
â–¡ VÃ©rifier que les index tiennent en RAM
â–¡ Documenter les changements
```

---

## Outils et mÃ©thodes de monitoring

### 1. Profiler MongoDB

```javascript
// Activer le profiler pour requÃªtes > 100ms
db.setProfilingLevel(1, { slowms: 100 })

// Analyser les requÃªtes lentes
db.system.profile.find({
  millis: { $gt: 100 }
}).sort({ ts: -1 }).limit(10).pretty()

// Identifier les patterns
db.system.profile.aggregate([
  { $match: { millis: { $gt: 100 } } },
  { $group: {
      _id: "$command.find",
      count: { $sum: 1 },
      avgTime: { $avg: "$millis" },
      maxTime: { $max: "$millis" }
  }},
  { $sort: { count: -1 } }
])
```

### 2. Index statistics

```javascript
// Utilisation des index
db.collection.aggregate([{ $indexStats: {} }])

// Identifier les index non utilisÃ©s
db.collection.aggregate([
  { $indexStats: {} },
  { $match: { "accesses.ops": { $lt: 100 } } }
])
```

### 3. Statistiques de collection

```javascript
// Taille des index
db.collection.stats()

// VÃ©rifier la fragmentation
db.collection.stats().wiredTiger.metadata

// Ratio index/donnÃ©es
const stats = db.collection.stats()
const ratio = stats.totalIndexSize / stats.size
console.log(`Ratio index/donnÃ©es : ${(ratio * 100).toFixed(2)}%`)
```

### 4. Script d'analyse automatique

```javascript
// Script pour analyser toutes les collections
db.getCollectionNames().forEach(collName => {
  print(`\n=== ${collName} ===`)
  const stats = db[collName].stats()

  print(`Documents : ${stats.count}`)
  print(`Taille donnÃ©es : ${(stats.size / 1024 / 1024).toFixed(2)} Mo`)
  print(`Taille index : ${(stats.totalIndexSize / 1024 / 1024).toFixed(2)} Mo`)

  // Index stats
  const indexStats = db[collName].aggregate([{ $indexStats: {} }]).toArray()
  print(`\nIndex (usage) :`)
  indexStats.forEach(idx => {
    print(`  - ${idx.name} : ${idx.accesses.ops} utilisations`)
  })
})
```

---

## Processus d'optimisation complet

### MÃ©thodologie en 7 Ã©tapes

```
Processus d'optimisation MongoDB
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Ã‰tape 1 : IDENTIFIER
â”œâ”€ Activer le profiler
â”œâ”€ Analyser les requÃªtes lentes
â””â”€ Prioriser par impact (frÃ©quence Ã— temps)

Ã‰tape 2 : MESURER
â”œâ”€ explain("executionStats") pour chaque requÃªte
â”œâ”€ Noter les mÃ©triques actuelles
â””â”€ Calculer le ratio d'efficacitÃ©

Ã‰tape 3 : ANALYSER
â”œâ”€ Identifier le goulot (COLLSCAN, SORT, ratio)
â”œâ”€ VÃ©rifier les index disponibles
â””â”€ DÃ©terminer la stratÃ©gie d'optimisation

Ã‰tape 4 : CONCEVOIR
â”œâ”€ DÃ©finir le nouvel index (ESR)
â”œâ”€ Ou modifier la requÃªte
â””â”€ Estimer l'impact

Ã‰tape 5 : TESTER
â”œâ”€ Appliquer en dev/staging
â”œâ”€ Mesurer l'amÃ©lioration
â””â”€ VÃ©rifier les effets secondaires

Ã‰tape 6 : DÃ‰PLOYER
â”œâ”€ Planifier le dÃ©ploiement
â”œâ”€ CrÃ©er l'index en production
â””â”€ Surveiller les mÃ©triques

Ã‰tape 7 : VALIDER
â”œâ”€ Confirmer l'amÃ©lioration
â”œâ”€ Documenter le changement
â””â”€ Surveiller Ã  long terme
```

### Exemple complet

```javascript
// Ã‰TAPE 1 : Identifier
// Profiler montre une requÃªte lente

// Ã‰TAPE 2 : Mesurer
const before = db.orders.find({
  userId: 12345,
  status: "pending"
}).sort({ createdAt: -1 })
  .explain("executionStats")

console.log(`Avant :`)
console.log(`  Stage : ${before.queryPlanner.winningPlan.stage}`)
console.log(`  Temps : ${before.executionStats.executionTimeMillis}ms`)
console.log(`  Docs examinÃ©s : ${before.executionStats.totalDocsExamined}`)
console.log(`  Docs retournÃ©s : ${before.executionStats.nReturned}`)
console.log(`  Ratio : ${(before.executionStats.nReturned / before.executionStats.totalDocsExamined * 100).toFixed(2)}%`)

// Ã‰TAPE 3 : Analyser
// â†’ IXSCAN sur userId_1
// â†’ Mais SORT en mÃ©moire
// â†’ Ratio 2% (trÃ¨s inefficace)

// Ã‰TAPE 4 : Concevoir
// Index composÃ© selon ESR :
// - userId (E)
// - status (E)
// - createdAt (S)

// Ã‰TAPE 5 : Tester en dev
db.orders.createIndex({
  userId: 1,
  status: 1,
  createdAt: -1
})

const after = db.orders.find({
  userId: 12345,
  status: "pending"
}).sort({ createdAt: -1 })
  .explain("executionStats")

console.log(`\nAprÃ¨s :`)
console.log(`  Stage : ${after.queryPlanner.winningPlan.inputStage.stage}`)
console.log(`  Index : ${after.queryPlanner.winningPlan.inputStage.indexName}`)
console.log(`  Temps : ${after.executionStats.executionTimeMillis}ms`)
console.log(`  Docs examinÃ©s : ${after.executionStats.totalDocsExamined}`)
console.log(`  Docs retournÃ©s : ${after.executionStats.nReturned}`)
console.log(`  Ratio : ${(after.executionStats.nReturned / after.executionStats.totalDocsExamined * 100).toFixed(2)}%`)

const improvement = before.executionStats.executionTimeMillis / after.executionStats.executionTimeMillis
console.log(`\nAmÃ©lioration : ${improvement.toFixed(1)}x plus rapide`)

// Ã‰TAPE 6 : DÃ©ployer en production
// (selon processus de l'Ã©quipe)

// Ã‰TAPE 7 : Valider et documenter
/*
Index crÃ©Ã© : userId_1_status_1_createdAt_-1
Date : 2024-12-01
RequÃªte optimisÃ©e : Orders pending par user avec tri
AmÃ©lioration : 234ms â†’ 8ms (29x plus rapide)
Ratio : 2% â†’ 100%
Impact : ~10,000 req/jour
*/
```

---

## Concepts clÃ©s Ã  retenir

### ğŸ¯ Points essentiels

1. **Mesurer avant d'optimiser**
   - Toujours utiliser explain("executionStats")
   - Comparer avant/aprÃ¨s
   - Documenter les rÃ©sultats

2. **L'index appropriÃ© est la clÃ©**
   - Un bon index > toute autre optimisation
   - Suivre la rÃ¨gle ESR
   - Viser un ratio de 100%

3. **StratÃ©gies par scÃ©nario**
   - Recherche simple â†’ Index simple
   - Filtres multiples â†’ Index composÃ©
   - Tri â†’ Inclure dans l'index
   - Pagination â†’ Curseur au lieu de skip()

4. **Patterns avancÃ©s**
   - Covered queries pour performances maximales
   - Index partiels pour Ã©conomiser l'espace
   - DÃ©normalisation calculÃ©e si nÃ©cessaire

5. **Ã‰viter les anti-patterns**
   - Pas d'index sur chaque champ
   - Pas de requÃªtes dans des boucles
   - Pas de $where pour logique simple
   - Pas de skip() profond

6. **Processus d'optimisation**
   - Identifier â†’ Mesurer â†’ Analyser
   - Concevoir â†’ Tester â†’ DÃ©ployer â†’ Valider

7. **Maintenance continue**
   - Surveiller les requÃªtes lentes
   - Analyser l'utilisation des index
   - Supprimer les index inutilisÃ©s
   - Adapter aux Ã©volutions

---

## Ressources pour aller plus loin

### Commandes essentielles

```javascript
// Analyse de requÃªte
db.collection.find({ ... }).explain("executionStats")

// Index stats
db.collection.aggregate([{ $indexStats: {} }])

// Profiler
db.setProfilingLevel(1, { slowms: 100 })
db.system.profile.find().sort({ ts: -1 })

// Stats collection
db.collection.stats()

// Cache de plans
db.collection.getPlanCache().list()
```

### Scripts utiles

```javascript
// Trouver les requÃªtes les plus lentes
db.system.profile.aggregate([
  { $match: { ns: "mydb.collection" } },
  { $group: {
      _id: "$command.filter",
      count: { $sum: 1 },
      avgTime: { $avg: "$millis" },
      maxTime: { $max: "$millis" }
  }},
  { $sort: { avgTime: -1 } },
  { $limit: 10 }
])

// Trouver les index inutilisÃ©s
db.collection.aggregate([
  { $indexStats: {} },
  { $match: { "accesses.ops": { $eq: 0 } } },
  { $project: { name: 1, key: 1 } }
])
```

---

## Analogie finale

> **Optimiser des requÃªtes MongoDB, c'est comme optimiser un trajet en voiture :**
>
> **Sans optimisation** = Routes secondaires, embouteillages
> - Vous arrivez, mais c'est long et inefficace
>
> **Avec un index simple** = Autoroute directe
> - Vous arrivez 10x plus vite
>
> **Avec un index composÃ© optimal** = Autoroute + voie rapide + GPS optimisÃ©
> - Vous arrivez 100x plus vite, trajet parfait
>
> **Avec toutes les optimisations** = Formule 1 sur circuit privÃ©
> - Performance maximale, chaque dÃ©tail compte
>
> **L'optimisation, c'est choisir le meilleur chemin avec les bons outils !** ğŸï¸

---

**Vous maÃ®trisez maintenant les stratÃ©gies d'optimisation des requÃªtes MongoDB !** ğŸš€

---


â­ï¸ [Index couvrants (Covered Queries)](/05-index-et-optimisation/09-index-couvrants.md)
