ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# Chapitre 13 : Monitoring et Administration

## Vue d'ensemble

Le monitoring et l'administration efficaces d'une infrastructure MongoDB sont essentiels pour garantir la disponibilitÃ©, les performances et la fiabilitÃ© des systÃ¨mes en production. Ce chapitre s'adresse aux SRE (Site Reliability Engineers) et administrateurs systÃ¨me qui ont la responsabilitÃ© d'exploiter MongoDB Ã  l'Ã©chelle, en fournissant une comprÃ©hension approfondie des mÃ©triques critiques, des outils d'observation et des pratiques d'administration.

## Importance du monitoring MongoDB

### Enjeux en production

Dans un environnement de production, l'absence de monitoring adÃ©quat peut entraÃ®ner :

- **DÃ©gradation silencieuse des performances** : Les requÃªtes lentes s'accumulent progressivement sans alerte prÃ©coce
- **Saturation de ressources** : MÃ©moire, CPU, disque ou connexions atteignent leurs limites sans anticipation
- **IndisponibilitÃ© non dÃ©tectÃ©e** : Les failovers ou pannes partielles passent inaperÃ§us jusqu'Ã  impact utilisateur
- **CoÃ»ts imprÃ©vus** : Surconsommation de ressources cloud sans visibilitÃ© sur l'origine
- **Incidents prolongÃ©s** : Temps de rÃ©solution allongÃ© par manque de donnÃ©es diagnostiques

### Objectifs du monitoring

Un systÃ¨me de monitoring MongoDB bien conÃ§u doit permettre de :

1. **DÃ©tecter proactivement** les anomalies avant qu'elles n'impactent les utilisateurs
2. **Diagnostiquer rapidement** la cause racine des problÃ¨mes de performance
3. **Planifier la capacitÃ©** en anticipant les besoins futurs en ressources
4. **Optimiser continuellement** les performances des requÃªtes et de l'infrastructure
5. **Respecter les SLA** en maintenant une visibilitÃ© constante sur les mÃ©triques critiques
6. **Documenter l'historique** pour les post-mortems et analyses de tendances

## Les couches du monitoring MongoDB

### 1. Couche infrastructure (matÃ©rielle)

Surveillance des ressources systÃ¨me sous-jacentes :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         INFRASTRUCTURE                  â”‚
â”‚  â€¢ CPU (utilisation, saturation)        â”‚
â”‚  â€¢ MÃ©moire (usage, swap, pression)      â”‚
â”‚  â€¢ Disque (IOPS, latence, espace)       â”‚
â”‚  â€¢ RÃ©seau (bande passante, latence)     â”‚
â”‚  â€¢ SystÃ¨me de fichiers                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Exemple de mÃ©triques critiques** :
- CPU : `%user`, `%system`, `%iowait`, `%steal` (en cloud)
- MÃ©moire : Resident Set Size (RSS), cache WiredTiger, pages dirty
- Disque : Latence en lecture/Ã©criture, taux d'utilisation, queue depth
- RÃ©seau : Connexions Ã©tablies, paquets perdus, bande passante saturÃ©e

### 2. Couche processus MongoDB

Surveillance du processus `mongod` et `mongos` :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         PROCESSUS MONGODB               â”‚
â”‚  â€¢ Connexions actives/disponibles       â”‚
â”‚  â€¢ OpÃ©rations en cours                  â”‚
â”‚  â€¢ Locks et contentions                 â”‚
â”‚  â€¢ Cache et mÃ©moire interne             â”‚
â”‚  â€¢ Latence des opÃ©rations               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Exemple d'analyse** :

```javascript
// Commande serverStatus pour obtenir l'Ã©tat du serveur
db.serverStatus()

// RÃ©sultat partiel simplifiÃ© :
{
  "connections": {
    "current": 847,
    "available": 51153,
    "totalCreated": 12453
  },
  "opcounters": {
    "insert": 425897,
    "query": 1847562,
    "update": 284563,
    "delete": 12453,
    "getmore": 45621,
    "command": 3254789
  },
  "wiredTiger": {
    "cache": {
      "bytes currently in the cache": 3221225472,
      "maximum bytes configured": 4294967296,
      "pages evicted by application threads": 12453
    }
  }
}
```

**Alertes recommandÃ©es** :
- `current connections / available connections > 80%` : Risque de saturation
- `cache eviction rate > seuil` : Pression mÃ©moire excessive
- `lock wait time > 100ms` : Contention importante

### 3. Couche base de donnÃ©es et collections

Surveillance au niveau applicatif :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         DATABASE & COLLECTIONS          â”‚
â”‚  â€¢ Taille des bases et collections      â”‚
â”‚  â€¢ Nombre de documents                  â”‚
â”‚  â€¢ Fragmentation                        â”‚
â”‚  â€¢ Performance des index                â”‚
â”‚  â€¢ Slow queries                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Exemple de commande dbStats** :

```javascript
db.stats()

// RÃ©sultat :
{
  "db": "production",
  "collections": 24,
  "views": 2,
  "objects": 45789234,      // Nombre total de documents
  "avgObjSize": 1247.56,    // Taille moyenne d'un document (bytes)
  "dataSize": 57123456789,  // Taille totale des donnÃ©es
  "storageSize": 62345678901, // Espace disque allouÃ©
  "indexes": 48,
  "indexSize": 4567890123,
  "totalSize": 66913568024,
  "scaleFactor": 1,
  "fsUsedSize": 445678901234,
  "fsTotalSize": 1099511627776
}
```

**MÃ©triques dÃ©rivÃ©es importantes** :
- **Ratio de fragmentation** : `storageSize / dataSize` (optimal proche de 1.0)
- **Index overhead** : `indexSize / dataSize` (surveiller si > 50%)
- **Taux de croissance** : Ã‰volution de `dataSize` par jour/semaine

### 4. Couche rÃ©plication et distribution

Pour les dÃ©ploiements Replica Set et Sharded Cluster :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         REPLICATION & SHARDING          â”‚
â”‚  â€¢ Lag de rÃ©plication                   â”‚
â”‚  â€¢ Health des membres                   â”‚
â”‚  â€¢ Ã‰lections et failovers               â”‚
â”‚  â€¢ Distribution des chunks              â”‚
â”‚  â€¢ Migration en cours                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Exemple d'analyse de replication lag** :

```javascript
rs.printSlaveReplicationInfo()

// RÃ©sultat typique :
source: secondary1.domain.com:27017
    syncedTo: Mon Dec 08 2025 14:32:45 GMT+0100
    0 secs (0 hrs) behind the primary

source: secondary2.domain.com:27017
    syncedTo: Mon Dec 08 2025 14:32:43 GMT+0100
    2 secs (0 hrs) behind the primary  // âš ï¸ Lag dÃ©tectÃ©
```

**Seuils d'alerte critiques** :
- Replication lag > 10 secondes : Warning
- Replication lag > 60 secondes : Critical
- Membre en Ã©tat RECOVERING > 5 minutes : Investigation requise
- Chunk migration stalled > 30 minutes : ProblÃ¨me de balancing

## Architecture de monitoring recommandÃ©e

### Approche multi-couches

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VISUALISATION                         â”‚
â”‚              Grafana / Atlas Charts                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  AGRÃ‰GATION / ALERTING                   â”‚
â”‚           Prometheus / Atlas Monitoring                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   COLLECTEURS                            â”‚
â”‚    MongoDB Exporter / mongodb_exporter                   â”‚
â”‚    Atlas Monitoring Agent / Cloud Watch                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  SOURCES DE DONNÃ‰ES                      â”‚
â”‚  serverStatus / dbStats / replSetGetStatus               â”‚
â”‚  currentOp / logs / FTDC                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Outils essentiels par catÃ©gorie

#### Outils natifs MongoDB

| Outil | Usage | FrÃ©quence |
|-------|-------|-----------|
| `serverStatus` | Ã‰tat global du serveur | Temps rÃ©el / 1s |
| `dbStats` | Statistiques par base | PÃ©riodique / 5min |
| `currentOp` | OpÃ©rations en cours | Diagnostic Ã  la demande |
| `explain()` | Analyse de requÃªtes | Optimisation continue |
| Profiler | RequÃªtes lentes | Troubleshooting |
| FTDC | Diagnostics continus | Analyse post-mortem |

#### Outils de monitoring externe

| CatÃ©gorie | Outils | Cas d'usage |
|-----------|--------|-------------|
| **Collecteurs** | mongodb_exporter, Telegraf | Export mÃ©triques vers Prometheus |
| **Stockage** | Prometheus, InfluxDB, TimescaleDB | Time-series database |
| **Visualisation** | Grafana, Kibana, Atlas Charts | Dashboards et exploration |
| **Alerting** | Alertmanager, PagerDuty, OpsGenie | Notifications et escalade |
| **Logs** | ELK Stack, Splunk, Loki | AgrÃ©gation et analyse de logs |
| **APM** | New Relic, Datadog, Dynatrace | Monitoring applicatif bout-en-bout |

#### Solutions managÃ©es

**MongoDB Atlas** offre une solution intÃ©grÃ©e avec :
- Monitoring en temps rÃ©el (rafraÃ®chissement 10s-1min)
- Alertes personnalisables sur 50+ mÃ©triques
- Query Performance Insights (requÃªtes lentes automatiques)
- Real-Time Performance Panel
- Logs accessibles via interface et API
- IntÃ©gration avec Datadog, New Relic, PagerDuty

**Exemple de configuration d'alerte Atlas** :

```json
{
  "eventTypeName": "REPLICATION_OPLOG_WINDOW_RUNNING_OUT",
  "enabled": true,
  "notifications": [
    {
      "typeName": "PAGER_DUTY",
      "intervalMin": 5,
      "delayMin": 0
    }
  ],
  "threshold": {
    "operator": "LESS_THAN",
    "threshold": 1,
    "units": "HOURS"
  }
}
```

## StratÃ©gie de monitoring recommandÃ©e

### 1. Ã‰tablir une baseline

Avant de dÃ©finir des alertes, comprendre le comportement normal :

```
ğŸ“Š Collecte pendant 2-4 semaines :
â”œâ”€â”€ Patterns quotidiens (heures de pointe)
â”œâ”€â”€ Variations hebdomadaires (weekend vs semaine)
â”œâ”€â”€ Pics mensuels (facturation, batch jobs)
â””â”€â”€ SaisonnalitÃ© (pÃ©riodes mÃ©tier)
```

**MÃ©triques de baseline critiques** :
- Latence P50, P95, P99 des opÃ©rations
- Throughput moyen et pics (ops/sec)
- Utilisation mÃ©moire en conditions normales
- Taille quotidienne de l'oplog consommÃ©e

### 2. DÃ©finir des SLI/SLO/SLA

**Service Level Indicators (SLI)** - MÃ©triques mesurÃ©es :
- DisponibilitÃ© : % de temps avec rÃ©ponse valide
- Latence : Percentile P95 < 100ms
- Throughput : CapacitÃ© Ã  gÃ©rer X ops/sec

**Service Level Objectives (SLO)** - Objectifs internes :
- 99.9% de disponibilitÃ© sur 30 jours
- P95 latency < 100ms pour 99.5% des requÃªtes
- Replication lag < 5s en conditions normales

**Service Level Agreements (SLA)** - Engagements contractuels :
- 99.95% uptime mensuel avec pÃ©nalitÃ©s si non respectÃ©

### 3. HiÃ©rarchiser les alertes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CRITICAL - Intervention immÃ©diate requise  â”‚
â”‚  â€¢ Primary down                             â”‚
â”‚  â€¢ Replication stopped                      â”‚
â”‚  â€¢ Disk full (>95%)                         â”‚
â”‚  â€¢ OOM imminent                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  WARNING - DÃ©gradation anticipÃ©e            â”‚
â”‚  â€¢ Replication lag > 30s                    â”‚
â”‚  â€¢ Slow queries > seuil                     â”‚
â”‚  â€¢ Disk usage > 80%                         â”‚
â”‚  â€¢ Connection pool > 70%                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INFO - Surveillance et tendances           â”‚
â”‚  â€¢ Index usage stats                        â”‚
â”‚  â€¢ Growth rate analysis                     â”‚
â”‚  â€¢ Query patterns changes                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4. ImplÃ©menter l'observabilitÃ© complÃ¨te

**Les trois piliers** :

1. **Metrics** (MÃ©triques)
   - SÃ©ries temporelles quantitatives
   - AgrÃ©gation et percentiles
   - Dashboards et graphiques

2. **Logs** (Journaux)
   - Events dÃ©taillÃ©s
   - Contexte et tracing
   - CorrÃ©lation avec mÃ©triques

3. **Traces** (Traces distribuÃ©es)
   - Suivi de requÃªtes bout-en-bout
   - Identification des goulots d'Ã©tranglement
   - DÃ©pendances inter-services

**Exemple de corrÃ©lation** :

```
[15:42:13] METRIC: Latency spike P95 = 2.3s (normally 85ms)
             â†“
[15:42:10] LOG: "[SLOW] Query on users.profiles took 2145ms"
             â†“
[15:42:10] TRACE: Span "db.query" â†’ Missing index on {email: 1}
             â†“
           ROOT CAUSE: Full collection scan aprÃ¨s dÃ©ploiement
```

## MÃ©triques clÃ©s par persona

### Pour les SRE (Site Reliability Engineers)

**Focus : DisponibilitÃ© et performance systÃ¨me**

```yaml
MÃ©triques prioritaires:
  - Uptime et availability (%)
  - Latency percentiles (P50, P95, P99)
  - Error rate (failed operations %)
  - Resource saturation (CPU, RAM, Disk)
  - Replication lag
  - Failover events et durÃ©e

Dashboards typiques:
  - Service health overview
  - Resource utilization trends
  - Incident timeline
  - Capacity planning projection
```

### Pour les DBA (Database Administrators)

**Focus : Optimisation des requÃªtes et donnÃ©es**

```yaml
MÃ©triques prioritaires:
  - Slow queries count et exemples
  - Index usage et efficacitÃ©
  - Lock contention et wait time
  - Collection growth rate
  - Fragmentation ratio
  - Query execution plans

Dashboards typiques:
  - Query performance analysis
  - Index effectiveness report
  - Schema evolution tracking
  - Maintenance windows planning
```

### Pour les dÃ©veloppeurs

**Focus : Performance applicative**

```yaml
MÃ©triques prioritaires:
  - Query latency par collection
  - Operation success rate
  - Connection pool exhaustion
  - Application error correlation
  - Transaction abort rate

Dashboards typiques:
  - Per-collection performance
  - API endpoint latency breakdown
  - Error rate by operation type
```

## Checklist de mise en place du monitoring

### Phase 1 : Infrastructure (Jour 1-3)

- [ ] DÃ©ployer les agents de collecte (node_exporter, mongodb_exporter)
- [ ] Configurer Prometheus ou solution time-series Ã©quivalente
- [ ] VÃ©rifier la collecte des mÃ©triques systÃ¨me (CPU, RAM, Disk, Network)
- [ ] Configurer la rÃ©tention des mÃ©triques (30-90 jours recommandÃ©)
- [ ] SÃ©curiser les endpoints de mÃ©triques (authentification, TLS)

### Phase 2 : MongoDB (Jour 4-7)

- [ ] Activer le monitoring MongoDB (serverStatus, dbStats)
- [ ] Configurer le profiler avec seuil appropriÃ© (100-200ms)
- [ ] Activer les logs structurÃ©s (JSON format)
- [ ] Configurer l'agrÃ©gation des logs (Loki, ELK, Splunk)
- [ ] Documenter la topologie (Replica Set / Sharded Cluster)

### Phase 3 : Visualisation (Jour 8-10)

- [ ] DÃ©ployer Grafana ou Atlas Charts
- [ ] Importer des dashboards de rÃ©fÃ©rence MongoDB
- [ ] CrÃ©er des dashboards personnalisÃ©s par service
- [ ] Configurer les variables de dashboard (env, cluster, node)
- [ ] Ã‰tablir les permissions d'accÃ¨s

### Phase 4 : Alerting (Jour 11-14)

- [ ] DÃ©finir les SLO par service
- [ ] Configurer les alertes critiques (downtime, replication issues)
- [ ] Configurer les alertes de warning (resource saturation)
- [ ] IntÃ©grer avec PagerDuty / OpsGenie
- [ ] Documenter les runbooks d'intervention
- [ ] Tester les alertes et escalations

### Phase 5 : Optimisation continue (Ongoing)

- [ ] RÃ©viser hebdomadairement les alertes non pertinentes
- [ ] Ajuster les seuils selon la baseline observÃ©e
- [ ] Documenter les incidents et post-mortems
- [ ] Automatiser les remediations courantes
- [ ] Mettre Ã  jour la documentation d'exploitation

## Exemples de dashboards essentiels

### Dashboard 1 : Health Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MongoDB Cluster Health                     [Last 1h â–¼]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚ â”‚Uptime   â”‚  â”‚Avg      â”‚  â”‚Active   â”‚  â”‚Repl     â”‚      â”‚
â”‚ â”‚99.98%   â”‚  â”‚Latency  â”‚  â”‚Conn     â”‚  â”‚Lag      â”‚      â”‚
â”‚ â”‚  ğŸŸ¢     â”‚  â”‚47ms ğŸŸ¢  â”‚  â”‚142 ğŸŸ¢   â”‚  â”‚0.2s ğŸŸ¢  â”‚      â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Operations Per Second                                   â”‚
â”‚ â–â–‚â–ƒâ–„â–…â–†â–ˆâ–‡â–†â–…â–„â–ƒâ–‚â–â–â–‚â–ƒâ–„â–…â–†â–ˆâ–‡â–†â–…â–„â–ƒâ–‚â–â–â–‚â–ƒâ–„â–…â–†â–ˆâ–‡â–†â–…â–„â–ƒâ–‚â– 1.2K ops/s   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Replica Set Members                                     â”‚
â”‚ primary1     [PRIMARY]    â¬¤ Healthy    Lag: 0ms        â”‚
â”‚ secondary1   [SECONDARY]  â¬¤ Healthy    Lag: 150ms      â”‚
â”‚ secondary2   [SECONDARY]  â¬¤ Healthy    Lag: 180ms      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Dashboard 2 : Resource Utilization

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Resource Utilization - node1.cluster.local              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ CPU Usage %                        RAM Usage GB         â”‚
â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 75%          â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 28/32â”‚
â”‚                                                         â”‚
â”‚ Disk IOPS                          Network MB/s         â”‚
â”‚ â–â–‚â–ƒâ–ˆâ–†â–…â–„â–ƒâ–‚â– 4.2K                  â–â–ƒâ–…â–ˆâ–†â–„â–ƒâ–‚â– 145 MB/s     â”‚
â”‚                                                         â”‚
â”‚ WiredTiger Cache                   Page Faults/s        â”‚
â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 3.2/4 GB       â–â–â–â–‚â–â–â–â– 12/s         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Dashboard 3 : Query Performance

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Top 5 Slowest Operations (Last 1h)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Collection      â”‚ Operation â”‚ Avg Time â”‚ Count â”‚ Index      â”‚
â”‚ users.profiles  â”‚ find      â”‚ 2.4s     â”‚ 234   â”‚ âŒ SCAN    â”‚
â”‚ orders.history  â”‚ aggregate â”‚ 1.8s     â”‚ 89    â”‚ âš ï¸ PARTIAL â”‚
â”‚ products.catalogâ”‚ find      â”‚ 890ms    â”‚ 1.2K  â”‚ âœ… IXSCAN  â”‚
â”‚ logs.events     â”‚ insert    â”‚ 450ms    â”‚ 45K   â”‚ N/A        â”‚
â”‚ sessions.active â”‚ update    â”‚ 380ms    â”‚ 3.4K  â”‚ âœ… IXSCAN  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Prochaines sections

Ce chapitre continue avec des sections dÃ©taillÃ©es sur :

- **13.1** MÃ©triques clÃ©s Ã  surveiller en dÃ©tail
- **13.2** Commandes d'administration essentielles
- **13.3** Profiler de requÃªtes et optimisation
- **13.4** Gestion et analyse des logs
- **13.5** MongoDB Database Tools
- **13.6** mongostat et mongotop
- **13.7** IntÃ©gration Prometheus et Grafana
- **13.8** MongoDB Ops Manager
- **13.9** Alerting et notifications
- **13.10** Diagnostics avec FTDC
- **13.11** Gestion de la mÃ©moire et du cache WiredTiger

---

**Points clÃ©s Ã  retenir** :

âœ… Le monitoring MongoDB nÃ©cessite une approche multi-couches (infrastructure, processus, application, distribution)

âœ… Ã‰tablir une baseline avant de configurer des alertes pour Ã©viter les faux positifs

âœ… Prioriser les mÃ©triques selon le rÃ´le (SRE, DBA, Dev) et les objectifs de service (SLO)

âœ… Combiner metrics, logs et traces pour une observabilitÃ© complÃ¨te

âœ… Automatiser la collecte, visualisation et alerting dÃ¨s le dÃ©part

âœ… Documenter les runbooks et procÃ©dures d'intervention pour chaque alerte

---

**Prochaine section** : 13.1 MÃ©triques clÃ©s Ã  surveiller

â­ï¸ [MÃ©triques clÃ©s Ã  surveiller](/13-monitoring-administration/01-metriques-cles.md)
