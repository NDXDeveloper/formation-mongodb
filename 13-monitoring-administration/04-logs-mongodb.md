ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 13.4 Logs MongoDB

## Introduction

Les **logs MongoDB** constituent la source primaire d'informations pour le diagnostic, le monitoring et l'audit des instances MongoDB. Contrairement au profiler qui se concentre sur les performances des requÃªtes, les logs offrent une vue holistique de tous les Ã©vÃ©nements systÃ¨me, des erreurs, des avertissements et des opÃ©rations d'administration.

Pour un SRE ou administrateur systÃ¨me, la maÃ®trise des logs MongoDB est cruciale pour :
- **Diagnostic rapide** des incidents en production
- **DÃ©tection proactive** des problÃ¨mes avant qu'ils n'impactent les utilisateurs
- **Audit de sÃ©curitÃ©** et traÃ§abilitÃ© des accÃ¨s
- **Analyse des tendances** et planification de capacitÃ©
- **Validation** des changements de configuration

---

## Architecture du SystÃ¨me de Logging

### Vue d'Ensemble

MongoDB utilise un systÃ¨me de logging structurÃ© basÃ© sur plusieurs composants :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     MongoDB Process                      â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   Network    â”‚  â”‚   Storage    â”‚  â”‚  Replication â”‚    â”‚
â”‚  â”‚  Component   â”‚  â”‚  Component   â”‚  â”‚  Component   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â”‚                  â”‚                  â”‚          â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                            â”‚                             â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚                    â”‚  Log Subsystem â”‚                    â”‚
â”‚                    â”‚  (Structured)  â”‚                    â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚            â”‚            â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”
         â”‚  mongod.logâ”‚ â”‚ syslog â”‚ â”‚  JSON   â”‚
         â”‚   (file)   â”‚ â”‚        â”‚ â”‚  file   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Destinations des Logs

MongoDB peut Ã©crire les logs vers plusieurs destinations :

| Destination | Usage | Avantages | InconvÃ©nients |
|-------------|-------|-----------|---------------|
| **File** | Production (dÃ©faut) | Rotation native, parsing facile | NÃ©cessite gestion disque |
| **Syslog** | IntÃ©gration systÃ¨me | Centralisation native | Format moins structurÃ© |
| **stdout/stderr** | Conteneurs Docker | Compatible 12-factor apps | Pas de rotation native |
| **JSON** | Analyse automatisÃ©e | Parsing structurÃ© | Plus verbeux |

---

## Configuration des Logs

### Fichier de Configuration (mongod.conf)

Configuration typique pour la production :

```yaml
systemLog:
  # Destination des logs
  destination: file
  path: /var/log/mongodb/mongod.log

  # Rotation automatique
  logRotate: reopen  # Options: rename, reopen
  logAppend: true

  # Format structurÃ© (MongoDB 4.4+)
  component:
    accessControl:
      verbosity: 1
    command:
      verbosity: 0
    control:
      verbosity: 0
    ftdc:
      verbosity: 0
    geo:
      verbosity: 0
    index:
      verbosity: 0
    network:
      verbosity: 0
    query:
      verbosity: 1
    replication:
      verbosity: 1
    sharding:
      verbosity: 1
    storage:
      verbosity: 0
      journal:
        verbosity: 1
    write:
      verbosity: 0

  # Niveau global
  verbosity: 0

  # Timestamps prÃ©cis (recommandÃ©)
  timeStampFormat: iso8601-utc
```

### Configuration via Ligne de Commande

```bash
# DÃ©marrage avec logs verbeux
mongod --logpath /var/log/mongodb/mongod.log \
       --logappend \
       --verbose \
       --setParameter diagnosticDataCollectionDirectoryPath=/var/log/mongodb/diagnostic.data

# Mode debug complet (seulement pour diagnostic temporaire)
mongod --logpath /var/log/mongodb/mongod-debug.log \
       --verbose vvvvv  # 5 niveaux de verbositÃ©
```

### Modification Dynamique en Runtime

```javascript
// Augmenter la verbositÃ© globalement
db.setLogLevel(1)

// Augmenter la verbositÃ© pour un composant spÃ©cifique
db.setLogLevel(2, "query")
db.setLogLevel(1, "replication")

// VÃ©rifier les niveaux actuels
db.getLogComponents()

// RÃ©sultat
{
  "verbosity": 0,
  "accessControl": { "verbosity": -1 },
  "command": { "verbosity": -1 },
  "control": { "verbosity": -1 },
  "query": { "verbosity": 2 },     // ModifiÃ©
  "replication": { "verbosity": 1 }, // ModifiÃ©
  "storage": {
    "verbosity": -1,
    "journal": { "verbosity": -1 },
    "recovery": { "verbosity": -1 }
  }
}
```

---

## Niveaux de VerbositÃ©

### HiÃ©rarchie des Niveaux

MongoDB utilise une Ã©chelle de verbositÃ© de -1 Ã  5 :

| Niveau | Nom | Description | Usage | Impact Performance |
|--------|-----|-------------|-------|-------------------|
| **-1** | Inherit | HÃ©rite du niveau parent | DÃ©faut des composants | Aucun |
| **0** | Default | Messages standards (INFO, WARNING, ERROR) | Production standard | Minimal (< 1%) |
| **1** | Debug 1 | Informations de debug basiques | Diagnostic lÃ©ger | Faible (1-3%) |
| **2** | Debug 2 | Informations de debug dÃ©taillÃ©es | Investigation | ModÃ©rÃ© (3-7%) |
| **3** | Debug 3 | Informations trÃ¨s dÃ©taillÃ©es | Debug approfondi | Significatif (7-15%) |
| **4** | Debug 4 | Trace complÃ¨te | Debug dÃ©veloppeur | Ã‰levÃ© (15-25%) |
| **5** | Debug 5 | Trace exhaustive | Debug interne MongoDB | TrÃ¨s Ã©levÃ© (25-40%) |

### Recommandations par Environnement

```yaml
# PRODUCTION - Configuration conservative
systemLog:
  verbosity: 0
  component:
    query:
      verbosity: 0     # Queries lentes uniquement (> slowms)
    replication:
      verbosity: 0     # Events majeurs uniquement
    sharding:
      verbosity: 0
    storage:
      journal:
        verbosity: 0

# STAGING - Plus de dÃ©tails pour validation
systemLog:
  verbosity: 0
  component:
    query:
      verbosity: 1     # Toutes les queries lentes + contexte
    replication:
      verbosity: 1     # Events + dÃ©tails sync
    command:
      verbosity: 1     # Commandes d'admin

# DÃ‰VELOPPEMENT - Maximum de visibilitÃ©
systemLog:
  verbosity: 1
  component:
    query:
      verbosity: 2     # DÃ©tails de parsing et plans
    replication:
      verbosity: 2
    network:
      verbosity: 1     # Connexions/dÃ©connexions
```

---

## Format des EntrÃ©es de Log

### Format Legacy (PrÃ©-4.4)

```
2024-12-08T15:23:45.678+0000 I NETWORK  [conn123] received client metadata from 10.0.1.45:54321
```

**Structure** :
- `2024-12-08T15:23:45.678+0000` - Timestamp ISO-8601
- `I` - SÃ©vÃ©ritÃ© (I=Info, W=Warning, E=Error, F=Fatal)
- `NETWORK` - Composant
- `[conn123]` - Contexte
- Message texte

### Format StructurÃ© (MongoDB 4.4+)

```json
{
  "t": {
    "$date": "2024-12-08T15:23:45.678Z"
  },
  "s": "I",
  "c": "NETWORK",
  "id": 51800,
  "ctx": "conn123",
  "msg": "client metadata",
  "attr": {
    "remote": "10.0.1.45:54321",
    "client": "conn123",
    "doc": {
      "application": {
        "name": "ProductionAPI"
      },
      "driver": {
        "name": "nodejs",
        "version": "4.12.0"
      },
      "os": {
        "type": "Linux",
        "name": "Ubuntu",
        "architecture": "x86_64",
        "version": "20.04"
      }
    }
  }
}
```

**Champs clÃ©s** :
- `t` - Timestamp prÃ©cis avec timezone
- `s` - Severity (I/W/E/F/D1-D5)
- `c` - Component
- `id` - Message ID unique
- `ctx` - Context (thread/connection)
- `msg` - Message template
- `attr` - Attributs structurÃ©s (variables)

---

## Composants et CatÃ©gories de Logs

### Composants Principaux

#### 1. ACCESS (ContrÃ´le d'AccÃ¨s)

**Ã‰vÃ©nements typiques** :
- Tentatives d'authentification
- Changements d'autorisation
- Ã‰checs de sÃ©curitÃ©

```json
// Authentification rÃ©ussie
{
  "s": "I",
  "c": "ACCESS",
  "id": 20250,
  "msg": "Authentication succeeded",
  "attr": {
    "principalName": "apiUser",
    "authenticationDatabase": "admin",
    "client": "10.0.1.45:54321",
    "mechanism": "SCRAM-SHA-256"
  }
}

// Ã‰chec d'authentification
{
  "s": "I",
  "c": "ACCESS",
  "id": 20249,
  "msg": "Authentication failed",
  "attr": {
    "principalName": "unknownUser",
    "authenticationDatabase": "admin",
    "client": "192.168.1.100:45678",
    "mechanism": "SCRAM-SHA-256",
    "result": "UserNotFound"
  }
}
```

#### 2. COMMAND (ExÃ©cution de Commandes)

**Ã‰vÃ©nements typiques** :
- Commandes d'administration
- AgrÃ©gations complexes
- OpÃ©rations longues

```json
{
  "s": "I",
  "c": "COMMAND",
  "id": 51803,
  "msg": "Slow query",
  "attr": {
    "type": "command",
    "ns": "mydb.users",
    "command": {
      "find": "users",
      "filter": {
        "status": "active",
        "lastLogin": { "$lt": { "$date": "2024-11-01T00:00:00Z" } }
      },
      "sort": { "createdAt": -1 },
      "limit": 1000
    },
    "planSummary": "IXSCAN { status: 1, lastLogin: 1 }",
    "keysExamined": 45678,
    "docsExamined": 45678,
    "nreturned": 1000,
    "durationMillis": 1234,
    "numYields": 0,
    "locks": {
      "Global": { "acquireCount": { "r": 1 } },
      "Database": { "acquireCount": { "r": 1 } },
      "Collection": { "acquireCount": { "r": 1 } }
    }
  }
}
```

#### 3. NETWORK (RÃ©seau)

**Ã‰vÃ©nements typiques** :
- Connexions/dÃ©connexions
- Erreurs rÃ©seau
- Timeouts

```json
// Nouvelle connexion
{
  "s": "I",
  "c": "NETWORK",
  "id": 22943,
  "msg": "Connection accepted",
  "attr": {
    "remote": "10.0.1.45:54321",
    "connectionId": 123,
    "connectionCount": 87
  }
}

// DÃ©connexion anormale
{
  "s": "I",
  "c": "NETWORK",
  "id": 22944,
  "msg": "Connection ended",
  "attr": {
    "remote": "10.0.1.45:54321",
    "connectionId": 123,
    "error": "SocketException: Connection reset by peer"
  }
}
```

#### 4. REPL (RÃ©plication)

**Ã‰vÃ©nements typiques** :
- Ã‰lections de primary
- Synchronisation
- Changements de statut

```json
// Ã‰lection d'un nouveau primary
{
  "s": "I",
  "c": "REPL",
  "id": 21358,
  "msg": "Election succeeded",
  "attr": {
    "term": 5,
    "newPrimary": "mongodb-rs0-1:27017",
    "votesReceived": 2,
    "votesRequired": 2
  }
}

// Lag de rÃ©plication dÃ©tectÃ©
{
  "s": "W",
  "c": "REPL",
  "id": 21236,
  "msg": "Replication lag detected",
  "attr": {
    "member": "mongodb-rs0-2:27017",
    "lagSeconds": 45,
    "lastApplied": { "$date": "2024-12-08T15:22:00.000Z" },
    "primaryLastApplied": { "$date": "2024-12-08T15:22:45.000Z" }
  }
}
```

#### 5. SHARDING (Sharding)

**Ã‰vÃ©nements typiques** :
- Migrations de chunks
- Balancing
- OpÃ©rations de configuration

```json
// DÃ©but de migration de chunk
{
  "s": "I",
  "c": "SHARDING",
  "id": 22016,
  "msg": "Chunk migration started",
  "attr": {
    "namespace": "mydb.orders",
    "chunk": {
      "min": { "orderId": 1000000 },
      "max": { "orderId": 2000000 }
    },
    "from": "shard01",
    "to": "shard02"
  }
}

// Migration terminÃ©e
{
  "s": "I",
  "c": "SHARDING",
  "id": 22017,
  "msg": "Chunk migration completed",
  "attr": {
    "namespace": "mydb.orders",
    "durationMillis": 15678,
    "docsMovedCount": 123456,
    "bytesMoved": 524288000
  }
}
```

#### 6. STORAGE (Stockage)

**Ã‰vÃ©nements typiques** :
- Checkpoints WiredTiger
- OpÃ©rations de journaling
- ProblÃ¨mes d'espace disque

```json
// Checkpoint WiredTiger
{
  "s": "I",
  "c": "STORAGE",
  "id": 22430,
  "msg": "WiredTiger message",
  "attr": {
    "message": "Checkpoint completed. Written 1234 MB in 2.5 seconds"
  }
}

// Avertissement espace disque
{
  "s": "W",
  "c": "STORAGE",
  "id": 22297,
  "msg": "Low disk space warning",
  "attr": {
    "path": "/data/db",
    "freeSpaceMB": 512,
    "totalSpaceMB": 102400,
    "usagePercent": 99.5
  }
}
```

#### 7. QUERY (RequÃªtes)

**Ã‰vÃ©nements typiques** :
- Plans de requÃªte
- RequÃªtes lentes
- Analyses de performance

```json
// RequÃªte lente avec dÃ©tails
{
  "s": "I",
  "c": "QUERY",
  "id": 51803,
  "msg": "Slow query",
  "attr": {
    "ns": "mydb.products",
    "durationMillis": 2345,
    "planSummary": "COLLSCAN",
    "keysExamined": 0,
    "docsExamined": 567890,
    "nreturned": 10,
    "queryHash": "A1B2C3D4",
    "planCacheKey": "E5F6G7H8",
    "command": {
      "find": "products",
      "filter": {
        "category": "electronics",
        "price": { "$gte": 100, "$lte": 500 }
      }
    }
  }
}
```

---

## Patterns de Log et Leur Signification

### Patterns Critiques Ã  Surveiller

#### 1. Connection Pool Exhaustion

```
Pattern: "Connection refused" ou "Too many connections"
```

```json
{
  "s": "W",
  "c": "NETWORK",
  "id": 22942,
  "msg": "Connection pool exhausted",
  "attr": {
    "maxPoolSize": 100,
    "currentConnections": 100,
    "queuedRequests": 45
  }
}
```

**Diagnostic** :
- Application ne libÃ¨re pas les connexions
- Pool size insuffisant
- Pic de trafic inattendu

**Action** :
```javascript
// VÃ©rifier les connexions actuelles
db.currentOp({ "active": true })

// Augmenter le pool cÃ´tÃ© driver ou serveur
// mongod.conf
net:
  maxIncomingConnections: 200
```

#### 2. Replication Lag Critique

```
Pattern: "Replication lag" avec lagSeconds Ã©levÃ©
```

**CritÃ¨res d'alerte** :
- lagSeconds > 30s : Warning
- lagSeconds > 60s : Critical
- lagSeconds > 300s : Emergency

**Actions** :
```javascript
// 1. VÃ©rifier l'Ã©tat du replica set
rs.status()

// 2. Analyser l'oplog
db.getReplicationInfo()

// 3. Identifier la source du lag
db.printSlaveReplicationInfo()
```

#### 3. Checkpoint Lent (WiredTiger)

```
Pattern: "Checkpoint completed" avec durÃ©e > 60s
```

```json
{
  "s": "W",
  "c": "STORAGE",
  "id": 22430,
  "msg": "WiredTiger checkpoint slow",
  "attr": {
    "durationSeconds": 127,
    "dataSizeMB": 45678,
    "writeRateMBps": 359
  }
}
```

**Causes possibles** :
- I/O disque saturÃ©
- Cache WiredTiger sous-dimensionnÃ©
- Volume d'Ã©critures excessif

**Diagnostic** :
```bash
# VÃ©rifier les I/O disque
iostat -x 1 10

# VÃ©rifier le cache WiredTiger
mongo --eval 'db.serverStatus().wiredTiger.cache' | grep "bytes currently in the cache"
```

#### 4. Ã‰lections FrÃ©quentes

```
Pattern: Multiples "Election succeeded" sur courte pÃ©riode
```

**Seuils d'alerte** :
- > 1 Ã©lection/heure : Investigation
- > 5 Ã©lections/heure : Critique

**Causes** :
- Latence rÃ©seau entre membres
- Heartbeat timeout trop court
- Charge CPU Ã©levÃ©e sur primary

**Analyse** :
```javascript
// Historique des Ã©lections
db.getSiblingDB('local').system.replset.find().pretty()

// Latences rÃ©seau
rs.status().members.forEach(function(m) {
  print(m.name + ": " + m.pingMs + "ms");
});
```

#### 5. OpÃ©rations Ã‰chouÃ©es avec WriteConflict

```
Pattern: "WriteConflict" dans les logs
```

```json
{
  "s": "I",
  "c": "WRITE",
  "id": 51803,
  "msg": "Write operation encountered WriteConflict",
  "attr": {
    "namespace": "mydb.inventory",
    "retries": 3,
    "totalDurationMillis": 156
  }
}
```

**Signification** :
- Contention Ã©levÃ©e sur documents
- Transactions concurrentes
- Normal en faible quantitÃ©, problÃ©matique si frÃ©quent

---

## Analyse des Logs

### Commandes Essentielles

#### 1. Extraction des Erreurs

```bash
# Toutes les erreurs
grep '"s":"E"' /var/log/mongodb/mongod.log

# Erreurs des derniÃ¨res 24h
find /var/log/mongodb -name "mongod.log*" -mtime -1 -exec grep '"s":"E"' {} \;

# Count par type d'erreur
grep '"s":"E"' /var/log/mongodb/mongod.log | \
  jq -r '.c' | sort | uniq -c | sort -rn
```

#### 2. Analyse des RequÃªtes Lentes

```bash
# RequÃªtes > 1 seconde
grep '"msg":"Slow query"' /var/log/mongodb/mongod.log | \
  jq 'select(.attr.durationMillis > 1000)'

# Top 10 des requÃªtes les plus lentes
grep '"msg":"Slow query"' /var/log/mongodb/mongod.log | \
  jq -r '[.attr.ns, .attr.durationMillis] | @csv' | \
  sort -t',' -k2 -rn | head -10

# Distribution des durÃ©es
grep '"msg":"Slow query"' /var/log/mongodb/mongod.log | \
  jq -r '.attr.durationMillis' | \
  awk '{
    if ($1 < 100) range["<100ms"]++
    else if ($1 < 500) range["100-500ms"]++
    else if ($1 < 1000) range["500ms-1s"]++
    else if ($1 < 5000) range["1-5s"]++
    else range[">5s"]++
  }
  END {
    for (r in range) print r ": " range[r]
  }'
```

#### 3. Analyse des Connexions

```bash
# Pics de connexions
grep '"msg":"Connection accepted"' /var/log/mongodb/mongod.log | \
  jq -r '.t.$date[0:13]' | uniq -c

# Connexions par IP
grep '"msg":"Connection accepted"' /var/log/mongodb/mongod.log | \
  jq -r '.attr.remote' | cut -d':' -f1 | sort | uniq -c | sort -rn

# DÃ©connexions anormales
grep '"msg":"Connection ended"' /var/log/mongodb/mongod.log | \
  jq 'select(.attr.error != null)'
```

#### 4. Monitoring de RÃ©plication

```bash
# Ã‰vÃ©nements de rÃ©plication
grep '"c":"REPL"' /var/log/mongodb/mongod.log | tail -50

# DÃ©tection de lag
grep '"msg":"Replication lag"' /var/log/mongodb/mongod.log | \
  jq '.attr | {member: .member, lagSeconds: .lagSeconds}'

# Historique des Ã©lections
grep '"msg":"Election succeeded"' /var/log/mongodb/mongod.log | \
  jq '{time: .t.$date, term: .attr.term, newPrimary: .attr.newPrimary}'
```

#### 5. Analyse de Sharding

```bash
# Migrations en cours
grep '"msg":"Chunk migration"' /var/log/mongodb/mongod.log | tail -20

# DurÃ©e des migrations
grep '"msg":"Chunk migration completed"' /var/log/mongodb/mongod.log | \
  jq '{namespace: .attr.namespace, durationMin: (.attr.durationMillis/60000), docsMoved: .attr.docsMovedCount}'

# Ã‰checs de balancing
grep '"c":"SHARDING"' /var/log/mongodb/mongod.log | \
  jq 'select(.s == "E" or .s == "W")'
```

---

## Outils d'Analyse AvancÃ©s

### 1. mtools (MongoDB Log Analysis)

Installation :
```bash
pip install mtools[mloginfo]
```

**Analyse statistique des logs** :
```bash
# Vue d'ensemble
mloginfo /var/log/mongodb/mongod.log

# Output exemple
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                         GENERAL STATS                         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Log file:        /var/log/mongodb/mongod.log                 â•‘
â•‘  Lines parsed:    1,234,567                                   â•‘
â•‘  Date range:      Dec 07 00:00:01 - Dec 08 15:30:45 (1d 15h) â•‘
â•‘  MongoDB version: 6.0.11                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                        QUERY PATTERNS                         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  namespace                 pattern              count   %     â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  mydb.users               find { status }       45678  37.0%  â•‘
â•‘  mydb.orders              aggregate             23456  19.0%  â•‘
â•‘  mydb.products            find { category }     12345  10.0%  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# RequÃªtes lentes uniquement
mloginfo /var/log/mongodb/mongod.log --queries --sort-queries duration

# Analyse des connexions
mloginfo /var/log/mongodb/mongod.log --connections

# Analyse de rÃ©plication
mloginfo /var/log/mongodb/mongod.log --rsstate
```

**Visualisation graphique** :
```bash
# Graphique des requÃªtes par heure
mplotqueries /var/log/mongodb/mongod.log --type duration --group hour

# Graphique de rÃ©plication
mplotqueries /var/log/mongodb/mongod.log --type replication
```

### 2. Parsing avec jq (JSON Query)

**Script d'analyse complet** :
```bash
#!/bin/bash
# analyze_mongodb_logs.sh

LOGFILE="/var/log/mongodb/mongod.log"
OUTPUT_DIR="./analysis_$(date +%Y%m%d_%H%M%S)"
mkdir -p "$OUTPUT_DIR"

echo "Analyzing MongoDB logs: $LOGFILE"

# 1. Summary statistics
echo "=== SUMMARY ===" > "$OUTPUT_DIR/summary.txt"
total=$(wc -l < "$LOGFILE")
errors=$(grep -c '"s":"E"' "$LOGFILE")
warnings=$(grep -c '"s":"W"' "$LOGFILE")
echo "Total lines: $total" >> "$OUTPUT_DIR/summary.txt"
echo "Errors: $errors" >> "$OUTPUT_DIR/summary.txt"
echo "Warnings: $warnings" >> "$OUTPUT_DIR/summary.txt"

# 2. Top errors
echo "=== TOP ERRORS ===" > "$OUTPUT_DIR/top_errors.txt"
grep '"s":"E"' "$LOGFILE" | \
  jq -r '.msg' | sort | uniq -c | sort -rn | head -20 >> "$OUTPUT_DIR/top_errors.txt"

# 3. Slow queries analysis
echo "=== SLOW QUERIES ===" > "$OUTPUT_DIR/slow_queries.json"
grep '"msg":"Slow query"' "$LOGFILE" | \
  jq -s 'sort_by(.attr.durationMillis) | reverse | .[0:50]' > "$OUTPUT_DIR/slow_queries.json"

# 4. Connection analysis
echo "=== CONNECTION STATS ===" > "$OUTPUT_DIR/connections.txt"
grep '"msg":"Connection accepted"' "$LOGFILE" | \
  jq -r '.attr.remote' | cut -d':' -f1 | sort | uniq -c | sort -rn >> "$OUTPUT_DIR/connections.txt"

# 5. Component breakdown
echo "=== COMPONENT ACTIVITY ===" > "$OUTPUT_DIR/components.txt"
jq -r '.c' "$LOGFILE" 2>/dev/null | sort | uniq -c | sort -rn >> "$OUTPUT_DIR/components.txt"

echo "Analysis complete. Results in: $OUTPUT_DIR"
```

### 3. Logrotate Configuration

Configuration optimale pour production :

```bash
# /etc/logrotate.d/mongodb
/var/log/mongodb/*.log {
    daily
    rotate 30
    missingok
    notifempty
    sharedscripts
    compress
    delaycompress
    postrotate
        /usr/bin/killall -SIGUSR1 mongod 2>/dev/null || true
    endscript
}
```

**Rotation manuelle** :
```javascript
// Via MongoDB
db.adminCommand({ logRotate: 1 })

// VÃ©rification
db.adminCommand({ getLog: "global" }).log.slice(-10)
```

---

## IntÃ©gration avec Stack de Monitoring

### 1. ELK Stack (Elasticsearch, Logstash, Kibana)

**Logstash Pipeline** :
```ruby
# /etc/logstash/conf.d/mongodb.conf
input {
  file {
    path => "/var/log/mongodb/mongod.log"
    start_position => "beginning"
    codec => json
    type => "mongodb"
  }
}

filter {
  if [type] == "mongodb" {
    # Parse timestamp
    date {
      match => ["t.$date", "ISO8601"]
      target => "@timestamp"
    }

    # Severity mapping
    translate {
      field => "s"
      destination => "severity_name"
      dictionary => {
        "F" => "FATAL"
        "E" => "ERROR"
        "W" => "WARNING"
        "I" => "INFO"
        "D" => "DEBUG"
      }
    }

    # Extract slow query metrics
    if [msg] == "Slow query" {
      mutate {
        add_field => {
          "query_duration_ms" => "%{[attr][durationMillis]}"
          "query_namespace" => "%{[attr][ns]}"
          "docs_examined" => "%{[attr][docsExamined]}"
          "keys_examined" => "%{[attr][keysExamined]}"
          "docs_returned" => "%{[attr][nreturned]}"
        }
      }

      # Calculate efficiency ratio
      ruby {
        code => "
          docs_examined = event.get('docs_examined').to_f
          docs_returned = event.get('docs_returned').to_f
          if docs_returned > 0
            event.set('efficiency_ratio', docs_examined / docs_returned)
          end
        "
      }
    }

    # Geo-IP for client IPs
    if [attr][remote] {
      grok {
        match => { "[attr][remote]" => "%{IP:client_ip}:%{NUMBER:client_port}" }
      }

      if [client_ip] {
        geoip {
          source => "client_ip"
        }
      }
    }
  }
}

output {
  elasticsearch {
    hosts => ["localhost:9200"]
    index => "mongodb-logs-%{+YYYY.MM.dd}"
  }
}
```

**Kibana Dashboard Queries** :
```json
// RequÃªtes lentes par namespace
{
  "size": 0,
  "query": {
    "bool": {
      "must": [
        { "match": { "msg": "Slow query" }},
        { "range": { "@timestamp": { "gte": "now-24h" }}}
      ]
    }
  },
  "aggs": {
    "by_namespace": {
      "terms": {
        "field": "query_namespace.keyword",
        "size": 10
      },
      "aggs": {
        "avg_duration": {
          "avg": { "field": "query_duration_ms" }
        }
      }
    }
  }
}
```

### 2. Prometheus + Loki

**Promtail Configuration** :
```yaml
# /etc/promtail/config.yml
server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
  - job_name: mongodb
    static_configs:
      - targets:
          - localhost
        labels:
          job: mongodb
          host: mongodb-prod-01
          __path__: /var/log/mongodb/*.log

    pipeline_stages:
      # Parse JSON
      - json:
          expressions:
            timestamp: t.$date
            severity: s
            component: c
            message: msg
            context: ctx

      # Extract timestamp
      - timestamp:
          source: timestamp
          format: RFC3339Nano

      # Add labels
      - labels:
          severity:
          component:

      # Extract metrics for slow queries
      - match:
          selector: '{job="mongodb"} |= "Slow query"'
          stages:
            - json:
                expressions:
                  duration: attr.durationMillis
                  namespace: attr.ns
            - labels:
                namespace:
            - metrics:
                slow_query_duration_ms:
                  type: Histogram
                  description: "MongoDB slow query duration"
                  source: duration
                  config:
                    buckets: [100, 500, 1000, 5000, 10000]
```

**LogQL Queries** :
```logql
# Taux d'erreurs par composant
sum by (component) (rate({job="mongodb", severity="E"}[5m]))

# RequÃªtes lentes > 1s
{job="mongodb"} |= "Slow query" | json | attr_durationMillis > 1000

# Connexions par IP
{job="mongodb"} |= "Connection accepted" | json | line_format "{{.attr_remote}}"

# Ã‰lections de replica set
{job="mongodb", component="REPL"} |= "Election"
```

### 3. Grafana Alerting

**Exemple de rÃ¨gles d'alerte** :
```yaml
# mongodb_alerts.yaml
groups:
  - name: mongodb_logs
    interval: 30s
    rules:
      - alert: HighErrorRate
        expr: |
          sum(rate({job="mongodb", severity="E"}[5m])) > 10
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Taux d'erreurs MongoDB Ã©levÃ©"
          description: "Plus de 10 erreurs/sec dÃ©tectÃ©es"

      - alert: ReplicationLag
        expr: |
          mongodb_replication_lag_seconds > 30
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Lag de rÃ©plication dÃ©tectÃ©"
          description: "Lag: {{ $value }}s sur {{ $labels.member }}"

      - alert: SlowQueriesSpike
        expr: |
          rate({job="mongodb"} |= "Slow query"[5m]) > 5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Pic de requÃªtes lentes"
          description: "Taux de requÃªtes lentes Ã©levÃ©"

      - alert: FrequentElections
        expr: |
          sum(increase({job="mongodb", component="REPL"} |= "Election succeeded"[1h])) > 2
        labels:
          severity: critical
        annotations:
          summary: "Ã‰lections frÃ©quentes du replica set"
          description: "Plus de 2 Ã©lections en 1 heure"
```

---

## Cas d'Usage AvancÃ©s

### ScÃ©nario 1 : Investigation Post-Mortem

**Contexte** : Incident de performance entre 14h00 et 14h30.

```bash
#!/bin/bash
# postmortem_analysis.sh

INCIDENT_START="2024-12-08T14:00:00"
INCIDENT_END="2024-12-08T14:30:00"
LOGFILE="/var/log/mongodb/mongod.log"
OUTPUT="incident_analysis_$(date +%Y%m%d).txt"

echo "=== POST-MORTEM ANALYSIS ===" > $OUTPUT
echo "Incident window: $INCIDENT_START to $INCIDENT_END" >> $OUTPUT
echo "" >> $OUTPUT

# 1. Timeline of events
echo "=== TIMELINE ===" >> $OUTPUT
jq -r 'select(.t."$date" >= "'"$INCIDENT_START"'" and .t."$date" <= "'"$INCIDENT_END"'") |
       [.t."$date", .s, .c, .msg] | @tsv' $LOGFILE | head -100 >> $OUTPUT

# 2. Errors during incident
echo -e "\n=== ERRORS ===" >> $OUTPUT
jq 'select(.t."$date" >= "'"$INCIDENT_START"'" and .t."$date" <= "'"$INCIDENT_END"'" and .s == "E")' \
   $LOGFILE >> $OUTPUT

# 3. Slow queries
echo -e "\n=== SLOW QUERIES ===" >> $OUTPUT
jq 'select(.t."$date" >= "'"$INCIDENT_START"'" and .t."$date" <= "'"$INCIDENT_END"'" and
           .msg == "Slow query")' $LOGFILE | \
   jq -s 'sort_by(.attr.durationMillis) | reverse | .[0:20]' >> $OUTPUT

# 4. Connection activity
echo -e "\n=== CONNECTION SPIKES ===" >> $OUTPUT
jq -r 'select(.t."$date" >= "'"$INCIDENT_START"'" and .t."$date" <= "'"$INCIDENT_END"'" and
              .msg == "Connection accepted") | .t."$date"[0:16]' $LOGFILE | \
   uniq -c | sort -rn >> $OUTPUT

# 5. Replication status
echo -e "\n=== REPLICATION EVENTS ===" >> $OUTPUT
jq 'select(.t."$date" >= "'"$INCIDENT_START"'" and .t."$date" <= "'"$INCIDENT_END"'" and
           .c == "REPL")' $LOGFILE >> $OUTPUT

echo "Analysis complete: $OUTPUT"
```

### ScÃ©nario 2 : DÃ©tection d'Anomalies

**Script de dÃ©tection automatique** :
```python
#!/usr/bin/env python3
# anomaly_detector.py

import json
import sys
from collections import defaultdict, Counter
from datetime import datetime, timedelta

class MongoDBAnomalyDetector:
    def __init__(self, logfile):
        self.logfile = logfile
        self.anomalies = []

    def detect(self):
        # Baselines
        normal_error_rate = 5  # erreurs/minute
        normal_slow_query_rate = 10  # requÃªtes/minute
        normal_connection_count = 100

        errors_per_minute = defaultdict(int)
        slow_queries_per_minute = defaultdict(int)
        connections_per_minute = defaultdict(int)

        with open(self.logfile, 'r') as f:
            for line in f:
                try:
                    entry = json.loads(line)
                    timestamp = entry['t']['$date'][:16]  # Minute precision

                    # Count errors
                    if entry['s'] == 'E':
                        errors_per_minute[timestamp] += 1

                    # Count slow queries
                    if entry.get('msg') == 'Slow query':
                        slow_queries_per_minute[timestamp] += 1

                    # Count connections
                    if 'Connection accepted' in entry.get('msg', ''):
                        connections_per_minute[timestamp] += 1

                except (json.JSONDecodeError, KeyError):
                    continue

        # Detect anomalies
        for minute, count in errors_per_minute.items():
            if count > normal_error_rate * 3:  # 3x baseline
                self.anomalies.append({
                    'type': 'HIGH_ERROR_RATE',
                    'timestamp': minute,
                    'value': count,
                    'baseline': normal_error_rate,
                    'severity': 'CRITICAL' if count > normal_error_rate * 5 else 'WARNING'
                })

        for minute, count in slow_queries_per_minute.items():
            if count > normal_slow_query_rate * 3:
                self.anomalies.append({
                    'type': 'HIGH_SLOW_QUERY_RATE',
                    'timestamp': minute,
                    'value': count,
                    'baseline': normal_slow_query_rate,
                    'severity': 'WARNING'
                })

        return self.anomalies

    def report(self):
        if not self.anomalies:
            print("No anomalies detected.")
            return

        print(f"\n=== DETECTED {len(self.anomalies)} ANOMALIES ===\n")

        for anomaly in sorted(self.anomalies, key=lambda x: x['timestamp']):
            print(f"[{anomaly['severity']}] {anomaly['type']}")
            print(f"  Time: {anomaly['timestamp']}")
            print(f"  Value: {anomaly['value']} (baseline: {anomaly['baseline']})")
            print()

if __name__ == '__main__':
    detector = MongoDBAnomalyDetector('/var/log/mongodb/mongod.log')
    detector.detect()
    detector.report()
```

### ScÃ©nario 3 : Audit de SÃ©curitÃ©

```bash
#!/bin/bash
# security_audit.sh

LOGFILE="/var/log/mongodb/mongod.log"
AUDIT_REPORT="security_audit_$(date +%Y%m%d).txt"

echo "=== MONGODB SECURITY AUDIT ===" > $AUDIT_REPORT
echo "Date: $(date)" >> $AUDIT_REPORT
echo "" >> $AUDIT_REPORT

# 1. Failed authentication attempts
echo "=== FAILED AUTHENTICATION ATTEMPTS ===" >> $AUDIT_REPORT
grep '"msg":"Authentication failed"' $LOGFILE | \
  jq -r '[.t.$date, .attr.client, .attr.principalName] | @tsv' | \
  column -t >> $AUDIT_REPORT

# 2. Successful authentications from unusual IPs
echo -e "\n=== AUTHENTICATIONS BY IP ===" >> $AUDIT_REPORT
grep '"msg":"Authentication succeeded"' $LOGFILE | \
  jq -r '.attr.client' | sort | uniq -c | sort -rn >> $AUDIT_REPORT

# 3. Admin command usage
echo -e "\n=== ADMIN COMMANDS ===" >> $AUDIT_REPORT
grep '"c":"COMMAND"' $LOGFILE | \
  jq 'select(.attr.command | keys[] |
     test("shutdown|dropDatabase|dropCollection|createUser|dropUser"))' | \
  jq -r '[.t.$date, .attr.command | keys[0], .ctx] | @tsv' | \
  column -t >> $AUDIT_REPORT

# 4. Connection attempts outside business hours
echo -e "\n=== OFF-HOURS CONNECTIONS ===" >> $AUDIT_REPORT
grep '"msg":"Connection accepted"' $LOGFILE | \
  jq -r 'select(.t.$date | test("T(0[0-6]|2[2-3]):")) |
         [.t.$date, .attr.remote] | @tsv' | \
  column -t >> $AUDIT_REPORT

echo "Audit report generated: $AUDIT_REPORT"
```

---

## Bonnes Pratiques pour SRE

### 1. Politique de RÃ©tention des Logs

| Environnement | RÃ©tention Locale | RÃ©tention CentralisÃ©e | Archivage Froid |
|---------------|------------------|----------------------|-----------------|
| **Production** | 7 jours | 90 jours | 1 an (S3/Glacier) |
| **Staging** | 3 jours | 30 jours | 3 mois |
| **DÃ©veloppement** | 1 jour | 7 jours | Aucun |

### 2. Checklist de Configuration

```yaml
# Production-ready logging configuration
âœ“ VerbositÃ© globale: 0
âœ“ Composant query: 0 ou 1 (selon SLA)
âœ“ Composant replication: 0 ou 1
âœ“ Format: JSON structurÃ© (MongoDB 4.4+)
âœ“ Rotation: ActivÃ©e (daily)
âœ“ Compression: ActivÃ©e
âœ“ Destination centralisÃ©e: ConfigurÃ©e (ELK/Loki)
âœ“ Alerting: ConfigurÃ© sur erreurs critiques
âœ“ Dashboards: CrÃ©Ã©s et testÃ©s
âœ“ Runbooks: DocumentÃ©s pour patterns courants
```

### 3. Niveaux d'Alerte RecommandÃ©s

```javascript
// Alerting tiers
const alertingRules = {
  P0_CRITICAL: {
    // NÃ©cessite action immÃ©diate - Page on-call
    conditions: [
      'error_rate > 50/min',
      'replica_set_down',
      'primary_election_failed',
      'disk_space < 5%'
    ],
    response_time: '5 minutes'
  },

  P1_HIGH: {
    // NÃ©cessite action rapide - Ticket urgent
    conditions: [
      'error_rate > 20/min for 5min',
      'replication_lag > 60s',
      'slow_queries > 100/min',
      'connection_pool_exhausted'
    ],
    response_time: '30 minutes'
  },

  P2_MEDIUM: {
    // Investigation nÃ©cessaire - Ticket normal
    conditions: [
      'warning_rate > 50/min',
      'replication_lag > 30s',
      'checkpoint_duration > 60s'
    ],
    response_time: '4 hours'
  },

  P3_LOW: {
    // Monitoring - Ticket planifiÃ©
    conditions: [
      'slow_query_pattern_detected',
      'unusual_connection_pattern',
      'deprecated_feature_usage'
    ],
    response_time: '1 business day'
  }
};
```

### 4. Runbook Template

```markdown
# Runbook: High Error Rate in MongoDB Logs

## Detection
Alert: "HighErrorRate" triggered
Threshold: > 10 errors/second for 5 minutes

## Triage (< 5 minutes)
1. VÃ©rifier le dashboard MongoDB
2. Identifier le type d'erreur dominant
3. VÃ©rifier le statut du replica set: `rs.status()`
4. VÃ©rifier les connexions: `db.currentOp({"active": true})`

## Common Patterns

### Pattern 1: Connection Errors
Symptoms: "Connection refused", "Too many connections"
Action:
  - Check connection pool: `db.serverStatus().connections`
  - Check application logs for connection leaks
  - Temporary: Increase maxIncomingConnections

### Pattern 2: Write Errors
Symptoms: "WriteConflict", "DuplicateKey"
Action:
  - Identify conflicting documents
  - Review application logic for retries
  - Check for missing indexes

### Pattern 3: Replication Errors
Symptoms: "Replication failed", "OplogSlotTooOld"
Action:
  - Check replica set status
  - Verify network connectivity between members
  - Check oplog size: `db.getReplicationInfo()`

## Escalation
If unresolved after 15 minutes:
1. Page secondary on-call
2. Prepare for potential failover
3. Document all actions in incident ticket
```

### 5. Monitoring Hygiene

```bash
# Weekly log maintenance script
#!/bin/bash
# weekly_log_maintenance.sh

MONGO_LOGS="/var/log/mongodb"
BACKUP_DIR="/backup/mongodb-logs"
RETENTION_DAYS=30

# 1. Compress old logs
find $MONGO_LOGS -name "mongod.log.*" -type f -mtime +7 ! -name "*.gz" \
  -exec gzip {} \;

# 2. Move to backup location
find $MONGO_LOGS -name "*.gz" -mtime +7 \
  -exec mv {} $BACKUP_DIR/ \;

# 3. Delete old backups
find $BACKUP_DIR -name "*.gz" -mtime +$RETENTION_DAYS \
  -exec rm {} \;

# 4. Verify log rotation is working
if [ ! -f "$MONGO_LOGS/mongod.log" ]; then
  echo "ERROR: Current log file missing!" | mail -s "MongoDB Log Alert" ops@example.com
fi

# 5. Check log size
current_size=$(du -m "$MONGO_LOGS/mongod.log" | cut -f1)
if [ $current_size -gt 1000 ]; then
  echo "WARNING: Current log file > 1GB" | mail -s "MongoDB Log Size Warning" ops@example.com
fi

# 6. Generate weekly report
./analyze_mongodb_logs.sh > weekly_report_$(date +%Y%m%d).txt
```

---

## Limitations et ConsidÃ©rations

### Limitations des Logs MongoDB

1. **Volume** : Logs en mode verbose peuvent gÃ©nÃ©rer plusieurs GB/jour
2. **Performance** : VerbositÃ© Ã©levÃ©e impacte les performances (jusqu'Ã  20-30%)
3. **Parsing** : Format legacy difficile Ã  parser automatiquement
4. **Contexte limitÃ©** : Pas de correlation ID natif entre requÃªtes
5. **Sampling** : Pas de sampling natif (tout ou rien par niveau)

### Alternatives ComplÃ©mentaires

| Besoin | Outil Principal | ComplÃ©ment |
|--------|----------------|------------|
| **Performance queries** | Profiler | Logs niveau 1 |
| **Monitoring temps rÃ©el** | mongostat/mongotop | Logs niveau 0 |
| **Audit dÃ©taillÃ©** | MongoDB Audit Log | Logs sÃ©curitÃ© |
| **MÃ©triques systÃ¨me** | Prometheus exporter | Logs + FTDC |
| **Diagnostic approfondi** | explain() + Profiler | Logs niveau 2 |

---

## RÃ©sumÃ© pour SRE

### Commandes Essentielles

```bash
# VÃ©rifier configuration actuelle
mongo --eval 'db.getLogComponents()'

# Modification temporaire (verbose queries)
mongo --eval 'db.setLogLevel(1, "query")'

# Rotation manuelle
mongo --eval 'db.adminCommand({ logRotate: 1 })'

# Analyse rapide
tail -f /var/log/mongodb/mongod.log | grep -E '"s":"(E|W)"'

# Extraction erreurs derniÃ¨re heure
grep '"s":"E"' /var/log/mongodb/mongod.log | \
  jq 'select(.t.$date > "'$(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%S)'")'
```

### Matrice de DÃ©cision : Niveau de VerbositÃ©

| Situation | Configuration | DurÃ©e Max |
|-----------|---------------|-----------|
| **Production normale** | Global: 0, Query: 0 | Permanent |
| **Post-dÃ©ploiement** | Global: 0, Query: 1, Repl: 1 | 48h |
| **Investigation performance** | Query: 2, Command: 1 | 4h |
| **Debug rÃ©plication** | Repl: 2, Network: 1 | 2h |
| **Debug sharding** | Sharding: 2, Network: 1 | 2h |
| **Audit sÃ©curitÃ©** | AccessControl: 2 | Session |

### KPIs Ã  Surveiller

```yaml
Critical KPIs:
  - Error rate: < 1/min normal, > 10/min critical
  - Warning rate: < 10/min normal, > 50/min warning
  - Slow query rate: < 5/min normal, > 20/min warning
  - Connection churn: < 100 new/min normal
  - Log growth: < 100 MB/day normal

Trends to Monitor:
  - Increasing slow query count: Review indexes
  - Growing error rate: Check application health
  - Connection spikes: Investigate connection pooling
  - Frequent elections: Check network/heartbeat
  - Checkpoint duration increase: I/O or cache issues
```

---

## Conclusion

Les **logs MongoDB** sont un outil fondamental pour tout SRE ou administrateur systÃ¨me. Une configuration appropriÃ©e, combinÃ©e avec des outils d'analyse modernes et une intÃ©gration dans un stack de monitoring centralisÃ©, permet :

1. **DÃ©tection proactive** des problÃ¨mes avant impact utilisateur
2. **Diagnostic rapide** lors d'incidents
3. **Analyse de tendances** pour la planification
4. **Audit de sÃ©curitÃ©** et conformitÃ©
5. **Documentation** des patterns d'utilisation

**Points clÃ©s Ã  retenir** :
- VerbositÃ© 0 en production, augmentation temporaire pour diagnostic
- JSON structurÃ© pour faciliter le parsing automatisÃ©
- Centralisation obligatoire (ELK/Loki) pour corrÃ©lation
- Alerting sur les patterns critiques, pas sur les Ã©vÃ©nements isolÃ©s
- Rotation et archivage planifiÃ©s pour gestion d'espace

**Prochaines Ã©tapes** :
- Configurer la centralisation des logs
- CrÃ©er les dashboards de monitoring essentiels
- Ã‰tablir les runbooks pour les patterns courants
- Automatiser l'analyse et l'alerting
- Former l'Ã©quipe aux outils d'analyse

---

**RÃ©fÃ©rences** :
- [MongoDB Log Messages Documentation](https://www.mongodb.com/docs/manual/reference/log-messages/)
- [MongoDB Logging and Monitoring](https://www.mongodb.com/docs/manual/administration/monitoring/)
- [mtools Documentation](https://github.com/rueckstiess/mtools)
- [MongoDB Production Notes](https://www.mongodb.com/docs/manual/administration/production-notes/)

â­ï¸ [MongoDB Database Tools](/13-monitoring-administration/05-mongodb-database-tools.md)
