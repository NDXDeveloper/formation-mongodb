ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 13.2.1 serverStatus

## Introduction

La commande `serverStatus` est la pierre angulaire du monitoring MongoDB. Elle retourne un document exhaustif contenant des centaines de mÃ©triques sur l'Ã©tat actuel du serveur, couvrant tous les aspects : performance, ressources, rÃ©plication, stockage, rÃ©seau, et bien plus. Pour un SRE ou administrateur systÃ¨me, maÃ®triser `serverStatus` est essentiel pour comprendre le comportement du systÃ¨me et diagnostiquer les problÃ¨mes.

## Vue d'ensemble

### CaractÃ©ristiques principales

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      serverStatus                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Type:        Commande administrative                       â”‚
â”‚  Scope:       Instance (mongod)                             â”‚
â”‚  Permission:  clusterMonitor                                â”‚
â”‚  Impact:      TrÃ¨s lÃ©ger (< 10ms)                           â”‚
â”‚  FrÃ©quence:   Temps rÃ©el (1-60s)                            â”‚
â”‚  Taille:      ~100-500 KB JSON                              â”‚
â”‚  CoÃ»t:        Lecture de compteurs en mÃ©moire               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Syntaxe et options

```javascript
// Syntaxe de base
db.serverStatus()

// Ou via runCommand
db.runCommand({ serverStatus: 1 })

// Via adminCommand (prÃ©fÃ©rÃ©)
db.adminCommand({ serverStatus: 1 })

// Avec options de filtrage
db.adminCommand({
  serverStatus: 1,
  repl: 1,              // Inclure les stats de rÃ©plication
  metrics: 1,           // Inclure les mÃ©triques dÃ©taillÃ©es
  locks: 0,             // Exclure les stats de locks
  rangeDeleter: 0,      // Exclure le range deleter
  tcmalloc: 0           // Exclure tcmalloc (si utilisÃ©)
})
```

### Options de filtrage

Pour optimiser la performance et rÃ©duire la taille du retour :

| Option | Valeur | Description |
|--------|--------|-------------|
| `repl` | 0/1 | Statistiques de rÃ©plication dÃ©taillÃ©es |
| `metrics` | 0/1 | MÃ©triques supplÃ©mentaires |
| `locks` | 0/1 | Statistiques de locks (verbose) |
| `rangeDeleter` | 0/1 | Stats du range deleter (sharding) |
| `flowControl` | 0/1 | Stats de flow control |
| `freeMonitoring` | 0/1 | Stats du monitoring gratuit |
| `sharding` | 0/1 | Stats de sharding |
| `tcmalloc` | 0/1 | Allocateur mÃ©moire (si applicable) |

**Exemple d'utilisation optimisÃ©e** :

```javascript
// Pour monitoring lÃ©ger, exclure les sections volumineuses
db.adminCommand({
  serverStatus: 1,
  locks: 0,           // Peut Ãªtre trÃ¨s verbose
  rangeDeleter: 0,
  flowControl: 0,
  freeMonitoring: 0,
  tcmalloc: 0
})

// Pour diagnostic approfondi, inclure tout
db.adminCommand({
  serverStatus: 1,
  repl: 1,
  metrics: 1
})
```

---

## Structure du document retournÃ©

Le document `serverStatus` contient de nombreuses sections. Voici une vue d'ensemble :

```javascript
{
  "host": "server01.example.com:27017",
  "version": "7.0.5",
  "process": "mongod",
  "pid": 12345,
  "uptime": 3456789,
  "uptimeMillis": 3456789012,
  "uptimeEstimate": 3456789,
  "localTime": ISODate("2025-12-08T15:42:30.123Z"),

  // Sections principales
  "connections": { ... },        // Ã‰tat des connexions
  "extra_info": { ... },         // Informations systÃ¨me
  "globalLock": { ... },         // Locks globaux
  "locks": { ... },              // Stats dÃ©taillÃ©es des locks
  "network": { ... },            // Statistiques rÃ©seau
  "opcounters": { ... },         // Compteurs d'opÃ©rations
  "opcountersRepl": { ... },     // Ops de rÃ©plication
  "storageEngine": { ... },      // Moteur de stockage
  "wiredTiger": { ... },         // Stats WiredTiger (volumineuses)
  "mem": { ... },                // MÃ©moire
  "metrics": { ... },            // MÃ©triques additionnelles
  "repl": { ... },               // RÃ©plication (si RS)
  "sharding": { ... },           // Sharding (si applicable)

  "ok": 1
}
```

---

## Section 1 : Informations gÃ©nÃ©rales

### MÃ©tadonnÃ©es du serveur

```javascript
var status = db.serverStatus()

// Informations de base
print(`Host: ${status.host}`)
print(`Version: ${status.version}`)
print(`Process: ${status.process}`)  // mongod ou mongos
print(`PID: ${status.pid}`)
print(`Uptime: ${Math.floor(status.uptime / 3600)} hours`)

// RÃ©sultat :
// Host: server01.example.com:27017
// Version: 7.0.5
// Process: mongod
// PID: 12345
// Uptime: 960 hours (40 jours)
```

### Temps et synchronisation

```javascript
status.localTime   // Heure locale du serveur MongoDB
status.uptime      // Secondes depuis le dÃ©marrage
status.uptimeMillis // Millisecondes depuis le dÃ©marrage

// VÃ©rifier si l'heure du serveur est synchronisÃ©e
var serverTime = new Date(status.localTime)
var clientTime = new Date()
var drift = Math.abs(serverTime - clientTime)

if (drift > 5000) {  // > 5 secondes
  print(`âš ï¸ Time drift detected: ${drift}ms`)
  print("Check NTP synchronization")
}
```

---

## Section 2 : Connexions

### Structure

```javascript
status.connections
{
  "current": 847,              // Connexions actuelles
  "available": 51153,          // Connexions disponibles restantes
  "totalCreated": 245789,      // Total crÃ©Ã© depuis dÃ©marrage
  "active": 23,                // Connexions avec opÃ©rations actives
  "threaded": 847,             // Connexions threadÃ©es
  "exhaustIsMaster": 0,        // Connexions isMaster exhaustives
  "exhaustHello": 0,           // Connexions hello exhaustives
  "awaitingTopologyChanges": 0 // Connexions en attente de changement
}
```

### MÃ©triques clÃ©s et analyse

```javascript
function analyzeConnections(status) {
  var conn = status.connections

  // Calcul du taux d'utilisation
  var totalPossible = conn.current + conn.available
  var usagePercent = (conn.current / totalPossible * 100).toFixed(2)

  // Ratio active/total
  var activePercent = (conn.active / conn.current * 100).toFixed(2)

  return {
    current: conn.current,
    available: conn.available,
    usagePercent: usagePercent,
    activePercent: activePercent,
    totalCreated: conn.totalCreated,

    // Alertes
    alerts: {
      poolExhaustion: usagePercent > 80 ? "âš ï¸ WARNING" : "âœ… OK",
      lowActivity: activePercent < 5 ? "âš ï¸ Many idle connections" : "âœ… OK"
    }
  }
}

// Utilisation
var connAnalysis = analyzeConnections(db.serverStatus())
print(JSON.stringify(connAnalysis, null, 2))

// RÃ©sultat :
// {
//   "current": 847,
//   "available": 51153,
//   "usagePercent": "1.63",
//   "activePercent": "2.72",
//   "totalCreated": 245789,
//   "alerts": {
//     "poolExhaustion": "âœ… OK",
//     "lowActivity": "âš ï¸ Many idle connections"
//   }
// }
```

### Calcul du connection churn

```javascript
// Collecter Ã  T0 et T1 (60 secondes d'intervalle)

var t0 = db.serverStatus().connections.totalCreated
// Attendre 60 secondes
var t1 = db.serverStatus().connections.totalCreated

var churnRate = (t1 - t0) / 60  // Nouvelles connexions par seconde
print(`Connection churn: ${churnRate.toFixed(2)} conn/sec`)

// InterprÃ©tation :
// < 1 conn/sec  : âœ… Excellent (pooling efficace)
// 1-10 conn/sec : âš ï¸ Acceptable (vÃ©rifier pooling)
// > 10 conn/sec : ğŸ”¥ ProblÃ¨me (pooling dÃ©faillant)
```

---

## Section 3 : Compteurs d'opÃ©rations (opcounters)

### Structure

```javascript
status.opcounters
{
  "insert": 45789234,      // Nombre d'insertions
  "query": 234567890,      // Nombre de queries
  "update": 67890123,      // Nombre d'updates
  "delete": 4567890,       // Nombre de deletions
  "getmore": 12345678,     // Nombre de getmore (curseurs)
  "command": 456789012     // Nombre de commandes
}

// Pour un Replica Set, opcounters de rÃ©plication
status.opcountersRepl
{
  "insert": 23456789,      // Inserts rÃ©pliquÃ©s
  "query": 0,              // Pas de queries rÃ©pliquÃ©es
  "update": 34567890,      // Updates rÃ©pliquÃ©s
  "delete": 2345678,       // Deletes rÃ©pliquÃ©s
  "getmore": 0,
  "command": 567890
}
```

### Calcul du throughput

```javascript
// Fonction pour calculer les ops/sec entre deux collectes

function calculateThroughput(opcounters0, opcounters1, deltaSeconds) {
  var throughput = {}

  for (let opType in opcounters1) {
    if (opType in opcounters0) {
      var opsPerSec = (opcounters1[opType] - opcounters0[opType]) / deltaSeconds
      throughput[opType] = Math.round(opsPerSec)
    }
  }

  // Total
  throughput.total = Object.values(throughput).reduce((a, b) => a + b, 0)

  return throughput
}

// Exemple d'utilisation
var ops0 = db.serverStatus().opcounters
// Attendre 60 secondes
var ops1 = db.serverStatus().opcounters

var throughput = calculateThroughput(ops0, ops1, 60)
print(JSON.stringify(throughput, null, 2))

// RÃ©sultat :
// {
//   "insert": 450,
//   "query": 1245,
//   "update": 356,
//   "delete": 45,
//   "getmore": 234,
//   "command": 2567,
//   "total": 4897
// }
```

### Analyse des patterns d'opÃ©rations

```javascript
function analyzeOperationPatterns(opcounters) {
  var total = Object.values(opcounters).reduce((sum, val) => sum + val, 0)

  var patterns = {}
  for (let op in opcounters) {
    var percentage = (opcounters[op] / total * 100).toFixed(2)
    patterns[op] = {
      count: opcounters[op],
      percentage: percentage + "%"
    }
  }

  // Identifier le pattern dominant
  var dominant = Object.entries(patterns)
    .sort((a, b) => parseFloat(b[1].percentage) - parseFloat(a[1].percentage))[0]

  return {
    patterns: patterns,
    dominant: dominant[0],
    classification: classifyWorkload(patterns)
  }
}

function classifyWorkload(patterns) {
  var queryPct = parseFloat(patterns.query.percentage)
  var writePct = parseFloat(patterns.insert.percentage) +
                 parseFloat(patterns.update.percentage) +
                 parseFloat(patterns.delete.percentage)

  if (queryPct > 70) return "Read-heavy"
  if (writePct > 60) return "Write-heavy"
  if (Math.abs(queryPct - writePct) < 20) return "Balanced"
  return "Mixed"
}

// Utilisation
var analysis = analyzeOperationPatterns(db.serverStatus().opcounters)
print(`Workload type: ${analysis.classification}`)
print(`Dominant operation: ${analysis.dominant}`)
```

---

## Section 4 : MÃ©moire (mem)

### Structure

```javascript
status.mem
{
  "bits": 64,              // Architecture (32 ou 64 bits)
  "resident": 4567,        // RAM physique utilisÃ©e (MB)
  "virtual": 8234,         // MÃ©moire virtuelle (MB)
  "supported": true,       // Reporting supportÃ©
  "mapped": 0,             // Deprecated (MMAPv1)
  "mappedWithJournal": 0   // Deprecated (MMAPv1)
}
```

### Analyse de la mÃ©moire

```javascript
function analyzeMemory(status) {
  var mem = status.mem
  var wt = status.wiredTiger

  // RÃ©cupÃ©rer la RAM totale du systÃ¨me
  var hostInfo = db.adminCommand({ hostInfo: 1 })
  var totalRAM = hostInfo.system.memSizeMB

  // Calcul des ratios
  var residentPercent = (mem.resident / totalRAM * 100).toFixed(2)

  // Cache WiredTiger
  var cacheMax = wt.cache["maximum bytes configured"] / (1024*1024)
  var cacheUsed = wt.cache["bytes currently in the cache"] / (1024*1024)
  var cachePercent = (cacheUsed / cacheMax * 100).toFixed(2)

  return {
    system: {
      totalRAM: totalRAM + " MB",
      architecture: mem.bits + "-bit"
    },
    process: {
      resident: mem.resident + " MB",
      virtual: mem.virtual + " MB",
      percentOfTotal: residentPercent + "%"
    },
    cache: {
      configured: cacheMax.toFixed(0) + " MB",
      used: cacheUsed.toFixed(0) + " MB",
      usage: cachePercent + "%"
    },
    alerts: {
      highMemory: residentPercent > 80 ? "âš ï¸ High memory usage" : "âœ… OK",
      cachePresure: cachePercent > 90 ? "âš ï¸ Cache under pressure" : "âœ… OK"
    }
  }
}

// Utilisation
var memAnalysis = analyzeMemory(db.serverStatus())
print(JSON.stringify(memAnalysis, null, 2))
```

---

## Section 5 : RÃ©seau (network)

### Structure

```javascript
status.network
{
  "bytesIn": 123456789012,           // Bytes reÃ§us (cumulatif)
  "bytesOut": 234567890123,          // Bytes envoyÃ©s (cumulatif)
  "physicalBytesIn": 98765432109,    // Bytes physiques reÃ§us
  "physicalBytesOut": 187654321098,  // Bytes physiques envoyÃ©s
  "numRequests": 45678901,           // Nombre total de requÃªtes
  "numSlowDNSOperations": 0,         // OpÃ©rations DNS lentes
  "numSlowSSLOperations": 0,         // OpÃ©rations SSL lentes
  "compression": {                    // Compression rÃ©seau
    "snappy": {
      "compressor": {
        "bytesIn": 12345678901,
        "bytesOut": 23456789012
      },
      "decompressor": {
        "bytesIn": 34567890123,
        "bytesOut": 45678901234
      }
    }
  }
}
```

### Calcul du dÃ©bit rÃ©seau

```javascript
function calculateNetworkThroughput(net0, net1, deltaSeconds) {
  // Calcul du dÃ©bit en MB/s
  var inMBps = (net1.bytesIn - net0.bytesIn) / deltaSeconds / (1024*1024)
  var outMBps = (net1.bytesOut - net0.bytesOut) / deltaSeconds / (1024*1024)

  // Calcul du nombre de requÃªtes par seconde
  var reqPerSec = (net1.numRequests - net0.numRequests) / deltaSeconds

  // Calcul de la taille moyenne de requÃªte
  var avgRequestSize = ((net1.bytesIn - net0.bytesIn) /
                        (net1.numRequests - net0.numRequests) / 1024).toFixed(2)

  return {
    throughput: {
      inbound: inMBps.toFixed(2) + " MB/s",
      outbound: outMBps.toFixed(2) + " MB/s",
      total: (inMBps + outMBps).toFixed(2) + " MB/s"
    },
    requests: {
      perSecond: reqPerSec.toFixed(2),
      avgSize: avgRequestSize + " KB"
    }
  }
}

// Collecter Ã  T0 et T1
var net0 = db.serverStatus().network
// Attendre 60 secondes
var net1 = db.serverStatus().network

var netThroughput = calculateNetworkThroughput(net0, net1, 60)
print(JSON.stringify(netThroughput, null, 2))
```

### Analyse de la compression

```javascript
function analyzeCompression(network) {
  if (!network.compression || !network.compression.snappy) {
    return { enabled: false }
  }

  var snappy = network.compression.snappy

  // Ratio de compression (compressor)
  var compRatioOut = snappy.compressor.bytesIn / snappy.compressor.bytesOut

  // Ratio de dÃ©compression (decompressor)
  var compRatioIn = snappy.decompressor.bytesOut / snappy.decompressor.bytesIn

  // Ã‰conomie de bande passante
  var bytesSaved = (snappy.compressor.bytesIn - snappy.compressor.bytesOut) +
                   (snappy.decompressor.bytesOut - snappy.decompressor.bytesIn)
  var savedGB = (bytesSaved / (1024*1024*1024)).toFixed(2)

  return {
    enabled: true,
    ratios: {
      outbound: compRatioOut.toFixed(2) + "x",
      inbound: compRatioIn.toFixed(2) + "x"
    },
    savings: savedGB + " GB saved"
  }
}

var compressionStats = analyzeCompression(db.serverStatus().network)
print(JSON.stringify(compressionStats, null, 2))
```

---

## Section 6 : Global Lock

### Structure

```javascript
status.globalLock
{
  "totalTime": 123456789012,  // Temps total depuis dÃ©marrage (Âµs)
  "currentQueue": {
    "total": 5,               // Ops en attente de lock
    "readers": 3,             // Lectures en attente
    "writers": 2              // Ã‰critures en attente
  },
  "activeClients": {
    "total": 45,              // Clients actifs
    "readers": 32,            // OpÃ©rations de lecture actives
    "writers": 13             // OpÃ©rations d'Ã©criture actives
  }
}
```

### Analyse des contentions

```javascript
function analyzeLockContention(globalLock) {
  var queue = globalLock.currentQueue
  var active = globalLock.activeClients

  // Ratio queue/active
  var queueRatio = active.total > 0 ?
    (queue.total / active.total).toFixed(2) : 0

  // Classification de la contention
  var contentionLevel = "Low"
  if (queue.total > 20) contentionLevel = "High"
  else if (queue.total > 10) contentionLevel = "Medium"

  return {
    queue: {
      total: queue.total,
      readers: queue.readers,
      writers: queue.writers
    },
    active: {
      total: active.total,
      readers: active.readers,
      writers: active.writers,
      readWriteRatio: (active.readers / active.writers).toFixed(2)
    },
    contention: {
      level: contentionLevel,
      queueRatio: queueRatio,
      alert: queue.total > 10 ? "âš ï¸ High queue" : "âœ… OK"
    }
  }
}

var lockAnalysis = analyzeLockContention(db.serverStatus().globalLock)
print(JSON.stringify(lockAnalysis, null, 2))
```

---

## Section 7 : Locks dÃ©taillÃ©s

### Structure

```javascript
status.locks
{
  "Global": {
    "acquireCount": {
      "r": 234567890,        // Nombre de read locks acquis
      "w": 12345678          // Nombre de write locks acquis
    },
    "acquireWaitCount": {
      "r": 234,              // Fois oÃ¹ il a fallu attendre (read)
      "w": 567               // Fois oÃ¹ il a fallu attendre (write)
    },
    "timeAcquiringMicros": {
      "r": 45678,            // Temps total d'attente read (Âµs)
      "w": 123456            // Temps total d'attente write (Âµs)
    }
  },
  "Database": { ... },       // Stats par database
  "Collection": { ... },     // Stats par collection
  "Mutex": { ... }          // Stats des mutex
}
```

### Calcul des mÃ©triques de contention

```javascript
function calculateLockMetrics(locks) {
  var results = {}

  for (let lockType in locks) {
    if (!locks[lockType].acquireCount) continue

    var data = locks[lockType]
    var metrics = {}

    // Pour chaque mode de lock (r = read, w = write)
    for (let mode in data.acquireCount) {
      var acquireCount = data.acquireCount[mode]
      var waitCount = data.acquireWaitCount?.[mode] || 0
      var waitTime = data.timeAcquiringMicros?.[mode] || 0

      // Taux de contention
      var contentionRate = acquireCount > 0 ?
        (waitCount / acquireCount * 100).toFixed(4) : 0

      // Temps d'attente moyen
      var avgWaitTime = waitCount > 0 ?
        (waitTime / waitCount / 1000).toFixed(2) : 0

      metrics[mode] = {
        acquireCount: acquireCount,
        waitCount: waitCount,
        contentionRate: contentionRate + "%",
        avgWaitTime: avgWaitTime + "ms"
      }
    }

    results[lockType] = metrics
  }

  return results
}

var lockMetrics = calculateLockMetrics(db.serverStatus().locks)

// Afficher uniquement les locks avec contention
for (let lockType in lockMetrics) {
  for (let mode in lockMetrics[lockType]) {
    var metric = lockMetrics[lockType][mode]
    if (parseFloat(metric.contentionRate) > 0.01) {
      print(`${lockType}.${mode}: ${metric.contentionRate} contention, ` +
            `avg wait: ${metric.avgWaitTime}`)
    }
  }
}
```

---

## Section 8 : WiredTiger Cache

### Structure (extrait)

```javascript
status.wiredTiger.cache
{
  "maximum bytes configured": 4294967296,          // 4 GB
  "bytes currently in the cache": 3758096384,     // 3.5 GB
  "tracked dirty bytes in the cache": 524288000,  // 500 MB
  "bytes read into cache": 123456789012,
  "bytes written from cache": 234567890123,
  "pages evicted by application threads": 45678,
  "pages read into cache": 12345678,
  "pages written from cache": 23456789,
  "pages currently held in the cache": 234567,
  "pages evicted because they exceeded the in-memory maximum count": 1234,
  "pages evicted because they exceeded the in-memory maximum time (usec)": 5678,
  "eviction server candidate queue empty when topping up": 89,
  "eviction server candidate queue not empty when topping up": 11,
  "eviction server evicting pages": 234,
  "eviction worker thread active": 4,
  "hazard pointer blocked page eviction": 123,
  "internal pages evicted": 234,
  "internal pages split during eviction": 45,
  "leaf pages split during eviction": 89
}
```

### Analyse du cache

```javascript
function analyzeWiredTigerCache(wt) {
  var cache = wt.cache

  // Utilisation du cache
  var maxBytes = cache["maximum bytes configured"]
  var currentBytes = cache["bytes currently in the cache"]
  var dirtyBytes = cache["tracked dirty bytes in the cache"]

  var usagePct = (currentBytes / maxBytes * 100).toFixed(2)
  var dirtyPct = (dirtyBytes / currentBytes * 100).toFixed(2)

  // MÃ©triques d'Ã©viction
  var pagesInCache = cache["pages currently held in the cache"]
  var pagesEvicted = cache["pages evicted by application threads"]

  // Ratio read/write
  var bytesRead = cache["bytes read into cache"]
  var bytesWritten = cache["bytes written from cache"]
  var writeRatio = (bytesWritten / bytesRead).toFixed(2)

  return {
    size: {
      configured: (maxBytes / (1024*1024*1024)).toFixed(2) + " GB",
      used: (currentBytes / (1024*1024*1024)).toFixed(2) + " GB",
      usagePercent: usagePct + "%",
      dirty: (dirtyBytes / (1024*1024*1024)).toFixed(2) + " GB",
      dirtyPercent: dirtyPct + "%"
    },
    pages: {
      inCache: pagesInCache,
      evicted: pagesEvicted,
      evictionWorkers: cache["eviction worker thread active"]
    },
    io: {
      bytesRead: (bytesRead / (1024*1024*1024)).toFixed(2) + " GB",
      bytesWritten: (bytesWritten / (1024*1024*1024)).toFixed(2) + " GB",
      writeRatio: writeRatio + "x"
    },
    alerts: {
      cacheUsage: usagePct > 90 ? "ğŸ”¥ CRITICAL" :
                  usagePct > 80 ? "âš ï¸ WARNING" : "âœ… OK",
      dirtyData: dirtyPct > 50 ? "âš ï¸ High dirty data" : "âœ… OK",
      evictionPressure: pagesEvicted > 10000 ? "âš ï¸ High evictions" : "âœ… OK"
    }
  }
}

var cacheAnalysis = analyzeWiredTigerCache(db.serverStatus().wiredTiger)
print(JSON.stringify(cacheAnalysis, null, 2))
```

### DÃ©tection de cache thrashing

```javascript
// Collecter les mÃ©triques Ã  deux moments
function detectCacheThrashing(wt0, wt1, deltaSeconds) {
  var evictions0 = wt0.cache["pages evicted by application threads"]
  var evictions1 = wt1.cache["pages evicted by application threads"]

  var evictionsPerSec = (evictions1 - evictions0) / deltaSeconds

  var reads0 = wt0.cache["pages read into cache"]
  var reads1 = wt1.cache["pages read into cache"]
  var readsPerSec = (reads1 - reads0) / deltaSeconds

  // Si le taux d'Ã©viction est Ã©levÃ© ET beaucoup de lectures
  var thrashing = evictionsPerSec > 100 && readsPerSec > 1000

  return {
    evictionsPerSecond: evictionsPerSec.toFixed(2),
    readsPerSecond: readsPerSec.toFixed(2),
    thrashing: thrashing,
    diagnosis: thrashing ?
      "ğŸ”¥ Cache thrashing detected - Working set > available cache" :
      "âœ… Cache operating normally",
    recommendation: thrashing ?
      "Increase cache size or add more RAM" :
      "No action needed"
  }
}

// Utilisation
var wt0 = db.serverStatus().wiredTiger
// Attendre 60 secondes
var wt1 = db.serverStatus().wiredTiger

var thrashingAnalysis = detectCacheThrashing(wt0, wt1, 60)
print(JSON.stringify(thrashingAnalysis, null, 2))
```

---

## Section 9 : WiredTiger Transaction

### Structure

```javascript
status.wiredTiger.transaction
{
  "transaction checkpoint max time (msecs)": 1234,
  "transaction checkpoint min time (msecs)": 45,
  "transaction checkpoint most recent time (msecs)": 567,
  "transaction checkpoint generation": 12345,
  "transaction checkpoint currently running": false,
  "transaction checkpoint scrub dirty target": 0,
  "transaction checkpoint scrub time (msecs)": 0,
  "transaction range of IDs currently pinned by a checkpoint": 0,
  "transaction range of timestamps currently pinned": 0,
  "transaction sync calls": 345,
  "transactions committed": 23456789,
  "transactions rolled back": 123
}
```

### Analyse des checkpoints

```javascript
function analyzeCheckpoints(wt) {
  var txn = wt.transaction

  var checkpointRunning = txn["transaction checkpoint currently running"]
  var lastCheckpointTime = txn["transaction checkpoint most recent time (msecs)"]
  var maxCheckpointTime = txn["transaction checkpoint max time (msecs)"]
  var minCheckpointTime = txn["transaction checkpoint min time (msecs)"]

  return {
    checkpoint: {
      running: checkpointRunning,
      lastDuration: lastCheckpointTime + "ms",
      maxDuration: maxCheckpointTime + "ms",
      minDuration: minCheckpointTime + "ms",
      generation: txn["transaction checkpoint generation"]
    },
    transactions: {
      committed: txn["transactions committed"],
      rolledBack: txn["transactions rolled back"],
      rollbackRate: (txn["transactions rolled back"] /
                    txn["transactions committed"] * 100).toFixed(4) + "%"
    },
    alerts: {
      longCheckpoint: lastCheckpointTime > 5000 ?
        "âš ï¸ Last checkpoint took > 5s" : "âœ… OK",
      highRollback: (txn["transactions rolled back"] /
                    txn["transactions committed"]) > 0.01 ?
        "âš ï¸ High rollback rate" : "âœ… OK"
    }
  }
}

var checkpointAnalysis = analyzeCheckpoints(db.serverStatus().wiredTiger)
print(JSON.stringify(checkpointAnalysis, null, 2))
```

---

## Section 10 : RÃ©plication (repl)

### Structure (si Replica Set)

```javascript
status.repl
{
  "hosts": [
    "primary.example.com:27017",
    "secondary1.example.com:27017",
    "secondary2.example.com:27017"
  ],
  "setName": "rs0",
  "setVersion": 5,
  "ismaster": true,         // Ce nÅ“ud est-il le primary?
  "secondary": false,
  "primary": "primary.example.com:27017",
  "me": "primary.example.com:27017",
  "electionId": ObjectId("..."),
  "rbid": 12,               // Rollback ID
  "members": [              // Liste des membres
    {
      "name": "primary.example.com:27017",
      "self": true,
      "stateStr": "PRIMARY"
    },
    {
      "name": "secondary1.example.com:27017",
      "stateStr": "SECONDARY",
      "optime": { "ts": Timestamp(...), "t": 5 },
      "optimeDurable": { "ts": Timestamp(...), "t": 5 }
    }
  ]
}
```

### VÃ©rification du rÃ´le

```javascript
function checkReplicaSetRole(status) {
  if (!status.repl) {
    return { isReplicaSet: false }
  }

  var repl = status.repl

  return {
    isReplicaSet: true,
    setName: repl.setName,
    role: repl.ismaster ? "PRIMARY" :
          repl.secondary ? "SECONDARY" : "OTHER",
    me: repl.me,
    primary: repl.primary,
    setVersion: repl.setVersion,
    members: repl.hosts,
    rbid: repl.rbid
  }
}

var roleInfo = checkReplicaSetRole(db.serverStatus())
print(JSON.stringify(roleInfo, null, 2))

if (roleInfo.isReplicaSet && roleInfo.role === "PRIMARY") {
  print("\nâœ… This node is the PRIMARY")
} else if (roleInfo.isReplicaSet && roleInfo.role === "SECONDARY") {
  print("\nâœ… This node is a SECONDARY")
  print(`   Replicating from: ${roleInfo.primary}`)
}
```

---

## Section 11 : MÃ©triques supplÃ©mentaires (metrics)

### Structure (extrait)

```javascript
status.metrics
{
  "commands": {
    "find": { "failed": 12, "total": 234567 },
    "insert": { "failed": 5, "total": 45678 },
    "update": { "failed": 8, "total": 12345 },
    // ... pour chaque commande
  },
  "cursor": {
    "timedOut": 45,
    "open": {
      "noTimeout": 23,
      "pinned": 12,
      "total": 234
    }
  },
  "document": {
    "deleted": 123456,
    "inserted": 456789,
    "returned": 2345678,
    "updated": 234567
  },
  "operation": {
    "scanAndOrder": 123,      // Queries nÃ©cessitant un sort sans index
    "writeConflicts": 45      // Conflits d'Ã©criture (transactions)
  },
  "query": {
    "planCacheTotalSizeEstimateBytes": 1234567,
    "planCacheHitRate": 0.85
  },
  "repl": {
    "apply": {
      "attemptsToBecomeSecondary": 2,
      "batchSize": 234,
      "batches": {
        "num": 12345,
        "totalMillis": 456789
      },
      "ops": 2345678
    },
    "buffer": {
      "count": 0,
      "sizeBytes": 0
    },
    "network": {
      "bytes": 12345678901,
      "getmores": {
        "num": 2345,
        "totalMillis": 45678
      },
      "ops": 234567,
      "readersCreated": 5
    }
  }
}
```

### Analyse des Ã©checs de commandes

```javascript
function analyzeCommandFailures(metrics) {
  var commands = metrics.commands
  var failures = []

  for (let cmd in commands) {
    var stats = commands[cmd]
    if (stats.failed > 0) {
      var failureRate = (stats.failed / stats.total * 100).toFixed(4)
      failures.push({
        command: cmd,
        total: stats.total,
        failed: stats.failed,
        failureRate: failureRate + "%"
      })
    }
  }

  // Trier par taux d'Ã©chec dÃ©croissant
  failures.sort((a, b) => parseFloat(b.failureRate) - parseFloat(a.failureRate))

  return {
    commandsWithFailures: failures.length,
    topFailures: failures.slice(0, 10)
  }
}

var failureAnalysis = analyzeCommandFailures(db.serverStatus().metrics)
print("Top commands by failure rate:")
failureAnalysis.topFailures.forEach(f => {
  print(`  ${f.command}: ${f.failureRate} (${f.failed}/${f.total})`)
})
```

### Analyse du plan cache

```javascript
function analyzePlanCache(metrics) {
  var query = metrics.query

  return {
    size: {
      bytes: query.planCacheTotalSizeEstimateBytes,
      megabytes: (query.planCacheTotalSizeEstimateBytes / (1024*1024)).toFixed(2) + " MB"
    },
    hitRate: {
      rate: (query.planCacheHitRate * 100).toFixed(2) + "%",
      assessment: query.planCacheHitRate > 0.8 ?
        "âœ… Excellent" :
        query.planCacheHitRate > 0.5 ?
        "âš ï¸ Fair" :
        "ğŸ”¥ Poor - Many query patterns"
    }
  }
}

var planCacheAnalysis = analyzePlanCache(db.serverStatus().metrics)
print(JSON.stringify(planCacheAnalysis, null, 2))
```

---

## Automatisation et monitoring continu

### Script de collecte pÃ©riodique

```javascript
// Script pour collecter serverStatus Ã  intervalles rÃ©guliers

function collectServerStatus(options = {}) {
  var interval = options.interval || 60000  // 60 secondes par dÃ©faut
  var duration = options.duration || 3600000 // 1 heure par dÃ©faut
  var storage = options.storage || "monitoring"

  var startTime = Date.now()
  var collectionCount = 0

  print(`Starting serverStatus collection...`)
  print(`Interval: ${interval/1000}s, Duration: ${duration/1000}s`)

  var intervalId = setInterval(() => {
    try {
      var status = db.adminCommand({
        serverStatus: 1,
        locks: 0,  // Exclure pour performance
        rangeDeleter: 0
      })

      // Extraire mÃ©triques clÃ©s
      var metrics = {
        timestamp: new Date(),
        host: status.host,
        connections: status.connections,
        opcounters: status.opcounters,
        memory: {
          resident: status.mem.resident,
          virtual: status.mem.virtual
        },
        cache: {
          used: status.wiredTiger.cache["bytes currently in the cache"],
          max: status.wiredTiger.cache["maximum bytes configured"]
        },
        network: {
          bytesIn: status.network.bytesIn,
          bytesOut: status.network.bytesOut,
          numRequests: status.network.numRequests
        }
      }

      // Stocker dans collection de monitoring
      db.getSiblingDB(storage).serverStatus.insertOne(metrics)
      collectionCount++

      // VÃ©rifier si la durÃ©e est atteinte
      if (Date.now() - startTime >= duration) {
        clearInterval(intervalId)
        print(`Collection complete: ${collectionCount} samples`)
      }

    } catch (e) {
      print(`Error collecting serverStatus: ${e.message}`)
    }
  }, interval)

  return intervalId
}

// Utilisation : collecter pendant 1 heure, toutes les 60 secondes
var collectionId = collectServerStatus({
  interval: 60000,
  duration: 3600000,
  storage: "monitoring"
})

// Pour arrÃªter manuellement :
// clearInterval(collectionId)
```

### Export vers Prometheus

```javascript
// Formatter serverStatus pour Prometheus

function exportPrometheusMetrics(status) {
  var metrics = []
  var timestamp = Date.now()
  var labels = `{host="${status.host}",instance="${status.process}"}`

  // Connexions
  metrics.push(`mongodb_connections_current${labels} ${status.connections.current} ${timestamp}`)
  metrics.push(`mongodb_connections_available${labels} ${status.connections.available} ${timestamp}`)

  // OpÃ©rations
  for (let op in status.opcounters) {
    metrics.push(`mongodb_opcounters_${op}_total${labels} ${status.opcounters[op]} ${timestamp}`)
  }

  // MÃ©moire
  metrics.push(`mongodb_memory_resident_bytes${labels} ${status.mem.resident * 1024 * 1024} ${timestamp}`)

  // Cache WiredTiger
  var cacheUsed = status.wiredTiger.cache["bytes currently in the cache"]
  var cacheMax = status.wiredTiger.cache["maximum bytes configured"]
  metrics.push(`mongodb_wiredtiger_cache_used_bytes${labels} ${cacheUsed} ${timestamp}`)
  metrics.push(`mongodb_wiredtiger_cache_max_bytes${labels} ${cacheMax} ${timestamp}`)

  // RÃ©seau
  metrics.push(`mongodb_network_bytes_in_total${labels} ${status.network.bytesIn} ${timestamp}`)
  metrics.push(`mongodb_network_bytes_out_total${labels} ${status.network.bytesOut} ${timestamp}`)

  // Global lock
  metrics.push(`mongodb_globallock_current_queue_total${labels} ${status.globalLock.currentQueue.total} ${timestamp}`)
  metrics.push(`mongodb_globallock_active_clients_total${labels} ${status.globalLock.activeClients.total} ${timestamp}`)

  return metrics.join("\n")
}

// Utilisation
var promMetrics = exportPrometheusMetrics(db.serverStatus())
print(promMetrics)

// Ou Ã©crire dans un fichier pour node_exporter textfile collector
// writeFile("/var/lib/node_exporter/textfile_collector/mongodb.prom", promMetrics)
```

---

## Dashboard de monitoring basÃ© sur serverStatus

### Script de dashboard temps rÃ©el

```javascript
// Dashboard interactif dans mongosh

function displayDashboard() {
  // Effacer l'Ã©cran (ANSI escape code)
  print("\x1Bc")

  var status = db.serverStatus()
  var now = new Date().toLocaleString()

  print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
  print("â•‘           MongoDB Server Status Dashboard                     â•‘")
  print(`â•‘  Time: ${now.padEnd(50)} â•‘`)
  print("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")

  // Section 1: Server Info
  print("â•‘  SERVER INFO                                                  â•‘")
  print(`â•‘  Host: ${status.host.padEnd(54)} â•‘`)
  print(`â•‘  Version: ${status.version.padEnd(51)} â•‘`)
  print(`â•‘  Uptime: ${Math.floor(status.uptime/3600)} hours`.padEnd(63) + "â•‘")
  print("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")

  // Section 2: Connections
  var conn = status.connections
  var connUsage = (conn.current / (conn.current + conn.available) * 100).toFixed(1)
  print("â•‘  CONNECTIONS                                                  â•‘")
  print(`â•‘  Current: ${conn.current}  Available: ${conn.available}  Usage: ${connUsage}%`.padEnd(63) + "â•‘")
  print("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")

  // Section 3: Memory
  var cacheUsed = status.wiredTiger.cache["bytes currently in the cache"]
  var cacheMax = status.wiredTiger.cache["maximum bytes configured"]
  var cachePct = (cacheUsed / cacheMax * 100).toFixed(1)
  print("â•‘  MEMORY                                                       â•‘")
  print(`â•‘  Resident: ${status.mem.resident} MB  Cache: ${cachePct}%`.padEnd(63) + "â•‘")
  print("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")

  // Section 4: Operations (nÃ©cessite calcul delta)
  print("â•‘  OPERATIONS (cumulative since startup)                        â•‘")
  print(`â•‘  Insert: ${status.opcounters.insert}  Query: ${status.opcounters.query}`.padEnd(63) + "â•‘")
  print(`â•‘  Update: ${status.opcounters.update}  Delete: ${status.opcounters.delete}`.padEnd(63) + "â•‘")
  print("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")

  // Section 5: Global Lock
  var queue = status.globalLock.currentQueue.total
  var active = status.globalLock.activeClients.total
  print("â•‘  GLOBAL LOCK                                                  â•‘")
  print(`â•‘  Active: ${active}  Queued: ${queue}`.padEnd(63) + "â•‘")
  print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

  print("\nPress Ctrl+C to exit")
}

// RafraÃ®chir toutes les 5 secondes
function startDashboard() {
  print("Starting dashboard... (Press Ctrl+C to stop)")
  var intervalId = setInterval(displayDashboard, 5000)
  displayDashboard()  // Afficher immÃ©diatement
  return intervalId
}

// DÃ©marrer
// var dashboardId = startDashboard()
// Pour arrÃªter: clearInterval(dashboardId)
```

---

## Cas d'usage pratiques

### 1. DÃ©tection de spike de charge

```javascript
function detectLoadSpike(baselineStatus, currentStatus) {
  var baseline = {
    connections: baselineStatus.connections.current,
    activeClients: baselineStatus.globalLock.activeClients.total,
    queuedOps: baselineStatus.globalLock.currentQueue.total
  }

  var current = {
    connections: currentStatus.connections.current,
    activeClients: currentStatus.globalLock.activeClients.total,
    queuedOps: currentStatus.globalLock.currentQueue.total
  }

  var spikes = []

  // DÃ©tection de spike de connexions (> 50% augmentation)
  if (current.connections > baseline.connections * 1.5) {
    spikes.push({
      metric: "connections",
      baseline: baseline.connections,
      current: current.connections,
      increase: ((current.connections / baseline.connections - 1) * 100).toFixed(2) + "%"
    })
  }

  // DÃ©tection de spike d'opÃ©rations actives
  if (current.activeClients > baseline.activeClients * 2) {
    spikes.push({
      metric: "activeClients",
      baseline: baseline.activeClients,
      current: current.activeClients,
      increase: ((current.activeClients / baseline.activeClients - 1) * 100).toFixed(2) + "%"
    })
  }

  // DÃ©tection de spike de queue
  if (current.queuedOps > 10 && current.queuedOps > baseline.queuedOps * 3) {
    spikes.push({
      metric: "queuedOperations",
      baseline: baseline.queuedOps,
      current: current.queuedOps,
      increase: "CRITICAL"
    })
  }

  return {
    spikeDetected: spikes.length > 0,
    spikes: spikes,
    timestamp: new Date()
  }
}

// Utilisation
var baseline = db.serverStatus()
// ... quelques minutes plus tard
var current = db.serverStatus()

var spikeAnalysis = detectLoadSpike(baseline, current)
if (spikeAnalysis.spikeDetected) {
  print("âš ï¸ Load spike detected!")
  print(JSON.stringify(spikeAnalysis, null, 2))
}
```

### 2. Health check complet

```javascript
function comprehensiveHealthCheck(status) {
  var health = {
    timestamp: new Date(),
    overall: "HEALTHY",
    checks: []
  }

  // Check 1: Connexions
  var connUsage = status.connections.current /
                 (status.connections.current + status.connections.available)
  if (connUsage > 0.9) {
    health.checks.push({
      name: "connections",
      status: "CRITICAL",
      message: "Connection pool > 90%"
    })
    health.overall = "CRITICAL"
  } else if (connUsage > 0.8) {
    health.checks.push({
      name: "connections",
      status: "WARNING",
      message: "Connection pool > 80%"
    })
    if (health.overall === "HEALTHY") health.overall = "WARNING"
  }

  // Check 2: Cache
  var cacheUsage = status.wiredTiger.cache["bytes currently in the cache"] /
                   status.wiredTiger.cache["maximum bytes configured"]
  if (cacheUsage > 0.95) {
    health.checks.push({
      name: "cache",
      status: "WARNING",
      message: "Cache usage > 95%"
    })
    if (health.overall === "HEALTHY") health.overall = "WARNING"
  }

  // Check 3: Queue
  if (status.globalLock.currentQueue.total > 50) {
    health.checks.push({
      name: "queue",
      status: "CRITICAL",
      message: `${status.globalLock.currentQueue.total} operations queued`
    })
    health.overall = "CRITICAL"
  }

  // Check 4: Replica Set (si applicable)
  if (status.repl && !status.repl.ismaster && !status.repl.secondary) {
    health.checks.push({
      name: "replication",
      status: "CRITICAL",
      message: "Node is not PRIMARY or SECONDARY"
    })
    health.overall = "CRITICAL"
  }

  // Si aucun problÃ¨me dÃ©tectÃ©
  if (health.checks.length === 0) {
    health.checks.push({
      name: "overall",
      status: "HEALTHY",
      message: "All systems operational"
    })
  }

  return health
}

// Utilisation
var healthCheck = comprehensiveHealthCheck(db.serverStatus())
print(`Overall Status: ${healthCheck.overall}`)
healthCheck.checks.forEach(check => {
  var icon = check.status === "HEALTHY" ? "âœ…" :
             check.status === "WARNING" ? "âš ï¸" : "ğŸ”¥"
  print(`${icon} ${check.name}: ${check.message}`)
})
```

---

## RÃ©sumÃ©

La commande `serverStatus` est l'outil le plus important pour le monitoring MongoDB :

âœ… **Exhaustive** : Des centaines de mÃ©triques sur tous les aspects du serveur

âœ… **Performante** : Impact minimal (< 10ms), lecture de compteurs en mÃ©moire

âœ… **Temps rÃ©el** : Snapshot instantanÃ© de l'Ã©tat actuel

âœ… **Versatile** : Utilisable pour monitoring continu, diagnostic, alerting

âœ… **StandardisÃ©e** : Format JSON structurÃ©, facilement parsable

**Sections critiques Ã  surveiller** :
- `connections` : Saturation du pool
- `opcounters` : Throughput et patterns
- `mem` + `wiredTiger.cache` : Pression mÃ©moire
- `network` : Bande passante et requÃªtes
- `globalLock` : Contentions
- `wiredTiger` : Cache, checkpoints, I/O
- `repl` : Ã‰tat de rÃ©plication (si RS)

**Bonnes pratiques** :
- Collecter toutes les 10-60 secondes pour monitoring
- Exclure sections volumineuses en production (`locks: 0`)
- Calculer des deltas pour throughput et taux
- Combiner avec d'autres commandes pour diagnostic complet
- Exporter vers systÃ¨mes de monitoring (Prometheus, Datadog)
- DÃ©finir des alertes sur mÃ©triques critiques

---


â­ï¸ [dbStats](/13-monitoring-administration/02.2-dbstats.md)
