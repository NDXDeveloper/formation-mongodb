üîù Retour au [Sommaire](/SOMMAIRE.md)

# 13.3 Profiler de Requ√™tes MongoDB

## Introduction

Le **Database Profiler** de MongoDB est un outil d'analyse essentiel qui enregistre les op√©rations de base de donn√©es dans une collection syst√®me d√©di√©e (`system.profile`). Il permet aux SRE et administrateurs d'identifier les requ√™tes lentes, d'analyser les patterns d'acc√®s et d'optimiser les performances en production.

Contrairement aux logs MongoDB qui peuvent √™tre verbeux et difficiles √† parser, le profiler structure les donn√©es de performance dans un format interrogeable, facilitant l'analyse post-mortem et le monitoring continu.

---

## Architecture et Fonctionnement

### Collection system.profile

Le profiler stocke ses donn√©es dans une **capped collection** nomm√©e `system.profile`, cr√©√©e automatiquement √† l'activation du profiling. Cette collection a les caract√©ristiques suivantes :

- **Taille par d√©faut** : 1 Mo (peut contenir environ 100-200 entr√©es selon leur complexit√©)
- **Type** : Capped collection (FIFO - First In, First Out)
- **Port√©e** : Une collection par base de donn√©es
- **Persistence** : Les donn√©es survivent au red√©marrage de MongoDB

```javascript
// V√©rifier la taille actuelle de la collection profiler
db.system.profile.stats()

// R√©sultat exemple
{
  "ns": "mydb.system.profile",
  "size": 1048576,  // 1 Mo
  "count": 156,
  "avgObjSize": 6721,
  "capped": true,
  "max": -1
}
```

### Redimensionnement de la Collection

Pour des environnements de production avec un volume √©lev√© d'op√©rations, augmenter la taille de la collection profiler est souvent n√©cessaire :

```javascript
// 1. D√©sactiver le profiler
db.setProfilingLevel(0)

// 2. Supprimer l'ancienne collection
db.system.profile.drop()

// 3. Cr√©er une nouvelle collection avec la taille souhait√©e (128 Mo)
db.createCollection("system.profile", {
  capped: true,
  size: 134217728  // 128 Mo en octets
})

// 4. R√©activer le profiler
db.setProfilingLevel(1, { slowms: 100 })
```

**Recommandations de dimensionnement** :
- **Environnement de d√©veloppement** : 1-10 Mo
- **Production √† faible charge** : 50-100 Mo
- **Production √† charge √©lev√©e** : 200-500 Mo
- **Analyse approfondie temporaire** : 1-2 Go

---

## Niveaux de Profiling

MongoDB offre trois niveaux de profiling, chacun avec son compromis entre visibilit√© et impact sur les performances.

### Niveau 0 : D√©sactiv√© (D√©faut)

```javascript
db.setProfilingLevel(0)
```

**Caract√©ristiques** :
- Aucune op√©ration n'est enregistr√©e dans system.profile
- Impact z√©ro sur les performances
- Les op√©rations lentes continuent d'appara√Ætre dans les logs MongoDB

**Cas d'usage** : Mode par d√©faut en production pour minimiser l'overhead.

### Niveau 1 : Op√©rations Lentes Uniquement

```javascript
// Profiler les op√©rations d√©passant 100ms
db.setProfilingLevel(1, { slowms: 100 })

// Profiler les op√©rations d√©passant 50ms
db.setProfilingLevel(1, { slowms: 50 })
```

**Caract√©ristiques** :
- Enregistre uniquement les op√©rations d√©passant le seuil `slowms`
- Impact minimal sur les performances (< 5%)
- Permet de capturer les requ√™tes probl√©matiques sans noyer les donn√©es

**Cas d'usage** :
- Monitoring continu en production
- Identification des requ√™tes n√©cessitant optimisation
- Diagnostic initial de probl√®mes de performance

**Recommandations de seuil** :
- **OLTP/Web applications** : 50-100ms
- **Analytics/Reporting** : 500-1000ms
- **Batch processing** : 2000-5000ms

### Niveau 2 : Toutes les Op√©rations

```javascript
db.setProfilingLevel(2)

// Avec filtres optionnels
db.setProfilingLevel(2, {
  slowms: 0,  // Toutes les op√©rations
  sampleRate: 0.1  // √âchantillonner 10% des op√©rations
})
```

**Caract√©ristiques** :
- Enregistre **toutes** les op√©rations de lecture et d'√©criture
- Impact significatif sur les performances (10-30%)
- Volume de donn√©es tr√®s √©lev√©
- La collection system.profile se remplit rapidement

**Cas d'usage** :
- Diagnostic approfondi de probl√®mes sp√©cifiques (sessions temporaires)
- Audit de s√©curit√© d√©taill√©
- Analyse de patterns d'acc√®s complets
- **Jamais en production continue sans √©chantillonnage**

---

## Configuration et Gestion

### V√©rification de l'√âtat Actuel

```javascript
// Obtenir le niveau et la configuration actuelle
db.getProfilingStatus()

// R√©sultat
{
  "was": 1,
  "slowms": 100,
  "sampleRate": 1.0,
  "ok": 1
}
```

### √âchantillonnage (MongoDB 4.4+)

L'option `sampleRate` permet de r√©duire le volume de donn√©es collect√©es en mode niveau 2 :

```javascript
// Profiler 25% de toutes les op√©rations
db.setProfilingLevel(2, { sampleRate: 0.25 })

// Profiler 5% des op√©rations lentes (> 200ms)
db.setProfilingLevel(1, {
  slowms: 200,
  sampleRate: 0.05
})
```

**Calcul de l'√©chantillonnage** :
- `sampleRate: 1.0` ‚Üí 100% des op√©rations (d√©faut)
- `sampleRate: 0.5` ‚Üí 50% des op√©rations
- `sampleRate: 0.01` ‚Üí 1% des op√©rations

### Configuration Multi-Bases

Le profiler est configur√© **par base de donn√©es**. Pour activer sur plusieurs bases :

```javascript
// Script pour activer le profiling sur toutes les bases
db.adminCommand("listDatabases").databases.forEach(function(d) {
  if (d.name !== "admin" && d.name !== "local" && d.name !== "config") {
    db.getSiblingDB(d.name).setProfilingLevel(1, { slowms: 100 });
  }
});
```

### Configuration via Fichier de Configuration

Pour persister la configuration au red√©marrage (MongoDB 4.4+) :

```yaml
# mongod.conf
operationProfiling:
  mode: slowOp
  slowOpThresholdMs: 100
  slowOpSampleRate: 1.0
```

---

## Structure des Entr√©es du Profiler

### Document Type Complet

Chaque op√©ration profil√©e g√©n√®re un document avec la structure suivante :

```javascript
{
  "op" : "query",              // Type d'op√©ration
  "ns" : "mydb.users",         // Namespace (base.collection)
  "command" : {                // Commande compl√®te ex√©cut√©e
    "find" : "users",
    "filter" : { "age" : { "$gte" : 30 } },
    "sort" : { "lastName" : 1 },
    "projection" : { "email" : 1, "lastName" : 1 },
    "limit" : 100
  },
  "keysExamined" : 15234,      // Cl√©s d'index examin√©es
  "docsExamined" : 15234,      // Documents examin√©s
  "nreturned" : 100,           // Documents retourn√©s
  "responseLength" : 12456,    // Taille de la r√©ponse en octets
  "millis" : 247,              // Dur√©e totale en millisecondes
  "planSummary" : "IXSCAN { age: 1, lastName: 1 }",  // Plan d'ex√©cution
  "execStats" : {              // Statistiques d√©taill√©es d'ex√©cution
    "stage" : "FETCH",
    "nReturned" : 100,
    "executionTimeMillisEstimate" : 245,
    "works" : 15335,
    "advanced" : 100,
    "needTime" : 15234,
    "inputStage" : {
      "stage" : "IXSCAN",
      "keyPattern" : { "age" : 1, "lastName" : 1 },
      "indexName" : "age_1_lastName_1",
      "direction" : "forward"
    }
  },
  "ts" : ISODate("2024-12-08T14:23:45.123Z"),  // Timestamp
  "client" : "10.0.1.45",      // Adresse IP du client
  "appName" : "ProductionAPI", // Nom de l'application
  "user" : "apiUser@mydb",     // Utilisateur MongoDB
  "locks" : {                  // Locks acquis
    "Global" : { "r" : 252 },
    "Database" : { "r" : 126 },
    "Collection" : { "r" : 126 }
  },
  "flowControl" : {            // Contr√¥le de flux
    "acquireCount" : 1,
    "timeAcquiringMicros" : 5
  }
}
```

### Champs Cl√©s pour l'Analyse

| Champ | Description | Utilit√© SRE |
|-------|-------------|-------------|
| `millis` | Dur√©e totale d'ex√©cution | Identifier les requ√™tes lentes |
| `keysExamined` / `docsExamined` | Nombre d'√©l√©ments scann√©s | D√©tecter les scans inefficaces |
| `nreturned` | Documents retourn√©s | Calculer le ratio d'efficacit√© |
| `planSummary` | R√©sum√© du plan d'ex√©cution | V√©rifier l'utilisation des index |
| `responseLength` | Taille de la r√©ponse | Identifier les r√©ponses volumineuses |
| `ns` | Namespace | Analyser par collection |
| `client` | IP du client | Tra√ßabilit√© et analyse par source |
| `locks` | Informations de verrouillage | Diagnostiquer les contentions |

---

## Analyse des Donn√©es du Profiler

### Requ√™tes d'Analyse Essentielles

#### 1. Top 10 des Requ√™tes les Plus Lentes

```javascript
db.system.profile.find()
  .sort({ millis: -1 })
  .limit(10)
  .pretty()
```

#### 2. Requ√™tes avec Ratio d'Efficacit√© Faible

Le ratio d'efficacit√© compare les documents examin√©s aux documents retourn√©s. Un ratio √©lev√© indique un scan inefficace.

```javascript
db.system.profile.aggregate([
  {
    $match: {
      op: { $in: ["query", "find"] },
      docsExamined: { $gt: 1000 }
    }
  },
  {
    $project: {
      ns: 1,
      millis: 1,
      docsExamined: 1,
      nreturned: 1,
      ratio: {
        $cond: {
          if: { $eq: ["$nreturned", 0] },
          then: "$docsExamined",
          else: { $divide: ["$docsExamined", "$nreturned"] }
        }
      }
    }
  },
  {
    $match: { ratio: { $gt: 100 } }  // Ratio > 100:1 est probl√©matique
  },
  { $sort: { ratio: -1 } },
  { $limit: 20 }
])
```

**Interpr√©tation** :
- **Ratio < 10** : Efficacit√© excellente
- **Ratio 10-100** : Acceptable, mais peut √™tre optimis√©
- **Ratio > 100** : Probl√®me majeur, n√©cessite investigation
- **Ratio > 1000** : Scan de table complet probable

#### 3. Analyse par Collection

```javascript
db.system.profile.aggregate([
  {
    $group: {
      _id: "$ns",
      count: { $sum: 1 },
      avgMillis: { $avg: "$millis" },
      maxMillis: { $max: "$millis" },
      totalDocsExamined: { $sum: "$docsExamined" }
    }
  },
  { $sort: { avgMillis: -1 } }
])
```

#### 4. Distribution Temporelle des Requ√™tes Lentes

```javascript
db.system.profile.aggregate([
  {
    $match: { millis: { $gt: 100 } }
  },
  {
    $group: {
      _id: {
        year: { $year: "$ts" },
        month: { $month: "$ts" },
        day: { $dayOfMonth: "$ts" },
        hour: { $hour: "$ts" }
      },
      count: { $sum: 1 },
      avgMillis: { $avg: "$millis" }
    }
  },
  { $sort: { "_id.year": 1, "_id.month": 1, "_id.day": 1, "_id.hour": 1 } }
])
```

#### 5. Requ√™tes Sans Index (Collection Scans)

```javascript
db.system.profile.find({
  "planSummary": { $regex: /^COLLSCAN/ }
}).sort({ millis: -1 }).limit(20)
```

#### 6. Analyse par Type d'Op√©ration

```javascript
db.system.profile.aggregate([
  {
    $group: {
      _id: "$op",
      count: { $sum: 1 },
      avgMillis: { $avg: "$millis" },
      maxMillis: { $max: "$millis" }
    }
  },
  { $sort: { count: -1 } }
])
```

#### 7. Requ√™tes par Application/Client

```javascript
db.system.profile.aggregate([
  {
    $group: {
      _id: {
        appName: "$appName",
        client: "$client"
      },
      count: { $sum: 1 },
      avgMillis: { $avg: "$millis" },
      slowQueries: {
        $sum: { $cond: [{ $gt: ["$millis", 1000] }, 1, 0] }
      }
    }
  },
  { $sort: { avgMillis: -1 } }
])
```

---

## M√©triques Cl√©s et Seuils d'Alerte

### Tableau des M√©triques Critiques

| M√©trique | Seuil Normal | Seuil Attention | Seuil Critique | Action |
|----------|--------------|-----------------|----------------|--------|
| **millis** | < 50ms | 50-200ms | > 200ms | Optimiser la requ√™te |
| **docsExamined/nreturned** | < 10 | 10-100 | > 100 | Ajouter/r√©viser index |
| **keysExamined/nreturned** | < 5 | 5-50 | > 50 | R√©viser index compos√©s |
| **responseLength** | < 1 MB | 1-10 MB | > 10 MB | Pagination/projection |
| **COLLSCAN** | 0% | < 5% | > 5% | Index manquants |
| **locks.timeAcquiringMicros** | < 1000 | 1000-10000 | > 10000 | Contention de locks |

### Exemples d'Alertes Prometheus/Grafana

```yaml
# R√®gle d'alerte pour requ√™tes lentes fr√©quentes
groups:
  - name: mongodb_profiler_alerts
    interval: 30s
    rules:
      - alert: HighSlowQueryRate
        expr: |
          rate(mongodb_profile_slow_queries_total[5m]) > 10
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Taux √©lev√© de requ√™tes lentes sur {{ $labels.database }}"

      - alert: CriticalCollectionScan
        expr: |
          mongodb_profile_collscan_percentage > 10
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Scans de collection excessifs sur {{ $labels.namespace }}"
```

---

## Patterns d'Optimisation Bas√©s sur le Profiler

### Pattern 1 : Index Manquant

**Sympt√¥me d√©tect√©** :
```javascript
{
  "planSummary": "COLLSCAN",
  "docsExamined": 45678,
  "nreturned": 10,
  "millis": 1245
}
```

**Diagnostic** : Scan de collection complet pour retourner seulement 10 documents.

**Solution** :
```javascript
// Analyser la requ√™te
db.collection.find({ status: "active", country: "FR" })

// Cr√©er l'index appropri√©
db.collection.createIndex({ status: 1, country: 1 })
```

### Pattern 2 : Index Non-S√©lectif

**Sympt√¥me d√©tect√©** :
```javascript
{
  "planSummary": "IXSCAN { status: 1 }",
  "keysExamined": 89234,
  "docsExamined": 89234,
  "nreturned": 50,
  "millis": 876
}
```

**Diagnostic** : L'index `status` est utilis√© mais non s√©lectif (presque tous les documents sont scann√©s).

**Solution** :
```javascript
// Index compos√© plus s√©lectif
db.collection.createIndex({ country: 1, status: 1, createdAt: -1 })
```

### Pattern 3 : Projection Manquante

**Sympt√¥me d√©tect√©** :
```javascript
{
  "responseLength": 15728640,  // ~15 MB
  "nreturned": 1000,
  "millis": 234
}
```

**Diagnostic** : Documents complets retourn√©s alors que seulement quelques champs sont n√©cessaires.

**Solution** :
```javascript
// Ajouter une projection
db.collection.find(
  { status: "active" },
  { _id: 1, name: 1, email: 1 }  // Seulement les champs n√©cessaires
).limit(1000)
```

### Pattern 4 : Pas de Limite

**Sympt√¥me d√©tect√©** :
```javascript
{
  "nreturned": 125000,
  "responseLength": 67108864,  // 64 MB
  "millis": 3456
}
```

**Diagnostic** : Requ√™te retournant un nombre excessif de documents.

**Solution** :
```javascript
// Impl√©menter la pagination
db.collection.find({ status: "active" })
  .sort({ createdAt: -1 })
  .limit(100)
  .skip(pageNumber * 100)
```

---

## Impact sur les Performances

### Overhead du Profiler

| Niveau | Overhead CPU | Overhead I/O | Overhead M√©moire |
|--------|--------------|--------------|------------------|
| Niveau 0 | 0% | 0% | 0% |
| Niveau 1 (slowms: 100ms) | 1-3% | 2-5% | Minimal |
| Niveau 1 (slowms: 10ms) | 3-7% | 5-10% | Faible |
| Niveau 2 (sample: 0.1) | 5-10% | 10-15% | Mod√©r√© |
| Niveau 2 (sample: 1.0) | 15-30% | 20-40% | √âlev√© |

### Recommandations de Production

**Environnements de Production Critiques** :
```javascript
// Configuration conservative
db.setProfilingLevel(1, {
  slowms: 200,      // Seuil √©lev√©
  sampleRate: 0.5   // √âchantillonner 50%
})

// Collection profiler dimensionn√©e
db.system.profile.drop()
db.createCollection("system.profile", {
  capped: true,
  size: 104857600  // 100 Mo
})
```

**Environnements de D√©veloppement/Staging** :
```javascript
// Configuration plus agressive pour capturer plus de donn√©es
db.setProfilingLevel(1, {
  slowms: 50,
  sampleRate: 1.0
})
```

**Diagnostic Temporaire** :
```javascript
// Activer niveau 2 temporairement (15-30 minutes max)
db.setProfilingLevel(2, { sampleRate: 0.1 })

// D√©sactiver apr√®s investigation
db.setProfilingLevel(0)
```

---

## Int√©gration avec les Outils de Monitoring

### Export vers Outils Externes

#### Script d'Export vers JSON

```javascript
// export_profiler.js
const fs = require('fs');
const { MongoClient } = require('mongodb');

async function exportProfiler() {
  const client = await MongoClient.connect('mongodb://localhost:27017');
  const db = client.db('mydb');

  const profiles = await db.collection('system.profile')
    .find({ millis: { $gt: 100 } })
    .sort({ ts: -1 })
    .limit(10000)
    .toArray();

  fs.writeFileSync('profiler_export.json', JSON.stringify(profiles, null, 2));
  await client.close();
}

exportProfiler();
```

#### Int√©gration Elasticsearch

```javascript
// Logstash pipeline pour indexer les donn√©es du profiler
input {
  mongodb {
    uri => "mongodb://localhost:27017/mydb"
    placeholder_db_dir => "/opt/logstash/data/"
    collection => "system.profile"
    batch_size => 5000
  }
}

filter {
  mutate {
    rename => { "millis" => "duration_ms" }
  }

  if [docsExamined] > 0 and [nreturned] > 0 {
    ruby {
      code => "event.set('efficiency_ratio', event.get('docsExamined').to_f / event.get('nreturned'))"
    }
  }
}

output {
  elasticsearch {
    hosts => ["localhost:9200"]
    index => "mongodb-profiler-%{+YYYY.MM.dd}"
  }
}
```

### Dashboard Grafana

Exemple de requ√™tes PromQL pour un exporter MongoDB :

```promql
# Taux de requ√™tes lentes par seconde
rate(mongodb_profile_slow_queries_total[5m])

# Dur√©e moyenne des requ√™tes lentes
avg(mongodb_profile_query_duration_ms{slow="true"})

# Pourcentage de collection scans
(mongodb_profile_collscan_total / mongodb_profile_queries_total) * 100

# Top 5 collections avec le plus de requ√™tes lentes
topk(5, sum by (namespace) (rate(mongodb_profile_slow_queries_total[10m])))
```

---

## Bonnes Pratiques pour SRE

### 1. Strat√©gie de Profiling Progressive

```javascript
// Phase 1 : Baseline (1 semaine)
db.setProfilingLevel(1, { slowms: 500, sampleRate: 1.0 })

// Phase 2 : R√©duction du seuil (2 semaines)
db.setProfilingLevel(1, { slowms: 200, sampleRate: 1.0 })

// Phase 3 : Monitoring continu
db.setProfilingLevel(1, { slowms: 100, sampleRate: 0.5 })
```

### 2. Rotation et Archivage

```javascript
// Script de rotation quotidien
use mydb

// Exporter les anciennes donn√©es
var yesterday = new Date();
yesterday.setDate(yesterday.getDate() - 1);

db.system.profile.find({ ts: { $lt: yesterday } }).forEach(function(doc) {
  db.profiler_archive.insert(doc);
});

// Nettoyer
db.system.profile.remove({ ts: { $lt: yesterday } });
```

### 3. Alerting Intelligent

**R√®gles d'alerte gradu√©es** :

```javascript
// Niveau 1 : Avertissement
// > 5 requ√™tes/sec d√©passant 200ms pendant 5 minutes

// Niveau 2 : Attention
// > 10 requ√™tes/sec d√©passant 500ms pendant 2 minutes

// Niveau 3 : Critique
// > 20 requ√™tes/sec d√©passant 1000ms pendant 1 minute
// OU > 50% des requ√™tes sont des COLLSCAN
```

### 4. Checklist de Review Hebdomadaire

1. **Analyser les nouvelles requ√™tes lentes** apparues cette semaine
2. **V√©rifier les tendances** de dur√©e moyenne par collection
3. **Identifier les patterns d'acc√®s** changeants
4. **Corr√©ler avec les d√©ploiements** et incidents
5. **Documenter les optimisations** effectu√©es
6. **Planifier les maintenances d'index** si n√©cessaire

### 5. Documentation des Optimisations

```javascript
// Template de documentation
{
  "date": "2024-12-08",
  "collection": "users",
  "issue": "COLLSCAN sur recherche par email",
  "profilerData": {
    "avgMillis": 1234,
    "docsExamined": 450000,
    "nreturned": 1
  },
  "solution": "Ajout d'index unique sur email",
  "command": "db.users.createIndex({ email: 1 }, { unique: true })",
  "result": {
    "avgMillis": 2,
    "docsExamined": 1,
    "improvement": "99.8%"
  }
}
```

---

## Limitations et Consid√©rations

### Limitations Techniques

1. **Pas d'historique long terme** : La collection capped a une taille limit√©e
2. **Overhead non n√©gligeable** en niveau 2
3. **Pas de profiling des op√©rations syst√®me** (compact, repairDatabase, etc.)
4. **Granularit√© limit√©e** : pas de profiling au niveau des √©tapes de pipeline
5. **Format de stockage** : BSON uniquement, pas de streaming direct

### Op√©rations Non Profil√©es

- Commandes d'administration (listDatabases, serverStatus)
- Op√©rations de r√©plication interne
- Op√©rations de balancing (sharding)
- Heartbeats de Replica Set
- Lectures du cache WiredTiger

### Alternatives et Compl√©ments

| Outil | Usage | Avantages | Inconv√©nients |
|-------|-------|-----------|---------------|
| **Profiler** | Analyse d√©taill√©e post-mortem | Donn√©es structur√©es, queryable | Overhead, pas de temps r√©el |
| **Logs MongoDB** | Monitoring continu | Overhead minimal | Format texte, parsing n√©cessaire |
| **mongostat** | Monitoring en temps r√©el | L√©ger, overview global | Pas de d√©tails par requ√™te |
| **explain()** | Analyse cibl√©e | Z√©ro overhead | Requ√™te par requ√™te uniquement |
| **PMM** | Monitoring complet | Dashboards, alerting | Infrastructure suppl√©mentaire |

---

## Cas d'Usage Avanc√©s

### Sc√©nario 1 : Investigation Post-Incident

**Contexte** : Pic de latence d√©tect√© entre 14h00 et 14h15.

```javascript
// 1. Analyser les requ√™tes pendant la p√©riode
db.system.profile.aggregate([
  {
    $match: {
      ts: {
        $gte: ISODate("2024-12-08T14:00:00Z"),
        $lte: ISODate("2024-12-08T14:15:00Z")
      },
      millis: { $gt: 500 }
    }
  },
  {
    $group: {
      _id: {
        ns: "$ns",
        op: "$op",
        planSummary: "$planSummary"
      },
      count: { $sum: 1 },
      avgMillis: { $avg: "$millis" },
      maxMillis: { $max: "$millis" },
      exampleCommand: { $first: "$command" }
    }
  },
  { $sort: { count: -1 } },
  { $limit: 10 }
])

// 2. Identifier la requ√™te probl√©matique
// 3. V√©rifier si un index est manquant ou non optimal
// 4. Documenter et cr√©er un ticket
```

### Sc√©nario 2 : Audit de Performance Mensuel

```javascript
// Script d'audit automatis√©
function monthlyPerformanceAudit() {
  const startDate = new Date();
  startDate.setMonth(startDate.getMonth() - 1);

  print("=== Audit de Performance MongoDB ===\n");

  // 1. Top 10 collections les plus sollicit√©es
  print("1. Collections les plus actives:");
  db.system.profile.aggregate([
    { $match: { ts: { $gte: startDate } } },
    { $group: { _id: "$ns", count: { $sum: 1 } } },
    { $sort: { count: -1 } },
    { $limit: 10 }
  ]).forEach(printjson);

  // 2. Requ√™tes les plus lentes
  print("\n2. Top 10 requ√™tes les plus lentes:");
  db.system.profile.find({ ts: { $gte: startDate } })
    .sort({ millis: -1 })
    .limit(10)
    .forEach(function(doc) {
      print(`${doc.ns} - ${doc.millis}ms - ${doc.planSummary}`);
    });

  // 3. Taux de collection scans
  const collscans = db.system.profile.count({
    ts: { $gte: startDate },
    planSummary: /^COLLSCAN/
  });
  const total = db.system.profile.count({ ts: { $gte: startDate } });
  print(`\n3. Taux de COLLSCAN: ${(collscans/total*100).toFixed(2)}%`);

  // 4. Distributions de latence
  print("\n4. Distribution de latence:");
  db.system.profile.aggregate([
    { $match: { ts: { $gte: startDate } } },
    {
      $bucket: {
        groupBy: "$millis",
        boundaries: [0, 10, 50, 100, 500, 1000, 5000, 10000],
        default: "10000+",
        output: { count: { $sum: 1 } }
      }
    }
  ]).forEach(printjson);
}

monthlyPerformanceAudit();
```

---

## R√©sum√© pour SRE

### Commandes Essentielles √† M√©moriser

```javascript
// Activation/D√©sactivation rapide
db.setProfilingLevel(1, { slowms: 100 })  // Mode production
db.setProfilingLevel(0)                   // D√©sactivation

// V√©rification √©tat
db.getProfilingStatus()

// Analyse rapide
db.system.profile.find().sort({ millis: -1 }).limit(10)

// Nettoyage
db.setProfilingLevel(0)
db.system.profile.drop()
```

### Points Cl√©s de D√©cision

| Situation | Configuration Recommand√©e |
|-----------|---------------------------|
| **Production stable** | Niveau 1, slowms: 200ms, sample: 0.5 |
| **Nouveau d√©ploiement** | Niveau 1, slowms: 100ms, sample: 1.0 (2 semaines) |
| **Investigation active** | Niveau 2, sample: 0.1 (< 1 heure) |
| **Audit de s√©curit√©** | Niveau 2, sample: 1.0 (session d√©di√©e) |
| **Environnement dev** | Niveau 1, slowms: 50ms, sample: 1.0 |

---

## Conclusion

Le **Database Profiler** est un outil indispensable dans l'arsenal de tout SRE ou administrateur MongoDB. Sa capacit√© √† capturer et structurer les informations de performance permet :

1. **Diagnostic pr√©cis** des probl√®mes de performance
2. **Identification proactive** des requ√™tes n√©cessitant optimisation
3. **Validation post-d√©ploiement** des changements
4. **Documentation** des patterns d'acc√®s

L'utilisation judicieuse du profiler, combin√©e avec une analyse r√©guli√®re et une int√©gration dans les pipelines de monitoring, garantit la sant√© et les performances optimales des bases de donn√©es MongoDB en production.

**Prochaines √©tapes recommand√©es** :
- Configurer le profiler avec des seuils adapt√©s √† votre SLA
- Automatiser l'analyse hebdomadaire des donn√©es
- Int√©grer les m√©triques dans votre stack de monitoring
- √âtablir des runbooks pour les patterns d'optimisation courants

---

**R√©f√©rences** :
- [MongoDB Database Profiler Documentation](https://www.mongodb.com/docs/manual/tutorial/manage-the-database-profiler/)
- [Profiling MongoDB Operations](https://www.mongodb.com/docs/manual/reference/database-profiler/)
- [MongoDB Performance Best Practices](https://www.mongodb.com/docs/manual/administration/analyzing-mongodb-performance/)

‚è≠Ô∏è [Logs MongoDB](/13-monitoring-administration/04-logs-mongodb.md)
