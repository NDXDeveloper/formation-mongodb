ðŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 13.8 MongoDB Ops Manager

## Introduction

**MongoDB Ops Manager** est la plateforme enterprise de monitoring, automatisation et gestion de MongoDB dÃ©ployÃ©e on-premise. Contrairement aux solutions open-source (Prometheus, Grafana) ou cloud (Atlas), Ops Manager offre une solution complÃ¨te et intÃ©grÃ©e dÃ©veloppÃ©e par MongoDB Inc., spÃ©cifiquement conÃ§ue pour gÃ©rer des dÃ©ploiements MongoDB complexes Ã  grande Ã©chelle dans des environnements privÃ©s.

### Positionnement dans l'Ã‰cosystÃ¨me MongoDB

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  MongoDB Management Solutions                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  MongoDB Atlas          Cloud Manager        Ops Manager        â”‚
â”‚  (SaaS, Cloud)         (SaaS, Hybrid)       (On-Premise)        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ â€¢ Fully Mgd  â”‚      â”‚ â€¢ Monitoring â”‚    â”‚ â€¢ Full Stack â”‚     â”‚
â”‚  â”‚ â€¢ Auto-Scale â”‚      â”‚ â€¢ Backup     â”‚    â”‚ â€¢ On-Prem    â”‚     â”‚
â”‚  â”‚ â€¢ Multi-Cloudâ”‚      â”‚ â€¢ Alerts     â”‚    â”‚ â€¢ Air-Gapped â”‚     â”‚
â”‚  â”‚ â€¢ Serverless â”‚      â”‚ â€¢ Self-Host  â”‚    â”‚ â€¢ Enterprise â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         â”‚                     â”‚                    â”‚            â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                    Same UI & Features                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Comparaison rapide** :

| Aspect | Ops Manager | Cloud Manager | MongoDB Atlas |
|--------|-------------|---------------|---------------|
| **DÃ©ploiement** | On-premise | SaaS | SaaS |
| **ContrÃ´le infrastructure** | Total | Partiel | Aucun |
| **Compliance** | Data reste on-prem | Data metadata cloud | Data in cloud |
| **Cost model** | License + infrastructure | License per node | Pay-as-you-go |
| **Use case** | Enterprise, rÃ©gulÃ©, air-gapped | Hybrid cloud | Cloud-first |

### FonctionnalitÃ©s Principales

Ops Manager offre **trois piliers fonctionnels** :

#### 1. Monitoring
- MÃ©triques en temps rÃ©el (100+ mÃ©triques)
- Alerting configurable multi-niveaux
- Dashboards personnalisables
- Historical trending et capacity planning
- Performance advisor

#### 2. Automation
- DÃ©ploiement automatisÃ© de clusters
- Upgrades rolling sans downtime
- Configuration management centralisÃ©
- Self-healing et auto-remediation
- Topology changes automatisÃ©s

#### 3. Backup
- Continuous backup (oplog-based)
- Point-in-time recovery
- Snapshot scheduling
- Queryable backups
- Automated testing de restauration

### Architecture Technique

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Ops Manager Architecture                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Ops Manager Application                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚   â”‚  Web UI      â”‚  â”‚  REST API    â”‚  â”‚  Query Engineâ”‚              â”‚
â”‚   â”‚  (port 8080) â”‚  â”‚  (port 8080) â”‚  â”‚              â”‚              â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚          â”‚                 â”‚                 â”‚                      â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                            â”‚                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚     Application Database (MongoDB)                 â”‚             â”‚
â”‚  â”‚     - Monitoring data                              â”‚             â”‚
â”‚  â”‚     - Configuration                                â”‚             â”‚
â”‚  â”‚     - Automation state                             â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                 â”‚                 â”‚
            â–¼                 â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Monitoring      â”‚ â”‚ Automation      â”‚ â”‚ Backup          â”‚
â”‚ Agent           â”‚ â”‚ Agent           â”‚ â”‚ Daemon          â”‚
â”‚ (per mongod)    â”‚ â”‚ (per server)    â”‚ â”‚ (per RS/cluster)â”‚
â”‚                 â”‚ â”‚                 â”‚ â”‚                 â”‚
â”‚ â€¢ Collect stats â”‚ â”‚ â€¢ Deploy mongod â”‚ â”‚ â€¢ Oplog capture â”‚
â”‚ â€¢ Push to OM    â”‚ â”‚ â€¢ Config mgmt   â”‚ â”‚ â€¢ Snapshots     â”‚
â”‚ â€¢ Health checks â”‚ â”‚ â€¢ Upgrades      â”‚ â”‚ â€¢ S3/filesystem â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                   â”‚                   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   MongoDB Deployments        â”‚
              â”‚   â€¢ Standalone               â”‚
              â”‚   â€¢ Replica Sets             â”‚
              â”‚   â€¢ Sharded Clusters         â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Composants ClÃ©s

#### Application Server
- Interface Web et API REST
- Moteur d'alerting
- Planificateur d'automation
- Stocke la configuration et les mÃ©triques

#### Monitoring Agent
- Un agent par processus mongod/mongos
- Collecte serverStatus() toutes les 60s
- Push vers Ops Manager
- Lightweight (~50 MB RAM)

#### Automation Agent
- Un agent par serveur physique
- GÃ¨re le cycle de vie des processus MongoDB
- Applique la configuration dÃ©sirÃ©e
- Effectue les upgrades/changements

#### Backup Daemon
- Un par replica set ou cluster shardÃ©
- Lit l'oplog en continu
- CrÃ©e des snapshots pÃ©riodiques
- GÃ¨re la retention

---

## Installation et Configuration

### PrÃ©requis SystÃ¨me

**Ops Manager Application Server** :

| Ressource | Minimum | RecommandÃ© Production | Large Scale |
|-----------|---------|----------------------|-------------|
| CPU | 4 cores | 8 cores | 16+ cores |
| RAM | 8 GB | 16 GB | 32+ GB |
| Disque | 50 GB | 200 GB SSD | 500+ GB SSD |
| OS | RHEL 7/8, Ubuntu 18.04+ | RHEL 8 | RHEL 8 |

**Application Database** (MongoDB backing Ops Manager) :
- Replica Set 3 membres minimum
- MongoDB 4.4+ (6.0+ recommandÃ©)
- 16 GB RAM minimum par membre
- SSD storage

**Agents** (par serveur gÃ©rÃ©) :
- 512 MB RAM (Monitoring)
- 256 MB RAM (Automation)
- 1-4 GB RAM (Backup Daemon, selon charge)

### Installation de l'Application

#### 1. PrÃ©paration du SystÃ¨me

```bash
# RHEL 8
sudo dnf install -y cyrus-sasl cyrus-sasl-plain cyrus-sasl-gssapi \
  krb5-libs libcurl net-snmp net-snmp-agent-libs openldap openssl \
  tcp_wrappers-libs

# CrÃ©er l'utilisateur systÃ¨me
sudo useradd -r -d /opt/mongodb/mms -s /bin/false mongodb-mms

# CrÃ©er les rÃ©pertoires
sudo mkdir -p /opt/mongodb/mms
sudo chown mongodb-mms:mongodb-mms /opt/mongodb/mms
```

#### 2. TÃ©lÃ©chargement et Installation

```bash
# TÃ©lÃ©charger Ops Manager (nÃ©cessite compte MongoDB Enterprise)
VERSION="7.0.0"
wget https://downloads.mongodb.com/on-prem-mms/rpm/mongodb-mms-${VERSION}.x86_64.rpm

# Installer
sudo rpm -ivh mongodb-mms-${VERSION}.x86_64.rpm

# VÃ©rifier l'installation
ls -la /opt/mongodb/mms/
# conf/
# bin/
# jdk/
# logs/
```

#### 3. Configuration Application Database

Ops Manager nÃ©cessite sa propre base MongoDB (backing database) :

```javascript
// DÃ©ployer un replica set dÃ©diÃ©
// rs-opsmgr-0, rs-opsmgr-1, rs-opsmgr-2

// Sur chaque membre
mongod --replSet opsmgr --port 27017 --dbpath /data/opsmgr

// Initialiser le replica set
rs.initiate({
  _id: "opsmgr",
  members: [
    { _id: 0, host: "rs-opsmgr-0:27017" },
    { _id: 1, host: "rs-opsmgr-1:27017" },
    { _id: 2, host: "rs-opsmgr-2:27017" }
  ]
})

// CrÃ©er l'utilisateur pour Ops Manager
use admin
db.createUser({
  user: "mmsAppUser",
  pwd: "strongPassword123!",
  roles: [
    { role: "readWriteAnyDatabase", db: "admin" },
    { role: "clusterAdmin", db: "admin" },
    { role: "userAdminAnyDatabase", db: "admin" }
  ]
})
```

#### 4. Configuration Ops Manager

```properties
# /opt/mongodb/mms/conf/conf-mms.properties

# MongoDB connection (backing database)
mongo.mongoUri=mongodb://mmsAppUser:strongPassword123!@rs-opsmgr-0:27017,rs-opsmgr-1:27017,rs-opsmgr-2:27017/?authSource=admin&replicaSet=opsmgr

# Base URL (accessible par agents et browsers)
mms.centralUrl=https://opsmgr.example.com:8080

# Email configuration (SMTP)
mms.mail.transport=smtp
mms.mail.hostname=smtp.example.com
mms.mail.port=587
mms.mail.username=opsmgr@example.com
mms.mail.password=emailPassword
mms.mail.tls=true
mms.fromEmailAddr=opsmgr@example.com

# Backup storage
mms.backup.fsstore.path=/data/backup

# Security
mms.https.PEMKeyFile=/opt/mongodb/mms/conf/certs/server.pem
mms.https.ClientCertificateMode=optional

# Performance tuning
mms.maxActiveJobs=30
mms.queryableBackupMaxConcurrentRestores=4

# Logging
mms.log.path=/opt/mongodb/mms/logs
mms.log.level=INFO
```

#### 5. DÃ©marrage et Initialisation

```bash
# DÃ©marrer le service
sudo systemctl start mongodb-mms

# VÃ©rifier les logs
sudo tail -f /opt/mongodb/mms/logs/mms0.log

# Output attendu
# [main] INFO  com.xgen.svc.mms.Application - Starting Ops Manager
# [main] INFO  com.mongodb.StartupService - All services started successfully

# Activer au dÃ©marrage
sudo systemctl enable mongodb-mms

# VÃ©rifier le statut
sudo systemctl status mongodb-mms
```

#### 6. Configuration Initiale via Web UI

```bash
# AccÃ©der Ã  l'interface web
https://opsmgr.example.com:8080

# 1. CrÃ©er le premier utilisateur admin
#    Username: admin
#    Email: admin@example.com
#    Password: ComplexPassword123!

# 2. Configurer l'organisation
#    Name: Production
#    Company: Example Corp

# 3. TÃ©lÃ©charger les agents
#    - Monitoring Agent
#    - Automation Agent
#    - Backup Agent

# 4. GÃ©nÃ©rer les clÃ©s API
#    Admin â†’ Settings â†’ Public API Access â†’ Generate
```

### Installation des Agents

#### Monitoring Agent

```bash
# Sur chaque serveur MongoDB Ã  monitorer
VERSION="12.0.28.7750"

# TÃ©lÃ©chargement
curl -OL https://downloads.mongodb.com/on-prem-mms/monitoring-agent/mongodb-mms-monitoring-agent-${VERSION}.x86_64.rpm

# Installation
sudo rpm -ivh mongodb-mms-monitoring-agent-${VERSION}.x86_64.rpm

# Configuration
sudo vi /etc/mongodb-mms/monitoring-agent.config

# Contenu
mmsBaseUrl=https://opsmgr.example.com:8080
mmsGroupId=YOUR_PROJECT_ID
mmsApiKey=YOUR_API_KEY

# Monitoring de tous les processus sur le serveur
# L'agent dÃ©couvrira automatiquement les mongod/mongos

# DÃ©marrage
sudo systemctl start mongodb-mms-monitoring-agent
sudo systemctl enable mongodb-mms-monitoring-agent

# VÃ©rification
sudo systemctl status mongodb-mms-monitoring-agent
tail -f /var/log/mongodb-mms/monitoring-agent.log
```

#### Automation Agent

```bash
# Installation
curl -OL https://downloads.mongodb.com/on-prem-mms/automation-agent/mongodb-mms-automation-agent-${VERSION}.x86_64.rpm
sudo rpm -ivh mongodb-mms-automation-agent-${VERSION}.x86_64.rpm

# Configuration
sudo vi /etc/mongodb-mms/automation-agent.config

mmsBaseUrl=https://opsmgr.example.com:8080
mmsGroupId=YOUR_PROJECT_ID
mmsApiKey=YOUR_API_KEY

# User pour exÃ©cuter mongod
mmsConfigBackup=/var/lib/mongodb-mms-automation/mms-cluster-config-backup.json
logPath=/var/log/mongodb-mms/automation-agent.log

# DÃ©marrage
sudo systemctl start mongodb-mms-automation-agent
sudo systemctl enable mongodb-mms-automation-agent
```

---

## Monitoring et MÃ©triques

### Dashboard Overview

Ops Manager offre plusieurs niveaux de dashboards :

#### 1. Deployment View (Vue Cluster)

```
Deployment: Production Replica Set (rs0)
â”œâ”€ Status: âœ“ Healthy
â”œâ”€ Version: MongoDB 7.0.4
â”œâ”€ Members: 3 (1 Primary, 2 Secondaries)
â”œâ”€ Oplog Window: 48 hours
â”œâ”€ Data Size: 1.2 TB
â””â”€ Active Alerts: 0

Real-time Metrics:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Operations/sec:     1,234                       â”‚
â”‚ Connections:        87 / 65,536                 â”‚
â”‚ Network In/Out:     15 MB/s / 45 MB/s           â”‚
â”‚ Memory (Resident):  8.2 GB / 16 GB              â”‚
â”‚ Replication Lag:    0.2s (max)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 2. Server View (Vue Serveur)

MÃ©triques par serveur incluent :

**System Metrics** :
- CPU utilization (user, system, iowait)
- Memory (resident, virtual, mapped)
- Disk I/O (IOPS, throughput, latency)
- Network (bytes in/out, connections)

**MongoDB Metrics** :
- Operations (insert, query, update, delete, getmore, command)
- Queues (read, write)
- Active connections
- Page faults
- Opcounters

**Replication Metrics** :
- Replication lag (per secondary)
- Oplog GB/hour
- Replication headroom

### MÃ©triques Critiques et Seuils

Ops Manager collecte **100+ mÃ©triques** automatiquement. Voici les plus critiques :

#### Operations Metrics

```
Metric: Operations per Second
Path: Performance > Operations
Query: opcounters (insert + query + update + delete + command)

Seuils SRE:
- Normal:    < 1,000 ops/sec
- Elevated:  1,000 - 5,000 ops/sec
- High:      5,000 - 10,000 ops/sec
- Critical:  > 10,000 ops/sec

Action si > 10k:
1. VÃ©rifier si spike attendu (dÃ©ploiement, batch job)
2. Analyser query patterns via Performance Advisor
3. VÃ©rifier index usage
4. ConsidÃ©rer scale-out si sustained
```

#### Memory Metrics

```
Metric: Memory - Resident
Path: Hardware > Memory
Query: mem.resident (MB)

Analysis:
resident_mb / total_system_ram_mb = memory_utilization

Seuils:
- Healthy:   < 75% total RAM
- Warning:   75-85% total RAM
- Critical:  > 85% total RAM

Correlation:
Si resident Ã©levÃ© + high page faults:
  â†’ Working set > RAM â†’ ConsidÃ©rer upgrade RAM
Si resident Ã©levÃ© + low page faults:
  â†’ Normal, cache est bien utilisÃ©
```

#### Cache Metrics

```
Metric: WiredTiger Cache - Dirty Bytes
Path: Performance > WiredTiger Cache

dirty_percent = (dirty_bytes / max_configured_bytes) * 100

Seuils:
- Normal:    < 10%
- Attention: 10-20%
- Warning:   20-40%
- Critical:  > 40%

Pattern Analysis:
dirty% croissant:
  â†’ Writes > disk flush capacity
  â†’ Check: I/O wait, checkpoint duration
  â†’ Action: Faster disks, adjust checkpoint interval
```

#### Replication Lag

```
Metric: Replication Lag
Path: Replica Set > Replication Lag
Query: (Primary optime - Secondary optime)

Seuils temporels:
- Normal:    < 10 seconds
- Elevated:  10-30 seconds
- Warning:   30-60 seconds
- Critical:  > 60 seconds

Seuils opÃ©rationnels:
- oplog_hours_remaining < 24 hours â†’ Warning
- oplog_hours_remaining < 12 hours â†’ Critical

Investigation:
1. VÃ©rifier network latency entre membres
2. Analyser slow queries sur secondary
3. VÃ©rifier I/O performance
4. ConsidÃ©rer write concern adjustment
```

### Performance Advisor

Ops Manager inclut un **Performance Advisor** qui analyse automatiquement :

#### Index Suggestions

```
Analysis Window: Last 24 hours
Slow Queries Analyzed: 1,247

Recommendations:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Collection: production.orders                              â”‚
â”‚ Impact: HIGH (487 slow queries)                            â”‚
â”‚ Suggestion: Create index { customerId: 1, orderDate: -1 }  â”‚
â”‚ Expected Improvement: 92% reduction in execution time      â”‚
â”‚                                                            â”‚
â”‚ Sample Query:                                              â”‚
â”‚ db.orders.find({ customerId: "C123" }).sort({ orderDate: -1 })
â”‚                                                            â”‚
â”‚ Current Plan: COLLSCAN (450k docs examined)                â”‚
â”‚ Proposed Plan: IXSCAN (8 docs examined)                    â”‚
â”‚                                                            â”‚
â”‚ [Create Index] [Ignore] [Details]                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**CrÃ©ation automatisÃ©e** :
```javascript
// Via Ops Manager UI ou API
// L'index sera crÃ©Ã© en background sur tous les membres

// Ã‰quivalent MongoDB shell
db.orders.createIndex(
  { customerId: 1, orderDate: -1 },
  { background: true }
)
```

#### Query Insights

```
Top 10 Slowest Query Shapes (Last 7 Days)

1. Collection: users
   Pattern: find({ email: ? }).sort({ createdAt: -1 })
   Avg Duration: 1,234 ms
   Executions: 45,678
   Total Time: 15.6 hours
   â†’ Missing index on email field

2. Collection: logs
   Pattern: aggregate([{ $match: { level: ? } }, { $group: ... }])
   Avg Duration: 892 ms
   Executions: 12,345
   Total Time: 3.1 hours
   â†’ Consider index on level, use $match early in pipeline
```

### Custom Charts et Dashboards

Ops Manager permet de crÃ©er des **custom charts** pour mÃ©triques spÃ©cifiques :

#### Exemple : Custom Dashboard "Application Performance"

```
Chart 1: Application Operation Mix
Type: Stacked Area
Metrics:
  - opcounters.insert (rate)
  - opcounters.query (rate)
  - opcounters.update (rate)
  - opcounters.delete (rate)
Display: Last 24 hours, 5-minute granularity

Chart 2: P95 Query Latency by Collection
Type: Line
Metrics:
  - top.total.time (p95) for top 5 collections
Display: Last 7 days, 1-hour granularity

Chart 3: Cache Efficiency
Type: Multi-line
Metrics:
  - wiredTiger.cache.bytes currently in the cache / max (%)
  - wiredTiger.cache.tracked dirty bytes / max (%)
  - wiredTiger.cache.pages evicted (rate)

Chart 4: Connection Pool Health
Type: Gauge
Metrics:
  - connections.current
  - connections.available
Thresholds:
  - Green: < 70% used
  - Yellow: 70-85% used
  - Red: > 85% used
```

---

## Alerting

### Configuration d'Alertes

Ops Manager offre un systÃ¨me d'alerting multi-niveaux avec **50+ conditions prÃ©dÃ©finies**.

#### Types d'Alertes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Alert Categories                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Host Alerts          Process Alerts      Backup Alerts     â”‚
â”‚  â”œâ”€ CPU > 80%         â”œâ”€ Primary Down     â”œâ”€ Backup Failed  â”‚
â”‚  â”œâ”€ Memory > 90%      â”œâ”€ Too Many         â”œâ”€ Snapshot Old   â”‚
â”‚  â”œâ”€ Disk Space < 10%  â”‚   Connections     â””â”€ No Recent Snap â”‚
â”‚  â””â”€ Network Issues    â”œâ”€ Replication Lag                    â”‚
â”‚                       â”œâ”€ Oplog < 1 hour                     â”‚
â”‚                       â””â”€ Assert Warnings                    â”‚
â”‚                                                             â”‚
â”‚  User Alerts          Backup Job Alerts                     â”‚
â”‚  â”œâ”€ Failed Login      â”œâ”€ Snapshot Taking                    â”‚
â”‚  â”œâ”€ User Changes      â”‚   Too Long                          â”‚
â”‚  â””â”€ API Key Changes   â””â”€ Queryable Backup                   â”‚
â”‚                           Stale                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Configuration d'Alerte Standard

**Exemple : Replication Lag Alert**

```json
{
  "typeName": "REPLICATION_LAG",
  "enabled": true,
  "eventTypeName": "REPLICATION_OPLOG_WINDOW_RUNNING_OUT",
  "threshold": {
    "value": 1,
    "units": "HOURS"
  },
  "notifications": [
    {
      "typeName": "EMAIL",
      "emailEnabled": true,
      "intervalMin": 5,
      "delayMin": 0,
      "emailAddress": "dba-oncall@example.com"
    },
    {
      "typeName": "PAGER_DUTY",
      "serviceKey": "YOUR_PAGERDUTY_KEY",
      "intervalMin": 0,
      "delayMin": 0
    },
    {
      "typeName": "SLACK",
      "channelName": "#mongodb-alerts",
      "apiToken": "YOUR_SLACK_TOKEN",
      "intervalMin": 5
    }
  ],
  "matchers": [
    {
      "fieldName": "REPLICA_SET_NAME",
      "operator": "EQUALS",
      "value": "production-rs0"
    }
  ]
}
```

#### Configuration via API

```bash
# CrÃ©er une alerte via REST API
curl -X POST \
  "https://opsmgr.example.com:8080/api/public/v1.0/groups/${PROJECT_ID}/alertConfigs" \
  -u "${PUBLIC_KEY}:${PRIVATE_KEY}" \
  -H "Content-Type: application/json" \
  -d '{
    "typeName": "HOST_METRIC",
    "metricName": "DISK_PARTITION_SPACE_USED_DATA",
    "mode": "AVERAGE",
    "operator": "GREATER_THAN",
    "threshold": 80,
    "units": "RAW",
    "enabled": true,
    "notifications": [
      {
        "typeName": "EMAIL",
        "emailAddress": "ops@example.com",
        "intervalMin": 15,
        "delayMin": 0
      }
    ]
  }'
```

#### Alert Escalation

Configuration d'escalade multi-niveaux :

```json
{
  "alertConfigId": "5f2c8b1234567890abcdef12",
  "typeName": "REPLICATION_LAG",
  "notifications": [
    {
      "typeName": "EMAIL",
      "emailAddress": "team-mongodb@example.com",
      "delayMin": 0,
      "intervalMin": 5
    },
    {
      "typeName": "PAGER_DUTY",
      "serviceKey": "PRIMARY_ONCALL_KEY",
      "delayMin": 5,
      "intervalMin": 0
    },
    {
      "typeName": "PAGER_DUTY",
      "serviceKey": "SECONDARY_ONCALL_KEY",
      "delayMin": 15,
      "intervalMin": 0
    }
  ]
}
```

**Logique d'escalade** :
1. t=0 : Email Ã  l'Ã©quipe
2. t=5min : Page on-call primary (si non rÃ©solu)
3. t=15min : Page on-call secondary (si non rÃ©solu)
4. RÃ©pÃ©ter email toutes les 5 minutes jusqu'Ã  rÃ©solution

### Suppression d'Alertes (Maintenance Windows)

```bash
# CrÃ©er une fenÃªtre de maintenance
curl -X POST \
  "https://opsmgr.example.com:8080/api/public/v1.0/groups/${PROJECT_ID}/maintenanceWindows" \
  -u "${PUBLIC_KEY}:${PRIVATE_KEY}" \
  -H "Content-Type: application/json" \
  -d '{
    "startDate": "2024-12-15T02:00:00Z",
    "endDate": "2024-12-15T04:00:00Z",
    "description": "Rolling upgrade to MongoDB 7.0.5",
    "alertTypeNames": [
      "HOST_DOWN",
      "REPLICA_SET_ELECTION",
      "PRIMARY_ELECTED"
    ]
  }'
```

---

## Automation et DÃ©ploiement

### Concept d'Automation

Ops Manager utilise un modÃ¨le **"desired state"** :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Automation Desired State Model                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  1. Administrator configures desired state in UI            â”‚
â”‚     â†“                                                       â”‚
â”‚  2. Ops Manager stores configuration                        â”‚
â”‚     â†“                                                       â”‚
â”‚  3. Automation Agents poll for configuration changes        â”‚
â”‚     â†“                                                       â”‚
â”‚  4. Agents compare current vs. desired state                â”‚
â”‚     â†“                                                       â”‚
â”‚  5. Agents execute changes to reach desired state           â”‚
â”‚     â†“                                                       â”‚
â”‚  6. Agents report back current state                        â”‚
â”‚     â†“                                                       â”‚
â”‚  7. Ops Manager validates goal state reached                â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### DÃ©ploiement AutomatisÃ© de Replica Set

#### Via UI

```
Deployment â†’ Add New Deployment â†’ Replica Set

Configuration:
â”œâ”€ Name: production-rs0
â”œâ”€ MongoDB Version: 7.0.4
â”œâ”€ Members: 3
â”‚  â”œâ”€ Host: mongo-prod-01:27017
â”‚  â”œâ”€ Host: mongo-prod-02:27017
â”‚  â””â”€ Host: mongo-prod-03:27017
â”œâ”€ Oplog Size: 10 GB
â”œâ”€ Storage Engine: WiredTiger
â”œâ”€ Authentication: SCRAM-SHA-256
â””â”€ TLS: Enabled

[Review & Deploy]
```

#### Via API

```bash
# DÃ©finition JSON du replica set
cat > replica-set-config.json <<'EOF'
{
  "name": "production-rs0",
  "processes": [
    {
      "hostname": "mongo-prod-01",
      "port": 27017,
      "processType": "mongod",
      "version": "7.0.4",
      "featureCompatibilityVersion": "7.0",
      "args2_6": {
        "net": {
          "port": 27017,
          "bindIp": "0.0.0.0"
        },
        "storage": {
          "dbPath": "/data/mongodb",
          "engine": "wiredTiger"
        },
        "systemLog": {
          "destination": "file",
          "path": "/var/log/mongodb/mongod.log"
        },
        "replication": {
          "replSetName": "production-rs0",
          "oplogSizeMB": 10240
        },
        "security": {
          "authorization": "enabled"
        }
      }
    },
    {
      "hostname": "mongo-prod-02",
      "port": 27017,
      "processType": "mongod",
      "version": "7.0.4",
      "featureCompatibilityVersion": "7.0",
      "args2_6": {
        // ... similar config
      }
    },
    {
      "hostname": "mongo-prod-03",
      "port": 27017,
      "processType": "mongod",
      "version": "7.0.4",
      "featureCompatibilityVersion": "7.0",
      "args2_6": {
        // ... similar config
      }
    }
  ],
  "replicaSets": [
    {
      "id": "production-rs0",
      "members": [
        {
          "id": 0,
          "hostname": "mongo-prod-01",
          "port": 27017,
          "priority": 1,
          "votes": 1
        },
        {
          "id": 1,
          "hostname": "mongo-prod-02",
          "port": 27017,
          "priority": 1,
          "votes": 1
        },
        {
          "id": 2,
          "hostname": "mongo-prod-03",
          "port": 27017,
          "priority": 1,
          "votes": 1
        }
      ]
    }
  ]
}
EOF

# DÃ©ployer via API
curl -X PUT \
  "https://opsmgr.example.com:8080/api/public/v1.0/groups/${PROJECT_ID}/automationConfig" \
  -u "${PUBLIC_KEY}:${PRIVATE_KEY}" \
  -H "Content-Type: application/json" \
  -d @replica-set-config.json
```

### Upgrades Rolling AutomatisÃ©s

#### Upgrade MongoDB 6.0 â†’ 7.0

**Processus automatique** :

```
Phase 1: Compatibility Version Upgrade
â”œâ”€ Set FCV to 6.0 (if not already)
â””â”€ Verify all nodes running 6.0

Phase 2: Binary Upgrade - Secondaries
â”œâ”€ Stop secondary-1
â”œâ”€ Replace binary 6.0 â†’ 7.0
â”œâ”€ Start secondary-1
â”œâ”€ Wait for sync (< 1s lag)
â”œâ”€ Stop secondary-2
â”œâ”€ Replace binary 6.0 â†’ 7.0
â”œâ”€ Start secondary-2
â”œâ”€ Wait for sync
â””â”€ All secondaries upgraded

Phase 3: Primary Stepdown and Upgrade
â”œâ”€ Step down primary â†’ secondary-1 becomes primary
â”œâ”€ Stop old primary (now secondary)
â”œâ”€ Replace binary 6.0 â†’ 7.0
â”œâ”€ Start as secondary
â””â”€ Wait for sync

Phase 4: FCV Upgrade
â”œâ”€ Set FCV to 7.0
â””â”€ New features now available

Estimated Downtime: 0 seconds (rolling)
Estimated Duration: 15-30 minutes (3 members)
```

**Configuration via UI** :

```
Deployment â†’ Settings â†’ Modify Deployment

1. Change MongoDB Version: 7.0.4
2. [Review Changes]
3. Confirmation:
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Changes to be applied:                          â”‚
   â”‚ â€¢ MongoDB version: 6.0.11 â†’ 7.0.4               â”‚
   â”‚ â€¢ Rolling upgrade: Yes                          â”‚
   â”‚ â€¢ Estimated duration: 20 minutes                â”‚
   â”‚ â€¢ Downtime: None (rolling)                      â”‚
   â”‚                                                 â”‚
   â”‚ This will:                                      â”‚
   â”‚ 1. Upgrade secondaries first                    â”‚
   â”‚ 2. Step down primary                            â”‚
   â”‚ 3. Upgrade old primary                          â”‚
   â”‚                                                 â”‚
   â”‚ [Cancel] [Confirm & Deploy]                     â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Configuration Management

#### Modification CentralisÃ©e

Changer un paramÃ¨tre sur tout le replica set :

```
Example: Enable Profiling Level 1

Deployment â†’ Configuration â†’ Edit

Add to mongod arguments:
operationProfiling:
  mode: slowOp
  slowOpThresholdMs: 100

[Review & Deploy]

Result:
- Automation agents update mongod.conf on all members
- Rolling restart if needed
- Change tracked in audit log
```

#### Configuration Drift Detection

Ops Manager dÃ©tecte les changements manuels (drift) :

```
Warning: Configuration Drift Detected

Server: mongo-prod-02
Process: mongod (port 27017)

Detected Changes:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Parameter            Expected    Actual            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ oplogSize            10240 MB    5120 MB           â”‚
â”‚ cacheSizeGB          8 GB        4 GB              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Actions:
[Revert to Managed Config] [Update Managed Config] [Ignore]
```

---

## Backup et Restauration

### Architecture de Backup

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Backup Architecture                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Replica Set (production-rs0)
â”œâ”€ Primary
â”œâ”€ Secondary-1
â””â”€ Secondary-2
     â”‚
     â”‚ oplog tail (continuous)
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Backup Daemon         â”‚
â”‚  â€¢ Reads oplog         â”‚
â”‚  â€¢ Creates snapshots   â”‚
â”‚  â€¢ Manages retention   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ store snapshots
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Backup Storage                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  Filesystem  â”‚  â”‚     S3       â”‚            â”‚
â”‚  â”‚   Blockstore â”‚  â”‚  Compatible  â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                â”‚
â”‚  Snapshots:                                    â”‚
â”‚  â”œâ”€ 2024-12-08 00:00 (Base)                    â”‚
â”‚  â”œâ”€ 2024-12-09 00:00 (Incremental)             â”‚
â”‚  â”œâ”€ 2024-12-10 00:00 (Incremental)             â”‚
â”‚  â””â”€ ... + continuous oplog                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ queryable backup
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Queryable Snapshots   â”‚
â”‚  (mongod read-only)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Configuration de Backup

#### 1. Activation du Backup

```
Deployment â†’ Backup â†’ Enable Backup

Configuration:
â”œâ”€ Snapshot Schedule
â”‚  â”œâ”€ Snapshot Interval: Daily at 02:00 UTC
â”‚  â”œâ”€ Snapshot Retention:
â”‚  â”‚  â”œâ”€ Daily: 7 days
â”‚  â”‚  â”œâ”€ Weekly: 4 weeks
â”‚  â”‚  â””â”€ Monthly: 12 months
â”‚  â””â”€ Continuous Oplog: Enabled
â”‚
â”œâ”€ Storage Configuration
â”‚  â”œâ”€ Type: S3-Compatible
â”‚  â”œâ”€ Endpoint: s3.amazonaws.com
â”‚  â”œâ”€ Bucket: mongodb-backups-prod
â”‚  â””â”€ Encryption: AES-256
â”‚
â””â”€ Backup Daemon Allocation
   â”œâ”€ Assigned Server: backup-daemon-01
   â””â”€ Backup Throughput: 100 MB/s

[Save & Enable]
```

#### 2. Configuration AvancÃ©e

```json
{
  "backupConfigs": [
    {
      "groupId": "${PROJECT_ID}",
      "clusterId": "production-rs0",
      "statusName": "STARTED",
      "syncSource": "SECONDARY",
      "snapshotIntervalHours": 24,
      "snapshotRetentionDays": 7,
      "pointInTimeWindowHours": 48,
      "provisioned": true,
      "blockstore": {
        "type": "S3",
        "s3BucketName": "mongodb-backups-prod",
        "s3BucketEndpoint": "s3.amazonaws.com",
        "sseEnabled": true,
        "maxCapacityGB": 5000
      }
    }
  ]
}
```

### Point-in-Time Recovery

#### Interface de Restauration

```
Backup â†’ Restore

Source Snapshot:
â”œâ”€ Replica Set: production-rs0
â”œâ”€ Snapshot: 2024-12-10 00:00:00
â””â”€ Point-in-Time: 2024-12-10 15:30:45

Restore Target:
â”œâ”€ Create New Cluster: restore-rs0
â”œâ”€ Hosts:
â”‚  â”œâ”€ restore-host-01:27017
â”‚  â”œâ”€ restore-host-02:27017
â”‚  â””â”€ restore-host-03:27017
â””â”€ MongoDB Version: 7.0.4

Options:
â”œâ”€ Download Snapshot Only: No
â”œâ”€ Restore System Databases: No
â””â”€ Oplog Replay: To 2024-12-10 15:30:45

[Start Restore]

Progress:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 65%                 â”‚
â”‚                                                â”‚
â”‚ Phase: Applying Oplog                          â”‚
â”‚ Elapsed: 12m 34s                               â”‚
â”‚ Estimated Remaining: 6m 15s                    â”‚
â”‚                                                â”‚
â”‚ Operations Replayed: 1,234,567 / 1,900,000     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Restauration via API

```bash
# Initier une restauration
curl -X POST \
  "https://opsmgr.example.com:8080/api/public/v1.0/groups/${PROJECT_ID}/clusters/${CLUSTER_ID}/restoreJobs" \
  -u "${PUBLIC_KEY}:${PRIVATE_KEY}" \
  -H "Content-Type: application/json" \
  -d '{
    "snapshotId": "5f2c8b1234567890abcdef12",
    "deliveryType": "AUTOMATED_RESTORE",
    "targetClusterId": "restore-cluster-id",
    "pointInTimeUTCMillis": 1702220445000,
    "oplogInc": 1,
    "oplogTs": "1702220445:1"
  }'

# Surveiller le statut
curl "https://opsmgr.example.com:8080/api/public/v1.0/groups/${PROJECT_ID}/clusters/${CLUSTER_ID}/restoreJobs/${JOB_ID}" \
  -u "${PUBLIC_KEY}:${PRIVATE_KEY}"

# Response
{
  "id": "restore-job-123",
  "statusName": "IN_PROGRESS",
  "pointInTimeUTCMillis": 1702220445000,
  "created": "2024-12-10T16:00:00Z",
  "targetClusterId": "restore-cluster-id",
  "percentComplete": 65
}
```

### Queryable Backups

FonctionnalitÃ© unique : **interroger directement les snapshots** sans restauration complÃ¨te.

```
Backup â†’ Snapshots â†’ [Select Snapshot] â†’ Query

Un mongod read-only temporaire est crÃ©Ã© avec le snapshot:
mongodb://queryable-backup-host:27017/

Use case:
- VÃ©rifier des donnÃ©es avant restauration complÃ¨te
- Extraire des documents spÃ©cifiques
- Audit et compliance
- Analyse forensique

Example:
mongo mongodb://queryable-backup-host:27017/production

> db.orders.find({ orderId: "ORD-12345" })
> db.users.count({ deletedAt: { $exists: false } })
```

### Automated Restore Testing

```yaml
# Configuration test de restauration mensuel
backupTestConfig:
  enabled: true
  schedule: "0 2 1 * *"  # 1er de chaque mois Ã  2h
  targetCluster: "restore-test-cluster"
  validationQueries:
    - database: production
      collection: users
      query: { active: true }
      expectedMinCount: 100000
    - database: production
      collection: orders
      query: { status: "completed" }
      expectedMinCount: 50000
  notificationEmail: dba-team@example.com
  retentionDays: 1  # Cleanup aprÃ¨s validation
```

---

## SÃ©curitÃ© et Authentification

### Authentication & Authorization

#### LDAP/Active Directory Integration

```properties
# conf-mms.properties

# LDAP configuration
mms.ldap.url=ldap://ldap.example.com:389
mms.ldap.bindDn=cn=opsmgr,ou=services,dc=example,dc=com
mms.ldap.bindPassword=ldapPassword

# User mapping
mms.ldap.userSearchBase=ou=users,dc=example,dc=com
mms.ldap.userSearchFilter=(&(objectClass=person)(uid={0}))

# Group mapping
mms.ldap.groupSearchBase=ou=groups,dc=example,dc=com
mms.ldap.groupSearchFilter=(member={0})
mms.ldap.groupRoleMapping=cn=DBAs,ou=groups,dc=example,dc=com:PROJECT_OWNER

# TLS
mms.ldap.tls=true
mms.ldap.trustStorePath=/opt/mongodb/mms/conf/truststore.jks
```

#### Role-Based Access Control

```
Organization â†’ Access Manager

Roles disponibles:
â”œâ”€ Organization Owner
â”‚  â””â”€ Full control (billing, users, all projects)
â”‚
â”œâ”€ Organization Member
â”‚  â””â”€ Access to assigned projects only
â”‚
â”œâ”€ Project Owner
â”‚  â””â”€ Full control within project
â”‚
â”œâ”€ Project Cluster Manager
â”‚  â””â”€ Manage deployments, no backup access
â”‚
â”œâ”€ Project Data Access Admin
â”‚  â””â”€ Create DB users, no cluster management
â”‚
â”œâ”€ Project Read Only
â”‚  â””â”€ View only, no modifications
â”‚
â””â”€ Project Backup Admin
   â””â”€ Manage backups only
```

**Mapping d'Ã©quipe** :

```
Team: Database Administrators
â”œâ”€ Users: alice@example.com, bob@example.com
â”œâ”€ Projects: All
â””â”€ Role: Project Owner

Team: Application Developers
â”œâ”€ Users: dev-team@example.com (LDAP group)
â”œâ”€ Projects: Development, Staging
â””â”€ Role: Project Data Access Admin

Team: Operations
â”œâ”€ Users: ops-team@example.com
â”œâ”€ Projects: All
â””â”€ Role: Project Cluster Manager

Team: Auditors
â”œâ”€ Users: audit@example.com
â”œâ”€ Projects: All
â””â”€ Role: Project Read Only
```

### Audit Logging

```properties
# Enable audit logging
mms.audit.enabled=true
mms.audit.destination=file
mms.audit.filePath=/opt/mongodb/mms/logs/audit.log
mms.audit.format=JSON

# Audit filters
mms.audit.filter.authentication=true
mms.audit.filter.authorization=true
mms.audit.filter.schema=true
mms.audit.filter.backup=true
```

**Sample audit entry** :

```json
{
  "timestamp": "2024-12-10T15:30:45.123Z",
  "atype": "authCheck",
  "result": "success",
  "user": "alice@example.com",
  "roles": ["PROJECT_OWNER"],
  "param": {
    "resource": {
      "projectId": "5f2c8b1234567890abcdef12",
      "resourceType": "CLUSTER"
    },
    "action": "MODIFY_SETTINGS"
  },
  "remote": {
    "ip": "203.0.113.45",
    "userAgent": "Mozilla/5.0..."
  }
}
```

### TLS/SSL Configuration

```properties
# conf-mms.properties

# HTTPS for web interface
mms.https.enabled=true
mms.https.port=8443
mms.https.PEMKeyFile=/opt/mongodb/mms/conf/certs/opsmgr.pem
mms.https.ClientCertificateMode=optional

# Agent communication
mms.agentTLS.enabled=true
mms.agentTLS.ClientCertificateMode=required
mms.agentTLS.CAFile=/opt/mongodb/mms/conf/certs/ca.pem
```

**Certificate rotation automatisÃ©e** :

```bash
#!/bin/bash
# rotate_certs.sh

NEW_CERT="/path/to/new/cert.pem"
OPSMGR_CONF="/opt/mongodb/mms/conf/conf-mms.properties"

# Update configuration
sed -i "s|mms.https.PEMKeyFile=.*|mms.https.PEMKeyFile=$NEW_CERT|" $OPSMGR_CONF

# Restart Ops Manager (agents reconnect automatically)
systemctl restart mongodb-mms

# Verify
curl -k https://opsmgr.example.com:8443/api/public/v1.0/unauth/version
```

---

## API et IntÃ©gration

### REST API Overview

Ops Manager expose une **REST API complÃ¨te** pour toutes les opÃ©rations.

**Base URL** : `https://opsmgr.example.com:8080/api/public/v1.0`

**Authentication** :
```bash
# Digest Authentication
PUBLIC_KEY="your-public-key"
PRIVATE_KEY="your-private-key"

# All requests use digest auth
curl -u "${PUBLIC_KEY}:${PRIVATE_KEY}" --digest \
  https://opsmgr.example.com:8080/api/public/v1.0/...
```

### Exemples d'IntÃ©gration

#### 1. Monitoring Integration (Prometheus Exporter)

```python
#!/usr/bin/env python3
# opsmgr_exporter.py

import requests
from requests.auth import HTTPDigestAuth
from prometheus_client import start_http_server, Gauge
import time

class OpsManagerExporter:
    def __init__(self, base_url, public_key, private_key, project_id):
        self.base_url = base_url
        self.auth = HTTPDigestAuth(public_key, private_key)
        self.project_id = project_id

        # Define Prometheus metrics
        self.metrics = {
            'ops': Gauge('opsmgr_operations_per_second', 'Operations per second', ['host']),
            'connections': Gauge('opsmgr_connections_current', 'Current connections', ['host']),
            'replication_lag': Gauge('opsmgr_replication_lag_seconds', 'Replication lag', ['host']),
            'memory': Gauge('opsmgr_memory_resident_mb', 'Resident memory MB', ['host'])
        }

    def get_processes(self):
        """Get all processes in project"""
        url = f"{self.base_url}/groups/{self.project_id}/processes"
        response = requests.get(url, auth=self.auth)
        return response.json()['results']

    def get_measurements(self, host, port, metrics):
        """Get measurements for specific host"""
        url = f"{self.base_url}/groups/{self.project_id}/hosts/{host}:{port}/measurements"
        params = {
            'granularity': 'PT1M',
            'period': 'PT1M',
            'metrics': ','.join(metrics)
        }
        response = requests.get(url, auth=self.auth, params=params)
        return response.json()

    def collect(self):
        """Collect metrics from Ops Manager"""
        processes = self.get_processes()

        for process in processes:
            if process['typeName'] != 'REPLICA_PRIMARY':
                continue

            host = process['hostname']
            port = process['port']
            host_label = f"{host}:{port}"

            # Get operations/sec
            data = self.get_measurements(host, port, ['OPCOUNTER_QUERY', 'OPCOUNTER_INSERT'])

            for measurement in data.get('measurements', []):
                if measurement['name'] == 'OPCOUNTER_QUERY':
                    value = measurement['dataPoints'][-1]['value'] if measurement['dataPoints'] else 0
                    self.metrics['ops'].labels(host=host_label).set(value)

    def run(self):
        """Main loop"""
        while True:
            try:
                self.collect()
            except Exception as e:
                print(f"Error collecting metrics: {e}")
            time.sleep(60)

if __name__ == '__main__':
    exporter = OpsManagerExporter(
        base_url='https://opsmgr.example.com:8080/api/public/v1.0',
        public_key='PUBLIC_KEY',
        private_key='PRIVATE_KEY',
        project_id='PROJECT_ID'
    )

    start_http_server(9217)
    print("Exporter started on port 9217")
    exporter.run()
```

#### 2. Automated Deployment Pipeline

```python
#!/usr/bin/env python3
# deploy_mongodb_cluster.py

import requests
from requests.auth import HTTPDigestAuth
import time
import json

class MongoDBDeployer:
    def __init__(self, ops_manager_url, public_key, private_key, project_id):
        self.base_url = f"{ops_manager_url}/api/public/v1.0"
        self.auth = HTTPDigestAuth(public_key, private_key)
        self.project_id = project_id

    def deploy_replica_set(self, config):
        """Deploy replica set via automation"""

        # Get current automation config
        url = f"{self.base_url}/groups/{self.project_id}/automationConfig"
        current_config = requests.get(url, auth=self.auth).json()

        # Add new replica set
        current_config['processes'].extend(config['processes'])
        current_config['replicaSets'].append(config['replicaSet'])

        # Apply new config
        response = requests.put(
            url,
            auth=self.auth,
            headers={'Content-Type': 'application/json'},
            data=json.dumps(current_config)
        )

        if response.status_code != 200:
            raise Exception(f"Deployment failed: {response.text}")

        # Wait for goal state
        return self.wait_for_goal_state()

    def wait_for_goal_state(self, timeout=1800):
        """Wait for automation to reach goal state"""
        url = f"{self.base_url}/groups/{self.project_id}/automationStatus"
        start_time = time.time()

        while time.time() - start_time < timeout:
            status = requests.get(url, auth=self.auth).json()

            if status['goalVersion'] == status['lastGoalVersionAchieved']:
                print("Goal state reached!")
                return True

            print(f"Waiting... Goal: {status['goalVersion']}, Current: {status['lastGoalVersionAchieved']}")
            time.sleep(30)

        raise TimeoutError("Goal state not reached within timeout")

# Usage
deployer = MongoDBDeployer(
    'https://opsmgr.example.com:8080',
    'PUBLIC_KEY',
    'PRIVATE_KEY',
    'PROJECT_ID'
)

replica_set_config = {
    'processes': [
        {
            'hostname': 'new-mongo-01',
            'port': 27017,
            'processType': 'mongod',
            'version': '7.0.4',
            'args2_6': {
                'replication': {'replSetName': 'new-rs0'},
                'storage': {'dbPath': '/data/mongodb'}
            }
        },
        # ... additional members
    ],
    'replicaSet': {
        'id': 'new-rs0',
        'members': [
            {'id': 0, 'hostname': 'new-mongo-01', 'port': 27017, 'priority': 1}
            # ... additional members
        ]
    }
}

deployer.deploy_replica_set(replica_set_config)
```

#### 3. Alert Webhook Handler

```python
#!/usr/bin/env python3
# webhook_handler.py

from flask import Flask, request, jsonify
import requests

app = Flask(__name__)

@app.route('/webhook/opsmgr', methods=['POST'])
def handle_opsmgr_webhook():
    """Handle Ops Manager webhook alerts"""

    alert = request.json

    # Parse alert
    alert_type = alert.get('typeName')
    severity = alert.get('status')
    group = alert.get('groupName')
    host = alert.get('hostId')

    # Custom logic based on alert type
    if alert_type == 'HOST_DOWN':
        handle_host_down(alert)
    elif alert_type == 'REPLICATION_LAG':
        handle_replication_lag(alert)
    elif alert_type == 'BACKUP_FAILED':
        handle_backup_failure(alert)

    return jsonify({'status': 'processed'}), 200

def handle_host_down(alert):
    """Auto-remediation for host down"""

    # Send to PagerDuty with high severity
    requests.post('https://events.pagerduty.com/v2/enqueue', json={
        'routing_key': 'YOUR_ROUTING_KEY',
        'event_action': 'trigger',
        'payload': {
            'summary': f"MongoDB host down: {alert['hostId']}",
            'severity': 'critical',
            'source': 'ops-manager'
        }
    })

    # Create JIRA ticket
    requests.post('https://jira.example.com/rest/api/2/issue', auth=('user', 'pass'), json={
        'fields': {
            'project': {'key': 'INFRA'},
            'summary': f"MongoDB host down: {alert['hostId']}",
            'issuetype': {'name': 'Incident'},
            'priority': {'name': 'Critical'}
        }
    })

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

---

## Cas d'Usage AvancÃ©s

### 1. Multi-Datacenter Deployment

Configuration active-passive multi-DC :

```
Organization: Global Corp
Project: Production MongoDB

Datacenter 1 (US-East - Active):
â”œâ”€ Replica Set: prod-us-rs0
â”‚  â”œâ”€ Primary: us-mongo-01 (Priority 2)
â”‚  â”œâ”€ Secondary: us-mongo-02 (Priority 1)
â”‚  â””â”€ Secondary: us-mongo-03 (Priority 1)
â”‚
â””â”€ Backup Daemon: us-backup-01

Datacenter 2 (EU-West - Passive/DR):
â”œâ”€ Replica Set Members:
â”‚  â”œâ”€ Secondary: eu-mongo-01 (Priority 0, Hidden)
â”‚  â””â”€ Secondary: eu-mongo-02 (Priority 0, Hidden)
â”‚
â””â”€ Backup Daemon: eu-backup-01

Configuration Ops Manager:
- Monitoring: All members from single Ops Manager
- Alerts: Datacenter-aware (suppress DR site during planned failover)
- Automation: Coordinated configuration changes
- Backup: Dual backup daemons for redundancy
```

**Failover automatisÃ©** :

```python
def failover_to_dr():
    """Promote DR site to active"""

    # 1. Update member priorities
    config = get_automation_config()

    # Reduce US members priority
    for member in config['replicaSets'][0]['members']:
        if member['hostname'].startswith('us-'):
            member['priority'] = 0

    # Increase EU members priority
    for member in config['replicaSets'][0]['members']:
        if member['hostname'].startswith('eu-'):
            member['priority'] = 1
            member['hidden'] = False

    # Apply configuration
    apply_automation_config(config)

    # 2. Wait for election
    wait_for_goal_state()

    # 3. Update DNS
    update_dns_to_eu()

    # 4. Send notifications
    notify_team("Failover to EU completed")
```

### 2. Capacity Planning Automation

```python
#!/usr/bin/env python3
# capacity_planner.py

import requests
from datetime import datetime, timedelta
from requests.auth import HTTPDigestAuth
import numpy as np

class CapacityPlanner:
    def __init__(self, ops_manager_url, public_key, private_key, project_id):
        self.base_url = f"{ops_manager_url}/api/public/v1.0"
        self.auth = HTTPDigestAuth(public_key, private_key)
        self.project_id = project_id

    def get_historical_metrics(self, host, port, metric, days=30):
        """Get historical data"""
        url = f"{self.base_url}/groups/{self.project_id}/hosts/{host}:{port}/measurements"

        end = datetime.utcnow()
        start = end - timedelta(days=days)

        params = {
            'granularity': 'PT1H',
            'period': f'P{days}D',
            'metrics': metric,
            'start': start.isoformat() + 'Z',
            'end': end.isoformat() + 'Z'
        }

        response = requests.get(url, auth=self.auth, params=params)
        data = response.json()

        if not data.get('measurements'):
            return []

        return [dp['value'] for dp in data['measurements'][0]['dataPoints'] if dp['value'] is not None]

    def predict_capacity(self, values, days_ahead=30):
        """Linear regression prediction"""
        if len(values) < 10:
            return None

        x = np.arange(len(values))
        y = np.array(values)

        # Linear regression
        coeffs = np.polyfit(x, y, 1)
        slope, intercept = coeffs

        # Predict future
        future_x = len(values) + (days_ahead * 24)  # hourly data
        prediction = slope * future_x + intercept

        return {
            'current': values[-1],
            'prediction': prediction,
            'growth_rate_per_day': slope * 24,
            'days_to_threshold': None
        }

    def analyze_project(self):
        """Analyze all clusters in project"""

        # Get all processes
        url = f"{self.base_url}/groups/{self.project_id}/processes"
        processes = requests.get(url, auth=self.auth).json()['results']

        report = []

        for process in processes:
            if process['typeName'] != 'REPLICA_PRIMARY':
                continue

            host = process['hostname']
            port = process['port']

            # Analyze storage
            storage_data = self.get_historical_metrics(host, port, 'DATABASE_STORAGE_SIZE', 30)
            storage_prediction = self.predict_capacity(storage_data)

            # Analyze memory
            memory_data = self.get_historical_metrics(host, port, 'SYSTEM_MEMORY_USED', 30)
            memory_prediction = self.predict_capacity(memory_data)

            report.append({
                'host': f"{host}:{port}",
                'storage': storage_prediction,
                'memory': memory_prediction
            })

        return report

# Usage
planner = CapacityPlanner(
    'https://opsmgr.example.com:8080',
    'PUBLIC_KEY',
    'PRIVATE_KEY',
    'PROJECT_ID'
)

report = planner.analyze_project()
for item in report:
    print(f"\nHost: {item['host']}")
    print(f"Storage: {item['storage']['current']:.2f} GB")
    print(f"Predicted (30d): {item['storage']['prediction']:.2f} GB")
    print(f"Growth rate: {item['storage']['growth_rate_per_day']:.2f} GB/day")
```

### 3. Compliance et Audit Reporting

```python
#!/usr/bin/env python3
# compliance_reporter.py

import requests
from requests.auth import HTTPDigestAuth
from datetime import datetime, timedelta
import csv

class ComplianceReporter:
    def __init__(self, ops_manager_url, public_key, private_key, project_id):
        self.base_url = f"{ops_manager_url}/api/public/v1.0"
        self.auth = HTTPDigestAuth(public_key, private_key)
        self.project_id = project_id

    def generate_backup_report(self, days=30):
        """Verify all clusters have successful backups"""

        url = f"{self.base_url}/groups/{self.project_id}/clusters"
        clusters = requests.get(url, auth=self.auth).json()['results']

        report = []
        end_date = datetime.utcnow()
        start_date = end_date - timedelta(days=days)

        for cluster in clusters:
            cluster_id = cluster['id']

            # Get snapshots
            snapshots_url = f"{self.base_url}/groups/{self.project_id}/clusters/{cluster_id}/snapshots"
            params = {
                'minDate': start_date.isoformat() + 'Z',
                'maxDate': end_date.isoformat() + 'Z'
            }
            snapshots = requests.get(snapshots_url, auth=self.auth, params=params).json()

            successful_snapshots = [s for s in snapshots.get('results', []) if s['status'] == 'COMPLETED']
            failed_snapshots = [s for s in snapshots.get('results', []) if s['status'] == 'FAILED']

            report.append({
                'cluster_name': cluster['clusterName'],
                'total_snapshots': len(snapshots.get('results', [])),
                'successful': len(successful_snapshots),
                'failed': len(failed_snapshots),
                'compliance': len(successful_snapshots) >= days,  # At least 1 per day
                'last_successful': successful_snapshots[0]['created'] if successful_snapshots else 'N/A'
            })

        return report

    def generate_security_report(self):
        """Audit security configuration"""

        url = f"{self.base_url}/groups/{self.project_id}/automationConfig"
        config = requests.get(url, auth=self.auth).json()

        report = {
            'tls_enabled': False,
            'authentication_enabled': False,
            'authorization_enabled': False,
            'encryption_at_rest': False,
            'audit_logging': False
        }

        # Check TLS
        for process in config.get('processes', []):
            args = process.get('args2_6', {})
            if args.get('net', {}).get('tls', {}).get('mode') in ['requireTLS', 'preferTLS']:
                report['tls_enabled'] = True
            if args.get('security', {}).get('authorization') == 'enabled':
                report['authorization_enabled'] = True
            if args.get('auditLog', {}).get('destination'):
                report['audit_logging'] = True

        return report

    def export_to_csv(self, backup_report, security_report, filename):
        """Export compliance report to CSV"""

        with open(filename, 'w', newline='') as csvfile:
            writer = csv.writer(csvfile)

            # Backup compliance
            writer.writerow(['Backup Compliance Report'])
            writer.writerow(['Cluster', 'Total Snapshots', 'Successful', 'Failed', 'Compliant', 'Last Success'])

            for item in backup_report:
                writer.writerow([
                    item['cluster_name'],
                    item['total_snapshots'],
                    item['successful'],
                    item['failed'],
                    'YES' if item['compliance'] else 'NO',
                    item['last_successful']
                ])

            writer.writerow([])
            writer.writerow(['Security Configuration'])
            writer.writerow(['Setting', 'Status'])

            for key, value in security_report.items():
                writer.writerow([key, 'ENABLED' if value else 'DISABLED'])

# Usage
reporter = ComplianceReporter(
    'https://opsmgr.example.com:8080',
    'PUBLIC_KEY',
    'PRIVATE_KEY',
    'PROJECT_ID'
)

backup_report = reporter.generate_backup_report(30)
security_report = reporter.generate_security_report()
reporter.export_to_csv(backup_report, security_report, 'compliance_report.csv')
```

---

## Troubleshooting

### ProblÃ¨me 1 : Agents Non ConnectÃ©s

**SymptÃ´mes** :
```
UI: Agent status "Not Connected" ou "Unavailable"
Monitoring data missing
Automation changes not applied
```

**Diagnostic** :
```bash
# 1. VÃ©rifier le statut du service
sudo systemctl status mongodb-mms-monitoring-agent
sudo systemctl status mongodb-mms-automation-agent

# 2. VÃ©rifier les logs
tail -f /var/log/mongodb-mms/monitoring-agent.log
tail -f /var/log/mongodb-mms/automation-agent.log

# Rechercher des erreurs
grep -i error /var/log/mongodb-mms/*-agent.log

# 3. VÃ©rifier la connectivitÃ© rÃ©seau
curl -v https://opsmgr.example.com:8080/api/public/v1.0/unauth/version

# 4. VÃ©rifier la configuration
cat /etc/mongodb-mms/monitoring-agent.config | grep -E "mmsBaseUrl|mmsGroupId|mmsApiKey"

# 5. Tester l'authentification API
curl -u "PUBLIC_KEY:PRIVATE_KEY" --digest \
  https://opsmgr.example.com:8080/api/public/v1.0/groups/PROJECT_ID
```

**Solutions** :
```bash
# 1. VÃ©rifier mmsApiKey valide
# Regenerate in UI: Project Settings â†’ Agents â†’ Agent API Key

# 2. VÃ©rifier les permissions firewall
sudo iptables -L -n | grep 8080
sudo firewall-cmd --list-all

# 3. VÃ©rifier les certificats TLS
openssl s_client -connect opsmgr.example.com:8080 -showcerts

# 4. Restart agents
sudo systemctl restart mongodb-mms-monitoring-agent
sudo systemctl restart mongodb-mms-automation-agent
```

### ProblÃ¨me 2 : Automation Stuck "In Progress"

**SymptÃ´mes** :
```
UI: Deployment shows "Changes being deployed" indefinitely
Goal state never reached
```

**Diagnostic** :
```bash
# Via API
curl -u "PUBLIC_KEY:PRIVATE_KEY" --digest \
  "https://opsmgr.example.com:8080/api/public/v1.0/groups/PROJECT_ID/automationStatus" | jq .

# Output
{
  "goalVersion": 42,
  "lastGoalVersionAchieved": 40
}

# Check agent logs for errors
grep -A 5 -i "error\|exception" /var/log/mongodb-mms/automation-agent.log

# Check if processes are running
ps aux | grep mongod
```

**Solutions** :
```bash
# 1. VÃ©rifier l'Ã©tat des processus MongoDB
mongo --eval "db.adminCommand({ serverStatus: 1 }).process"

# 2. VÃ©rifier les permissions filesystem
ls -la /data/mongodb
sudo chown -R mongodb:mongodb /data/mongodb

# 3. VÃ©rifier le disk space
df -h /data/mongodb

# 4. En dernier recours : rÃ©initialiser l'automation agent
sudo systemctl stop mongodb-mms-automation-agent
sudo rm -rf /var/lib/mongodb-mms-automation/automation-agent.status
sudo systemctl start mongodb-mms-automation-agent
```

### ProblÃ¨me 3 : Backup Failures

**SymptÃ´mes** :
```
Alert: "Backup snapshot failed"
Missing snapshots in UI
```

**Diagnostic** :
```bash
# VÃ©rifier le statut du backup daemon
sudo systemctl status mongodb-mms-backup-daemon

# Logs
tail -f /var/log/mongodb-mms/backup-daemon.log

# VÃ©rifier l'espace de stockage backup
df -h /data/backup  # ou bucket S3

# VÃ©rifier la connectivitÃ© au replica set
mongo "mongodb://backup-user:pass@rs0-primary:27017,rs0-sec1:27017,rs0-sec2:27017/?replicaSet=rs0&readPreference=secondary"

# VÃ©rifier l'oplog
db.getReplicationInfo()
```

**Solutions** :
```bash
# 1. Augmenter l'espace disque si plein

# 2. VÃ©rifier les credentials backup user
mongo --eval "
  use admin
  db.getUser('backup-user')
"

# 3. VÃ©rifier les permissions S3 (si applicable)
aws s3 ls s3://mongodb-backups-prod/ --profile backup

# 4. Restart backup daemon
sudo systemctl restart mongodb-mms-backup-daemon

# 5. Re-sync si corruption
# Via UI: Backup â†’ Settings â†’ Resync Backup
```

---

## Bonnes Pratiques

### 1. Architecture et Dimensionnement

```yaml
Ops Manager Application:
  DÃ©ploiement:
    âœ“ HA avec load balancer (2+ instances)
    âœ“ Application database en replica set (3+ membres)
    âœ“ SSD pour application database
    âœ“ Backup automatisÃ© de l'application database

  Monitoring:
    âœ“ Monitoring de l'Ops Manager lui-mÃªme (meta-monitoring)
    âœ“ Alertes sur la santÃ© de l'application
    âœ“ Logs centralisÃ©s (Splunk/ELK)

Agents:
  âœ“ Un automation agent par serveur physique/VM
  âœ“ Un monitoring agent par processus MongoDB
  âœ“ Backup daemon co-localisÃ© ou dÃ©diÃ© selon charge
  âœ“ Agents sur version latest (auto-update recommandÃ©)

Network:
  âœ“ Faible latence entre Ops Manager et agents (< 100ms)
  âœ“ Bandwidth suffisant pour metrics (~ 1 Mbps par 100 agents)
  âœ“ Firewall rules pour ports : 8080 (HTTPS), 27017+ (MongoDB)
```

### 2. SÃ©curitÃ©

```yaml
Authentication:
  âœ“ LDAP/AD integration pour SSO
  âœ“ MFA obligatoire pour admin users
  âœ“ API keys rotation tous les 90 jours
  âœ“ Audit logging activÃ©

Authorization:
  âœ“ Principe du moindre privilÃ¨ge
  âœ“ SÃ©paration des rÃ´les (cluster mgmt vs backup)
  âœ“ Review trimestriel des accÃ¨s

Encryption:
  âœ“ TLS pour UI et agents
  âœ“ Encrypted at rest pour backup storage
  âœ“ Secrets management (Vault) pour credentials

Compliance:
  âœ“ Audit logs exportÃ©s vers SIEM
  âœ“ Backup retention conforme aux rÃ©gulations
  âœ“ Regular security scans
```

### 3. OpÃ©rations

```yaml
Monitoring:
  âœ“ Baseline performance Ã©tabli
  âœ“ Alertes configurÃ©es pour tous clusters critiques
  âœ“ Dashboard review hebdomadaire
  âœ“ Performance advisor consultÃ© rÃ©guliÃ¨rement

Automation:
  âœ“ Infrastructure as Code pour configurations
  âœ“ Change control process pour modifications
  âœ“ Maintenance windows planifiÃ©es
  âœ“ Rollback plan documentÃ©

Backup:
  âœ“ Restore testing mensuel
  âœ“ Point-in-time recovery validÃ©
  âœ“ Backup storage redundancy (multi-rÃ©gion)
  âœ“ Retention policy conforme business needs

Documentation:
  âœ“ Runbooks Ã  jour pour alertes communes
  âœ“ Architecture diagrams actualisÃ©s
  âœ“ On-call escalation path dÃ©fini
  âœ“ Disaster recovery plan testÃ© annuellement
```

### 4. Checklist DÃ©ploiement Production

```markdown
Phase 1: PrÃ©paration
â–¡ Sizing calculÃ© (application, database, agents)
â–¡ Infrastructure provisionnÃ©e
â–¡ Network configuration validÃ©e
â–¡ Firewall rules appliquÃ©es
â–¡ DNS entries crÃ©Ã©s
â–¡ TLS certificates obtenus

Phase 2: Installation
â–¡ Ops Manager application installÃ©
â–¡ Application database configurÃ© en HA
â–¡ Initial admin user crÃ©Ã©
â–¡ Organization/Project structure dÃ©finie
â–¡ LDAP integration configurÃ©e (si applicable)

Phase 3: Configuration
â–¡ Agents dÃ©ployÃ©s sur tous serveurs MongoDB
â–¡ Tous clusters discovered et managed
â–¡ Monitoring alerting configurÃ©
â–¡ Backup activÃ© pour clusters production
â–¡ API access configurÃ© pour automation

Phase 4: Validation
â–¡ Monitoring data visible pour tous clusters
â–¡ Test alert envoyÃ© et reÃ§u
â–¡ Test backup et restore effectuÃ©
â–¡ Test automation change (config update)
â–¡ Performance baseline Ã©tabli

Phase 5: Documentation
â–¡ Runbooks crÃ©Ã©s
â–¡ Architecture documentÃ©e
â–¡ Access list (qui a quelles permissions)
â–¡ Escalation procedures
â–¡ Disaster recovery plan

Phase 6: Go-Live
â–¡ Communication Ã©quipe
â–¡ Monitoring 24/7 pendant premiÃ¨re semaine
â–¡ Post-implementation review aprÃ¨s 2 semaines
```

---

## RÃ©sumÃ© pour SRE

### Avantages vs Autres Solutions

| Aspect | Ops Manager | Prometheus/Grafana | MongoDB Atlas |
|--------|-------------|-------------------|---------------|
| **Setup complexity** | Ã‰levÃ© | ModÃ©rÃ© | Minimal |
| **Automation** | Complet (deploy, upgrade) | Aucune | Complet |
| **Backup** | IntÃ©grÃ© (PITR) | Externe | IntÃ©grÃ© |
| **On-premise** | âœ“ | âœ“ | âœ— |
| **Licensing** | Enterprise | Open-source | SaaS pricing |
| **Best for** | Enterprise on-prem | Cloud-native, multi-vendor | Cloud-first |

### Commandes Essentielles API

```bash
# List all clusters
curl -u "$KEY:$SECRET" --digest \
  "https://opsmgr/api/public/v1.0/groups/$PROJECT/clusters" | jq .

# Get automation status
curl -u "$KEY:$SECRET" --digest \
  "https://opsmgr/api/public/v1.0/groups/$PROJECT/automationStatus" | jq .

# List alerts
curl -u "$KEY:$SECRET" --digest \
  "https://opsmgr/api/public/v1.0/groups/$PROJECT/alerts" | jq .

# Get measurements
curl -u "$KEY:$SECRET" --digest \
  "https://opsmgr/api/public/v1.0/groups/$PROJECT/hosts/$HOST:$PORT/measurements?metrics=OPCOUNTER_QUERY&granularity=PT1M" | jq .

# Trigger backup snapshot
curl -X POST -u "$KEY:$SECRET" --digest \
  "https://opsmgr/api/public/v1.0/groups/$PROJECT/clusters/$CLUSTER/snapshots" \
  -H "Content-Type: application/json" \
  -d '{"description":"Manual snapshot"}'
```

### MÃ©triques Critiques Top 10

```
1. Automation Goal State: goalVersion == lastGoalVersionAchieved
2. Agent Connectivity: all agents "connected"
3. Replication Lag: < 10 seconds
4. Backup Success Rate: > 99% snapshots successful
5. Oplog Window: > 24 hours
6. Operations/sec: baseline + 3Ïƒ
7. Connections: < 80% max
8. Cache Usage: 60-80% used, < 20% dirty
9. Disk Space: > 20% free
10. Alert Response Time: < 15 minutes moyenne
```

---

## Conclusion

MongoDB Ops Manager est la solution **enterprise-grade** pour gÃ©rer des dÃ©ploiements MongoDB Ã  grande Ã©chelle dans des environnements on-premise ou air-gapped. Sa combinaison unique de **monitoring**, **automation** et **backup** en fait un choix idÃ©al pour :

**Cas d'usage idÃ©aux** :
- Secteurs rÃ©gulÃ©s (finance, santÃ©, gouvernement)
- Exigences de data residency strictes
- Air-gapped environments
- Besoins de contrÃ´le total sur l'infrastructure
- DÃ©ploiements multi-datacenters complexes

**Points clÃ©s Ã  retenir** :
- Investissement initial Ã©levÃ© mais ROI fort Ã  grande Ã©chelle
- Automatisation rÃ©duit les erreurs humaines
- Backup intÃ©grÃ© simplifie la compliance
- Courbe d'apprentissage modÃ©rÃ©e
- Support MongoDB Enterprise inclus

**Prochaines Ã©tapes** :
- Ã‰valuer le sizing pour votre environnement
- PoC sur environnement non-production
- Former l'Ã©quipe aux concepts d'automation
- Ã‰tablir les runbooks et procÃ©dures
- Planifier migration progressive des clusters

---

**RÃ©fÃ©rences** :
- [Ops Manager Documentation](https://www.mongodb.com/docs/ops-manager/)
- [Ops Manager API Reference](https://www.mongodb.com/docs/ops-manager/current/reference/api/)
- [Ops Manager Sizing Calculator](https://www.mongodb.com/docs/ops-manager/current/installation/#prerequisites)
- [MongoDB Enterprise Advanced](https://www.mongodb.com/products/mongodb-enterprise-advanced)

â­ï¸ [Alerting et notifications](/13-monitoring-administration/09-alerting-notifications.md)
