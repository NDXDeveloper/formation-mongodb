üîù Retour au [Sommaire](/SOMMAIRE.md)

# 22.2 Probl√®mes de Performance

## Vue d'ensemble

Les probl√®mes de performance sont parmi les incidents les plus fr√©quents et peuvent avoir des impacts critiques sur l'exp√©rience utilisateur et la stabilit√© du syst√®me. Cette section fournit des m√©thodologies compl√®tes pour diagnostiquer et r√©soudre les probl√®mes de performance MongoDB.

---

## Table des Mati√®res

1. [Requ√™tes Lentes](#1-requ%C3%AAtes-lentes)
2. [Utilisation CPU √âlev√©e](#2-utilisation-cpu-%C3%A9lev%C3%A9e)
3. [Saturation M√©moire](#3-saturation-m%C3%A9moire)
4. [Goulots d'√âtranglement I/O](#4-goulots-d%C3%A9tranglement-io)
5. [Lock Contention](#5-lock-contention)
6. [Probl√®mes de Cache](#6-probl%C3%A8mes-de-cache)
7. [Probl√®mes d'Agr√©gation](#7-probl%C3%A8mes-dagr%C3%A9gation)
8. [Monitoring et M√©triques](#8-monitoring-et-m%C3%A9triques)

---

## 1. Requ√™tes Lentes

### Sympt√¥mes

```
Application timeouts
Response times > 1 second
High queue depth
User complaints about slowness
```

### Causes Possibles

- Absence d'index appropri√©s
- Index non utilis√©s (query planner inefficace)
- Collection scans complets
- Requ√™tes sur documents trop volumineux
- Projection insuffisante
- Requ√™tes complexes non optimis√©es

---

### Diagnostic Pas √† Pas

#### √âtape 1 : Activer et Analyser le Profiler

```javascript
// Activer le profiler pour les requ√™tes > 100ms
db.setProfilingLevel(1, {slowms: 100})

// V√©rifier le niveau actuel
db.getProfilingStatus()

// Voir les requ√™tes les plus lentes
db.system.profile.find()
  .sort({millis: -1})
  .limit(10)
  .pretty()

// Analyse statistique des requ√™tes lentes
db.system.profile.aggregate([
  {$match: {millis: {$gt: 100}}},
  {$group: {
    _id: "$ns",
    count: {$sum: 1},
    avgMillis: {$avg: "$millis"},
    maxMillis: {$max: "$millis"},
    operations: {$push: {
      op: "$op",
      millis: "$millis",
      ts: "$ts"
    }}
  }},
  {$sort: {avgMillis: -1}}
])
```

**Interpr√©ter les r√©sultats du profiler :**

```javascript
// Exemple de sortie
{
  "op" : "query",                    // Type d'op√©ration
  "ns" : "mydb.users",               // Collection
  "command" : {
    "find" : "users",
    "filter" : { "age" : { "$gt" : 25 } }
  },
  "keysExamined" : 0,                // ‚ö†Ô∏è 0 = pas d'index utilis√©
  "docsExamined" : 1000000,          // ‚ö†Ô∏è Scan complet !
  "nreturned" : 50000,               // Documents retourn√©s
  "responseLength" : 5000000,        // Taille de la r√©ponse
  "millis" : 2543,                   // ‚ö†Ô∏è 2.5 secondes !
  "execStats" : {
    "stage" : "COLLSCAN",            // ‚ö†Ô∏è Collection scan
    "nReturned" : 50000,
    "executionTimeMillis" : 2543
  }
}
```

**Signaux d'alerte :**
- `keysExamined: 0` ‚Üí Aucun index utilis√©
- `docsExamined >> nreturned` ‚Üí Scan inefficace
- `stage: "COLLSCAN"` ‚Üí Scan complet de collection
- `millis > 1000` ‚Üí Requ√™te tr√®s lente

#### √âtape 2 : Analyser avec explain()

```javascript
// Analyse d√©taill√©e d'une requ√™te
db.users.find({age: {$gt: 25}}).explain("executionStats")

// Analyse d'une requ√™te complexe
db.users.find({
  age: {$gt: 25},
  city: "Paris"
}).sort({created: -1}).limit(10).explain("executionStats")

// Pour les agr√©gations
db.orders.explain("executionStats").aggregate([
  {$match: {status: "completed"}},
  {$group: {_id: "$customerId", total: {$sum: "$amount"}}}
])
```

**Interpr√©ter explain() :**

```javascript
{
  "queryPlanner" : {
    "winningPlan" : {
      "stage" : "FETCH",             // √âtape de r√©cup√©ration
      "inputStage" : {
        "stage" : "IXSCAN",          // ‚úÖ Index scan (bon)
        "keyPattern" : { "age" : 1 },
        "indexName" : "age_1"
      }
    }
  },
  "executionStats" : {
    "executionTimeMillis" : 45,      // Temps d'ex√©cution
    "totalKeysExamined" : 50000,     // Cl√©s d'index examin√©es
    "totalDocsExamined" : 50000,     // Documents examin√©s
    "nReturned" : 50000,             // Documents retourn√©s
    "executionStages" : {
      "stage" : "FETCH",
      "nReturned" : 50000,
      "executionTimeMillisEstimate" : 40,
      "inputStage" : {
        "stage" : "IXSCAN",          // Index utilis√©
        "nReturned" : 50000,
        "executionTimeMillisEstimate" : 10
      }
    }
  }
}
```

**M√©triques importantes :**

```
Ratio d'efficacit√© = nReturned / totalDocsExamined

‚úÖ Excellent : ratio > 0.9 (90%+ des documents examin√©s sont retourn√©s)
‚ö†Ô∏è Moyen : ratio 0.5-0.9
‚ùå Mauvais : ratio < 0.5 (beaucoup de documents examin√©s inutilement)
```

#### √âtape 3 : Identifier les Index Manquants

```javascript
// V√©rifier les index existants
db.users.getIndexes()

// Analyser l'utilisation des index
db.users.aggregate([{$indexStats: {}}])

// Identifier les collections sans index (sauf _id)
db.getCollectionNames().forEach(function(collection) {
  var indexes = db[collection].getIndexes();
  if (indexes.length === 1) {  // Seulement _id
    print(collection + " has only _id index");
  }
})

// Voir les index inutilis√©s
db.users.aggregate([
  {$indexStats: {}},
  {$match: {"accesses.ops": 0}},
  {$project: {name: 1, "accesses.since": 1}}
])
```

#### √âtape 4 : Analyser les Patterns d'Acc√®s

```javascript
// Top des requ√™tes par op√©ration
db.system.profile.aggregate([
  {$group: {
    _id: {
      ns: "$ns",
      op: "$op",
      query: "$command.filter"
    },
    count: {$sum: 1},
    avgTime: {$avg: "$millis"},
    maxTime: {$max: "$millis"}
  }},
  {$sort: {count: -1}},
  {$limit: 20}
])

// Identifier les requ√™tes avec projections manquantes
db.system.profile.find({
  "command.projection": {$exists: false},
  "responseLength": {$gt: 1000000}  // > 1MB
})
```

#### √âtape 5 : Mesurer l'Impact sur les Ressources

```javascript
// V√©rifier les op√©rations en cours
db.currentOp({
  "active": true,
  "secs_running": {$gt: 5}
})

// Voir les op√©rations longues avec d√©tails
db.currentOp(true).inprog.filter(op =>
  op.secs_running > 5 && op.op === "query"
).map(op => ({
  opid: op.opid,
  secs_running: op.secs_running,
  ns: op.ns,
  query: op.command
}))
```

---

### R√©solution Pas √† Pas

#### Solution 1 : Cr√©er les Index Appropri√©s

**Analyse et cr√©ation :**

```javascript
// 1. Identifier le pattern de requ√™te
db.system.profile.aggregate([
  {$match: {ns: "mydb.users"}},
  {$group: {
    _id: "$command.filter",
    count: {$sum: 1},
    avgTime: {$avg: "$millis"}
  }},
  {$sort: {count: -1}}
])

// 2. Cr√©er un index simple
db.users.createIndex({age: 1})

// 3. V√©rifier l'am√©lioration
db.users.find({age: {$gt: 25}}).explain("executionStats")

// 4. Index compos√© pour requ√™tes multiples
db.users.createIndex({city: 1, age: 1})

// 5. Index avec ordre de tri
db.users.createIndex({status: 1, created: -1})

// 6. Cr√©er en arri√®re-plan (production)
db.users.createIndex(
  {email: 1},
  {background: true, name: "email_idx"}
)
```

**Ordre des champs dans l'index compos√© (ESR Rule) :**

```
E - Equality (√©galit√©)
S - Sort (tri)
R - Range (plage)

Exemple :
Query: {status: "active", age: {$gt: 25}}, sort: {created: -1}
Index optimal : {status: 1, created: -1, age: 1}
             (Equality) (Sort)      (Range)
```

**Exemple complet :**

```javascript
// Requ√™te probl√©matique
db.orders.find({
  status: "completed",
  customerId: {$in: [1, 2, 3]},
  amount: {$gt: 100}
}).sort({orderDate: -1})

// Analyse
db.orders.find({
  status: "completed",
  customerId: {$in: [1, 2, 3]},
  amount: {$gt: 100}
}).sort({orderDate: -1}).explain("executionStats")

// Cr√©ation de l'index optimal
db.orders.createIndex({
  status: 1,           // Equality
  orderDate: -1,       // Sort
  customerId: 1,       // Range ($in)
  amount: 1            // Range ($gt)
})

// V√©rification de l'am√©lioration
// AVANT : 2500ms, COLLSCAN
// APR√àS : 15ms, IXSCAN
```

#### Solution 2 : Optimiser les Projections

```javascript
// ‚ùå MAUVAIS : R√©cup√®re tous les champs
db.users.find({age: {$gt: 25}})

// ‚úÖ BON : Projection explicite
db.users.find(
  {age: {$gt: 25}},
  {name: 1, email: 1, _id: 0}
)

// ‚ùå MAUVAIS : Documents volumineux
db.articles.find({category: "tech"})

// ‚úÖ BON : Exclure les champs volumineux
db.articles.find(
  {category: "tech"},
  {content: 0, comments: 0}  // Exclure gros champs
)

// Index couvrant (covered query)
db.users.createIndex({age: 1, name: 1, email: 1})

db.users.find(
  {age: {$gt: 25}},
  {name: 1, email: 1, _id: 0}  // Tous les champs sont dans l'index
)
// R√©sultat : Pas de FETCH, seulement IXSCAN !
```

#### Solution 3 : Optimiser la Pagination

**‚ùå Pagination inefficace avec skip() :**

```javascript
// PROBL√àME : Skip examine tous les documents pr√©c√©dents
db.products.find()
  .sort({_id: 1})
  .skip(10000)   // ‚ö†Ô∏è Examine 10000 docs !
  .limit(20)

// Performance se d√©grade avec l'offset
// Page 1 : 10ms
// Page 100 : 150ms
// Page 1000 : 2500ms
```

**‚úÖ Pagination optimale avec range query :**

```javascript
// Premi√®re page
db.products.find()
  .sort({_id: 1})
  .limit(20)

// Sauvegarder le dernier _id : lastId = <dernier document _id>

// Pages suivantes
db.products.find({_id: {$gt: lastId}})
  .sort({_id: 1})
  .limit(20)

// Performance constante quelle que soit la page !
```

**Pagination avec index compos√© :**

```javascript
// Index pour tri + filtrage
db.products.createIndex({category: 1, created: -1, _id: 1})

// Premi√®re page
var results = db.products.find({category: "electronics"})
  .sort({created: -1, _id: 1})
  .limit(20)

// R√©cup√©rer les marqueurs
var lastCreated = results[results.length - 1].created
var lastId = results[results.length - 1]._id

// Pages suivantes
db.products.find({
  category: "electronics",
  $or: [
    {created: {$lt: lastCreated}},
    {created: lastCreated, _id: {$gt: lastId}}
  ]
})
.sort({created: -1, _id: 1})
.limit(20)
```

#### Solution 4 : Limiter les R√©sultats

```javascript
// ‚ùå MAUVAIS : R√©cup√®re potentiellement millions de docs
db.logs.find({level: "info"})

// ‚úÖ BON : Toujours limiter
db.logs.find({level: "info"}).limit(1000)

// ‚úÖ BON : Compter sans tout charger
db.logs.countDocuments({level: "info"})

// ‚úÖ BON : Estimation rapide (moins pr√©cis mais instantan√©)
db.logs.estimatedDocumentCount()

// ‚ùå MAUVAIS : Sort en m√©moire sur r√©sultats non index√©s
db.logs.find({message: /error/}).sort({timestamp: -1})

// ‚úÖ BON : Sort avec index
db.logs.createIndex({timestamp: -1})
db.logs.find().sort({timestamp: -1}).limit(100)
```

#### Solution 5 : Re√©crire les Requ√™tes Inefficaces

**Exemple 1 : $where ‚Üí Op√©rateurs standards**

```javascript
// ‚ùå TR√àS LENT : $where ex√©cute du JavaScript
db.users.find({
  $where: "this.age > 25 && this.status === 'active'"
})

// ‚úÖ RAPIDE : Op√©rateurs natifs
db.users.find({
  age: {$gt: 25},
  status: "active"
})
```

**Exemple 2 : $regex non ancr√© ‚Üí $regex ancr√©**

```javascript
// ‚ùå LENT : Scan complet m√™me avec index
db.users.find({email: /example\.com/})

// ‚úÖ RAPIDE : Peut utiliser l'index
db.users.find({email: /^.*@example\.com$/})

// ‚úÖ ENCORE MIEUX : Recherche exacte
db.users.find({email: "user@example.com"})

// ‚úÖ OPTIMAL : Index texte pour recherche
db.users.createIndex({email: "text"})
db.users.find({$text: {$search: "example.com"}})
```

**Exemple 3 : $in avec beaucoup de valeurs ‚Üí Alternative**

```javascript
// ‚ö†Ô∏è PEUT √äTRE LENT : $in avec 1000+ valeurs
db.orders.find({customerId: {$in: [/* 10000 IDs */]}})

// ‚úÖ MIEUX : Si possible, inverser la relation
// Plut√¥t que chercher dans orders
// Ajouter les orderIds dans customer
db.customers.findOne({_id: customerId}).orderIds

// ‚úÖ OU : Chunker les requ√™tes
const chunkSize = 1000
for (let i = 0; i < customerIds.length; i += chunkSize) {
  const chunk = customerIds.slice(i, i + chunkSize)
  db.orders.find({customerId: {$in: chunk}})
}
```

#### Solution 6 : Utiliser les Hints pour Forcer un Index

```javascript
// Query planner choisit mal
db.users.find({
  age: {$gt: 25},
  city: "Paris"
}).explain("executionStats")
// Utilise age_1 mais city_1_age_1 serait meilleur

// Forcer l'utilisation d'un index sp√©cifique
db.users.find({
  age: {$gt: 25},
  city: "Paris"
}).hint({city: 1, age: 1})

// Forcer par nom d'index
db.users.find({
  age: {$gt: 25},
  city: "Paris"
}).hint("city_1_age_1")

// D√©sactiver l'utilisation d'index (forcer COLLSCAN)
db.users.find({age: {$gt: 25}}).hint({$natural: 1})
```

---

## 2. Utilisation CPU √âlev√©e

### Sympt√¥mes

```
CPU usage > 80% sustained
High load average
System unresponsive
Slow query execution even with indexes
```

### Causes Possibles

- Requ√™tes complexes non optimis√©es
- Agr√©gations lourdes
- Scan de collections volumineuses
- Tri en m√©moire
- Calculs JavaScript c√¥t√© serveur
- Lock contention
- Trop d'op√©rations concurrentes

---

### Diagnostic Pas √† Pas

#### √âtape 1 : Identifier la Cause de la Charge CPU

```bash
# V√©rifier l'utilisation CPU globale
top -p $(pgrep -d',' mongod)

# D√©tails par thread MongoDB
top -H -p $(pgrep mongod)

# Statistiques d√©taill√©es
pidstat -t -p $(pgrep mongod) 1 10

# Tracer les appels syst√®me (attention : overhead)
strace -c -p $(pgrep mongod)
```

```javascript
// Identifier les op√©rations consommatrices
db.currentOp({
  "secs_running": {$gt: 5},
  "microsecs_running": {$gt: 5000000}
}).inprog.forEach(op => {
  printjson({
    opid: op.opid,
    op: op.op,
    ns: op.ns,
    secs: op.secs_running,
    query: op.command
  })
})

// Voir les op√©rations par type
db.currentOp().inprog.reduce((acc, op) => {
  acc[op.op] = (acc[op.op] || 0) + 1
  return acc
}, {})
```

#### √âtape 2 : Analyser les M√©triques Serveur

```javascript
// M√©triques globales
var stats = db.serverStatus()

// Compteurs d'op√©rations
printjson(stats.opcounters)
// {
//   insert: 123456,
//   query: 987654,
//   update: 456789,
//   delete: 12345,
//   getmore: 234567,
//   command: 876543
// }

// M√©triques r√©seau
printjson(stats.network)
// Identifier si beaucoup de donn√©es transf√©r√©es

// Connexions
printjson(stats.connections)

// WiredTiger cache
printjson(stats.wiredTiger.cache)
```

#### √âtape 3 : Identifier les Requ√™tes Probl√©matiques

```javascript
// Top des requ√™tes CPU-intensives
db.system.profile.aggregate([
  {$match: {
    millis: {$gt: 1000},
    ts: {$gt: new Date(Date.now() - 3600000)}  // Derni√®re heure
  }},
  {$group: {
    _id: {
      ns: "$ns",
      op: "$op",
      planSummary: "$planSummary"
    },
    count: {$sum: 1},
    avgTime: {$avg: "$millis"},
    maxTime: {$max: "$millis"},
    totalTime: {$sum: "$millis"}
  }},
  {$sort: {totalTime: -1}},
  {$limit: 10}
])
```

#### √âtape 4 : Analyser les Patterns de Tri

```javascript
// Identifier les sorts en m√©moire (tr√®s co√ªteux)
db.system.profile.find({
  "execStats.stage": "SORT",
  "execStats.sortPattern": {$exists: true}
})

// Taille des sorts en m√©moire
db.system.profile.find({
  "execStats.memUsage": {$gt: 33554432}  // > 32MB
}).forEach(doc => {
  print("Sort memory: " + (doc.execStats.memUsage / 1024 / 1024) + " MB")
  printjson(doc.command)
})
```

---

### R√©solution Pas √† Pas

#### Solution 1 : Optimiser les Tris avec Index

```javascript
// ‚ùå PROBL√àME : Sort en m√©moire
db.orders.find({status: "completed"})
  .sort({orderDate: -1})
  .limit(100)

// Explain montre :
// "stage": "SORT"
// "memUsage": 52428800  // 50MB en m√©moire !
// "inputStage": {"stage": "COLLSCAN"}

// ‚úÖ SOLUTION : Index sur le champ de tri
db.orders.createIndex({status: 1, orderDate: -1})

// Apr√®s :
// "stage": "FETCH"
// "inputStage": {"stage": "IXSCAN"}
// Pas de sort en m√©moire !
```

**Index pour tri compos√© :**

```javascript
// Query avec filtrage et tri
db.orders.find({
  status: "completed",
  customerId: 123
}).sort({orderDate: -1, amount: 1})

// Index optimal
db.orders.createIndex({
  status: 1,
  customerId: 1,
  orderDate: -1,
  amount: 1
})
```

#### Solution 2 : Limiter les Calculs JavaScript

```javascript
// ‚ùå TR√àS LENT : $where avec JavaScript
db.products.find({
  $where: function() {
    return this.price * this.quantity > 1000
  }
})

// ‚úÖ RAPIDE : $expr avec op√©rateurs natifs
db.products.find({
  $expr: {
    $gt: [{$multiply: ["$price", "$quantity"]}, 1000]
  }
})

// ‚úÖ ENCORE MIEUX : Champ calcul√© stock√©
// Ajouter un champ "totalValue" lors de l'insertion/update
db.products.updateMany({}, [{
  $set: {
    totalValue: {$multiply: ["$price", "$quantity"]}
  }
}])

// Cr√©er un index sur le champ calcul√©
db.products.createIndex({totalValue: 1})

// Query devient simple
db.products.find({totalValue: {$gt: 1000}})
```

#### Solution 3 : Augmenter les Ressources Serveur

**V√©rifier la configuration WiredTiger :**

```javascript
// Voir le cache actuel
db.serverStatus().wiredTiger.cache

// Ajuster le cache (50% de RAM par d√©faut)
// /etc/mongod.conf
storage:
  wiredTiger:
    engineConfig:
      cacheSizeGB: 8  // Ajuster selon RAM disponible

// Red√©marrer MongoDB
// sudo systemctl restart mongod
```

**Augmenter les ressources syst√®me :**

```bash
# V√©rifier les limites actuelles
ulimit -a

# Augmenter les limites
# /etc/security/limits.conf
mongodb soft nofile 64000
mongodb hard nofile 64000
mongodb soft nproc 32000
mongodb hard nproc 32000
```

#### Solution 4 : Distribuer la Charge

**Read Preference sur Secondaries :**

```javascript
// Node.js - Lire depuis secondaries
const client = new MongoClient(uri, {
  readPreference: 'secondaryPreferred',
  readConcern: { level: 'available' }
})

// Requ√™tes analytics sur secondary
db.orders.find({status: "completed"}).readPref("secondary")
```

**Sharding pour distribution horizontale :**

```javascript
// Activer le sharding
sh.enableSharding("mydb")

// Sharder une collection volumineuse
sh.shardCollection("mydb.orders", {customerId: "hashed"})

// V√©rifier la distribution
db.orders.getShardDistribution()
```

#### Solution 5 : Impl√©menter le Caching Applicatif

```javascript
// Node.js avec Redis
const redis = require('redis')
const client = redis.createClient()

async function getUser(userId) {
  // 1. V√©rifier le cache
  const cached = await client.get(`user:${userId}`)
  if (cached) {
    return JSON.parse(cached)
  }

  // 2. Query MongoDB
  const user = await db.users.findOne({_id: userId})

  // 3. Mettre en cache (TTL 5 min)
  await client.setex(
    `user:${userId}`,
    300,
    JSON.stringify(user)
  )

  return user
}

// Invalider le cache lors des updates
async function updateUser(userId, data) {
  await db.users.updateOne(
    {_id: userId},
    {$set: data}
  )

  // Invalider le cache
  await client.del(`user:${userId}`)
}
```

---

## 3. Saturation M√©moire

### Sympt√¥mes

```
High memory usage (> 90%)
OOM (Out of Memory) errors
Swapping activity
Slow performance despite good queries
MongoDB restarts unexpectedly
```

### Causes Possibles

- Cache WiredTiger trop grand
- Documents tr√®s volumineux
- R√©sultats de requ√™tes non pagin√©s
- Accumulation de connexions
- Memory leaks dans l'application
- Agr√©gations volumineuses

---

### Diagnostic Pas √† Pas

#### √âtape 1 : Analyser l'Utilisation M√©moire

```bash
# M√©moire globale du syst√®me
free -h
vmstat 1 10

# M√©moire MongoDB sp√©cifique
ps aux | grep mongod | awk '{print $6}'  # RSS en KB

# D√©tails de la m√©moire MongoDB
pmap -x $(pgrep mongod) | tail -1

# V√©rifier le swapping
vmstat 1 5
# si: swap in, so: swap out
# Si > 0 : syst√®me utilise le swap (MAUVAIS)
```

```javascript
// M√©triques m√©moire MongoDB
var mem = db.serverStatus().mem
printjson(mem)
// {
//   bits: 64,
//   resident: 2048,    // M√©moire r√©sidente (MB)
//   virtual: 4096,     // M√©moire virtuelle (MB)
//   mapped: 0,
//   mappedWithJournal: 0
// }

// Cache WiredTiger
var cache = db.serverStatus().wiredTiger.cache
printjson({
  "maximum bytes configured": cache["maximum bytes configured"],
  "bytes currently in cache": cache["bytes currently in the cache"],
  "pages evicted by application threads": cache["pages evicted by application threads"],
  "percentage overhead": cache["percentage overhead"]
})
```

#### √âtape 2 : Identifier les Collections Volumineuses

```javascript
// Taille des collections
db.getCollectionNames().map(name => ({
  collection: name,
  size: db[name].stats().size / 1024 / 1024,  // MB
  storageSize: db[name].stats().storageSize / 1024 / 1024,  // MB
  count: db[name].count(),
  avgObjSize: db[name].stats().avgObjSize
})).sort((a, b) => b.size - a.size)

// Identifier les documents tr√®s volumineux
db.collection.find().forEach(doc => {
  var size = Object.bsonsize(doc)
  if (size > 1024 * 1024) {  // > 1MB
    print(doc._id + ": " + (size / 1024 / 1024) + " MB")
  }
})
```

#### √âtape 3 : Analyser les √âvictions de Cache

```javascript
// Statistiques d'√©viction du cache
var cache = db.serverStatus().wiredTiger.cache

var evictionRate = cache["pages evicted by application threads"] /
                   cache["pages read into cache"]

print("Eviction rate: " + (evictionRate * 100).toFixed(2) + "%")

// Taux √©lev√© (> 10%) = cache trop petit ou workload inadapt√©
```

#### √âtape 4 : V√©rifier les Requ√™tes Gourmandes

```javascript
// Requ√™tes retournant beaucoup de donn√©es
db.system.profile.find({
  "responseLength": {$gt: 16777216}  // > 16MB
}).sort({responseLength: -1}).forEach(doc => {
  printjson({
    ns: doc.ns,
    op: doc.op,
    responseLength: (doc.responseLength / 1024 / 1024).toFixed(2) + " MB",
    nreturned: doc.nreturned,
    millis: doc.millis
  })
})
```

---

### R√©solution Pas √† Pas

#### Solution 1 : Ajuster le Cache WiredTiger

```yaml
# /etc/mongod.conf
storage:
  wiredTiger:
    engineConfig:
      # Par d√©faut : 50% de (RAM - 1GB) ou 256MB
      # Recommandations :
      # - Serveur d√©di√© : 50-60% de la RAM
      # - Serveur partag√© : 30-40% de la RAM
      # - Laisser au moins 2-4GB pour l'OS
      cacheSizeGB: 4
```

**Calcul du cache optimal :**

```
RAM totale : 16GB
MongoDB d√©di√© : cacheSizeGB = (16 - 2) * 0.5 = 7GB

RAM totale : 16GB
Serveur partag√© : cacheSizeGB = (16 - 4) * 0.4 = 4.8GB
```

```bash
# Appliquer la configuration
sudo systemctl restart mongod

# V√©rifier
mongosh --eval "db.serverStatus().wiredTiger.cache['maximum bytes configured']"
```

#### Solution 2 : Optimiser les Documents Volumineux

**Pattern Extended Reference :**

```javascript
// ‚ùå PROBL√àME : Documents √©normes avec historique complet
{
  _id: ObjectId("..."),
  userId: 123,
  orders: [
    {orderId: 1, items: [...], total: 150, date: ISODate("...")},
    {orderId: 2, items: [...], total: 200, date: ISODate("...")},
    // ... 1000 orders
  ],
  reviews: [/* 500 reviews */],
  preferences: {/* data */}
}

// ‚úÖ SOLUTION : S√©parer en collections
// Collection users (petite)
{
  _id: 123,
  name: "John Doe",
  email: "john@example.com",
  preferences: {/* data */}
}

// Collection orders (s√©par√©e)
{
  _id: ObjectId("..."),
  userId: 123,
  items: [...],
  total: 150,
  date: ISODate("...")
}

// Index pour requ√™tes rapides
db.orders.createIndex({userId: 1, date: -1})
```

**Pattern Subset :**

```javascript
// Garder seulement un subset dans le document principal
{
  _id: 123,
  name: "John Doe",
  email: "john@example.com",
  recentOrders: [  // Seulement les 5 derniers
    {orderId: 998, total: 150, date: ISODate("...")},
    {orderId: 999, total: 200, date: ISODate("...")},
    {orderId: 1000, total: 180, date: ISODate("...")}
  ],
  totalOrders: 1000  // Compteur
}

// Historique complet dans collection s√©par√©e
```

#### Solution 3 : Impl√©menter la Pagination Correcte

```javascript
// ‚ùå PROBL√àME : Charger tous les r√©sultats
const allUsers = await db.users.find({status: "active"}).toArray()
// Peut charger des millions de documents en m√©moire !

// ‚úÖ SOLUTION : Pagination avec cursor
async function processAllUsers() {
  const cursor = db.users.find({status: "active"}).batchSize(100)

  while (await cursor.hasNext()) {
    const user = await cursor.next()
    // Traiter un utilisateur √† la fois
    await processUser(user)
  }
}

// ‚úÖ SOLUTION : Pagination par batch
async function processUsersBatch() {
  const batchSize = 1000
  let lastId = null

  while (true) {
    const query = lastId
      ? {status: "active", _id: {$gt: lastId}}
      : {status: "active"}

    const batch = await db.users
      .find(query)
      .sort({_id: 1})
      .limit(batchSize)
      .toArray()

    if (batch.length === 0) break

    // Traiter le batch
    await processBatch(batch)

    lastId = batch[batch.length - 1]._id
  }
}
```

#### Solution 4 : Nettoyer les Donn√©es Obsol√®tes

```javascript
// TTL Index pour suppression automatique
db.sessions.createIndex(
  {createdAt: 1},
  {expireAfterSeconds: 3600}  // 1 heure
)

// Archivage des anciennes donn√©es
// D√©placer vers collection archive
db.orders.aggregate([
  {$match: {
    orderDate: {$lt: new Date('2023-01-01')}
  }},
  {$out: "orders_archive"}
])

// Supprimer de la collection principale
db.orders.deleteMany({
  orderDate: {$lt: new Date('2023-01-01')}
})

// Compacter la collection
db.runCommand({compact: "orders"})
```

#### Solution 5 : Limiter la Taille des Connexions

```javascript
// Node.js - Limiter le pool
const client = new MongoClient(uri, {
  maxPoolSize: 50,           // Max connexions (d√©faut: 100)
  minPoolSize: 10,           // Min connexions
  maxIdleTimeMS: 30000,      // Fermer apr√®s 30s idle
  maxConnecting: 2           // Max connexions simultan√©es
})

// Monitoring du pool
client.on('connectionCreated', (event) => {
  console.log('Connections:', event.connectionId)
})

client.on('connectionClosed', (event) => {
  console.log('Connection closed:', event.connectionId)
})
```

---

## 4. Goulots d'√âtranglement I/O

### Sympt√¥mes

```
High disk I/O wait
Slow read/write operations
Disk queue depth > 10
iostat shows high %util
```

### Causes Possibles

- Disques lents (HDD vs SSD)
- RAID mal configur√©
- Trop d'√©critures simultan√©es
- Journal trop volumineux
- Snapshots fr√©quents
- Pas assez de RAM (cache insuffisant)

---

### Diagnostic Pas √† Pas

#### √âtape 1 : Analyser l'I/O Disque

```bash
# I/O par device
iostat -x 1 10

# Sortie importante :
# %util  : Utilisation du disque (> 80% = satur√©)
# await  : Temps d'attente moyen (> 10ms = probl√®me)
# r/s, w/s : Op√©rations lecture/√©criture par seconde
# rMB/s, wMB/s : D√©bit

# I/O par processus
iotop -p $(pgrep mongod)

# Latence des I/O
ioping /var/lib/mongodb
```

```javascript
// M√©triques I/O MongoDB
var wtStats = db.serverStatus().wiredTiger

printjson({
  "bytes read": wtStats.block_cache["bytes read into cache"],
  "bytes written": wtStats.block_cache["bytes written from cache"],
  "pages read": wtStats.data_handle["pages read into cache"],
  "pages written": wtStats.data_handle["pages written from cache"]
})
```

#### √âtape 2 : Identifier les Op√©rations I/O-Intensives

```javascript
// Op√©rations avec beaucoup de lectures
db.system.profile.find({
  "docsExamined": {$gt: 100000}
}).sort({ts: -1})

// Op√©rations d'√©criture volumineuses
db.system.profile.find({
  "op": {$in: ["insert", "update", "delete"]},
  "nreturned": {$gt: 1000}
})
```

#### √âtape 3 : Analyser le Journal

```bash
# Taille du journal
du -sh /var/lib/mongodb/journal/

# V√©rifier la configuration
mongosh --eval "db.serverStatus().dur"
```

---

### R√©solution Pas √† Pas

#### Solution 1 : Optimiser la Configuration Storage

```yaml
# /etc/mongod.conf
storage:
  dbPath: /var/lib/mongodb
  journal:
    enabled: true
    commitIntervalMs: 100    # D√©faut: 100ms (r√©duit l'I/O)

  wiredTiger:
    engineConfig:
      cacheSizeGB: 8
      journalCompressor: snappy  # Compression du journal
      directoryForIndexes: true   # S√©parer indexes et donn√©es

    collectionConfig:
      blockCompressor: snappy      # Compression des donn√©es

    indexConfig:
      prefixCompression: true      # Compression des index
```

#### Solution 2 : Utiliser des Disques Plus Rapides

**Migration vers SSD :**

```bash
# 1. Arr√™ter MongoDB proprement
mongosh --eval "db.adminCommand({shutdown: 1})"

# 2. Copier les donn√©es vers le nouveau disque
rsync -av /var/lib/mongodb/ /mnt/ssd/mongodb/

# 3. Mettre √† jour la configuration
# /etc/mongod.conf
storage:
  dbPath: /mnt/ssd/mongodb

# 4. Ajuster les permissions
chown -R mongodb:mongodb /mnt/ssd/mongodb

# 5. Red√©marrer
systemctl start mongod
```

**Configuration RAID :**

```bash
# RAID 10 recommand√© pour MongoDB
# - RAID 0 : Performance mais pas de redondance
# - RAID 1 : Redondance mais pas de performance
# - RAID 5/6 : MAUVAIS pour MongoDB (p√©nalit√© √©criture)
# - RAID 10 : OPTIMAL (performance + redondance)

# Exemple cr√©ation RAID 10 avec 4 disques
mdadm --create /dev/md0 --level=10 --raid-devices=4 /dev/sdb /dev/sdc /dev/sdd /dev/sde
```

#### Solution 3 : Optimiser les Patterns d'√âcriture

**Bulk Operations :**

```javascript
// ‚ùå LENT : Insertions individuelles
for (let i = 0; i < 10000; i++) {
  await db.logs.insertOne({
    timestamp: new Date(),
    message: `Log ${i}`
  })
}
// 10000 I/O writes !

// ‚úÖ RAPIDE : Bulk insert
const docs = []
for (let i = 0; i < 10000; i++) {
  docs.push({
    timestamp: new Date(),
    message: `Log ${i}`
  })
}
await db.logs.insertMany(docs, {ordered: false})
// 1 I/O write (ou quelques-uns avec gros volumes)
```

**Write Concern :**

```javascript
// Write concern moins strict = moins d'I/O
await db.logs.insertMany(docs, {
  writeConcern: {
    w: 1,           // Acknowledge du primary seulement
    j: false        // Pas de journal (ATTENTION : risque de perte)
  }
})

// Pour donn√©es critiques : write concern strict
await db.orders.insertOne(order, {
  writeConcern: {
    w: "majority",  // Majorit√© du replica set
    j: true,        // Avec journal
    wtimeout: 5000  // Timeout 5s
  }
})
```

#### Solution 4 : Partitionnement I/O

**S√©parer Journal et Donn√©es :**

```yaml
# /etc/mongod.conf
storage:
  dbPath: /var/lib/mongodb
  journal:
    enabled: true

  # WiredTiger peut s√©parer journal sur autre disque
  wiredTiger:
    engineConfig:
      # Journal sur disque rapide d√©di√©
      journalPath: /mnt/journal-ssd
```

**Volumes s√©par√©s :**

```bash
# Monter les disques
/dev/sda1 -> /var/lib/mongodb       # Donn√©es (RAID 10)
/dev/sdb1 -> /var/log/mongodb       # Logs (disque s√©par√©)
/dev/sdc1 -> /mnt/journal           # Journal (SSD)
```

#### Solution 5 : Monitorer et Alerter

```javascript
// Script de monitoring I/O
function checkIOPerformance() {
  const stats = db.serverStatus().wiredTiger.block_cache

  const readLatency = stats["bytes read into cache"] /
                      stats["reads"]

  if (readLatency > 10) {  // > 10ms moyen
    console.error(`HIGH I/O LATENCY: ${readLatency.toFixed(2)}ms`)
    // Envoyer alerte
  }
}

setInterval(checkIOPerformance, 60000)
```

---

## 5. Lock Contention

### Sympt√¥mes

```
Queries waiting for locks
High lock wait time
Write conflicts
Timeouts on writes
```

### Causes Possibles

- Transactions longues
- Index builds bloquants
- Op√©rations DDL (drop, rename)
- Write conflicts sur documents
- Lock escalation

---

### Diagnostic Pas √† Pas

#### √âtape 1 : Identifier les Locks

```javascript
// Voir les op√©rations en attente de locks
db.currentOp({
  "waitingForLock": true
})

// D√©tails des locks
db.currentOp().inprog.filter(op =>
  op.waitingForLock
).map(op => ({
  opid: op.opid,
  op: op.op,
  ns: op.ns,
  secs_running: op.secs_running,
  locks: op.locks
}))

// Statistiques de locks globales
db.serverStatus().locks
```

#### √âtape 2 : Analyser les Transactions

```javascript
// Transactions actives
db.currentOp({
  "active": true,
  "transaction": {$exists: true}
})

// Transactions qui durent longtemps
db.currentOp({
  "transaction": {$exists: true},
  "transaction.timeActiveMicros": {$gt: 5000000}  // > 5s
})
```

---

### R√©solution Pas √† Pas

#### Solution 1 : Optimiser les Transactions

```javascript
// ‚ùå MAUVAIS : Transaction trop longue
const session = client.startSession()
session.startTransaction()

try {
  // Beaucoup d'op√©rations
  for (let i = 0; i < 10000; i++) {
    await db.orders.updateOne({_id: i}, {$set: {status: "processed"}}, {session})
  }

  await session.commitTransaction()
} catch (error) {
  await session.abortTransaction()
}

// ‚úÖ BON : Transactions courtes et cibl√©es
const session = client.startSession()
session.startTransaction()

try {
  // Op√©rations limit√©es et rapides
  await db.accounts.updateOne(
    {_id: sourceId},
    {$inc: {balance: -amount}},
    {session}
  )

  await db.accounts.updateOne(
    {_id: targetId},
    {$inc: {balance: amount}},
    {session}
  )

  await session.commitTransaction()
} catch (error) {
  await session.abortTransaction()
}
```

#### Solution 2 : Index Builds Non-Bloquants

```javascript
// ‚ùå Bloquant (par d√©faut avant MongoDB 4.2)
db.users.createIndex({email: 1})

// ‚úÖ Non-bloquant (background)
db.users.createIndex(
  {email: 1},
  {background: true}
)

// ‚úÖ MongoDB 4.2+ : Hybrid index build (non-bloquant par d√©faut)
db.users.createIndex({email: 1})
// Ne bloque pas les lectures/√©critures
```

#### Solution 3 : R√©duire la Contention avec Sharding

```javascript
// Distribuer les √©critures sur plusieurs shards
sh.shardCollection("mydb.orders", {userId: "hashed"})

// Les √©critures vont sur diff√©rents shards
// R√©duit la contention sur un seul serveur
```

---

## 6. Probl√®mes de Cache

### Sympt√¥mes

```
Cache hit rate < 90%
Frequent page evictions
Slow queries despite indexes
High I/O despite good cache size
```

### Diagnostic

```javascript
// Cache statistics
var cache = db.serverStatus().wiredTiger.cache

var hitRate = (cache["pages read into cache"] - cache["pages requested from the cache"]) /
              cache["pages read into cache"]

print("Cache hit rate: " + (hitRate * 100).toFixed(2) + "%")

// √âvictions
print("Pages evicted:", cache["pages evicted by application threads"])
```

### R√©solution

**Augmenter le cache ou optimiser le working set :**

```yaml
storage:
  wiredTiger:
    engineConfig:
      cacheSizeGB: 12  # Augmenter si possible
```

---

## 7. Probl√®mes d'Agr√©gation

### Diagnostic

```javascript
// Agr√©gations lentes
db.system.profile.find({
  "command.aggregate": {$exists: true},
  "millis": {$gt: 1000}
})
```

### R√©solution

**Optimiser le pipeline :**

```javascript
// ‚ùå LENT : $lookup puis $match
db.orders.aggregate([
  {$lookup: {
    from: "customers",
    localField: "customerId",
    foreignField: "_id",
    as: "customer"
  }},
  {$match: {"customer.country": "France"}}
])

// ‚úÖ RAPIDE : $match avant $lookup
db.orders.aggregate([
  {$match: {country: "France"}},  // Filtrer d'abord
  {$lookup: {
    from: "customers",
    localField: "customerId",
    foreignField: "_id",
    as: "customer"
  }}
])
```

---

## 8. Monitoring et M√©triques

### Dashboard de Performance Essentiel

```javascript
// Script de monitoring complet
function performanceReport() {
  const stats = db.serverStatus()

  return {
    // Connexions
    connections: {
      current: stats.connections.current,
      available: stats.connections.available,
      usage: `${(stats.connections.current / (stats.connections.current + stats.connections.available) * 100).toFixed(1)}%`
    },

    // Op√©rations
    ops: {
      insert: stats.opcounters.insert,
      query: stats.opcounters.query,
      update: stats.opcounters.update,
      delete: stats.opcounters.delete
    },

    // M√©moire
    memory: {
      resident: `${stats.mem.resident} MB`,
      virtual: `${stats.mem.virtual} MB`
    },

    // Cache
    cache: {
      size: `${(stats.wiredTiger.cache["bytes currently in the cache"] / 1024 / 1024).toFixed(0)} MB`,
      maxConfig: `${(stats.wiredTiger.cache["maximum bytes configured"] / 1024 / 1024).toFixed(0)} MB`,
      usage: `${(stats.wiredTiger.cache["bytes currently in the cache"] / stats.wiredTiger.cache["maximum bytes configured"] * 100).toFixed(1)}%`
    },

    // Performance
    performance: {
      activeReads: stats.globalLock.activeClients.readers,
      activeWrites: stats.globalLock.activeClients.writers,
      queuedReads: stats.globalLock.currentQueue.readers,
      queuedWrites: stats.globalLock.currentQueue.writers
    }
  }
}

print(JSON.stringify(performanceReport(), null, 2))
```

### Alertes Recommand√©es

```javascript
// Seuils d'alerte
const THRESHOLDS = {
  connectionUsage: 80,      // %
  cacheUsage: 90,           // %
  queueDepth: 10,           // op√©rations
  slowQuery: 1000,          // ms
  lockWaitTime: 5000        // ms
}

function checkAlerts() {
  const report = performanceReport()
  const alerts = []

  if (parseFloat(report.connections.usage) > THRESHOLDS.connectionUsage) {
    alerts.push(`HIGH CONNECTION USAGE: ${report.connections.usage}`)
  }

  if (parseFloat(report.cache.usage) > THRESHOLDS.cacheUsage) {
    alerts.push(`HIGH CACHE USAGE: ${report.cache.usage}`)
  }

  if (report.performance.queuedReads + report.performance.queuedWrites > THRESHOLDS.queueDepth) {
    alerts.push(`HIGH QUEUE DEPTH: ${report.performance.queuedReads + report.performance.queuedWrites}`)
  }

  return alerts
}
```

---

## Checklist Globale de Performance

### Diagnostic Rapide (5 minutes)

```bash
# 1. Op√©rations lentes actuelles
mongosh --eval "db.currentOp({secs_running: {\$gt: 5}})"

# 2. Top 10 requ√™tes lentes (profiler)
mongosh --eval "db.system.profile.find().sort({millis: -1}).limit(10)"

# 3. Utilisation ressources
top -p $(pgrep mongod)
iostat -x 1 3

# 4. M√©triques MongoDB
mongosh --eval "db.serverStatus().opcounters"
mongosh --eval "db.serverStatus().connections"

# 5. Cache hit rate
mongosh --eval "var c = db.serverStatus().wiredTiger.cache; print('Hit rate: ' + ((1 - c['pages read into cache'] / c['pages requested from the cache']) * 100).toFixed(2) + '%')"
```

### Optimisation Progressive

```
Phase 1: Quick Wins (1 jour)
‚ñ° Cr√©er les index manquants √©vidents
‚ñ° Ajouter projections aux requ√™tes
‚ñ° Limiter les r√©sultats non pagin√©s
‚ñ° Activer le profiler

Phase 2: Optimisation Moyenne (1 semaine)
‚ñ° Revoir la mod√©lisation des donn√©es
‚ñ° Optimiser les agr√©gations
‚ñ° Impl√©menter le caching applicatif
‚ñ° Ajuster les param√®tres WiredTiger

Phase 3: Architecture (1 mois)
‚ñ° √âvaluer le sharding
‚ñ° Impl√©menter le read splitting
‚ñ° Optimiser l'infrastructure (SSD, RAM)
‚ñ° Mettre en place monitoring avanc√©
```

---

## Conclusion

Les probl√®mes de performance MongoDB n√©cessitent une approche syst√©matique :

1. **Mesurer** avec pr√©cision (profiler, explain, metrics)
2. **Identifier** les goulots (CPU, m√©moire, I/O, requ√™tes)
3. **Optimiser** de mani√®re cibl√©e (index, queries, config)
4. **Valider** l'am√©lioration (avant/apr√®s)
5. **Monitorer** en continu

**Points cl√©s :**
- ‚úÖ Index appropri√©s sur tous les champs de requ√™te/tri
- ‚úÖ Projections pour limiter les donn√©es transf√©r√©es
- ‚úÖ Pagination correcte (pas de skip)
- ‚úÖ Cache WiredTiger bien dimensionn√©
- ‚úÖ Monitoring proactif avec alertes

---


‚è≠Ô∏è [Probl√®mes de r√©plication](/22-depannage-resolution-problemes/03-problemes-replication.md)
