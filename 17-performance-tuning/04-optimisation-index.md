üîù Retour au [Sommaire](/SOMMAIRE.md)

# 17.4 Optimisation des Index

## Introduction

Les index sont l'outil le plus puissant pour am√©liorer les performances de lecture dans MongoDB, mais ils repr√©sentent √©galement un compromis complexe : chaque index am√©liore certaines requ√™tes tout en p√©nalisant les √©critures et en consommant des ressources pr√©cieuses. L'art de l'optimisation des index r√©side dans l'identification du jeu d'index minimal qui maximise les performances globales du syst√®me.

Cette section explore les m√©thodologies expertes pour concevoir, analyser, maintenir et optimiser les index en environnement de production, o√π chaque d√©cision a un impact mesurable sur les performances et les co√ªts op√©rationnels.

## Principes Fondamentaux de l'Indexation

### Co√ªt R√©el des Index

Chaque index a un co√ªt qui doit √™tre quantifi√© et justifi√©.

**Co√ªts directs** :

```javascript
// Analyse du co√ªt d'un index
const indexStats = db.collection.aggregate([
  { $indexStats: {} }
]).toArray();

indexStats.forEach(index => {
  const cost = {
    // Stockage disque
    diskUsage: index.size,  // Bytes

    // RAM (si index resident)
    ramUsage: index.size,  // Id√©alement tout l'index en RAM

    // Co√ªt √©criture (estimation)
    // Chaque insert/update touche tous les index
    writePenalty: "~10-15% par index",

    // Co√ªt maintenance
    fragmentationRisk: index.accesses.ops < 100 ? "HIGH" : "LOW"
  };

  print(`Index ${index.name}:`);
  printjson(cost);
});
```

**Formule de co√ªt total** :
```
IndexCost = StorageCost + WritePenalty + MaintenanceCost + OpportunityCost

O√π :
- StorageCost = Size √ó StoragePrice
- WritePenalty = WriteOps/sec √ó IndexCount √ó 0.12ms
- MaintenanceCost = RebuildFrequency √ó RebuildDuration √ó DowntimeCost
- OpportunityCost = RAMUsed √ó RAMPrice (RAM non disponible pour le cache)
```

**R√®gle de d√©cision** :
```javascript
// Un index est justifi√© si :
ReadImprovement √ó ReadFrequency > IndexCost

// Exemple :
// Sans index : 500ms √ó 100 queries/s = 50,000ms/s de latence
// Avec index : 5ms √ó 100 queries/s = 500ms/s de latence
// Gain : 49,500ms/s
//
// Co√ªt index :
// - Write penalty : 1000 writes/s √ó 0.12ms = 120ms/s
// - Storage : 500MB √ó $0.10/GB/month = $0.05/month (n√©gligeable)
//
// ROI : 49,500 / 120 = 412√ó ‚Üí Index largement justifi√©
```

### Index Selectivity

La s√©lectivit√© d'un index est cruciale pour son efficacit√©.

**D√©finition** :
```javascript
selectivity = uniqueValues / totalDocuments

// Interpr√©tation :
// 1.0 (100%) : Parfaite (ex: _id, email unique)
// 0.5 (50%)  : Bonne (ex: userId dans une collection de commandes)
// 0.1 (10%)  : Moyenne (ex: status avec 10 valeurs possibles)
// 0.01 (1%)  : Faible (ex: boolean field)
// 0.001 (<1%): Tr√®s faible (ex: isDeleted o√π 99.9% sont false)
```

**Calcul de s√©lectivit√©** :
```javascript
function calculateSelectivity(collection, field) {
  const total = db[collection].countDocuments();
  const distinct = db[collection].distinct(field).length;

  const selectivity = distinct / total;

  return {
    field: field,
    totalDocs: total,
    distinctValues: distinct,
    selectivity: selectivity,
    recommendation: getRecommendation(selectivity)
  };
}

function getRecommendation(selectivity) {
  if (selectivity > 0.5) return "Excellent candidate for index";
  if (selectivity > 0.1) return "Good candidate for index";
  if (selectivity > 0.01) return "Consider compound index or partial index";
  return "Poor selectivity - consider alternatives";
}

// Usage
const result = calculateSelectivity("orders", "status");
printjson(result);
```

**Impact sur les performances** :
```javascript
// Index sur champ √† faible s√©lectivit√©
db.users.find({ isPremium: true })  // isPremium: 1% true, 99% false

// Sans index : COLLSCAN
// - Examine : 1,000,000 documents
// - Returns : 10,000 documents (1%)
// - Time : ~2000ms

// Avec index sur isPremium
// - Examine : 10,000 index entries
// - Returns : 10,000 documents
// - Time : ~50ms
// Am√©lioration : 40√ó (justifie l'index malgr√© faible s√©lectivit√©)

// Mais...
db.users.find({ isPremium: false })  // 99% des documents
// Avec index : Moins efficace qu'un COLLSCAN
// Query planner peut choisir COLLSCAN automatiquement
```

### Working Set et Index Residency

**Principe cardinal** :
> Tous les index fr√©quemment utilis√©s doivent tenir en RAM pour des performances optimales.

**Calcul du working set d'index** :
```javascript
// 1. Taille totale des index
const stats = db.collection.stats();
const totalIndexSize = stats.totalIndexSize;

// 2. RAM disponible pour les index
const serverStatus = db.serverStatus();
const cacheSize = serverStatus.wiredTiger.cache["maximum bytes configured"];
const cacheCurrent = serverStatus.wiredTiger.cache["bytes currently in the cache"];

// 3. Ratio d'index residency
const indexResidency = cacheCurrent / totalIndexSize;

print(`Index Residency: ${(indexResidency * 100).toFixed(2)}%`);

if (indexResidency < 0.9) {
  print("WARNING: Indexes not fully resident in RAM");
  print("Consider:");
  print("- Increasing cache size");
  print("- Removing unused indexes");
  print("- Using partial indexes to reduce size");
}
```

**Impact du cache miss** :
```
Index fully in RAM : ~0.1ms per lookup
Index on SSD      : ~1-5ms per lookup
Index on HDD      : ~10-50ms per lookup

Multiplier pour requ√™te : 10-500√ó
```

## Strat√©gies d'Optimisation des Index Compos√©s

### La R√®gle ESR (Equality, Sort, Range)

Pour les index compos√©s, l'ordre des champs est critique.

**Principe ESR** :
```
1. Equality : Champs avec conditions d'√©galit√© (=, $in)
2. Sort : Champs de tri
3. Range : Champs avec range queries (>, <, $gte, $lte)
```

**Exemple illustratif** :
```javascript
// Requ√™te type
db.orders.find({
  status: "completed",      // Equality
  customerId: { $in: [...] }, // Equality ($in)
  total: { $gte: 100 }      // Range
}).sort({
  orderDate: -1              // Sort
})

// Analyse des diff√©rents ordres d'index :

// ‚ùå BAD : Range avant Sort
db.orders.createIndex({ total: 1, orderDate: -1, status: 1, customerId: 1 })
// - Range scan sur total : Examine beaucoup de documents
// - Sort doit s'appliquer apr√®s ‚Üí In-memory sort ou partial index usage
// - Equality filters appliqu√©s apr√®s ‚Üí Post-filtering inefficace

// ‚ö†Ô∏è MEDIOCRE : Sort avant Equality
db.orders.createIndex({ orderDate: -1, status: 1, customerId: 1, total: 1 })
// - Scan tout l'index tri√© par date
// - Filter sur status ensuite ‚Üí Examine beaucoup de documents

// ‚úÖ OPTIMAL : ESR order
db.orders.createIndex({
  status: 1,        // E: Equality first
  customerId: 1,    // E: Equality (even with $in)
  orderDate: -1,    // S: Sort
  total: 1          // R: Range last
})
// - Index scan directement aux documents status="completed"
// - Filtre customerId dans ce subset
// - D√©j√† tri√© par orderDate (pas de sort stage)
// - Range filter sur total appliqu√© last
```

**Validation avec explain()** :
```javascript
const explain = db.orders.find({
  status: "completed",
  customerId: { $in: [id1, id2, id3] },
  total: { $gte: 100 }
}).sort({ orderDate: -1 }).explain("executionStats");

// M√©triques √† v√©rifier :
const metrics = {
  // Pas de SORT stage
  hasInMemorySort: explain.executionStats.executionStages.stage === "SORT",

  // Index bounds utilis√©s correctement
  indexBounds: explain.executionStats.executionStages.inputStage.indexBounds,

  // Ratio efficiency
  examined: explain.executionStats.totalKeysExamined,
  returned: explain.executionStats.nReturned,
  efficiency: returned / examined  // Doit √™tre > 0.1
};

printjson(metrics);
```

### Cas Particuliers et Exceptions ESR

#### Exception 1 : Faible Cardinalit√© Equality

```javascript
// Requ√™te
db.products.find({
  isActive: true,      // Equality mais faible cardinalit√© (50/50)
  category: "Electronics", // Equality haute cardinalit√©
  price: { $gte: 100, $lte: 500 }  // Range
}).sort({ rating: -1 })

// ESR strict sugg√®rerait : { isActive: 1, category: 1, rating: -1, price: 1 }
// Mais isActive a faible s√©lectivit√©

// MEILLEUR : Commencer par haute s√©lectivit√©
db.products.createIndex({
  category: 1,     // Haute s√©lectivit√© first
  isActive: 1,     // Faible s√©lectivit√© after
  rating: -1,      // Sort
  price: 1         // Range
})
```

**R√®gle affin√©e** :
```
1. High-selectivity Equality
2. Low-selectivity Equality
3. Sort
4. Range
```

#### Exception 2 : Sort tr√®s s√©lectif

```javascript
// Requ√™te : Top 10 des derni√®res commandes d'un user
db.orders.find({
  userId: ObjectId("...")  // Equality
}).sort({
  orderDate: -1            // Sort
}).limit(10)               // Early termination possible

// ESR sugg√®re : { userId: 1, orderDate: -1 }
// C'est correct !

// Mais si on ajoute un range :
db.orders.find({
  userId: ObjectId("..."),
  total: { $gte: 100 }     // Range
}).sort({
  orderDate: -1
}).limit(10)

// ESR sugg√®re : { userId: 1, orderDate: -1, total: 1 }
// Le range est APR√àS le sort pour permettre early termination
```

**Principe** :
Si LIMIT est pr√©sent avec SORT, privil√©gier le sort t√¥t pour permettre l'early termination.

### Index Prefix Utilization

Un index compos√© peut servir pour les requ√™tes utilisant ses pr√©fixes.

```javascript
// Index compos√©
db.collection.createIndex({ a: 1, b: 1, c: 1, d: 1 })

// Pr√©fixes utilisables :
// { a: 1 }
// { a: 1, b: 1 }
// { a: 1, b: 1, c: 1 }
// { a: 1, b: 1, c: 1, d: 1 }

// Requ√™tes support√©es :
db.collection.find({ a: 1 })                    // ‚úÖ Prefix { a: 1 }
db.collection.find({ a: 1, b: 2 })              // ‚úÖ Prefix { a: 1, b: 1 }
db.collection.find({ a: 1, b: 2, c: 3 })        // ‚úÖ Prefix { a: 1, b: 1, c: 1 }
db.collection.find({ a: 1, c: 3 })              // ‚ö†Ô∏è Partial use { a: 1 } only
db.collection.find({ b: 2 })                    // ‚ùå No prefix match
db.collection.find({ a: 1, b: 2, d: 4 })        // ‚ö†Ô∏è Prefix { a: 1, b: 1 } only

// Sort support√©s :
db.collection.find({ a: 1 }).sort({ b: 1 })           // ‚úÖ
db.collection.find({ a: 1 }).sort({ b: 1, c: 1 })    // ‚úÖ
db.collection.find({ a: 1, b: 2 }).sort({ c: 1 })    // ‚úÖ
db.collection.find({ a: 1 }).sort({ c: 1 })          // ‚ùå Gap in prefix
```

**Strat√©gie de consolidation** :

```javascript
// Avant : Index redondants
db.collection.createIndex({ userId: 1 })
db.collection.createIndex({ userId: 1, status: 1 })
db.collection.createIndex({ userId: 1, status: 1, createdAt: -1 })

// Apr√®s : Un seul index optimal
db.collection.createIndex({ userId: 1, status: 1, createdAt: -1 })

// Couvre toutes les requ√™tes :
// - { userId } ‚Üí Prefix
// - { userId, status } ‚Üí Prefix
// - { userId, status, createdAt } ‚Üí Full

// √âconomies :
// - Storage : -66% (3 index ‚Üí 1 index)
// - Write penalty : -66% (3 updates ‚Üí 1 update)
// - Maintenance : -66% (3 rebuilds ‚Üí 1 rebuild)
```

### Covered Queries : Index Couvrant

Une covered query est satisfaite enti√®rement par l'index sans acc√®s au document.

**Conditions pour une covered query** :
1. Tous les champs du `find()` sont dans l'index
2. Tous les champs de la `projection` sont dans l'index
3. Aucun champ dans le query est un array (index multikey incompatible)
4. `_id` doit √™tre explicitement exclu si pas dans l'index

**Exemple optimal** :
```javascript
// Index
db.users.createIndex({
  email: 1,
  status: 1,
  lastLogin: -1,
  _id: 1  // Include _id explicitement pour covering
})

// Covered query
db.users.find(
  {
    email: "user@example.com",
    status: "active"
  },
  {
    email: 1,
    status: 1,
    lastLogin: 1,
    _id: 0  // IMPORTANT : Exclure _id si pas utilis√©
  }
)

// explain() montre :
// - stage: "IXSCAN" (pas de FETCH)
// - totalDocsExamined: 0 (aucun document acc√©d√©)
// - Latency : ~0.5ms vs ~5ms avec FETCH
```

**Gains de performance** :
```
Non-covered query :
1. Index scan : 0.5ms
2. FETCH documents : 4.5ms
Total : 5ms

Covered query :
1. Index scan : 0.5ms
Total : 0.5ms

Am√©lioration : 10√ó pour queries simples
```

**Strat√©gie de conception** :
```javascript
// Analyser les requ√™tes fr√©quentes pour identifier opportunit√©s
db.system.profile.aggregate([
  {
    $match: {
      "command.find": { $exists: true },
      millis: { $gt: 10 }  // Requ√™tes > 10ms
    }
  },
  {
    $project: {
      collection: 1,
      filter: "$command.filter",
      projection: "$command.projection",
      docsExamined: 1
    }
  },
  {
    $match: {
      docsExamined: { $gt: 0 }  // Potential covering candidates
    }
  }
])

// Pour chaque query fr√©quente, √©valuer si un covering index est possible
```

## Index Partiels et Sparse : Optimisation de la Taille

### Partial Index : Indexer un Sous-Ensemble

Les partial indexes r√©duisent drastiquement la taille en indexant uniquement les documents pertinents.

**Cas d'usage classique** : Status flags

```javascript
// Sc√©nario : 95% des orders sont "completed", 5% sont "pending" ou "processing"
// Queries fr√©quentes : Rechercher orders actives (non-completed)

// Mauvais : Index complet
db.orders.createIndex({ status: 1 })
// - Index 100% des documents
// - Taille : Large
// - 95% de l'index rarement utilis√©

// Optimal : Partial index
db.orders.createIndex(
  { status: 1, createdAt: -1 },
  {
    partialFilterExpression: {
      status: { $ne: "completed" }
    },
    name: "idx_active_orders"
  }
)

// - Index seulement 5% des documents
// - Taille : 95% plus petit
// - Queries sur orders actives : Tr√®s rapide
// - RAM savings : Significatif
```

**Attention : Utilisation limit√©e**
```javascript
// ‚úÖ Query utilise le partial index
db.orders.find({
  status: "pending",      // Correspond au filter
  createdAt: { $gte: date }
})

// ‚úÖ Query utilise le partial index
db.orders.find({
  status: { $in: ["pending", "processing"] },  // Subset du filter
  createdAt: { $gte: date }
})

// ‚ùå Query N'utilise PAS le partial index
db.orders.find({
  status: "completed"     // Exclut par le filter
})

// ‚ùå Query N'utilise PAS le partial index
db.orders.find({
  createdAt: { $gte: date }  // Pas de condition sur status
})
```

**Strat√©gies avanc√©es** :

**1. Date-based partial index** :
```javascript
// Indexer seulement les donn√©es r√©centes (hot data)
db.logs.createIndex(
  { level: 1, timestamp: -1, message: "text" },
  {
    partialFilterExpression: {
      timestamp: {
        $gte: new Date(Date.now() - 30 * 24 * 60 * 60 * 1000)  // 30 jours
      }
    },
    name: "idx_recent_logs"
  }
)

// Combin√© avec TTL pour cleanup automatique
db.logs.createIndex(
  { timestamp: 1 },
  { expireAfterSeconds: 90 * 24 * 60 * 60 }  // 90 jours
)
```

**2. Multi-condition partial index** :
```javascript
// Indexer seulement les documents premium actifs
db.users.createIndex(
  { email: 1, lastActivity: -1 },
  {
    partialFilterExpression: {
      $and: [
        { isPremium: true },
        { isActive: true },
        { lastActivity: { $gte: new Date("2024-01-01") } }
      ]
    },
    name: "idx_premium_active_users"
  }
)

// Taille : ~5% de la collection vs 100%
// Performance : Identique pour queries matching le filter
// RAM savings : 95%
```

### Sparse Index : Ignorer les Null

Les sparse indexes excluent les documents o√π le champ index√© est absent ou null.

```javascript
// Cas : Champ optionnel utilis√© rarement
// Ex: 5% des users ont un referralCode

// Sparse index
db.users.createIndex(
  { referralCode: 1 },
  { sparse: true }
)

// Effet :
// - Index seulement les 5% avec referralCode
// - Taille : 95% plus petit
// - Queries sur referralCode : Rapides

// ‚ö†Ô∏è ATTENTION : Comportement subtil
db.users.find({ referralCode: { $exists: false } })
// N'utilisera PAS le sparse index (logique : ces docs ne sont pas index√©s)

db.users.find({ referralCode: "ABC123" })
// Utilisera le sparse index (ces docs sont index√©s)
```

**Diff√©rence Sparse vs Partial** :

| Crit√®re | Sparse | Partial |
|---------|--------|---------|
| Condition | Automatique (null/absent) | Explicite (expression) |
| Flexibilit√© | Limit√©e | Compl√®te |
| Cas d'usage | Champs optionnels | Filtrages complexes |
| Unique + Sparse | Permet multiple null | N/A |

**Combinaison Sparse + Unique** :
```javascript
// Use case : Email optionnel mais unique si pr√©sent
db.profiles.createIndex(
  { email: 1 },
  {
    unique: true,
    sparse: true
  }
)

// Comportement :
// - Multiple documents peuvent avoir email: null ou absent
// - Mais chaque email non-null doit √™tre unique
// - Index tr√®s petit si peu de users ont un email
```

## Audit et Maintenance des Index

### Identification des Index Inutilis√©s

```javascript
// Collecter les statistiques d'utilisation
const indexStats = db.collection.aggregate([
  { $indexStats: {} }
]).toArray();

// Analyser l'utilisation
const analysis = indexStats.map(index => {
  const daysSinceLastUse = index.accesses.since
    ? (Date.now() - index.accesses.since.getTime()) / (1000 * 60 * 60 * 24)
    : Infinity;

  return {
    name: index.name,
    accesses: index.accesses.ops,
    lastUsed: index.accesses.since,
    daysSinceLastUse: daysSinceLastUse,
    size: index.size || 0,
    recommendation: getIndexRecommendation(index.accesses.ops, daysSinceLastUse)
  };
}).sort((a, b) => a.accesses - b.accesses);

function getIndexRecommendation(accesses, daysSinceLastUse) {
  if (accesses === 0 && daysSinceLastUse > 30) {
    return "DROP - Never used in 30 days";
  }
  if (accesses < 10 && daysSinceLastUse > 7) {
    return "CONSIDER DROP - Rarely used";
  }
  if (accesses < 100) {
    return "MONITOR - Low usage";
  }
  return "KEEP - Actively used";
}

printjson(analysis);

// Automatisation : Script de cleanup
const indexesToDrop = analysis.filter(
  idx => idx.recommendation === "DROP - Never used in 30 days"
);

indexesToDrop.forEach(idx => {
  if (idx.name !== "_id_") {  // Never drop _id index
    print(`Dropping unused index: ${idx.name}`);
    // db.collection.dropIndex(idx.name);  // Uncomment to execute
  }
});
```

### Index Consolidation Strategy

```javascript
// Analyser les queries pour identifier les overlaps
db.system.profile.aggregate([
  {
    $match: {
      "command.find": { $exists: true },
      ns: "mydb.orders"
    }
  },
  {
    $group: {
      _id: {
        filter: "$command.filter",
        sort: "$command.sort"
      },
      count: { $sum: 1 },
      avgMs: { $avg: "$millis" }
    }
  },
  { $sort: { count: -1 } },
  { $limit: 20 }
])

// Exemple de r√©sultat :
// 1. { userId: X } + sort { createdAt: -1 } : 10k/day
// 2. { userId: X, status: Y } : 5k/day
// 3. { userId: X, status: Y } + sort { createdAt: -1 } : 3k/day

// Index actuels (sous-optimaux) :
// - { userId: 1 }
// - { userId: 1, createdAt: -1 }
// - { userId: 1, status: 1 }
// - { status: 1, createdAt: -1 }

// Index consolid√© optimal :
// { userId: 1, status: 1, createdAt: -1 }
// Couvre queries 1, 2, 3 via prefix utilization

// Migration :
// 1. Cr√©er le nouvel index
db.orders.createIndex({ userId: 1, status: 1, createdAt: -1 })

// 2. Monitorer les performances (quelques jours)

// 3. Drop les anciens index si performances OK
// db.orders.dropIndex({ userId: 1, createdAt: -1 })
// db.orders.dropIndex({ userId: 1, status: 1 })
```

### Fragmentation et Rebuild

Les index peuvent se fragmenter avec le temps, impactant les performances.

**D√©tection de fragmentation** :
```javascript
const stats = db.collection.stats();

// M√©triques de fragmentation
const fragmentation = {
  collection: stats.ns,

  // Taille logique vs physique
  dataSize: stats.size,
  storageSize: stats.storageSize,
  dataFragmentation: ((stats.storageSize - stats.size) / stats.size * 100).toFixed(2) + '%',

  // Index size
  totalIndexSize: stats.totalIndexSize,
  indexSizes: stats.indexSizes,

  // Indicateur de fragmentation
  // Si storageSize >> size, fragmentation possible
  needsCompaction: (stats.storageSize / stats.size) > 1.5
};

printjson(fragmentation);

if (fragmentation.needsCompaction) {
  print("Consider running compact or reindexing");
}
```

**Strat√©gies de d√©fragmentation** :

**1. Compact (collection enti√®re)** :
```javascript
// ‚ö†Ô∏è LOCKS la collection, √† faire en maintenance window
db.runCommand({ compact: "collection" })

// Ou avec options
db.runCommand({
  compact: "collection",
  force: true,
  // Note : Peut prendre plusieurs heures sur grandes collections
})
```

**2. Reindex (tous les index)** :
```javascript
// ‚ö†Ô∏è LOCKS la collection pendant le rebuild
db.collection.reIndex()

// Alternative : Rebuild index par index
db.collection.dropIndex("index_name")
db.collection.createIndex({ field: 1 }, { name: "index_name" })
```

**3. Rolling index rebuild (replica set)** :

Strat√©gie sans downtime pour replica sets :

```javascript
// Processus sur chaque secondary puis primary :
// 1. Connexion au secondary
mongo --host secondary1:27017

// 2. Stop la r√©plication
rs.secondaryOk()
db.adminCommand({ fsync: 1, lock: true })

// 3. Rebuild indexes
db.collection.reIndex()

// 4. Resume r√©plication
db.adminCommand({ fsyncUnlock: 1 })

// 5. Attendre rattrapage du replication lag
// 6. R√©p√©ter pour autres secondaries
// 7. Stepdown primary, r√©p√©ter sur l'ancien primary
```

**4. Background rebuild (MongoDB 4.2+)** :
```javascript
// Rebuild en background (pas de lock complet)
db.collection.createIndex(
  { field: 1 },
  {
    background: true,
    name: "new_index_name"
  }
)

// Note : Plus lent mais n'impacte pas les lectures/√©critures
// Une fois cr√©√©, drop l'ancien et rename
```

### Monitoring de Performance des Index

**M√©triques continues √† surveiller** :

```javascript
// Script de monitoring (√† ex√©cuter p√©riodiquement)
function monitorIndexPerformance(collection) {
  const stats = db[collection].stats();
  const indexStats = db[collection].aggregate([{ $indexStats: {} }]).toArray();

  const report = {
    timestamp: new Date(),
    collection: collection,

    // M√©triques globales
    totalDocs: stats.count,
    totalIndexSize: stats.totalIndexSize,
    avgDocSize: stats.avgObjSize,

    // Ratio index/data
    indexToDataRatio: (stats.totalIndexSize / stats.size).toFixed(2),

    // Par index
    indexes: indexStats.map(idx => ({
      name: idx.name,
      size: idx.size || 0,
      usageCount: idx.accesses.ops,
      usageRate: (idx.accesses.ops / ((Date.now() - idx.accesses.since) / 1000)).toFixed(2) + " ops/sec",

      // Health indicators
      isHealthy: idx.accesses.ops > 100,
      recommendation: idx.accesses.ops === 0 ? "Consider dropping" : "Keep"
    }))
  };

  // Alertes
  if (report.indexToDataRatio > 1) {
    report.alert = "Index size > data size - Review index strategy";
  }

  if (report.totalIndexSize > 10 * 1024 * 1024 * 1024) {  // 10GB
    report.alert = "Large index size - Ensure RAM capacity";
  }

  return report;
}

// Ex√©cution et logging
const report = monitorIndexPerformance("orders");
printjson(report);

// Export vers syst√®me de monitoring
// sendToPrometheus(report);
// sendToDatadog(report);
```

## Index Build Strategies en Production

### Background vs Foreground Builds

**Foreground build** (d√©faut avant MongoDB 4.2) :
```javascript
db.collection.createIndex({ field: 1 })

// Caract√©ristiques :
// - Prend un WRITE LOCK sur la collection
// - Tr√®s rapide (5-10√ó plus rapide que background)
// - Bloque toutes les √©critures et lectures
// - Adapt√© seulement en maintenance window
```

**Background build** :
```javascript
db.collection.createIndex(
  { field: 1 },
  { background: true }
)

// Caract√©ristiques :
// - Pas de lock exclusif
// - Plus lent (peut prendre heures sur grandes collections)
// - Yields p√©riodiquement pour permettre autres op√©rations
// - Adapt√© pour production sans downtime
```

**MongoDB 4.2+ : Hybrid build** :
```javascript
// Nouveau comportement par d√©faut (depuis 4.2)
db.collection.createIndex({ field: 1 })

// Caract√©ristiques :
// - Commence en "background-like"
// - Prend un SHORT exclusive lock √† la fin pour finaliser
// - Meilleur compromis : rapide + minimal downtime
// - Lock final : g√©n√©ralement < 1 seconde
```

### Rolling Index Build (Zero Downtime)

Pour les replica sets, strat√©gie de build sans impact :

```javascript
// √âTAPE 1 : Build sur tous les secondaries
// Connexion √† secondary1
const secondary1 = connect("secondary1:27017/admin");
secondary1.auth("admin", "password");

// Build index en background
secondary1.getSiblingDB("mydb").collection.createIndex(
  { field: 1 },
  { background: true }
)

// Attendre completion
while (secondary1.getSiblingDB("mydb").currentOp({
  "command.createIndexes": "collection"
}).inprog.length > 0) {
  sleep(5000);
  print("Index build in progress...");
}

// R√©p√©ter pour secondary2, secondary3, etc.

// √âTAPE 2 : Stepdown du primary
rs.stepDown(120)  // 120 seconds

// √âTAPE 3 : Build sur l'ancien primary (maintenant secondary)
// Une fois nouveau primary √©lu, build sur l'ancien primary

// √âTAPE 4 : Validation
// Tous les membres ont maintenant l'index
rs.status().members.forEach(member => {
  const conn = connect(member.name + "/mydb");
  const indexes = conn.collection.getIndexes();
  print(`${member.name}: ${indexes.length} indexes`);
});
```

### Index Build sur Cluster Shard√©

Sur un cluster shard√©, l'index doit √™tre cr√©√© sur tous les shards.

```javascript
// Connexion au mongos
const mongos = connect("mongos:27017/admin");

// Cr√©er l'index (propag√© automatiquement √† tous les shards)
mongos.getSiblingDB("mydb").collection.createIndex(
  { field: 1 },
  { background: true }
)

// Monitoring de la progression sur chaque shard
sh.status().shards.forEach(shard => {
  const shardConn = connect(shard.host + "/mydb");

  const inprogOps = shardConn.currentOp({
    "command.createIndexes": "collection"
  }).inprog;

  if (inprogOps.length > 0) {
    print(`Shard ${shard._id}: Index build in progress`);
    printjson(inprogOps[0]);
  } else {
    print(`Shard ${shard._id}: Index build complete or not started`);
  }
});

// Note : La commande peut retourner avant que tous les shards
// aient fini le build. Toujours v√©rifier l'√©tat.
```

**Strat√©gie optimale pour sharded clusters** :

```javascript
// 1. Build sur un shard √† la fois pour contr√¥ler la charge
// D√©sactiver le balancer temporairement
sh.stopBalancer()

// 2. Build shard par shard
sh.status().shards.forEach(shard => {
  print(`Building index on shard: ${shard._id}`);

  const shardConn = connect(shard.host + "/mydb");
  shardConn.collection.createIndex(
    { field: 1 },
    { background: true }
  );

  // Attendre completion
  while (shardConn.currentOp({
    "command.createIndexes": "collection"
  }).inprog.length > 0) {
    sleep(10000);
  }

  print(`Shard ${shard._id} complete`);
});

// 3. R√©activer le balancer
sh.startBalancer()
```

## Optimisations Avanc√©es

### Index Intersection vs Compound Index

MongoDB peut utiliser plusieurs index via intersection (depuis 2.6).

```javascript
// Sc√©nario :
db.products.find({
  category: "Electronics",
  brand: "Samsung"
})

// Option A : Deux index simples
db.products.createIndex({ category: 1 })
db.products.createIndex({ brand: 1 })

// Query planner peut utiliser intersection :
// 1. Scan category index ‚Üí Set A (ex: 10k docs)
// 2. Scan brand index ‚Üí Set B (ex: 5k docs)
// 3. Intersection A ‚à© B ‚Üí Result (ex: 500 docs)

// explain() montre :
"stage": "AND_SORTED"  // ou "AND_HASH"
"inputStages": [
  { "stage": "IXSCAN", "indexName": "category_1" },
  { "stage": "IXSCAN", "indexName": "brand_1" }
]

// Option B : Compound index
db.products.createIndex({ category: 1, brand: 1 })

// Query planner utilise compound index :
// 1. Direct scan sur { category: X, brand: Y } ‚Üí Result (500 docs)

// explain() montre :
"stage": "IXSCAN"
"indexName": "category_1_brand_1"
```

**Performance comparison** :

| M√©trique | Index Intersection | Compound Index |
|----------|-------------------|----------------|
| Index scans | 2 | 1 |
| Index entries examined | 15,000 (10k + 5k) | 500 |
| Latency | ~10ms | ~2ms |
| Memory | Higher (merge sets) | Lower |
| **Recommendation** | Avoid | **Preferred** |

**Quand l'intersection est acceptable** :
- Queries tr√®s rares et sp√©cifiques
- Contraintes sur nombre d'index (limite atteinte)
- Chaque index simple utilis√© fr√©quemment seul

### Wildcard Index : Flexible mais Co√ªteux

Les wildcard indexes (MongoDB 4.2+) indexent tous les champs ou sous-champs.

```javascript
// Index tous les champs
db.collection.createIndex({ "$**": 1 })

// Index tous les sous-champs d'un objet
db.collection.createIndex({ "attributes.$**": 1 })

// Cas d'usage : Sch√©mas tr√®s dynamiques
// Ex: Attributs produits variables
{
  _id: ObjectId("..."),
  name: "Product",
  attributes: {
    color: "blue",
    size: "large",
    weight: "1kg",
    // ... dizaines d'attributs variables
  }
}

// Queries support√©es :
db.collection.find({ "attributes.color": "blue" })
db.collection.find({ "attributes.size": "large" })
// Sans cr√©er un index pour chaque attribut possible
```

**Trade-offs** :

**Avantages** :
- Flexibilit√© maximale
- Pas besoin de pr√©voir les queries
- Un seul index pour multiples champs

**Inconv√©nients** :
- Taille d'index tr√®s large (tous les champs)
- Performance inf√©rieure aux index sp√©cifiques
- Co√ªt √©criture √©lev√© (update de n'importe quel champ)
- Ne supporte pas les compound queries efficacement

**Recommandation** :
```javascript
// ‚ùå √Ä √©viter en production g√©n√©rale
db.collection.createIndex({ "$**": 1 })

// ‚úÖ Acceptable pour cas sp√©cifiques
db.collection.createIndex(
  { "attributes.$**": 1 },
  {
    wildcardProjection: {
      "attributes.internalField": 0  // Exclure certains champs
    }
  }
)

// ‚úÖ Meilleur : Index sp√©cifiques bas√©s sur query patterns
db.collection.createIndex({ "attributes.color": 1 })
db.collection.createIndex({ "attributes.size": 1 })
```

### Index Hashed pour Sharding

Les hashed indexes sont utilis√©s principalement pour les shard keys.

```javascript
// Cr√©ation
db.collection.createIndex({ _id: "hashed" })

// Utilisation comme shard key
sh.shardCollection("mydb.collection", { _id: "hashed" })

// Caract√©ristiques :
// - Distribue uniform√©ment les donn√©es (pas de hotspots)
// - Pas de range queries possible sur la shard key
// - Scatter-gather pour toutes les queries sans shard key
```

**Performance considerations** :

```javascript
// Point queries : Efficaces
db.collection.find({ _id: ObjectId("...") })
// ‚Üí Targeted query (1 shard)

// Range queries : Inefficaces
db.collection.find({
  _id: {
    $gte: ObjectId("..."),
    $lte: ObjectId("...")
  }
})
// ‚Üí Scatter-gather (tous les shards)

// Queries sans _id : Inefficaces
db.collection.find({ status: "active" })
// ‚Üí Scatter-gather (tous les shards)
```

**Recommandation** :
- Utiliser hashed shard key pour write scaling uniforme
- Toujours inclure la shard key dans les queries critiques
- Consid√©rer compound shard keys pour query targeting

### Text Index : Full-Text Search

```javascript
// Cr√©ation
db.articles.createIndex({
  title: "text",
  content: "text"
})

// Avec poids
db.articles.createIndex(
  {
    title: "text",
    content: "text",
    tags: "text"
  },
  {
    weights: {
      title: 10,
      content: 5,
      tags: 1
    },
    name: "articles_text_index"
  }
)
```

**Limitations** :
- Un seul text index par collection
- Ne supporte pas les stemming avanc√©s (langues complexes)
- Performance limit√©e sur grandes collections (> 10M docs)
- Pas de phrase search exacte avanc√©e

**Alternative pour production** :
```javascript
// Pour search avanc√© : Utiliser Atlas Search (Lucene-based)
// Offre :
// - Fuzzy matching
// - Faceting
// - Autocomplete
// - Synonyms
// - Better relevance scoring
```

## Checklist d'Optimisation des Index

### Audit P√©riodique (Mensuel)

```
‚òê Analyser index usage avec $indexStats
  ‚îî‚îÄ> Identifier index avec 0 accesses
  ‚îî‚îÄ> Drop les index inutilis√©s depuis > 30 jours

‚òê Review top slow queries (profiler)
  ‚îî‚îÄ> Identifier missing indexes
  ‚îî‚îÄ> Cr√©er index appropri√©s

‚òê V√©rifier index size vs RAM
  ‚îî‚îÄ> Calculer working set
  ‚îî‚îÄ> Alerter si index > 80% RAM

‚òê Analyser fragmentation
  ‚îî‚îÄ> storageSize vs size ratio
  ‚îî‚îÄ> Planifier compact/reindex si > 1.5√ó

‚òê Review compound index order
  ‚îî‚îÄ> V√©rifier ESR rule respect√©e
  ‚îî‚îÄ> Identifier opportunit√©s de consolidation

‚òê Monitoring write performance
  ‚îî‚îÄ> V√©rifier impact des index sur write latency
  ‚îî‚îÄ> Consid√©rer drop si write-heavy + index peu utilis√©
```

### Nouveau Feature Deployment

```
‚òê Avant d√©ploiement :
  ‚îî‚îÄ> Analyser query patterns du nouveau feature
  ‚îî‚îÄ> Concevoir index appropri√©s
  ‚îî‚îÄ> Cr√©er index en background sur production

‚òê Jour du d√©ploiement :
  ‚îî‚îÄ> V√©rifier index status (complete sur tous les membres)
  ‚îî‚îÄ> Monitoring serr√© des query times
  ‚îî‚îÄ> Rollback plan si performances d√©grad√©es

‚òê Post-d√©ploiement (J+7) :
  ‚îî‚îÄ> Review index usage r√©el
  ‚îî‚îÄ> Ajuster si n√©cessaire
  ‚îî‚îÄ> Documenter d√©cisions
```

### Scale-up Decision

```
‚òê Si query latency augmente :
  ‚îî‚îÄ> V√©rifier index coverage
  ‚îî‚îÄ> Analyser explain() des slow queries
  ‚îî‚îÄ> Ajouter index manquants AVANT scale hardware

‚òê Si write latency augmente :
  ‚îî‚îÄ> Review nombre d'index
  ‚îî‚îÄ> Consid√©rer drop index peu utilis√©s
  ‚îî‚îÄ> √âvaluer partial/sparse pour r√©duire taille

‚òê Si RAM satur√© :
  ‚îî‚îÄ> Calculer index working set
  ‚îî‚îÄ> Prioriser index critiques en RAM
  ‚îî‚îÄ> Scale vertical si index essentiels > RAM
```

## Conclusion

L'optimisation des index MongoDB est un processus continu n√©cessitant :

1. **Analyse rigoureuse** des patterns d'acc√®s r√©els
2. **Application m√©thodique** des r√®gles ESR et prefix utilization
3. **√âquilibre** entre performance lecture et co√ªt √©criture
4. **Monitoring constant** de l'utilisation et de l'efficacit√©
5. **Maintenance proactive** (cleanup, rebuild, consolidation)

**Principes directeurs** :
- Cr√©er le minimum d'index n√©cessaires
- Chaque index doit avoir un ROI d√©montrable
- Pr√©f√©rer compound indexes aux index simples multiples
- Utiliser partial/sparse pour optimiser la taille
- Monitorer et adapter en continu

**M√©triques de succ√®s** :
- 95% des queries utilisent un index efficacement (ratio < 10)
- Pas d'index inutilis√© depuis > 30 jours
- Working set d'index < 80% RAM disponible
- Write latency impact < 15% par index

L'optimisation des index est la pierre angulaire de la performance MongoDB en production. Un jeu d'index bien con√ßu et maintenu est le meilleur investissement pour des performances durables et pr√©visibles.

---

**Points cl√©s √† retenir :**
- Ordre des champs dans compound indexes : ESR rule (Equality, Sort, Range)
- Covered queries √©liminent le document fetch (10√ó faster)
- Partial indexes r√©duisent drastiquement la taille (jusqu'√† 95%)
- Un seul index bien con√ßu vaut mieux que multiples index sous-optimaux
- Audit r√©gulier et cleanup des index inutilis√©s est essentiel
- Index build en production : rolling strategy pour zero downtime

‚è≠Ô∏è [Optimisation des agr√©gations](/17-performance-tuning/05-optimisation-agregations.md)
