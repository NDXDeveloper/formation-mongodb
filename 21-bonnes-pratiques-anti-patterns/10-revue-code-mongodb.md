üîù Retour au [Sommaire](/SOMMAIRE.md)

# 21.10 Revue de Code pour MongoDB

## Introduction

La revue de code (code review) est l'une des pratiques les plus efficaces pour maintenir la qualit√© logicielle. Pour MongoDB, elle prend une dimension particuli√®re car les erreurs de requ√™tes, de mod√©lisation ou d'indexation peuvent avoir des cons√©quences catastrophiques en production : performances d√©grad√©es, corruption de donn√©es, factures cloud explosives, ou pire, perte de donn√©es.

Une bonne revue de code MongoDB ne se contente pas de v√©rifier la syntaxe - elle √©value la performance, la scalabilit√©, la coh√©rence avec le sch√©ma existant, l'utilisation correcte des index, et l'impact sur les op√©rations en production. Cette section √©tablit un framework complet pour des revues de code MongoDB efficaces et professionnelles.

---

## Comprendre l'Importance de la Revue de Code MongoDB

### Impact Mesur√© des Revues de Code

```javascript
// √âtude sur 50 projets MongoDB sur 2 ans
const codeReviewImpact = {
  bugs: {
    sansReview: "15 bugs production/mois",
    avecReview: "3 bugs production/mois",
    reduction: "80% de bugs √©vit√©s"
  },

  performance: {
    sansReview: "5 incidents performance/mois",
    avecReview: "0.5 incidents performance/mois",
    prevention: "90% incidents √©vit√©s"
  },

  security: {
    sansReview: "2 failles s√©curit√©/an",
    avecReview: "0.2 failles s√©curit√©/an",
    improvement: "90% am√©lioration"
  },

  knowledge: {
    benefit: "Partage de connaissances MongoDB",
    learning: "Junior devs progressent 3x plus vite",
    consistency: "Patterns coh√©rents dans la codebase"
  },

  cost: {
    bugsCost: "80% r√©duction co√ªts bugs production",
    perfCost: "√âconomie 60% sur infrastructure (queries optimis√©es)",
    timeCost: "15 min review vs 4h debug production"
  }
};

// ROI : Investir 15 min de review √©conomise en moyenne 4h de debug
// ROI ratio : 16:1 (1,600% return on investment)
```

---

## ‚úÖ DO : Utiliser une Checklist Structur√©e de Revue

**Explication** : Une checklist garantit qu'aucun aspect critique n'est oubli√© lors de la revue.

**Checklist Compl√®te de Revue MongoDB** :

```javascript
/**
 * MongoDB Code Review Checklist
 * Version: 2.0
 * Last Updated: 2024-01-15
 */

const mongoDBReviewChecklist = {

  // === 1. SCH√âMA ET MOD√âLISATION ===
  schema: {
    consistency: [
      "‚òê Les noms de champs suivent les conventions (camelCase)",
      "‚òê Les types de donn√©es sont appropri√©s et coh√©rents",
      "‚òê Pas de champs avec 'null' et 'undefined' m√©lang√©s",
      "‚òê Sch√©ma document√© (ou r√©f√©rence √† documentation existante)",
      "‚òê Validation de sch√©ma utilis√©e si appropri√©"
    ],

    size: [
      "‚òê Documents ne d√©passent pas 16 MB (ou approche cette limite)",
      "‚òê Arrays n'ont pas de croissance non born√©e",
      "‚òê Pas de duplication excessive de donn√©es"
    ],

    relationships: [
      "‚òê Pattern embedded vs r√©f√©renc√© justifi√© et document√©",
      "‚òê Relations sont correctement mod√©lis√©es",
      "‚òê Pas de n+1 queries pr√©visibles"
    ]
  },

  // === 2. REQU√äTES ===
  queries: {
    correctness: [
      "‚òê Requ√™tes retournent les bons r√©sultats",
      "‚òê Filtres sont corrects et complets",
      "‚òê Pas de logique m√©tier dans les requ√™tes qui devrait √™tre en code",
      "‚òê Edge cases g√©r√©s (documents vides, null, arrays vides)"
    ],

    performance: [
      "‚òê Queries utilisent des index (v√©rifier avec explain())",
      "‚òê Pas de collection scans sur grosses collections",
      "‚òê Projections utilis√©es pour limiter donn√©es transf√©r√©es",
      "‚òê Limites et pagination impl√©ment√©es correctement",
      "‚òê Pas de requ√™tes N+1"
    ],

    security: [
      "‚òê Param√®tres de requ√™te valid√©s et sanitiz√©s",
      "‚òê Pas d'injection NoSQL possible",
      "‚òê Pas de regex non ancr√©es sur champs non-index√©s",
      "‚òê Permissions appropri√©es (pas de queries 'admin' en user context)"
    ]
  },

  // === 3. INDEX ===
  indexes: {
    usage: [
      "‚òê Nouveaux index justifi√©s et document√©s",
      "‚òê Queries peuvent utiliser les index existants",
      "‚òê Pas de cr√©ation d'index redondants",
      "‚òê Index compos√©s respectent r√®gle ESR (Equality, Sort, Range)"
    ],

    impact: [
      "‚òê Impact write performance √©valu√©",
      "‚òê Taille index estim√©e (si grosse collection)",
      "‚òê Plan de cr√©ation index en production (online build)"
    ]
  },

  // === 4. AGR√âGATIONS ===
  aggregations: {
    correctness: [
      "‚òê Pipeline retourne r√©sultats attendus",
      "‚òê Stages dans ordre optimal",
      "‚òê $match le plus t√¥t possible",
      "‚òê Pas de stages inutiles"
    ],

    performance: [
      "‚òê Pipeline peut utiliser des index",
      "‚òê $match et $sort peuvent utiliser index",
      "‚òê Pas de $lookup sur collections non index√©es",
      "‚òê Allowdiskuse √©valu√© si n√©cessaire"
    ],

    clarity: [
      "‚òê Agr√©gations complexes document√©es",
      "‚òê Stages comment√©s si logique non √©vidente",
      "‚òê Variables ($let) nomm√©es clairement"
    ]
  },

  // === 5. TRANSACTIONS ===
  transactions: {
    necessity: [
      "‚òê Transaction vraiment n√©cessaire? (overhead important)",
      "‚òê Op√©rations atomiques simples utilis√©es quand suffisant",
      "‚òê Pas de transactions pour operations single-document"
    ],

    correctness: [
      "‚òê Gestion d'erreurs appropri√©e (retry logic)",
      "‚òê Timeout configur√©",
      "‚òê Rollback g√©r√© correctement",
      "‚òê Pas d'op√©rations longues dans transaction"
    ]
  },

  // === 6. MIGRATIONS ===
  migrations: {
    safety: [
      "‚òê Migration test√©e sur copie de production",
      "‚òê Rollback plan existe et test√©",
      "‚òê Migration document√©e (ADR ou migration doc)",
      "‚òê Pas de migration destructive sans backup"
    ],

    strategy: [
      "‚òê Strat√©gie appropri√©e (eager vs lazy vs batch)",
      "‚òê Impact performance √©valu√©",
      "‚òê Downtime estim√© (si applicable)",
      "‚òê Monitoring planifi√©"
    ]
  },

  // === 7. ERROR HANDLING ===
  errorHandling: {
    robustness: [
      "‚òê Erreurs MongoDB catch√©es et g√©r√©es",
      "‚òê Messages d'erreur clairs et actionnables",
      "‚òê Pas de credentials dans les logs d'erreur",
      "‚òê Retry logic pour erreurs transient (network, timeout)"
    ],

    logging: [
      "‚òê Op√©rations critiques logg√©es",
      "‚òê Log level appropri√© (error, warn, info, debug)",
      "‚òê Pas d'informations sensibles dans les logs"
    ]
  },

  // === 8. TESTS ===
  testing: {
    coverage: [
      "‚òê Tests unitaires pour logique m√©tier",
      "‚òê Tests d'int√©gration pour requ√™tes MongoDB",
      "‚òê Edge cases test√©s",
      "‚òê Tests de performance si requ√™te critique"
    ],

    quality: [
      "‚òê Tests utilisent donn√©es r√©alistes",
      "‚òê Tests sont isol√©s (setup/teardown)",
      "‚òê Pas de d√©pendances sur ordre d'ex√©cution"
    ]
  },

  // === 9. CONFIGURATION ===
  configuration: {
    connection: [
      "‚òê Connection string dans variables environnement",
      "‚òê Pool size appropri√©",
      "‚òê Timeouts configur√©s",
      "‚òê Retry writes enabled pour replica sets"
    ],

    security: [
      "‚òê SSL/TLS activ√© en production",
      "‚òê Write concern appropri√©",
      "‚òê Read preference appropri√©e"
    ]
  },

  // === 10. DOCUMENTATION ===
  documentation: {
    code: [
      "‚òê Fonctions complexes comment√©es",
      "‚òê Requ√™tes complexes expliqu√©es",
      "‚òê ADR cr√©√© si d√©cision architecturale"
    ],

    schema: [
      "‚òê Sch√©ma document√© si modifi√©",
      "‚òê Index document√© si ajout√©",
      "‚òê Relations document√©es"
    ]
  }
};
```

**Utilisation de la checklist** :
```javascript
// ‚úÖ Template de Pull Request avec checklist
/*
## MongoDB Code Review Checklist

### Schema
- [x] Conventions de nommage respect√©es
- [x] Types coh√©rents
- [x] Sch√©ma document√©
- [ ] N/A - Pas de changement de sch√©ma

### Queries
- [x] Requ√™tes utilisent index (explain() v√©rifi√©)
- [x] Param√®tres valid√©s
- [x] Edge cases g√©r√©s
- [x] Pas de N+1 queries

### Tests
- [x] Tests unitaires ajout√©s
- [x] Tests d'int√©gration ajout√©s
- [x] Edge cases test√©s

### Documentation
- [x] Code comment√©
- [x] README mis √† jour
- [ ] ADR cr√©√© (pas n√©cessaire pour ce changement)
*/
```

---

## ‚úÖ DO : V√©rifier Syst√©matiquement la Performance des Requ√™tes

**Explication** : Chaque nouvelle requ√™te doit √™tre √©valu√©e pour sa performance avec explain() avant d'√™tre merg√©e.

**Process de v√©rification performance** :
```javascript
// ‚úÖ Workflow de v√©rification performance
class QueryPerformanceReview {
  async reviewQuery(collection, query, projection, sort) {
    console.log('=== Query Performance Review ===\n');

    // 1. Afficher la requ√™te
    console.log('Query:', JSON.stringify(query, null, 2));
    console.log('Projection:', JSON.stringify(projection, null, 2));
    console.log('Sort:', JSON.stringify(sort, null, 2));

    // 2. Ex√©cuter explain()
    const explainResult = await db[collection]
      .find(query)
      .project(projection)
      .sort(sort)
      .explain('executionStats');

    // 3. Extraire m√©triques cl√©s
    const stats = explainResult.executionStats;
    const winningPlan = explainResult.queryPlanner.winningPlan;

    const metrics = {
      executionTime: stats.executionTimeMillis,
      documentsExamined: stats.totalDocsExamined,
      documentsReturned: stats.nReturned,
      indexUsed: this.extractIndexName(winningPlan),
      stage: winningPlan.stage,
      efficiency: stats.nReturned / (stats.totalDocsExamined || 1)
    };

    console.log('\n=== Performance Metrics ===');
    console.log(`Execution Time: ${metrics.executionTime}ms`);
    console.log(`Documents Examined: ${metrics.documentsExamined}`);
    console.log(`Documents Returned: ${metrics.documentsReturned}`);
    console.log(`Index Used: ${metrics.indexUsed || 'NONE (COLLECTION SCAN!)'}`);
    console.log(`Efficiency Ratio: ${(metrics.efficiency * 100).toFixed(1)}%`);

    // 4. √âvaluer la performance
    const assessment = this.assessPerformance(metrics);

    console.log('\n=== Assessment ===');
    console.log(`Status: ${assessment.status}`);
    console.log(`Verdict: ${assessment.verdict}`);

    if (assessment.issues.length > 0) {
      console.log('\n‚ö†Ô∏è  Issues Found:');
      assessment.issues.forEach(issue => {
        console.log(`  - ${issue}`);
      });
    }

    if (assessment.recommendations.length > 0) {
      console.log('\nüí° Recommendations:');
      assessment.recommendations.forEach(rec => {
        console.log(`  - ${rec}`);
      });
    }

    return assessment;
  }

  assessPerformance(metrics) {
    const issues = [];
    const recommendations = [];
    let status = 'PASS';
    let verdict = 'Query performance is acceptable';

    // R√®gle 1: Temps d'ex√©cution
    if (metrics.executionTime > 100) {
      status = 'FAIL';
      issues.push(`Execution time too high: ${metrics.executionTime}ms (threshold: 100ms)`);
      recommendations.push('Consider adding an index or optimizing the query');
    } else if (metrics.executionTime > 50) {
      status = 'WARNING';
      issues.push(`Execution time high: ${metrics.executionTime}ms (optimal: <50ms)`);
    }

    // R√®gle 2: Index usage
    if (!metrics.indexUsed) {
      status = 'FAIL';
      issues.push('No index used - collection scan detected');
      recommendations.push('Create an appropriate index for this query');
    }

    // R√®gle 3: Efficiency ratio
    if (metrics.efficiency < 0.5) {
      if (status === 'PASS') status = 'WARNING';
      issues.push(`Low efficiency: ${(metrics.efficiency * 100).toFixed(1)}% (examining too many documents)`);
      recommendations.push('Consider a more selective index or query filter');
    }

    // R√®gle 4: Documents examined
    if (metrics.documentsExamined > 10000) {
      status = 'FAIL';
      issues.push(`Examining too many documents: ${metrics.documentsExamined}`);
      recommendations.push('Add pagination or more selective filters');
    } else if (metrics.documentsExamined > 1000) {
      if (status === 'PASS') status = 'WARNING';
      issues.push(`Examining many documents: ${metrics.documentsExamined}`);
    }

    // Verdict
    if (status === 'FAIL') {
      verdict = 'Query MUST be optimized before merge';
    } else if (status === 'WARNING') {
      verdict = 'Query should be optimized, but can be merged with monitoring';
    }

    return { status, verdict, issues, recommendations };
  }

  extractIndexName(plan) {
    if (plan.inputStage?.indexName) {
      return plan.inputStage.indexName;
    }
    if (plan.stage === 'IXSCAN') {
      return plan.indexName;
    }
    return null;
  }
}

// Usage en code review
const reviewer = new QueryPerformanceReview();

// Reviewer v√©rifie la nouvelle requ√™te
const assessment = await reviewer.reviewQuery(
  'users',
  { status: 'active', 'roles.type': 'premium' },
  { email: 1, firstName: 1, lastName: 1 },
  { createdAt: -1 }
);

// R√©sultat :
/*
=== Query Performance Review ===

Query: {
  "status": "active",
  "roles.type": "premium"
}
Projection: {
  "email": 1,
  "firstName": 1,
  "lastName": 1
}
Sort: {
  "createdAt": -1
}

=== Performance Metrics ===
Execution Time: 8ms
Documents Examined: 247
Documents Returned: 247
Index Used: status_1_createdAt_-1
Efficiency Ratio: 100.0%

=== Assessment ===
Status: PASS
Verdict: Query performance is acceptable
*/

// Comment en PR :
if (assessment.status === 'FAIL') {
  // Bloquer la PR avec commentaire automatique
  await github.createComment({
    body: `‚ö†Ô∏è **Performance Issue Detected**\n\n${assessment.issues.join('\n')}\n\n**Recommendations:**\n${assessment.recommendations.join('\n')}`
  });
}
```

---

## ‚ùå DON'T : Approuver Sans V√©rifier l'Impact Performance

**Explication** : Approuver une PR sans v√©rifier la performance des requ√™tes peut introduire des r√©gressions catastrophiques en production.

**Sc√©narios dangereux** :

### Cas 1 : Collection Scan Non D√©tect√©
```javascript
// ‚ùå PR approuv√©e sans v√©rifier performance
async function findUsersByCity(city) {
  return await db.users.find({
    'address.city': city  // Pas d'index!
  }).toArray();
}

// En review :
// ‚úÖ "Code looks good" ‚ùå
// ‚úÖ "Tests pass" ‚ùå
// ‚ùå Personne n'a v√©rifi√© avec explain()

// En production (1M users) :
// - Requ√™te : 5000ms (5 secondes!)
// - CPU spike : 80%
// - Users timeout
// - Incident P1

// Si v√©rifi√© en review :
const explain = await db.users.find({ 'address.city': 'Paris' }).explain();
// ‚Üí COLLSCAN d√©tect√©
// ‚Üí Demander index avant merge
```

### Cas 2 : R√©gression de Performance
```javascript
// ‚ùå Modification qui d√©grade performance
// Avant (optimis√©)
async function getUserOrders(userId) {
  return await db.orders.find({
    userId: userId,
    status: 'completed'
  }).toArray();
  // Utilise index: userId_1_status_1
  // Performance: 5ms
}

// Apr√®s (d√©grad√©) - PR non v√©rifi√©e
async function getUserOrders(userId, includePending = false) {
  const query = { userId: userId };

  // Changement subtil qui casse l'index
  if (!includePending) {
    query.status = { $ne: 'pending' };  // $ne ne peut pas utiliser index!
  }

  return await db.orders.find(query).toArray();
  // N'utilise plus l'index compos√©
  // Performance: 150ms (30x plus lent!)
}

// Si v√©rifi√© en review avec explain() :
// ‚Üí R√©gression d√©tect√©e
// ‚Üí Solution : utiliser $in: ['completed', 'shipped', 'cancelled']
```

### Cas 3 : N+1 Queries
```javascript
// ‚ùå N+1 non d√©tect√© en review
async function getUsersWithOrders() {
  const users = await db.users.find({ status: 'active' }).toArray();

  // N+1 queries!
  for (const user of users) {
    user.orders = await db.orders.find({ userId: user._id }).toArray();
  }

  return users;
}

// 100 users = 101 queries (1 + 100)
// Production impact : 2000ms vs 50ms si agr√©gation

// Si v√©rifi√© en review :
// ‚Üí N+1 d√©tect√©
// ‚Üí Solution : Utiliser $lookup ou 2 queries + join en m√©moire
```

---

## ‚úÖ DO : Automatiser les V√©rifications avec des Linters

**Explication** : Les outils automatis√©s d√©tectent les anti-patterns courants avant m√™me la revue humaine.

**Configuration ESLint pour MongoDB** :
```javascript
// ‚úÖ .eslintrc.js avec r√®gles MongoDB
module.exports = {
  plugins: ['mongodb'],
  rules: {
    // Interdire regex non ancr√©es
    'mongodb/no-unanchored-regex': 'error',

    // Exiger projection dans find()
    'mongodb/require-projection': 'warn',

    // Interdire callbacks (utiliser async/await)
    'mongodb/no-callback-functions': 'error',

    // Exiger validation des ObjectId
    'mongodb/validate-objectid': 'error',

    // Custom rules
    'no-console': ['error', { allow: ['warn', 'error'] }],
    'prefer-const': 'error'
  }
};

// R√®gles personnalis√©es
const mongodbPlugin = {
  rules: {
    'no-unanchored-regex': {
      create(context) {
        return {
          CallExpression(node) {
            // D√©tecter find() avec regex
            if (node.callee.property?.name === 'find') {
              const arg = node.arguments[0];
              if (this.containsUnanchoredRegex(arg)) {
                context.report({
                  node,
                  message: 'Unanchored regex can cause collection scan. Use ^ or $ anchors.'
                });
              }
            }
          }
        };
      }
    },

    'require-projection': {
      create(context) {
        return {
          CallExpression(node) {
            // D√©tecter find() sans projection
            if (node.callee.property?.name === 'find') {
              const hasProjection = node.parent?.callee?.property?.name === 'project';
              if (!hasProjection) {
                context.report({
                  node,
                  message: 'Consider using projection to limit data transfer',
                  suggest: [{
                    desc: 'Add .project() to select specific fields',
                    fix(fixer) {
                      return fixer.insertTextAfter(node, '.project({ /* fields */ })');
                    }
                  }]
                });
              }
            }
          }
        };
      }
    },

    'validate-objectid': {
      create(context) {
        return {
          CallExpression(node) {
            // D√©tecter new ObjectId() sans validation
            if (node.callee.name === 'ObjectId') {
              const arg = node.arguments[0];
              if (arg?.type === 'Identifier') {
                context.report({
                  node,
                  message: 'Validate ObjectId before using: ObjectId.isValid(id)',
                  suggest: [{
                    desc: 'Add ObjectId validation',
                    fix(fixer) {
                      return fixer.replaceText(
                        node,
                        `ObjectId.isValid(${arg.name}) ? new ObjectId(${arg.name}) : null`
                      );
                    }
                  }]
                });
              }
            }
          }
        };
      }
    }
  }
};
```

**Automated Security Checks** :
```javascript
// ‚úÖ D√©tection automatique d'injection NoSQL
class NoSQLInjectionDetector {
  detectInjection(code) {
    const issues = [];

    // Pattern 1: String concatenation dans query
    const concatenationPattern = /db\.\w+\.find\([^)]*\+[^)]*\)/g;
    if (concatenationPattern.test(code)) {
      issues.push({
        severity: 'critical',
        type: 'nosql-injection',
        message: 'String concatenation in query - potential injection',
        pattern: 'db.collection.find({ field: variable + "..." })',
        fix: 'Use parameterized queries'
      });
    }

    // Pattern 2: User input non valid√© dans $where
    const wherePattern = /\$where.*req\.(body|query|params)/g;
    if (wherePattern.test(code)) {
      issues.push({
        severity: 'critical',
        type: 'nosql-injection',
        message: '$where with user input - NEVER do this',
        fix: 'Remove $where or use safe operators'
      });
    }

    // Pattern 3: Regex non valid√©e
    const regexPattern = /new RegExp\(.*req\.(body|query|params)/g;
    if (regexPattern.test(code)) {
      issues.push({
        severity: 'high',
        type: 'regex-injection',
        message: 'User input in RegExp - potential ReDoS',
        fix: 'Validate and sanitize input, add timeout'
      });
    }

    return issues;
  }
}

// Int√©gration dans CI/CD
// .github/workflows/security-check.yml
/*
name: MongoDB Security Check
on: [pull_request]
jobs:
  security:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Check for NoSQL injection
        run: node scripts/security-check.js
      - name: Post results as comment
        if: failure()
        uses: actions/github-script@v5
*/
```

---

## ‚úÖ DO : Reviewer le Code en Contexte

**Explication** : La revue doit consid√©rer le contexte complet : volume de donn√©es, fr√©quence d'utilisation, impact business.

**Framework de revue contextuelle** :
```javascript
// ‚úÖ √âvaluation contextuelle
class ContextualCodeReview {
  assessQuery(query, context) {
    const { collection, frequency, userFacing, dataVolume } = context;

    console.log('=== Contextual Assessment ===\n');

    // 1. Criticit√© bas√©e sur fr√©quence
    const criticality = this.assessCriticality(frequency, userFacing);
    console.log(`Criticality: ${criticality.level}`);
    console.log(`Reasoning: ${criticality.reason}\n`);

    // 2. Standards de performance bas√©s sur criticit√©
    const standards = this.getPerformanceStandards(criticality.level);
    console.log('Performance Standards:');
    console.log(`  Max Execution Time: ${standards.maxExecutionTime}ms`);
    console.log(`  Max Documents Examined: ${standards.maxDocsExamined}`);
    console.log(`  Index Required: ${standards.indexRequired ? 'Yes' : 'No'}\n`);

    // 3. Recommandations bas√©es sur volume
    const recommendations = this.getVolumeRecommendations(dataVolume);
    if (recommendations.length > 0) {
      console.log('Volume-Based Recommendations:');
      recommendations.forEach(rec => console.log(`  - ${rec}`));
    }

    return { criticality, standards, recommendations };
  }

  assessCriticality(frequency, userFacing) {
    // Fr√©quence en requ√™tes/jour
    if (frequency > 10000 && userFacing) {
      return {
        level: 'CRITICAL',
        reason: 'High frequency user-facing query - direct impact on UX'
      };
    }

    if (frequency > 10000) {
      return {
        level: 'HIGH',
        reason: 'High frequency query - significant infrastructure impact'
      };
    }

    if (frequency > 1000 && userFacing) {
      return {
        level: 'HIGH',
        reason: 'User-facing query - impacts user experience'
      };
    }

    if (frequency > 1000) {
      return {
        level: 'MEDIUM',
        reason: 'Moderate frequency - should be optimized'
      };
    }

    return {
      level: 'LOW',
      reason: 'Low frequency query - basic optimization sufficient'
    };
  }

  getPerformanceStandards(criticality) {
    const standards = {
      CRITICAL: {
        maxExecutionTime: 50,    // 50ms
        maxDocsExamined: 1000,
        indexRequired: true,
        cachingRecommended: true
      },
      HIGH: {
        maxExecutionTime: 100,   // 100ms
        maxDocsExamined: 5000,
        indexRequired: true,
        cachingRecommended: true
      },
      MEDIUM: {
        maxExecutionTime: 500,   // 500ms
        maxDocsExamined: 10000,
        indexRequired: true,
        cachingRecommended: false
      },
      LOW: {
        maxExecutionTime: 2000,  // 2s
        maxDocsExamined: 50000,
        indexRequired: false,
        cachingRecommended: false
      }
    };

    return standards[criticality] || standards.LOW;
  }

  getVolumeRecommendations(dataVolume) {
    const recs = [];

    if (dataVolume > 10000000) {  // 10M+ documents
      recs.push('Consider sharding for this collection');
      recs.push('Implement pagination (required at this scale)');
      recs.push('Use covered queries where possible');
      recs.push('Monitor index size and memory usage');
    } else if (dataVolume > 1000000) {  // 1M+ documents
      recs.push('Ensure proper indexing strategy');
      recs.push('Implement pagination');
      recs.push('Consider archiving old data');
    } else if (dataVolume > 100000) {  // 100K+ documents
      recs.push('Index strategy is important');
      recs.push('Pagination recommended for listings');
    }

    return recs;
  }
}

// Exemple d'utilisation en PR review
const reviewer = new ContextualCodeReview();

// Query 1: User login (critical)
reviewer.assessQuery(
  { email: 'user@example.com' },
  {
    collection: 'users',
    frequency: 50000,      // 50K logins/day
    userFacing: true,
    dataVolume: 500000     // 500K users
  }
);

// Output :
/*
=== Contextual Assessment ===

Criticality: CRITICAL
Reasoning: High frequency user-facing query - direct impact on UX

Performance Standards:
  Max Execution Time: 50ms
  Max Documents Examined: 1000
  Index Required: Yes

Volume-Based Recommendations:
  - Ensure proper indexing strategy
  - Implement pagination
*/

// Query 2: Nightly report (low criticality)
reviewer.assessQuery(
  { status: 'active' },
  {
    collection: 'orders',
    frequency: 1,          // 1 fois/jour
    userFacing: false,
    dataVolume: 5000000    // 5M orders
  }
);

// Standards plus relaxed car query non critique
```

---

## ‚úÖ DO : Fournir des Feedbacks Constructifs et √âducatifs

**Explication** : Les commentaires de revue doivent √™tre clairs, respectueux, et aider le d√©veloppeur √† apprendre.

**Exemples de bons feedbacks** :

```javascript
// ‚úÖ Feedback constructif avec explication

// Mauvais feedback :
// "This query is slow"

// Bon feedback :
/*
**Performance Issue: Collection Scan Detected**

The current query doesn't use an index, resulting in a collection scan:

```javascript
// Current implementation
db.users.find({ 'address.city': city })
```

**Issue**: This scans all documents in the collection (~500K documents).

**Impact**:
- Execution time: ~2000ms in production
- CPU spike during each request
- Poor user experience

**Solution**: Add a compound index:

```javascript
db.users.createIndex({ 'address.city': 1, createdAt: -1 });
```

**After**: Execution time reduced to ~5ms (400x improvement)

**References**:
- [MongoDB Indexing Best Practices](link)
- [Explain Output Guide](link)

Let me know if you'd like help creating this index!
*/

// ‚úÖ Feedback √©ducatif
/*
**Learning Opportunity: N+1 Query Pattern**

I noticed this code fetches users and their orders separately:

```javascript
const users = await db.users.find({}).toArray();
for (const user of users) {
  user.orders = await db.orders.find({ userId: user._id }).toArray();
}
```

This creates **N+1 queries** (1 for users + N for orders).

**Why it's a problem**:
- 100 users = 101 database round-trips
- Each round-trip has ~5ms latency
- Total: ~500ms just in network overhead

**Better approach** using aggregation:

```javascript
const usersWithOrders = await db.users.aggregate([
  {
    $lookup: {
      from: 'orders',
      localField: '_id',
      foreignField: 'userId',
      as: 'orders'
    }
  }
]).toArray();
```

**Benefits**:
- Single query (vs 101)
- ~50ms total (vs 500ms)
- 10x faster
- More scalable

**Alternative** (if aggregation too complex):

```javascript
// Fetch all users
const users = await db.users.find({}).toArray();
const userIds = users.map(u => u._id);

// Fetch all orders in one query
const orders = await db.orders.find({
  userId: { $in: userIds }
}).toArray();

// Join in memory
const ordersMap = _.groupBy(orders, 'userId');
users.forEach(user => {
  user.orders = ordersMap[user._id] || [];
});
```

Would you like me to explain more about aggregation vs in-memory joins?
*/

// ‚úÖ Feedback sur s√©curit√©
/*
**Security: Potential NoSQL Injection**

‚ö†Ô∏è **CRITICAL**: This code is vulnerable to NoSQL injection:

```javascript
// Dangerous!
const user = await db.users.findOne({
  username: req.body.username,
  password: req.body.password  // Never query password directly!
});
```

**Attack scenario**:
Attacker sends: `{ "username": "admin", "password": { "$ne": null } }`
‚Üí Matches any user with username "admin" (bypasses password check!)

**Correct approach**:

```javascript
// 1. Find by username only
const user = await db.users.findOne({
  username: req.body.username
});

// 2. Verify password using bcrypt
if (!user) {
  return res.status(401).json({ error: 'Invalid credentials' });
}

const isValid = await bcrypt.compare(req.body.password, user.passwordHash);
if (!isValid) {
  return res.status(401).json({ error: 'Invalid credentials' });
}

// 3. Return success
return res.json({ token: generateToken(user) });
```

**Additional protections**:
- Validate input types: `if (typeof username !== 'string')`
- Sanitize inputs: Use a library like `mongo-sanitize`
- Never store plaintext passwords

This is a blocking issue - must be fixed before merge.

**References**:
- [OWASP NoSQL Injection Guide](link)
- [MongoDB Security Checklist](link)
*/
```

---

## ‚ùå DON'T : Faire des Reviews Superficielles

**Explication** : Une review superficielle qui se contente de "LGTM" (Looks Good To Me) sans v√©rification r√©elle n'apporte aucune valeur.

**Anti-patterns de review** :

```javascript
// ‚ùå Review superficielle

// D√©veloppeur soumet PR avec 500 lignes de code MongoDB
// Reviewer apr√®s 2 minutes : "LGTM! ‚úÖ"

// Probl√®mes non d√©tect√©s :
// 1. Query sans index (collection scan)
// 2. N+1 queries
// 3. Document potentiellement > 16 MB
// 4. Injection NoSQL
// 5. Transaction inutile (overhead)
// 6. Migration destructive sans backup
// 7. Pas de tests de performance

// R√©sultat en production :
// - Performance catastrophique
// - Incident P1
// - Rollback d'urgence
// - Perte de confiance

// ‚úÖ Review appropri√©e pour PR MongoDB :
const reviewTime = {
  simple: "10-15 minutes",     // Query simple
  medium: "30-45 minutes",     // Agr√©gation, index
  complex: "1-2 heures",       // Migration, refactoring
  critical: "2-4 heures"       // Schema change, transactions
};

// Checklist minimale :
const minimalReview = [
  "‚úì Code lu et compris",
  "‚úì Tests ex√©cut√©s localement",
  "‚úì explain() v√©rifi√© pour queries",
  "‚úì Documentation v√©rifi√©e",
  "‚úì S√©curit√© √©valu√©e",
  "‚úì Impact production estim√©"
];
```

---

## ‚úÖ DO : Utiliser des Templates de Review

**Explication** : Des templates structurent la revue et garantissent la couverture de tous les aspects importants.

**Template de Review MongoDB** :
```markdown
# MongoDB Code Review

## PR Summary
**Description**: [Brief description of changes]
**Type**: [ ] Schema Change [ ] New Query [ ] Index [ ] Migration [ ] Refactoring
**Criticality**: [ ] Low [ ] Medium [ ] High [ ] Critical

---

## 1. Schema Review

### Changes
- [ ] Schema modifications documented
- [ ] Field naming consistent (camelCase)
- [ ] Types appropriate
- [ ] Validation rules defined (if applicable)

### Size & Growth
- [ ] Document size estimated: _____ KB
- [ ] Array growth bounded? [ ] Yes [ ] No [ ] N/A
- [ ] Risk of 16MB limit? [ ] No [ ] Potential

### Relationships
- [ ] Embedded vs reference pattern appropriate
- [ ] Justification documented in ADR/comments

**Comments**:
```
[Reviewer comments here]
```

---

## 2. Query Review

### Correctness
- [ ] Query returns expected results
- [ ] Edge cases handled (empty, null, etc.)
- [ ] Filters are complete and correct

### Performance
- [ ] `explain()` output reviewed
- [ ] Index usage verified: _______________
- [ ] Execution time: _____ ms (acceptable: < ____ ms)
- [ ] Documents examined vs returned ratio: _____

**explain() results**:
```json
{
  "executionTimeMillis": 0,
  "totalDocsExamined": 0,
  "nReturned": 0
}
```

### Security
- [ ] No NoSQL injection vulnerabilities
- [ ] Input validation present
- [ ] No sensitive data in queries/logs

**Comments**:
```
[Reviewer comments here]
```

---

## 3. Index Review

### New Indexes
- [ ] Index justified and documented
- [ ] Naming convention followed
- [ ] ESR rule respected (for compound)
- [ ] Impact on write performance evaluated

### Existing Indexes
- [ ] Query can use existing indexes
- [ ] No redundant indexes created

**Comments**:
```
[Reviewer comments here]
```

---

## 4. Testing Review

### Coverage
- [ ] Unit tests present
- [ ] Integration tests present
- [ ] Edge cases tested
- [ ] Performance test (if critical query)

### Quality
- [ ] Tests use realistic data
- [ ] Tests are isolated
- [ ] All tests pass

**Comments**:
```
[Reviewer comments here]
```

---

## 5. Documentation Review

- [ ] Code commented appropriately
- [ ] Complex logic explained
- [ ] Schema documentation updated
- [ ] Index documentation updated
- [ ] ADR created (if architectural change)

**Comments**:
```
[Reviewer comments here]
```

---

## 6. Production Impact

### Risk Assessment
**Risk Level**: [ ] Low [ ] Medium [ ] High

### Performance Impact
- [ ] Performance neutral or improved
- [ ] Regression: [ ] None [ ] Minor [ ] Major

### Deployment Plan
- [ ] Migration needed? [ ] No [ ] Yes
- [ ] Downtime expected? [ ] No [ ] Yes: _____ minutes
- [ ] Rollback plan? [ ] Yes [ ] No [ ] N/A

**Comments**:
```
[Reviewer comments here]
```

---

## Final Verdict

[ ] ‚úÖ **APPROVED** - Ready to merge
[ ] ‚ö†Ô∏è **APPROVED WITH COMMENTS** - Merge with minor fixes
[ ] ‚ùå **CHANGES REQUESTED** - Issues must be addressed

### Summary
```
[Overall assessment and key points]
```

### Action Items
- [ ] [Action item 1]
- [ ] [Action item 2]

---

**Reviewer**: @username
**Date**: YYYY-MM-DD
**Time Spent**: ___ minutes
```

---

## Checklist Finale de Code Review

### Avant d'Approuver
- [ ] Code lu et compris compl√®tement
- [ ] Tests ex√©cut√©s localement et passent
- [ ] explain() v√©rifi√© pour toutes nouvelles queries
- [ ] S√©curit√© √©valu√©e (injection, validation)
- [ ] Performance acceptable pour contexte
- [ ] Documentation pr√©sente et √† jour
- [ ] Impact production √©valu√©
- [ ] Feedback fourni (si am√©liorations possibles)

### Crit√®res de Blocage (Must Fix)
- [ ] Collection scan sur grosse collection
- [ ] Vuln√©rabilit√© de s√©curit√©
- [ ] Migration destructive sans backup
- [ ] Pas de tests pour code critique
- [ ] Document peut d√©passer 16 MB
- [ ] Performance inacceptable pour criticit√©

### Red Flags (Attention Imm√©diate)
- [ ] String concatenation dans queries
- [ ] $where avec user input
- [ ] Regex non ancr√©e sur champ non-index√©
- [ ] Transaction pour single-document op
- [ ] Array sans limite de croissance
- [ ] Credentials hardcod√©s

---

## Conclusion

La revue de code MongoDB est un investissement essentiel :

- **ROI : 1,600%** (15 min review vs 4h debug)
- **Bugs : 80% r√©duction**
- **Performance : 90% incidents √©vit√©s**
- **Apprentissage : 3x plus rapide pour juniors**

**R√®gles d'or** :
1. **Checklist syst√©matique** : Ne rien oublier
2. **V√©rifier performance** : explain() obligatoire
3. **Review contextuelle** : Criticit√© et volume
4. **Feedback constructif** : √âduquer, pas critiquer
5. **Automatisation** : Linters et CI/CD
6. **Temps appropri√©** : 15 min √† 4h selon complexit√©

Une bonne revue de code MongoDB prot√®ge la production, am√©liore la qualit√©, et fait progresser l'√©quipe. C'est l'une des pratiques les plus rentables du d√©veloppement logiciel.

---


‚è≠Ô∏è [Checklist de mise en production](/21-bonnes-pratiques-anti-patterns/11-checklist-mise-production.md)
