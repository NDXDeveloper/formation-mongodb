ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# D.1 - Configuration Replica Set (3 nÅ“uds)

## PrÃ©sentation

### Objectif
Configuration standard de haute disponibilitÃ© avec 3 membres MongoDB pour assurer la rÃ©silience et la continuitÃ© de service en cas de panne d'un nÅ“ud.

### Topologie

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Replica Set: rs-prod                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   PRIMARY    â”‚     â”‚  SECONDARY   â”‚     â”‚  SECONDARY   â”‚ â”‚
â”‚  â”‚              â”‚â”€â”€â”€â”€â–¶â”‚              â”‚â”€â”€â”€â”€â–¶â”‚              â”‚ â”‚
â”‚  â”‚ mongo-rs-01  â”‚     â”‚ mongo-rs-02  â”‚     â”‚ mongo-rs-03  â”‚ â”‚
â”‚  â”‚  27017       â”‚â—€â”€â”€â”€â”€â”‚  27017       â”‚â—€â”€â”€â”€â”€â”‚  27017       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                     â”‚                     â”‚       â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                    RÃ©plication bidirectionnelle             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### CaractÃ©ristiques

- **Haute disponibilitÃ©** : Failover automatique en cas de panne du Primary
- **Lecture distribuÃ©e** : PossibilitÃ© de lire depuis les Secondary
- **Ã‰lection automatique** : Nouveau Primary Ã©lu en < 10 secondes
- **CohÃ©rence des donnÃ©es** : RÃ©plication asynchrone avec oplog
- **TolÃ©rance aux pannes** : Survit Ã  la perte de 1 nÅ“ud

---

## PrÃ©requis matÃ©riels

### Configuration minimale (par nÅ“ud)

| Ressource | Minimum | RecommandÃ© |
|-----------|---------|------------|
| **CPU** | 2 cores | 4 cores |
| **RAM** | 8 GB | 16 GB |
| **Stockage** | 100 GB SSD | 500 GB NVMe SSD |
| **RÃ©seau** | 1 Gbps | 10 Gbps |
| **Latence rÃ©seau** | < 50ms | < 10ms |

### Configuration recommandÃ©e (production)

| Ressource | SpÃ©cification |
|-----------|---------------|
| **CPU** | 8 cores @ 3+ GHz |
| **RAM** | 32 GB |
| **Stockage OS** | 50 GB SSD |
| **Stockage donnÃ©es** | 1 TB NVMe SSD (RAID 10) |
| **RÃ©seau** | 10 Gbps avec redondance |

### SystÃ¨me d'exploitation

- **Ubuntu** : 22.04 LTS ou 24.04 LTS
- **Rocky Linux** : 9.x
- **Debian** : 12
- **MongoDB** : 6.0+, 7.0+ ou 8.0+

---

## Architecture rÃ©seau

### Plan d'adressage

| NÅ“ud | Hostname | IP PrivÃ©e | RÃ´le Initial | Port |
|------|----------|-----------|--------------|------|
| NÅ“ud 1 | mongo-rs-01 | 10.0.1.10 | PRIMARY | 27017 |
| NÅ“ud 2 | mongo-rs-02 | 10.0.1.11 | SECONDARY | 27017 |
| NÅ“ud 3 | mongo-rs-03 | 10.0.1.12 | SECONDARY | 27017 |

### RÃ¨gles firewall

```bash
# Autoriser MongoDB entre les nÅ“uds du Replica Set
iptables -A INPUT -p tcp --dport 27017 -s 10.0.1.10 -j ACCEPT
iptables -A INPUT -p tcp --dport 27017 -s 10.0.1.11 -j ACCEPT
iptables -A INPUT -p tcp --dport 27017 -s 10.0.1.12 -j ACCEPT

# Autoriser les applications
iptables -A INPUT -p tcp --dport 27017 -s 10.0.2.0/24 -j ACCEPT

# Bloquer tout le reste
iptables -A INPUT -p tcp --dport 27017 -j DROP
```

### RÃ©solution DNS

```bash
# /etc/hosts sur chaque nÅ“ud
10.0.1.10   mongo-rs-01
10.0.1.11   mongo-rs-02
10.0.1.12   mongo-rs-03
```

---

## Configuration systÃ¨me

### ParamÃ¨tres kernel Linux

```bash
# /etc/sysctl.conf - Ã€ appliquer sur tous les nÅ“uds
vm.swappiness = 1
vm.dirty_ratio = 15
vm.dirty_background_ratio = 5
net.core.somaxconn = 4096
net.ipv4.tcp_fin_timeout = 30
net.ipv4.tcp_keepalive_time = 300
net.ipv4.tcp_keepalive_probes = 5
net.ipv4.tcp_keepalive_intvl = 15
fs.file-max = 98000

# Appliquer
sudo sysctl -p
```

### Limites systÃ¨me

```bash
# /etc/security/limits.conf
mongod soft nofile 64000
mongod hard nofile 64000
mongod soft nproc 32000
mongod hard nproc 32000
mongod soft memlock unlimited
mongod hard memlock unlimited
```

### DÃ©sactivation de Transparent Huge Pages

```bash
# /etc/systemd/system/disable-thp.service
[Unit]
Description=Disable Transparent Huge Pages (THP)
DefaultDependencies=no
After=sysinit.target local-fs.target
Before=mongod.service

[Service]
Type=oneshot
ExecStart=/bin/sh -c 'echo never > /sys/kernel/mm/transparent_hugepage/enabled'
ExecStart=/bin/sh -c 'echo never > /sys/kernel/mm/transparent_hugepage/defrag'

[Install]
WantedBy=basic.target

# Activer le service
sudo systemctl daemon-reload
sudo systemctl enable disable-thp.service
sudo systemctl start disable-thp.service
```

---

## PrÃ©paration des volumes

### Structure des rÃ©pertoires

```bash
# CrÃ©er les rÃ©pertoires sur chaque nÅ“ud
sudo mkdir -p /data/mongodb
sudo mkdir -p /var/log/mongodb
sudo mkdir -p /var/run/mongodb

# DÃ©finir les propriÃ©taires
sudo chown -R mongod:mongod /data/mongodb
sudo chown -R mongod:mongod /var/log/mongodb
sudo chown -R mongod:mongod /var/run/mongodb

# Permissions
sudo chmod 755 /data/mongodb
sudo chmod 755 /var/log/mongodb
sudo chmod 755 /var/run/mongodb
```

### Formatage XFS (recommandÃ©)

```bash
# Formatter le volume de donnÃ©es en XFS
sudo mkfs.xfs -f /dev/sdb

# Monter avec les options optimisÃ©es
sudo mount -t xfs -o noatime,nobarrier /dev/sdb /data/mongodb

# /etc/fstab - Montage automatique
/dev/sdb  /data/mongodb  xfs  noatime,nobarrier  0 0
```

---

## Configuration MongoDB

### GÃ©nÃ©ration du Keyfile (sÃ©curitÃ©)

```bash
# GÃ©nÃ©rer sur le premier nÅ“ud
openssl rand -base64 756 > /etc/mongodb-keyfile
chmod 400 /etc/mongodb-keyfile
chown mongod:mongod /etc/mongodb-keyfile

# Copier sur les autres nÅ“uds (mÃªme contenu exact)
scp /etc/mongodb-keyfile root@mongo-rs-02:/etc/
scp /etc/mongodb-keyfile root@mongo-rs-03:/etc/

# Permissions sur tous les nÅ“uds
sudo chmod 400 /etc/mongodb-keyfile
sudo chown mongod:mongod /etc/mongodb-keyfile
```

### Fichier de configuration - NÅ“ud 1 (PRIMARY)

```yaml
# /etc/mongod.conf - mongo-rs-01

# Stockage
storage:
  dbPath: /data/mongodb
  journal:
    enabled: true
  wiredTiger:
    engineConfig:
      cacheSizeGB: 12  # 50% RAM - 1 GB pour serveur 16 GB
      journalCompressor: snappy
    collectionConfig:
      blockCompressor: snappy
    indexConfig:
      prefixCompression: true

# Journalisation
systemLog:
  destination: file
  path: /var/log/mongodb/mongod.log
  logAppend: true
  logRotate: reopen
  timeStampFormat: iso8601-utc
  verbosity: 0
  component:
    replication:
      verbosity: 1

# RÃ©seau
net:
  port: 27017
  bindIp: 0.0.0.0
  maxIncomingConnections: 65536
  compression:
    compressors: snappy,zstd,zlib

# Processus
processManagement:
  fork: true
  pidFilePath: /var/run/mongodb/mongod.pid
  timeZoneInfo: /usr/share/zoneinfo

# SÃ©curitÃ©
security:
  authorization: enabled
  keyFile: /etc/mongodb-keyfile

# RÃ©plication
replication:
  replSetName: rs-prod
  oplogSizeMB: 10240  # 10 GB

# ParamÃ¨tres opÃ©rationnels
operationProfiling:
  mode: slowOp
  slowOpThresholdMs: 100
```

### Fichier de configuration - NÅ“ud 2 (SECONDARY)

```yaml
# /etc/mongod.conf - mongo-rs-02
# MÃªme configuration que mongo-rs-01
# Seul le bindIp pourrait diffÃ©rer si nÃ©cessaire

storage:
  dbPath: /data/mongodb
  journal:
    enabled: true
  wiredTiger:
    engineConfig:
      cacheSizeGB: 12
      journalCompressor: snappy
    collectionConfig:
      blockCompressor: snappy
    indexConfig:
      prefixCompression: true

systemLog:
  destination: file
  path: /var/log/mongodb/mongod.log
  logAppend: true
  logRotate: reopen
  timeStampFormat: iso8601-utc
  verbosity: 0
  component:
    replication:
      verbosity: 1

net:
  port: 27017
  bindIp: 0.0.0.0
  maxIncomingConnections: 65536
  compression:
    compressors: snappy,zstd,zlib

processManagement:
  fork: true
  pidFilePath: /var/run/mongodb/mongod.pid
  timeZoneInfo: /usr/share/zoneinfo

security:
  authorization: enabled
  keyFile: /etc/mongodb-keyfile

replication:
  replSetName: rs-prod
  oplogSizeMB: 10240

operationProfiling:
  mode: slowOp
  slowOpThresholdMs: 100
```

### Fichier de configuration - NÅ“ud 3 (SECONDARY)

```yaml
# /etc/mongod.conf - mongo-rs-03
# Identique aux nÅ“uds 1 et 2

storage:
  dbPath: /data/mongodb
  journal:
    enabled: true
  wiredTiger:
    engineConfig:
      cacheSizeGB: 12
      journalCompressor: snappy
    collectionConfig:
      blockCompressor: snappy
    indexConfig:
      prefixCompression: true

systemLog:
  destination: file
  path: /var/log/mongodb/mongod.log
  logAppend: true
  logRotate: reopen
  timeStampFormat: iso8601-utc
  verbosity: 0
  component:
    replication:
      verbosity: 1

net:
  port: 27017
  bindIp: 0.0.0.0
  maxIncomingConnections: 65536
  compression:
    compressors: snappy,zstd,zlib

processManagement:
  fork: true
  pidFilePath: /var/run/mongodb/mongod.pid
  timeZoneInfo: /usr/share/zoneinfo

security:
  authorization: enabled
  keyFile: /etc/mongodb-keyfile

replication:
  replSetName: rs-prod
  oplogSizeMB: 10240

operationProfiling:
  mode: slowOp
  slowOpThresholdMs: 100
```

---

## DÃ©ploiement

### Ã‰tape 1 : DÃ©marrage des instances

```bash
# Sur chaque nÅ“ud (mongo-rs-01, mongo-rs-02, mongo-rs-03)
sudo systemctl start mongod
sudo systemctl enable mongod

# VÃ©rifier le dÃ©marrage
sudo systemctl status mongod
tail -f /var/log/mongodb/mongod.log
```

### Ã‰tape 2 : Initialisation du Replica Set

Se connecter au premier nÅ“ud **sans authentification** (la premiÃ¨re fois) :

```bash
# Se connecter Ã  mongo-rs-01
mongosh --host mongo-rs-01 --port 27017
```

Initialiser le Replica Set :

```javascript
// Configuration du Replica Set
rs.initiate({
  _id: "rs-prod",
  members: [
    { _id: 0, host: "mongo-rs-01:27017", priority: 2 },
    { _id: 1, host: "mongo-rs-02:27017", priority: 1 },
    { _id: 2, host: "mongo-rs-03:27017", priority: 1 }
  ]
})

// Attendre quelques secondes puis vÃ©rifier
rs.status()
```

### Ã‰tape 3 : CrÃ©ation de l'administrateur

```javascript
// Sur le PRIMARY (mongo-rs-01 normalement)
use admin

db.createUser({
  user: "admin",
  pwd: "VotreMotDePasseSecurise123!",  // CHANGER EN PRODUCTION
  roles: [
    { role: "root", db: "admin" }
  ]
})

// Tester la connexion
exit
mongosh --host mongo-rs-01 --port 27017 -u admin -p --authenticationDatabase admin
```

### Ã‰tape 4 : CrÃ©ation des utilisateurs applicatifs

```javascript
// Se connecter en tant qu'admin
use admin
db.auth("admin", "VotreMotDePasseSecurise123!")

// Utilisateur en lecture/Ã©criture pour l'application
use myapp

db.createUser({
  user: "myapp_rw",
  pwd: "AppPassword456!",  // CHANGER EN PRODUCTION
  roles: [
    { role: "readWrite", db: "myapp" }
  ]
})

// Utilisateur en lecture seule pour les analytics
db.createUser({
  user: "myapp_ro",
  pwd: "ReadOnlyPass789!",  // CHANGER EN PRODUCTION
  roles: [
    { role: "read", db: "myapp" }
  ]
})
```

---

## VÃ©rification du dÃ©ploiement

### VÃ©rifier le statut du Replica Set

```javascript
// Se connecter au PRIMARY
mongosh "mongodb://admin:PASSWORD@mongo-rs-01:27017/admin"

// Statut complet
rs.status()

// Vue simplifiÃ©e
rs.isMaster()

// Configuration active
rs.conf()
```

### RÃ©sultat attendu de rs.status()

```javascript
{
  set: 'rs-prod',
  members: [
    {
      _id: 0,
      name: 'mongo-rs-01:27017',
      stateStr: 'PRIMARY',
      health: 1,
      // ...
    },
    {
      _id: 1,
      name: 'mongo-rs-02:27017',
      stateStr: 'SECONDARY',
      health: 1,
      syncSourceHost: 'mongo-rs-01:27017'
      // ...
    },
    {
      _id: 2,
      name: 'mongo-rs-03:27017',
      stateStr: 'SECONDARY',
      health: 1,
      syncSourceHost: 'mongo-rs-01:27017'
      // ...
    }
  ],
  ok: 1
}
```

### Tests de lecture/Ã©criture

```javascript
// Sur le PRIMARY
use test

// Ã‰criture
db.testCollection.insertOne({ test: "Hello Replica Set", date: new Date() })

// Lecture sur PRIMARY
db.testCollection.find()

// Se connecter Ã  un SECONDARY
mongosh "mongodb://admin:PASSWORD@mongo-rs-02:27017/admin"

use test

// Activer les lectures sur SECONDARY
db.getMongo().setReadPref("secondary")

// VÃ©rifier la rÃ©plication
db.testCollection.find()
```

### VÃ©rifier l'oplog

```javascript
// Sur le PRIMARY
use local

// Taille de l'oplog
db.oplog.rs.stats()

// PremiÃ¨res et derniÃ¨res entrÃ©es
db.oplog.rs.find().sort({$natural: 1}).limit(1).pretty()
db.oplog.rs.find().sort({$natural: -1}).limit(1).pretty()

// Calcul de la fenÃªtre de rÃ©plication (en heures)
var firstOp = db.oplog.rs.find().sort({$natural: 1}).limit(1).next()
var lastOp = db.oplog.rs.find().sort({$natural: -1}).limit(1).next()
var replicationWindow = (lastOp.ts.getTime() - firstOp.ts.getTime()) / 3600
print("FenÃªtre de rÃ©plication : " + replicationWindow + " heures")
```

---

## Connexion depuis les applications

### Connection String standard

```javascript
// Connexion avec failover automatique
mongodb://myapp_rw:AppPassword456!@mongo-rs-01:27017,mongo-rs-02:27017,mongo-rs-03:27017/myapp?replicaSet=rs-prod&authSource=myapp

// Avec Read Preference
mongodb://myapp_ro:ReadOnlyPass789!@mongo-rs-01:27017,mongo-rs-02:27017,mongo-rs-03:27017/myapp?replicaSet=rs-prod&authSource=myapp&readPreference=secondary

// Avec Write Concern et Read Concern
mongodb://myapp_rw:AppPassword456!@mongo-rs-01:27017,mongo-rs-02:27017,mongo-rs-03:27017/myapp?replicaSet=rs-prod&authSource=myapp&w=majority&readConcernLevel=majority
```

### Exemple Node.js

```javascript
const { MongoClient } = require('mongodb');

const uri = "mongodb://myapp_rw:AppPassword456!@mongo-rs-01:27017,mongo-rs-02:27017,mongo-rs-03:27017/myapp?replicaSet=rs-prod&authSource=myapp";

const client = new MongoClient(uri, {
  maxPoolSize: 50,
  minPoolSize: 10,
  serverSelectionTimeoutMS: 5000,
  socketTimeoutMS: 45000,
});

async function run() {
  try {
    await client.connect();
    console.log("ConnectÃ© au Replica Set");

    const db = client.db("myapp");
    const result = await db.collection("test").findOne();
    console.log(result);
  } finally {
    await client.close();
  }
}

run().catch(console.dir);
```

### Exemple Python

```python
from pymongo import MongoClient, ReadPreference

# Connexion au Replica Set
client = MongoClient(
    "mongodb://myapp_rw:AppPassword456!@mongo-rs-01:27017,mongo-rs-02:27017,mongo-rs-03:27017/myapp?replicaSet=rs-prod&authSource=myapp",
    maxPoolSize=50,
    minPoolSize=10,
    serverSelectionTimeoutMS=5000
)

# Utiliser la base de donnÃ©es
db = client.myapp

# Ã‰criture sur PRIMARY
db.test.insert_one({"message": "Hello from Python"})

# Lecture depuis SECONDARY
client_read = MongoClient(
    "mongodb://myapp_ro:ReadOnlyPass789!@mongo-rs-01:27017,mongo-rs-02:27017,mongo-rs-03:27017/myapp?replicaSet=rs-prod&authSource=myapp",
    read_preference=ReadPreference.SECONDARY
)

db_read = client_read.myapp
doc = db_read.test.find_one()
print(doc)
```

---

## Maintenance

### RedÃ©marrage d'un membre SECONDARY

```bash
# 1. Se connecter au Replica Set
mongosh "mongodb://admin:PASSWORD@mongo-rs-01:27017/admin"

# 2. VÃ©rifier que le nÅ“ud est bien SECONDARY
rs.status()

# 3. Sur le serveur Ã  redÃ©marrer (mongo-rs-02 par exemple)
sudo systemctl restart mongod

# 4. VÃ©rifier le retour du nÅ“ud
rs.status()
```

### RedÃ©marrage du PRIMARY (avec failover)

```bash
# 1. Forcer une Ã©lection (stepDown du PRIMARY)
mongosh "mongodb://admin:PASSWORD@mongo-rs-01:27017/admin"

rs.stepDown(60)  // Le nÅ“ud devient SECONDARY pendant 60 secondes

# 2. Attendre qu'un nouveau PRIMARY soit Ã©lu
rs.status()

# 3. RedÃ©marrer l'ancien PRIMARY (maintenant SECONDARY)
sudo systemctl restart mongod

# 4. Le nÅ“ud peut redevenir PRIMARY automatiquement (selon priority)
```

### Rolling restart complet

```bash
# Script de rolling restart
#!/bin/bash

NODES=("mongo-rs-02" "mongo-rs-03" "mongo-rs-01")

for node in "${NODES[@]}"; do
  echo "RedÃ©marrage de $node..."

  if [ "$node" == "mongo-rs-01" ]; then
    # Forcer stepDown si c'est le PRIMARY
    mongosh "mongodb://admin:PASSWORD@$node:27017/admin" --eval "rs.stepDown(60)"
    sleep 10
  fi

  ssh $node "sudo systemctl restart mongod"

  echo "Attente de la synchronisation de $node..."
  sleep 30

  # VÃ©rifier que le nÅ“ud est de retour
  mongosh "mongodb://admin:PASSWORD@mongo-rs-01:27017/admin" --eval "rs.status()" | grep -A 5 $node

  echo "$node redÃ©marrÃ© avec succÃ¨s"
  echo "---"
done
```

### Ajout d'un nouveau membre (scale to 4 nodes)

```javascript
// Se connecter au PRIMARY
mongosh "mongodb://admin:PASSWORD@mongo-rs-01:27017/admin"

// Ajouter le 4e nÅ“ud
rs.add({
  host: "mongo-rs-04:27017",
  priority: 1,
  votes: 1
})

// VÃ©rifier
rs.status()
rs.conf()
```

### Retrait d'un membre

```javascript
// Se connecter au PRIMARY
mongosh "mongodb://admin:PASSWORD@mongo-rs-01:27017/admin"

// Retirer un nÅ“ud (par hostname)
rs.remove("mongo-rs-03:27017")

// Ou par ID
rs.remove(2)

// VÃ©rifier
rs.conf()
```

### Changement de prioritÃ©

```javascript
// Modifier la prioritÃ© d'un membre
var cfg = rs.conf()
cfg.members[1].priority = 3  // Membre index 1 prioritaire
rs.reconfig(cfg)

// VÃ©rifier
rs.conf()
```

---

## Sauvegarde

### Sauvegarde depuis un SECONDARY

```bash
# Se connecter Ã  un SECONDARY (mongo-rs-02 par exemple)
mongosh "mongodb://admin:PASSWORD@mongo-rs-02:27017/admin"

# VÃ©rifier que c'est bien un SECONDARY
rs.status()

# CrÃ©er la sauvegarde
mongodump \
  --host mongo-rs-02:27017 \
  --username admin \
  --password "VotreMotDePasseSecurise123!" \
  --authenticationDatabase admin \
  --out /backup/mongodb/$(date +%Y%m%d) \
  --oplog \
  --gzip

# Archive tar
cd /backup/mongodb
tar -czf backup-$(date +%Y%m%d-%H%M%S).tar.gz $(date +%Y%m%d)/
```

### Script de sauvegarde automatisÃ©

```bash
#!/bin/bash
# /usr/local/bin/mongodb-backup.sh

BACKUP_DIR="/backup/mongodb"
RETENTION_DAYS=7
DATE=$(date +%Y%m%d-%H%M%S)

# CrÃ©er le rÃ©pertoire
mkdir -p $BACKUP_DIR/$DATE

# Sauvegarde
mongodump \
  --host mongo-rs-02:27017 \
  --username admin \
  --password "VotreMotDePasseSecurise123!" \
  --authenticationDatabase admin \
  --out $BACKUP_DIR/$DATE \
  --oplog \
  --gzip \
  2>&1 | tee $BACKUP_DIR/$DATE/backup.log

# Archive
cd $BACKUP_DIR
tar -czf backup-$DATE.tar.gz $DATE/
rm -rf $DATE/

# Nettoyage des anciennes sauvegardes
find $BACKUP_DIR -name "backup-*.tar.gz" -mtime +$RETENTION_DAYS -delete

echo "Sauvegarde terminÃ©e : backup-$DATE.tar.gz"
```

### Cron pour sauvegardes quotidiennes

```bash
# crontab -e
# Sauvegarde tous les jours Ã  2h du matin
0 2 * * * /usr/local/bin/mongodb-backup.sh >> /var/log/mongodb/backup.log 2>&1
```

---

## Monitoring

### MÃ©triques clÃ©s Ã  surveiller

```javascript
// Statut de rÃ©plication
rs.status()

// Lag de rÃ©plication
rs.printSlaveReplicationInfo()

// Oplog info
rs.printReplicationInfo()

// Statistiques serveur
db.serverStatus()

// Connexions actives
db.currentOp()

// Statistiques de base de donnÃ©es
db.stats()
```

### Script de monitoring simple

```bash
#!/bin/bash
# /usr/local/bin/mongodb-health-check.sh

PRIMARY=$(mongosh "mongodb://admin:PASSWORD@mongo-rs-01:27017/admin" --quiet --eval "rs.isMaster().primary")
echo "PRIMARY actuel : $PRIMARY"

# VÃ©rifier tous les membres
for host in mongo-rs-01 mongo-rs-02 mongo-rs-03; do
  echo "---"
  echo "VÃ©rification de $host:"

  STATE=$(mongosh "mongodb://admin:PASSWORD@$host:27017/admin" --quiet --eval "rs.status().myState")

  if [ $? -eq 0 ]; then
    echo "  Ã‰tat : $STATE"

    CONNECTIONS=$(mongosh "mongodb://admin:PASSWORD@$host:27017/admin" --quiet --eval "db.serverStatus().connections.current")
    echo "  Connexions : $CONNECTIONS"

    REPL_LAG=$(mongosh "mongodb://admin:PASSWORD@$host:27017/admin" --quiet --eval "rs.printSlaveReplicationInfo()" | grep "syncedTo" | awk '{print $4}')
    echo "  Replication lag : $REPL_LAG"
  else
    echo "  ERREUR : Impossible de se connecter"
  fi
done
```

---

## Troubleshooting

### ProblÃ¨me : Membre bloquÃ© en STARTUP ou RECOVERING

```javascript
// VÃ©rifier les logs
// Sur le serveur problÃ©matique
tail -f /var/log/mongodb/mongod.log

// Solutions possibles :

// 1. VÃ©rifier la connectivitÃ© rÃ©seau
ping mongo-rs-01
telnet mongo-rs-01 27017

// 2. VÃ©rifier l'oplog
use local
db.oplog.rs.stats()

// 3. Resync complet si nÃ©cessaire
rs.syncFrom("mongo-rs-01:27017")

// 4. En dernier recours : resynchronisation initiale
// ATTENTION : Efface toutes les donnÃ©es du nÅ“ud
mongosh "mongodb://admin:PASSWORD@mongo-rs-02:27017/admin"
db.shutdownServer()

// Sur le serveur
sudo rm -rf /data/mongodb/*
sudo systemctl start mongod

// Le nÅ“ud se resynchronisera automatiquement
```

### ProblÃ¨me : Lag de rÃ©plication Ã©levÃ©

```javascript
// Identifier le lag
rs.printSlaveReplicationInfo()

// Solutions :

// 1. VÃ©rifier les performances rÃ©seau
// Sur le serveur
iftop -i eth0

// 2. VÃ©rifier les write operations
db.serverStatus().opcounters

// 3. VÃ©rifier l'I/O disk
iostat -x 1

// 4. Augmenter l'oplog si nÃ©cessaire
// ATTENTION : OpÃ©ration impactante, Ã  faire en maintenance
db.adminCommand({replSetResizeOplog: 1, size: 20480}) // 20 GB
```

### ProblÃ¨me : Elections frÃ©quentes

```javascript
// VÃ©rifier l'historique des Ã©lections
use local
db.system.replset.find()

// Causes possibles :
// - ProblÃ¨mes rÃ©seau intermittents
// - Charge CPU/mÃ©moire excessive
// - Latence rÃ©seau Ã©levÃ©e

// Solution : Ajuster les timeouts
cfg = rs.conf()
cfg.settings = {
  electionTimeoutMillis: 10000,  // DÃ©faut : 10000ms
  heartbeatTimeoutSecs: 10        // DÃ©faut : 10s
}
rs.reconfig(cfg)
```

### ProblÃ¨me : ImpossibilitÃ© d'Ã©lire un PRIMARY

```javascript
// VÃ©rifier la majoritÃ©
// Il faut au moins 2 nÅ“uds sur 3 disponibles

// Si un seul nÅ“ud disponible, forcer la reconfiguration
cfg = rs.conf()
cfg.members = [cfg.members[0]]  // Garder seulement le nÅ“ud actuel
rs.reconfig(cfg, {force: true})

// ATTENTION : Ã€ faire uniquement en cas d'urgence
// Reconfigurer correctement dÃ¨s que les autres nÅ“uds sont disponibles
```

---

## Checklist de mise en production

- [ ] Tous les nÅ“uds dÃ©marrÃ©s et joignables
- [ ] Replica Set initialisÃ© et Ã©tat = OK
- [ ] PRIMARY Ã©lu et stable
- [ ] Keyfile configurÃ© sur tous les nÅ“uds
- [ ] Utilisateur admin crÃ©Ã©
- [ ] Utilisateurs applicatifs crÃ©Ã©s
- [ ] Firewall configurÃ©
- [ ] THP dÃ©sactivÃ© sur tous les nÅ“uds
- [ ] ParamÃ¨tres kernel optimisÃ©s
- [ ] Monitoring en place
- [ ] Sauvegarde automatisÃ©e configurÃ©e
- [ ] Test de failover rÃ©ussi
- [ ] Connection strings testÃ©es depuis l'application
- [ ] Documentation architecture Ã  jour
- [ ] Contacts d'escalade dÃ©finis

---

## Ressources complÃ©mentaires

### Documentation officielle
- [Deploy a Replica Set](https://docs.mongodb.com/manual/tutorial/deploy-replica-set/)
- [Replica Set Configuration](https://docs.mongodb.com/manual/reference/replica-configuration/)
- [Replica Set Maintenance](https://docs.mongodb.com/manual/administration/replica-set-maintenance/)

### Commandes utiles

```javascript
// Cheat sheet Replica Set
rs.help()              // Aide sur les commandes
rs.status()            // Statut complet
rs.isMaster()          // Qui est le PRIMARY
rs.conf()              // Configuration
rs.printReplicationInfo()       // Info oplog
rs.printSlaveReplicationInfo()  // Lag de rÃ©plication
```

---


â­ï¸ [Configuration Sharded Cluster](/annexes/configuration-reference/02-configuration-sharded-cluster.md)
