üîù Retour au [Sommaire](/SOMMAIRE.md)

# G.1 Scripts de backup

## Introduction

Les **scripts de backup** sont essentiels pour garantir la **continuit√© de service** et la **r√©cup√©ration apr√®s incident**. Cette section fournit des scripts pr√™ts √† l'emploi pour diff√©rents sc√©narios de sauvegarde MongoDB.

## Vue d'ensemble des strat√©gies

| Strat√©gie | M√©thode | Avantages | Inconv√©nients |
|-----------|---------|-----------|---------------|
| **mongodump** | Logique | Portable, flexible | Plus lent, charge CPU |
| **Snapshot filesystem** | Physique | Rapide, coh√©rent | N√©cessite LVM/Cloud |
| **Oplog tailing** | Incr√©mental | Sauvegarde continue | Complexe √† restaurer |
| **Cloud Backup** | Managed | Automatis√©, fiable | Co√ªt, d√©pendance |

## Configuration commune

### Fichier de configuration (.env)

```bash
# /opt/mongodb/scripts/.env
# Configuration des backups MongoDB

# Connexion MongoDB
MONGO_HOST="localhost"
MONGO_PORT="27017"
MONGO_USER="backup_user"
MONGO_PASSWORD="secure_password"
MONGO_AUTH_DB="admin"

# URI de connexion compl√®te (alternative)
MONGO_URI="mongodb://backup_user:secure_password@localhost:27017/admin?authSource=admin"

# Replica Set (si applicable)
MONGO_REPLICA_SET="rs0"

# Chemins
BACKUP_ROOT="/backup/mongodb"
BACKUP_DAILY_DIR="$BACKUP_ROOT/daily"
BACKUP_WEEKLY_DIR="$BACKUP_ROOT/weekly"
BACKUP_MONTHLY_DIR="$BACKUP_ROOT/monthly"
LOG_DIR="/var/log/mongodb/backup"

# R√©tention (en jours)
RETENTION_DAILY=7
RETENTION_WEEKLY=30
RETENTION_MONTHLY=365

# Compression
COMPRESSION="gzip"  # Options: gzip, none

# Notifications
EMAIL_ADMIN="admin@example.com"
SLACK_WEBHOOK=""
ENABLE_NOTIFICATIONS=true

# Parall√©lisme
NUM_PARALLEL_COLLECTIONS=4

# Options avanc√©es
OPLOG_BACKUP=true
EXCLUDE_COLLECTIONS="logs,temp"
```

### Biblioth√®que de fonctions communes

```bash
# /opt/mongodb/scripts/lib/backup-common.sh
# Fonctions communes pour les scripts de backup

# Couleurs pour les logs
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Fonction de logging
log() {
    local level=$1
    shift
    local message="$@"
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')

    case $level in
        INFO)
            echo -e "[${timestamp}] ${GREEN}[INFO]${NC} ${message}" | tee -a "$LOG_FILE"
            ;;
        WARN)
            echo -e "[${timestamp}] ${YELLOW}[WARN]${NC} ${message}" | tee -a "$LOG_FILE"
            ;;
        ERROR)
            echo -e "[${timestamp}] ${RED}[ERROR]${NC} ${message}" | tee -a "$LOG_FILE"
            ;;
        *)
            echo -e "[${timestamp}] [${level}] ${message}" | tee -a "$LOG_FILE"
            ;;
    esac
}

# Gestion des erreurs
error_exit() {
    log ERROR "$1"
    send_notification "‚ùå Backup MongoDB √©chou√©" "$1"
    exit 1
}

# Envoi de notifications
send_notification() {
    local subject="$1"
    local message="$2"

    [ "$ENABLE_NOTIFICATIONS" != "true" ] && return 0

    # Email
    if [ -n "$EMAIL_ADMIN" ]; then
        echo "$message" | mail -s "$subject" "$EMAIL_ADMIN" 2>/dev/null || true
    fi

    # Slack
    if [ -n "$SLACK_WEBHOOK" ]; then
        curl -X POST -H 'Content-type: application/json' \
            --data "{\"text\":\"${subject}\n${message}\"}" \
            "$SLACK_WEBHOOK" 2>/dev/null || true
    fi
}

# Cr√©er les r√©pertoires n√©cessaires
create_directories() {
    local dirs=("$@")
    for dir in "${dirs[@]}"; do
        if [ ! -d "$dir" ]; then
            mkdir -p "$dir" || error_exit "Impossible de cr√©er le r√©pertoire: $dir"
            log INFO "R√©pertoire cr√©√©: $dir"
        fi
    done
}

# V√©rifier l'espace disque disponible
check_disk_space() {
    local path=$1
    local required_gb=${2:-10}  # 10 GB par d√©faut

    local available_kb=$(df "$path" | awk 'NR==2 {print $4}')
    local available_gb=$((available_kb / 1024 / 1024))

    if [ "$available_gb" -lt "$required_gb" ]; then
        error_exit "Espace disque insuffisant: ${available_gb}GB disponible, ${required_gb}GB requis"
    fi

    log INFO "Espace disque: ${available_gb}GB disponible"
}

# V√©rifier la connexion MongoDB
check_mongo_connection() {
    log INFO "V√©rification de la connexion MongoDB..."

    if mongosh "$MONGO_URI" --quiet --eval "db.adminCommand('ping')" >/dev/null 2>&1; then
        log INFO "Connexion MongoDB r√©ussie"
        return 0
    else
        error_exit "Impossible de se connecter √† MongoDB"
    fi
}

# Obtenir la taille d'une base de donn√©es
get_db_size() {
    local db_name=$1
    mongosh "$MONGO_URI" --quiet --eval "print(db.getSiblingDB('${db_name}').stats().dataSize)" 2>/dev/null
}

# Nettoyer les anciens backups
cleanup_old_backups() {
    local backup_dir=$1
    local retention_days=$2

    log INFO "Nettoyage des backups de plus de ${retention_days} jours dans ${backup_dir}"

    find "$backup_dir" -type d -mtime +${retention_days} -exec rm -rf {} + 2>/dev/null || true

    local remaining=$(find "$backup_dir" -type d -maxdepth 1 | wc -l)
    log INFO "Backups restants: $((remaining - 1))"
}

# Calculer la dur√©e d'ex√©cution
calculate_duration() {
    local start_time=$1
    local end_time=$2
    local duration=$((end_time - start_time))

    local hours=$((duration / 3600))
    local minutes=$(((duration % 3600) / 60))
    local seconds=$((duration % 60))

    printf "%02d:%02d:%02d" $hours $minutes $seconds
}

# Valider un backup
validate_backup() {
    local backup_path=$1

    log INFO "Validation du backup: $backup_path"

    # V√©rifier l'existence du r√©pertoire
    if [ ! -d "$backup_path" ]; then
        error_exit "R√©pertoire de backup introuvable: $backup_path"
    fi

    # V√©rifier la pr√©sence de fichiers BSON
    local bson_count=$(find "$backup_path" -name "*.bson" -o -name "*.bson.gz" | wc -l)
    if [ "$bson_count" -eq 0 ]; then
        error_exit "Aucun fichier BSON trouv√© dans le backup"
    fi

    log INFO "Backup valid√©: ${bson_count} collections sauvegard√©es"
    return 0
}
```

## 1. Backup complet avec mongodump

### Script de backup quotidien

```bash
#!/bin/bash
#
# Script: backup-daily.sh
# Description: Backup complet quotidien avec mongodump
# Usage: ./backup-daily.sh [database_name]
#

set -euo pipefail

# Configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
source "$SCRIPT_DIR/.env"
source "$SCRIPT_DIR/lib/backup-common.sh"

# Variables
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_NAME="backup_${TIMESTAMP}"
BACKUP_PATH="$BACKUP_DAILY_DIR/$BACKUP_NAME"
LOG_FILE="$LOG_DIR/backup-daily-${TIMESTAMP}.log"
START_TIME=$(date +%s)

# Base de donn√©es sp√©cifique ou toutes
TARGET_DB="${1:-all}"

# Fonction principale
main() {
    log INFO "=========================================="
    log INFO "D√©but du backup quotidien MongoDB"
    log INFO "=========================================="

    # Pr√©requis
    create_directories "$BACKUP_DAILY_DIR" "$LOG_DIR"
    check_disk_space "$BACKUP_ROOT" 20
    check_mongo_connection

    # Ex√©cution du backup
    perform_backup

    # Validation
    validate_backup "$BACKUP_PATH"

    # Compression (optionnel)
    if [ "$COMPRESSION" == "gzip" ]; then
        compress_backup
    fi

    # Nettoyage
    cleanup_old_backups "$BACKUP_DAILY_DIR" "$RETENTION_DAILY"

    # Rapport final
    END_TIME=$(date +%s)
    DURATION=$(calculate_duration $START_TIME $END_TIME)
    BACKUP_SIZE=$(du -sh "$BACKUP_PATH" | cut -f1)

    log INFO "=========================================="
    log INFO "Backup termin√© avec succ√®s"
    log INFO "Dur√©e: $DURATION"
    log INFO "Taille: $BACKUP_SIZE"
    log INFO "Chemin: $BACKUP_PATH"
    log INFO "=========================================="

    # Notification de succ√®s
    send_notification \
        "‚úÖ Backup MongoDB r√©ussi" \
        "Backup: $BACKUP_NAME\nDur√©e: $DURATION\nTaille: $BACKUP_SIZE"
}

# Fonction de backup
perform_backup() {
    log INFO "D√©marrage de mongodump..."

    local mongodump_cmd="mongodump --uri=\"$MONGO_URI\""
    mongodump_cmd="$mongodump_cmd --out=\"$BACKUP_PATH\""
    mongodump_cmd="$mongodump_cmd --numParallelCollections=$NUM_PARALLEL_COLLECTIONS"

    # Backup d'une base sp√©cifique
    if [ "$TARGET_DB" != "all" ]; then
        log INFO "Backup de la base: $TARGET_DB"
        mongodump_cmd="$mongodump_cmd --db=$TARGET_DB"
    else
        log INFO "Backup de toutes les bases de donn√©es"
    fi

    # Inclure l'oplog (pour replica sets)
    if [ "$OPLOG_BACKUP" == "true" ] && [ -n "$MONGO_REPLICA_SET" ]; then
        log INFO "Backup avec oplog activ√©"
        mongodump_cmd="$mongodump_cmd --oplog"
    fi

    # Exclure certaines collections
    if [ -n "$EXCLUDE_COLLECTIONS" ]; then
        IFS=',' read -ra EXCLUDED <<< "$EXCLUDE_COLLECTIONS"
        for collection in "${EXCLUDED[@]}"; do
            mongodump_cmd="$mongodump_cmd --excludeCollection=$collection"
        done
        log INFO "Collections exclues: $EXCLUDE_COLLECTIONS"
    fi

    # Compression gzip
    if [ "$COMPRESSION" == "gzip" ]; then
        mongodump_cmd="$mongodump_cmd --gzip"
    fi

    # Ex√©cution
    eval $mongodump_cmd >> "$LOG_FILE" 2>&1 || error_exit "mongodump a √©chou√©"

    log INFO "mongodump termin√© avec succ√®s"
}

# Compression du backup (si non fait par mongodump)
compress_backup() {
    log INFO "Compression du backup..."

    local archive_name="${BACKUP_NAME}.tar.gz"
    local archive_path="$BACKUP_DAILY_DIR/$archive_name"

    tar -czf "$archive_path" -C "$BACKUP_DAILY_DIR" "$BACKUP_NAME" || error_exit "Compression √©chou√©e"

    # Supprimer le r√©pertoire non compress√©
    rm -rf "$BACKUP_PATH"
    BACKUP_PATH="$archive_path"

    log INFO "Backup compress√©: $archive_name"
}

# Ex√©cution
main "$@"
```

## 2. Backup de Replica Set

```bash
#!/bin/bash
#
# Script: backup-replicaset.sh
# Description: Backup d'un Replica Set avec oplog
#

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
source "$SCRIPT_DIR/.env"
source "$SCRIPT_DIR/lib/backup-common.sh"

TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_NAME="rs_backup_${TIMESTAMP}"
BACKUP_PATH="$BACKUP_DAILY_DIR/$BACKUP_NAME"
LOG_FILE="$LOG_DIR/backup-replicaset-${TIMESTAMP}.log"

main() {
    log INFO "D√©but du backup Replica Set: $MONGO_REPLICA_SET"

    create_directories "$BACKUP_DAILY_DIR" "$LOG_DIR"
    check_disk_space "$BACKUP_ROOT" 30

    # V√©rifier l'√©tat du replica set
    check_replicaset_status

    # Backup depuis un membre SECONDARY (pr√©f√©rable)
    local secondary_host=$(get_secondary_host)

    if [ -n "$secondary_host" ]; then
        log INFO "Backup depuis le noeud SECONDARY: $secondary_host"
        BACKUP_URI="mongodb://${MONGO_USER}:${MONGO_PASSWORD}@${secondary_host}/${MONGO_AUTH_DB}?replicaSet=${MONGO_REPLICA_SET}"
    else
        log WARN "Aucun SECONDARY disponible, utilisation du PRIMARY"
        BACKUP_URI="$MONGO_URI"
    fi

    # Ex√©cution du backup avec oplog
    log INFO "Ex√©cution de mongodump avec oplog..."

    mongodump \
        --uri="$BACKUP_URI" \
        --out="$BACKUP_PATH" \
        --oplog \
        --gzip \
        --numParallelCollections=$NUM_PARALLEL_COLLECTIONS \
        >> "$LOG_FILE" 2>&1 || error_exit "mongodump a √©chou√©"

    # Validation
    validate_backup "$BACKUP_PATH"

    # V√©rifier la pr√©sence de l'oplog
    if [ -f "$BACKUP_PATH/oplog.bson.gz" ] || [ -f "$BACKUP_PATH/oplog.bson" ]; then
        log INFO "Oplog sauvegard√© avec succ√®s"
    else
        log WARN "Fichier oplog non trouv√©"
    fi

    cleanup_old_backups "$BACKUP_DAILY_DIR" "$RETENTION_DAILY"

    log INFO "Backup Replica Set termin√©: $BACKUP_PATH"
}

# V√©rifier l'√©tat du replica set
check_replicaset_status() {
    log INFO "V√©rification de l'√©tat du Replica Set..."

    local rs_status=$(mongosh "$MONGO_URI" --quiet --eval "JSON.stringify(rs.status())" 2>/dev/null)

    if [ -z "$rs_status" ]; then
        error_exit "Impossible d'obtenir le statut du Replica Set"
    fi

    log INFO "Replica Set op√©rationnel"
}

# Obtenir l'adresse d'un noeud SECONDARY
get_secondary_host() {
    mongosh "$MONGO_URI" --quiet --eval "
        var status = rs.status();
        var secondary = status.members.find(m => m.stateStr === 'SECONDARY');
        if (secondary) print(secondary.name);
    " 2>/dev/null | tail -1
}

main "$@"
```

## 3. Backup de Cluster Shard√©

```bash
#!/bin/bash
#
# Script: backup-sharded.sh
# Description: Backup d'un cluster shard√©
#

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
source "$SCRIPT_DIR/.env"
source "$SCRIPT_DIR/lib/backup-common.sh"

TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_NAME="sharded_backup_${TIMESTAMP}"
BACKUP_PATH="$BACKUP_DAILY_DIR/$BACKUP_NAME"
LOG_FILE="$LOG_DIR/backup-sharded-${TIMESTAMP}.log"

# Configuration sp√©cifique au sharding
MONGOS_HOST="${MONGOS_HOST:-localhost:27017}"
CONFIG_SERVERS="${CONFIG_SERVERS:-localhost:27019}"

main() {
    log INFO "D√©but du backup du cluster shard√©"

    create_directories "$BACKUP_DAILY_DIR" "$LOG_DIR"
    check_disk_space "$BACKUP_ROOT" 50

    # 1. Arr√™ter le balancer
    stop_balancer

    # 2. Backup des config servers
    backup_config_servers

    # 3. Backup de chaque shard
    backup_all_shards

    # 4. Red√©marrer le balancer
    start_balancer

    # Validation finale
    validate_backup "$BACKUP_PATH"
    cleanup_old_backups "$BACKUP_DAILY_DIR" "$RETENTION_DAILY"

    log INFO "Backup du cluster shard√© termin√©: $BACKUP_PATH"
}

# Arr√™ter le balancer
stop_balancer() {
    log INFO "Arr√™t du balancer..."

    mongosh "mongodb://${MONGO_USER}:${MONGO_PASSWORD}@${MONGOS_HOST}/admin" --quiet --eval "
        sh.stopBalancer();
        while(sh.isBalancerRunning()) {
            sleep(1000);
        }
        print('Balancer arr√™t√©');
    " >> "$LOG_FILE" 2>&1

    log INFO "Balancer arr√™t√© avec succ√®s"
}

# D√©marrer le balancer
start_balancer() {
    log INFO "Red√©marrage du balancer..."

    mongosh "mongodb://${MONGO_USER}:${MONGO_PASSWORD}@${MONGOS_HOST}/admin" --quiet --eval "
        sh.startBalancer();
        print('Balancer d√©marr√©');
    " >> "$LOG_FILE" 2>&1

    log INFO "Balancer red√©marr√© avec succ√®s"
}

# Backup des config servers
backup_config_servers() {
    log INFO "Backup des config servers..."

    local config_backup_path="$BACKUP_PATH/config_servers"
    mkdir -p "$config_backup_path"

    mongodump \
        --uri="mongodb://${MONGO_USER}:${MONGO_PASSWORD}@${CONFIG_SERVERS}/admin" \
        --out="$config_backup_path" \
        --oplog \
        --gzip \
        >> "$LOG_FILE" 2>&1 || error_exit "Backup des config servers √©chou√©"

    log INFO "Config servers sauvegard√©s"
}

# Backup de tous les shards
backup_all_shards() {
    log INFO "R√©cup√©ration de la liste des shards..."

    local shards=$(mongosh "mongodb://${MONGO_USER}:${MONGO_PASSWORD}@${MONGOS_HOST}/admin" --quiet --eval "
        db.getSiblingDB('config').shards.find({}, {_id:1, host:1}).forEach(function(s) {
            print(s._id + ':' + s.host);
        });
    ")

    while IFS=':' read -r shard_id shard_host; do
        [ -z "$shard_id" ] && continue

        log INFO "Backup du shard: $shard_id ($shard_host)"

        local shard_backup_path="$BACKUP_PATH/shard_${shard_id}"
        mkdir -p "$shard_backup_path"

        # Extraire le host principal du replica set
        local primary_host=$(echo "$shard_host" | sed 's|.*\/||' | cut -d',' -f1)

        mongodump \
            --uri="mongodb://${MONGO_USER}:${MONGO_PASSWORD}@${primary_host}/admin" \
            --out="$shard_backup_path" \
            --oplog \
            --gzip \
            --numParallelCollections=$NUM_PARALLEL_COLLECTIONS \
            >> "$LOG_FILE" 2>&1 || log ERROR "Backup du shard $shard_id √©chou√©"

        log INFO "Shard $shard_id sauvegard√©"
    done <<< "$shards"
}

main "$@"
```

## 4. Backup incr√©mental avec Oplog

```bash
#!/bin/bash
#
# Script: backup-incremental.sh
# Description: Backup incr√©mental bas√© sur l'oplog
#

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
source "$SCRIPT_DIR/.env"
source "$SCRIPT_DIR/lib/backup-common.sh"

TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_NAME="incremental_${TIMESTAMP}"
BACKUP_PATH="$BACKUP_DAILY_DIR/$BACKUP_NAME"
LOG_FILE="$LOG_DIR/backup-incremental-${TIMESTAMP}.log"
LAST_BACKUP_TS_FILE="$BACKUP_ROOT/.last_oplog_timestamp"

main() {
    log INFO "D√©but du backup incr√©mental"

    create_directories "$BACKUP_DAILY_DIR" "$LOG_DIR"

    # V√©rifier si c'est le premier backup incr√©mental
    if [ ! -f "$LAST_BACKUP_TS_FILE" ]; then
        log INFO "Premier backup incr√©mental, cr√©ation d'un backup complet de r√©f√©rence"
        create_base_backup
    fi

    # Lire le dernier timestamp
    local last_ts=$(cat "$LAST_BACKUP_TS_FILE")
    log INFO "Dernier timestamp: $last_ts"

    # Extraire l'oplog depuis le dernier timestamp
    extract_oplog "$last_ts"

    # Sauvegarder le nouveau timestamp
    save_current_timestamp

    log INFO "Backup incr√©mental termin√©: $BACKUP_PATH"
}

# Cr√©er un backup complet de base
create_base_backup() {
    local base_backup="$BACKUP_ROOT/base_backup"

    log INFO "Cr√©ation du backup de base..."

    mongodump \
        --uri="$MONGO_URI" \
        --out="$base_backup" \
        --oplog \
        --gzip \
        >> "$LOG_FILE" 2>&1 || error_exit "Backup de base √©chou√©"

    # Sauvegarder le timestamp initial
    mongosh "$MONGO_URI" --quiet --eval "
        var oplog = db.getSiblingDB('local').oplog.rs.find().sort({ts: -1}).limit(1).toArray()[0];
        print(oplog.ts.toString());
    " > "$LAST_BACKUP_TS_FILE"

    log INFO "Backup de base cr√©√©: $base_backup"
}

# Extraire l'oplog depuis un timestamp
extract_oplog() {
    local start_ts=$1

    log INFO "Extraction de l'oplog depuis: $start_ts"

    mkdir -p "$BACKUP_PATH"

    # Requ√™te pour extraire l'oplog
    mongodump \
        --uri="$MONGO_URI" \
        --db=local \
        --collection=oplog.rs \
        --query="{ts: {\$gt: Timestamp($start_ts)}}" \
        --out="$BACKUP_PATH" \
        --gzip \
        >> "$LOG_FILE" 2>&1 || error_exit "Extraction de l'oplog √©chou√©e"

    log INFO "Oplog extrait avec succ√®s"
}

# Sauvegarder le timestamp actuel
save_current_timestamp() {
    local current_ts=$(mongosh "$MONGO_URI" --quiet --eval "
        var oplog = db.getSiblingDB('local').oplog.rs.find().sort({ts: -1}).limit(1).toArray()[0];
        print(oplog.ts.toString());
    ")

    echo "$current_ts" > "$LAST_BACKUP_TS_FILE"
    log INFO "Nouveau timestamp sauvegard√©: $current_ts"
}

main "$@"
```

## 5. Script de restauration

```bash
#!/bin/bash
#
# Script: restore-backup.sh
# Description: Restauration d'un backup MongoDB
# Usage: ./restore-backup.sh <backup_path> [target_db]
#

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
source "$SCRIPT_DIR/.env"
source "$SCRIPT_DIR/lib/backup-common.sh"

BACKUP_TO_RESTORE="${1:?Usage: $0 <backup_path> [target_db]}"
TARGET_DB="${2:-}"
LOG_FILE="$LOG_DIR/restore-$(date +%Y%m%d_%H%M%S).log"

main() {
    log INFO "=========================================="
    log INFO "D√©but de la restauration MongoDB"
    log INFO "=========================================="

    # V√©rifications
    check_backup_exists
    confirm_restore

    # D√©compression si n√©cessaire
    if [[ "$BACKUP_TO_RESTORE" == *.tar.gz ]]; then
        decompress_backup
    fi

    # Restauration
    perform_restore

    log INFO "=========================================="
    log INFO "Restauration termin√©e avec succ√®s"
    log INFO "=========================================="
}

# V√©rifier l'existence du backup
check_backup_exists() {
    if [ ! -e "$BACKUP_TO_RESTORE" ]; then
        error_exit "Backup introuvable: $BACKUP_TO_RESTORE"
    fi

    log INFO "Backup trouv√©: $BACKUP_TO_RESTORE"
}

# Confirmation interactive
confirm_restore() {
    log WARN "ATTENTION: Cette op√©ration va restaurer les donn√©es MongoDB"

    if [ -n "$TARGET_DB" ]; then
        log WARN "Base de donn√©es cible: $TARGET_DB"
    else
        log WARN "Restauration compl√®te de toutes les bases de donn√©es"
    fi

    read -p "Voulez-vous continuer? (yes/no): " -r
    if [[ ! $REPLY =~ ^[Yy][Ee][Ss]$ ]]; then
        log INFO "Restauration annul√©e par l'utilisateur"
        exit 0
    fi
}

# D√©compression
decompress_backup() {
    log INFO "D√©compression du backup..."

    local temp_dir="/tmp/mongodb_restore_$$"
    mkdir -p "$temp_dir"

    tar -xzf "$BACKUP_TO_RESTORE" -C "$temp_dir" || error_exit "D√©compression √©chou√©e"

    BACKUP_TO_RESTORE="$temp_dir/$(ls -1 $temp_dir | head -1)"
    log INFO "Backup d√©compress√© dans: $BACKUP_TO_RESTORE"
}

# Restauration
perform_restore() {
    log INFO "D√©marrage de mongorestore..."

    local restore_cmd="mongorestore --uri=\"$MONGO_URI\""

    # Options
    if [ -n "$TARGET_DB" ]; then
        restore_cmd="$restore_cmd --db=$TARGET_DB"
        log INFO "Restauration dans la base: $TARGET_DB"
    fi

    # Drop avant restauration (optionnel)
    # restore_cmd="$restore_cmd --drop"

    # Parall√©lisme
    restore_cmd="$restore_cmd --numParallelCollections=$NUM_PARALLEL_COLLECTIONS"

    # Gzip
    if ls "$BACKUP_TO_RESTORE"/*.bson.gz >/dev/null 2>&1; then
        restore_cmd="$restore_cmd --gzip"
    fi

    # Oplog replay (si pr√©sent)
    if [ -f "$BACKUP_TO_RESTORE/oplog.bson" ] || [ -f "$BACKUP_TO_RESTORE/oplog.bson.gz" ]; then
        log INFO "Application de l'oplog"
        restore_cmd="$restore_cmd --oplogReplay"
    fi

    # Chemin du backup
    restore_cmd="$restore_cmd \"$BACKUP_TO_RESTORE\""

    # Ex√©cution
    eval $restore_cmd >> "$LOG_FILE" 2>&1 || error_exit "mongorestore a √©chou√©"

    log INFO "mongorestore termin√© avec succ√®s"
}

main "$@"
```

## 6. Script de v√©rification de backup

```bash
#!/bin/bash
#
# Script: verify-backup.sh
# Description: V√©rification approfondie d'un backup
#

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
source "$SCRIPT_DIR/.env"
source "$SCRIPT_DIR/lib/backup-common.sh"

BACKUP_PATH="${1:?Usage: $0 <backup_path>}"
LOG_FILE="$LOG_DIR/verify-$(date +%Y%m%d_%H%M%S).log"

main() {
    log INFO "V√©rification du backup: $BACKUP_PATH"

    # V√©rifications de base
    check_backup_structure
    check_metadata_files
    check_bson_files
    check_oplog

    # Statistiques
    generate_statistics

    log INFO "V√©rification termin√©e: Backup valide ‚úì"
}

# V√©rifier la structure du backup
check_backup_structure() {
    if [ ! -d "$BACKUP_PATH" ]; then
        error_exit "Le chemin n'est pas un r√©pertoire valide"
    fi

    log INFO "Structure du backup v√©rifi√©e"
}

# V√©rifier les fichiers de m√©tadonn√©es
check_metadata_files() {
    log INFO "V√©rification des m√©tadonn√©es..."

    local db_count=0
    for db_dir in "$BACKUP_PATH"/*/; do
        [ -d "$db_dir" ] || continue

        local db_name=$(basename "$db_dir")
        db_count=$((db_count + 1))

        # V√©rifier les fichiers metadata.json
        local metadata_files=$(find "$db_dir" -name "*.metadata.json*" | wc -l)
        log INFO "  Base: $db_name - $metadata_files collections"
    done

    if [ $db_count -eq 0 ]; then
        error_exit "Aucune base de donn√©es trouv√©e dans le backup"
    fi

    log INFO "Bases de donn√©es trouv√©es: $db_count"
}

# V√©rifier les fichiers BSON
check_bson_files() {
    log INFO "V√©rification des fichiers BSON..."

    local bson_count=$(find "$BACKUP_PATH" -name "*.bson" -o -name "*.bson.gz" | wc -l)

    if [ $bson_count -eq 0 ]; then
        error_exit "Aucun fichier BSON trouv√©"
    fi

    log INFO "Fichiers BSON trouv√©s: $bson_count"
}

# V√©rifier l'oplog
check_oplog() {
    if [ -f "$BACKUP_PATH/oplog.bson" ] || [ -f "$BACKUP_PATH/oplog.bson.gz" ]; then
        log INFO "Oplog pr√©sent dans le backup ‚úì"
    else
        log WARN "Aucun oplog trouv√© (normal pour backup standalone)"
    fi
}

# G√©n√©rer des statistiques
generate_statistics() {
    log INFO "G√©n√©ration des statistiques..."

    local total_size=$(du -sh "$BACKUP_PATH" | cut -f1)
    local file_count=$(find "$BACKUP_PATH" -type f | wc -l)
    local oldest_file=$(find "$BACKUP_PATH" -type f -printf '%T+ %p\n' | sort | head -1 | cut -d' ' -f1)

    log INFO "----------------------------------------"
    log INFO "Statistiques du backup:"
    log INFO "  Taille totale: $total_size"
    log INFO "  Nombre de fichiers: $file_count"
    log INFO "  Date de cr√©ation: $oldest_file"
    log INFO "----------------------------------------"
}

main "$@"
```

## 7. Backup automatis√© avec rotation

```bash
#!/bin/bash
#
# Script: backup-with-rotation.sh
# Description: Backup avec rotation quotidien/hebdomadaire/mensuel
#

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
source "$SCRIPT_DIR/.env"
source "$SCRIPT_DIR/lib/backup-common.sh"

TIMESTAMP=$(date +%Y%m%d_%H%M%S)
DAY_OF_WEEK=$(date +%u)     # 1-7 (Lundi-Dimanche)
DAY_OF_MONTH=$(date +%d)    # 01-31
LOG_FILE="$LOG_DIR/backup-rotation-${TIMESTAMP}.log"

main() {
    log INFO "D√©but du backup avec rotation"

    create_directories "$BACKUP_DAILY_DIR" "$BACKUP_WEEKLY_DIR" "$BACKUP_MONTHLY_DIR" "$LOG_DIR"
    check_disk_space "$BACKUP_ROOT" 50

    # D√©terminer le type de backup
    if [ "$DAY_OF_MONTH" == "01" ]; then
        # Backup mensuel (1er du mois)
        perform_monthly_backup
    elif [ "$DAY_OF_WEEK" == "7" ]; then
        # Backup hebdomadaire (dimanche)
        perform_weekly_backup
    else
        # Backup quotidien
        perform_daily_backup
    fi

    log INFO "Backup avec rotation termin√©"
}

# Backup quotidien
perform_daily_backup() {
    log INFO "Ex√©cution du backup quotidien"

    local backup_name="daily_$(date +%Y%m%d)"
    local backup_path="$BACKUP_DAILY_DIR/$backup_name"

    mongodump \
        --uri="$MONGO_URI" \
        --out="$backup_path" \
        --gzip \
        --numParallelCollections=$NUM_PARALLEL_COLLECTIONS \
        >> "$LOG_FILE" 2>&1 || error_exit "Backup quotidien √©chou√©"

    cleanup_old_backups "$BACKUP_DAILY_DIR" "$RETENTION_DAILY"

    send_notification "üìÖ Backup quotidien MongoDB" "Backup: $backup_name"
}

# Backup hebdomadaire
perform_weekly_backup() {
    log INFO "Ex√©cution du backup hebdomadaire"

    local backup_name="weekly_$(date +%Y_W%V)"
    local backup_path="$BACKUP_WEEKLY_DIR/$backup_name"

    mongodump \
        --uri="$MONGO_URI" \
        --out="$backup_path" \
        --oplog \
        --gzip \
        --numParallelCollections=$NUM_PARALLEL_COLLECTIONS \
        >> "$LOG_FILE" 2>&1 || error_exit "Backup hebdomadaire √©chou√©"

    cleanup_old_backups "$BACKUP_WEEKLY_DIR" "$RETENTION_WEEKLY"

    send_notification "üìÖ Backup hebdomadaire MongoDB" "Backup: $backup_name"
}

# Backup mensuel
perform_monthly_backup() {
    log INFO "Ex√©cution du backup mensuel"

    local backup_name="monthly_$(date +%Y%m)"
    local backup_path="$BACKUP_MONTHLY_DIR/$backup_name"

    mongodump \
        --uri="$MONGO_URI" \
        --out="$backup_path" \
        --oplog \
        --gzip \
        --numParallelCollections=$NUM_PARALLEL_COLLECTIONS \
        >> "$LOG_FILE" 2>&1 || error_exit "Backup mensuel √©chou√©"

    cleanup_old_backups "$BACKUP_MONTHLY_DIR" "$RETENTION_MONTHLY"

    send_notification "üìÖ Backup mensuel MongoDB" "Backup: $backup_name"
}

main "$@"
```

## Configuration Cron

```cron
# /etc/crontab ou crontab -e

# Backup quotidien √† 2h du matin
0 2 * * * /opt/mongodb/scripts/backup-daily.sh >> /var/log/mongodb/cron-backup.log 2>&1

# Backup avec rotation
0 2 * * * /opt/mongodb/scripts/backup-with-rotation.sh >> /var/log/mongodb/cron-rotation.log 2>&1

# V√©rification des backups (tous les jours √† 3h)
0 3 * * * /opt/mongodb/scripts/verify-last-backup.sh >> /var/log/mongodb/cron-verify.log 2>&1

# Nettoyage hebdomadaire (dimanche √† 4h)
0 4 * * 0 /opt/mongodb/scripts/cleanup-old-backups.sh >> /var/log/mongodb/cron-cleanup.log 2>&1
```

## Checklist de d√©ploiement

- [ ] Variables d'environnement configur√©es dans `.env`
- [ ] Utilisateur MongoDB avec droits `backup` cr√©√©
- [ ] R√©pertoires de backup cr√©√©s avec permissions appropri√©es
- [ ] Scripts test√©s en environnement de d√©veloppement
- [ ] Restauration test√©e √† partir d'un backup
- [ ] Notifications configur√©es et test√©es
- [ ] T√¢ches cron planifi√©es
- [ ] Monitoring des jobs de backup actif
- [ ] Documentation de restauration √† jour
- [ ] Plan de disaster recovery document√©

## Bonnes pratiques

### S√©curit√©
- ‚úÖ Stocker les credentials dans des fichiers prot√©g√©s (chmod 600)
- ‚úÖ Utiliser un utilisateur d√©di√© avec privil√®ges minimaux
- ‚úÖ Chiffrer les backups sensibles
- ‚úÖ Stocker les backups hors site (S3, NAS distant)

### Performance
- ‚úÖ Faire les backups depuis un noeud SECONDARY
- ‚úÖ Utiliser `--numParallelCollections` pour acc√©l√©rer
- ‚úÖ Planifier pendant les heures creuses
- ‚úÖ Compresser avec `--gzip`

### Fiabilit√©
- ‚úÖ Toujours valider les backups apr√®s cr√©ation
- ‚úÖ Tester r√©guli√®rement les restaurations
- ‚úÖ Conserver plusieurs g√©n√©rations (3-2-1 rule)
- ‚úÖ Monitorer l'espace disque disponible

### Automatisation
- ‚úÖ Utiliser des scripts standardis√©s
- ‚úÖ Logger toutes les op√©rations
- ‚úÖ Envoyer des notifications en cas d'√©chec
- ‚úÖ Documenter les proc√©dures

---


‚è≠Ô∏è [Scripts de monitoring](/annexes/scripts-automatisation/02-scripts-monitoring.md)
