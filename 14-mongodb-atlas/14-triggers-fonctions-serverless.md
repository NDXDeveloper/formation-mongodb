ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 14.14 Triggers et Fonctions Serverless

## Introduction

Les **Triggers** et **Functions** d'Atlas App Services constituent une plateforme serverless complÃ¨te pour l'automatisation et l'orchestration event-driven. RÃ©agissez aux changements de donnÃ©es en temps rÃ©el, planifiez des tÃ¢ches rÃ©currentes, orchestrez des workflows complexes, et intÃ©grez des services externes : tout en code JavaScript/Node.js sans gÃ©rer de serveurs. Cette section approfondit les patterns avancÃ©s et les architectures event-driven pour des systÃ¨mes production-grade.

### ğŸ¯ Objectifs de cette Section

- MaÃ®triser les patterns avancÃ©s de triggers
- Orchestrer des workflows complexes multi-Ã©tapes
- ImplÃ©menter error handling et retry robuste
- Monitorer et observer les fonctions serverless
- DÃ©ployer via CI/CD et Infrastructure-as-Code
- Construire des architectures event-driven scalables
- Optimiser performances et coÃ»ts

---

## ğŸ¯ Architecture Event-Driven

### Vue d'Ensemble

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              EVENT-DRIVEN ARCHITECTURE WITH TRIGGERS                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚
â”‚  Ã‰VÃ‰NEMENTS
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”‚
â”‚  â”‚  Database     Scheduled      Authentication    HTTP
â”‚  â”‚  Changes      Events         Events            Webhooks
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€     â”€â”€â”€â”€â”€â”€â”€â”€       â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€â”€
â”‚  â”‚  INSERT       Cron jobs      User signup       External API
â”‚  â”‚  UPDATE       Daily tasks    Login             Payment gateway
â”‚  â”‚  DELETE       Hourly checks  Logout            3rd party service
â”‚  â”‚  REPLACE      Maintenance    Delete account    IoT devices
â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚       â”‚              â”‚                â”‚                 â”‚
â”‚       â–¼              â–¼                â–¼                 â–¼
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”‚                      TRIGGER ROUTER
â”‚  â”‚  â€¢ Event matching
â”‚  â”‚  â€¢ Filter evaluation
â”‚  â”‚  â€¢ Function invocation
â”‚  â”‚  â€¢ Retry management
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚       â”‚              â”‚                â”‚                 â”‚
â”‚       â–¼              â–¼                â–¼                 â–¼
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”‚Function â”‚  â”‚Function â”‚  â”‚Function  â”‚  â”‚Function Orchestrator â”‚
â”‚  â”‚   A     â”‚  â”‚   B     â”‚  â”‚   C      â”‚  â”‚  (Complex Workflow)  â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚       â”‚            â”‚            â”‚                   â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚                                 â–¼
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”‚                    SIDE EFFECTS
â”‚  â”‚  â€¢ MongoDB operations (CRUD)
â”‚  â”‚  â€¢ External API calls (REST, GraphQL)
â”‚  â”‚  â€¢ Email/SMS notifications
â”‚  â”‚  â€¢ Message queues (SQS, Kafka)
â”‚  â”‚  â€¢ Other triggers invocation (chaining)
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â”‚  AVANTAGES:
â”‚  âœ… DÃ©couplage (loose coupling)
â”‚  âœ… ScalabilitÃ© automatique
â”‚  âœ… RÃ©silience (retry, error handling)
â”‚  âœ… ObservabilitÃ© (logs, metrics)
â”‚  âœ… CoÃ»t optimisÃ© (pay per execution)
â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Database Triggers AvancÃ©s

### Patterns de Triggers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATABASE TRIGGER PATTERNS                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚  1. AUDIT TRAIL (TraÃ§abilitÃ©)                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Ã‰vÃ©nement: INSERT, UPDATE, DELETE sur orders                     â”‚ â”‚
â”‚  â”‚ Action: CrÃ©er log d'audit avec before/after                      â”‚ â”‚
â”‚  â”‚                                                                  â”‚ â”‚
â”‚  â”‚ Use case: Compliance, forensics, debugging                       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                       â”‚
â”‚  2. DATA ENRICHMENT (Enrichissement)                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Ã‰vÃ©nement: INSERT sur users                                      â”‚ â”‚
â”‚  â”‚ Action: Appel API externe pour gÃ©olocalisation, enrichir profil  â”‚ â”‚
â”‚  â”‚                                                                  â”‚ â”‚
â”‚  â”‚ Use case: Profile completion, data augmentation                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                       â”‚
â”‚  3. CASCADE OPERATIONS (OpÃ©rations en cascade)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Ã‰vÃ©nement: DELETE sur users                                      â”‚ â”‚
â”‚  â”‚ Action: Supprimer orders, sessions, preferences associÃ©s         â”‚ â”‚
â”‚  â”‚                                                                  â”‚ â”‚
â”‚  â”‚ Use case: Data cleanup, referential integrity                    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                       â”‚
â”‚  4. MATERIALIZED VIEWS (Vues matÃ©rialisÃ©es)                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Ã‰vÃ©nement: INSERT/UPDATE sur orders                              â”‚ â”‚
â”‚  â”‚ Action: Mettre Ã  jour aggregated_stats (totals, counts)          â”‚ â”‚
â”‚  â”‚                                                                  â”‚ â”‚
â”‚  â”‚ Use case: Performance optimization, real-time dashboards         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                       â”‚
â”‚  5. EVENT SOURCING (Source d'Ã©vÃ©nements)                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Ã‰vÃ©nement: Tout changement sur entities                          â”‚ â”‚
â”‚  â”‚ Action: Append to event_log (immutable, ordered)                 â”‚ â”‚
â”‚  â”‚                                                                  â”‚ â”‚
â”‚  â”‚ Use case: Event store, time-travel queries, replay               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                       â”‚
â”‚  6. NOTIFICATION DISPATCH (Distribution notifications)                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Ã‰vÃ©nement: UPDATE status="shipped" sur orders                    â”‚ â”‚
â”‚  â”‚ Action: Email + push notification au client                      â”‚ â”‚
â”‚  â”‚                                                                  â”‚ â”‚
â”‚  â”‚ Use case: User engagement, transactional messages                â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ImplÃ©mentation Audit Trail Robuste

```javascript
// Trigger: Audit complet avec before/after states

exports = async function(changeEvent) {
  const {
    operationType,
    fullDocument,
    fullDocumentBeforeChange,
    documentKey,
    ns,
    clusterTime
  } = changeEvent;

  // Collection d'audit
  const auditCollection = context.services.get("mongodb-atlas")
    .db("audit")
    .collection("change_log");

  // Construire entrÃ©e d'audit
  const auditEntry = {
    // MÃ©tadonnÃ©es Ã©vÃ©nement
    timestamp: new Date(clusterTime.getTime() * 1000),
    operation: operationType,
    collection: `${ns.db}.${ns.coll}`,
    documentId: documentKey._id,

    // User context (si authentifiÃ©)
    userId: context.user ? context.user.id : null,
    userEmail: context.user ? context.user.data.email : null,

    // Before/After states
    before: fullDocumentBeforeChange || null,
    after: fullDocument || null,

    // Changements dÃ©taillÃ©s (delta)
    changes: operationType === "update"
      ? calculateChanges(fullDocumentBeforeChange, fullDocument)
      : null,

    // Contexte applicatif
    source: context.values.get("appVersion") || "unknown",
    environment: context.environment.values.environment || "production"
  };

  try {
    await auditCollection.insertOne(auditEntry);
    console.log(`Audit log created for ${operationType} on ${documentKey._id}`);
  } catch (error) {
    // Logging critique - ne pas bloquer l'opÃ©ration source
    console.error("Failed to create audit log:", error);

    // Optionnel: Dead letter queue pour retry
    await context.functions.execute("sendToDeadLetterQueue", {
      type: "audit_failure",
      data: auditEntry,
      error: error.message
    });
  }
};

// Helper: Calculer diffÃ©rences entre before/after
function calculateChanges(before, after) {
  if (!before || !after) return null;

  const changes = {};
  const allKeys = new Set([...Object.keys(before), ...Object.keys(after)]);

  for (const key of allKeys) {
    if (JSON.stringify(before[key]) !== JSON.stringify(after[key])) {
      changes[key] = {
        from: before[key],
        to: after[key]
      };
    }
  }

  return Object.keys(changes).length > 0 ? changes : null;
}
```

### Data Enrichment avec Rate Limiting

```javascript
// Trigger: Enrichir profil utilisateur avec API externe

exports = async function(changeEvent) {
  const { operationType, fullDocument } = changeEvent;

  // Seulement sur INSERT
  if (operationType !== "insert") return;

  const user = fullDocument;

  // Ã‰viter re-enrichment si dÃ©jÃ  fait
  if (user.enriched) return;

  try {
    // Rate limiting: VÃ©rifier quota disponible
    const rateLimiter = await checkRateLimit("geocoding_api", 1000); // 1000/day
    if (!rateLimiter.allowed) {
      console.warn(`Rate limit exceeded for geocoding API`);
      return; // Skip enrichment, retry demain
    }

    // Appel API gÃ©olocalisation
    const geoData = await enrichWithGeolocation(user.email, user.ipAddress);

    // Appel API donnÃ©es dÃ©mographiques
    const demoData = await enrichWithDemographics(user.email);

    // Mise Ã  jour document utilisateur
    const users = context.services.get("mongodb-atlas")
      .db("mydb")
      .collection("users");

    await users.updateOne(
      { _id: user._id },
      {
        $set: {
          enriched: true,
          enrichedAt: new Date(),
          geolocation: geoData,
          demographics: demoData
        }
      }
    );

    console.log(`User ${user._id} enriched successfully`);

  } catch (error) {
    console.error(`Failed to enrich user ${user._id}:`, error);

    // Marquer pour retry ultÃ©rieur
    await users.updateOne(
      { _id: user._id },
      {
        $set: {
          enrichmentFailed: true,
          enrichmentError: error.message,
          enrichmentRetryAt: new Date(Date.now() + 3600000) // 1h
        }
      }
    );
  }
};

// Helper: Rate limiting simple
async function checkRateLimit(key, maxPerDay) {
  const rateLimits = context.services.get("mongodb-atlas")
    .db("system")
    .collection("rate_limits");

  const today = new Date().toISOString().split('T')[0];
  const limitDoc = await rateLimits.findOne({ key, date: today });

  if (!limitDoc) {
    await rateLimits.insertOne({ key, date: today, count: 1 });
    return { allowed: true, remaining: maxPerDay - 1 };
  }

  if (limitDoc.count >= maxPerDay) {
    return { allowed: false, remaining: 0 };
  }

  await rateLimits.updateOne(
    { key, date: today },
    { $inc: { count: 1 } }
  );

  return { allowed: true, remaining: maxPerDay - limitDoc.count - 1 };
}
```

---

## â° Scheduled Triggers AvancÃ©s

### Patterns de Scheduling

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   SCHEDULED TRIGGER PATTERNS                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚  CRON EXPRESSIONS COURANTES:                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚  "0 0 * * *"      â†’ Daily at midnight                                 â”‚
â”‚  "0 */6 * * *"    â†’ Every 6 hours                                     â”‚
â”‚  "*/15 * * * *"   â†’ Every 15 minutes                                  â”‚
â”‚  "0 9 * * 1"      â†’ Every Monday at 9 AM                              â”‚
â”‚  "0 0 1 * *"      â†’ First day of month at midnight                    â”‚
â”‚                                                                       â”‚
â”‚  USE CASES:                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ 1. Data Cleanup (Nettoyage)                                      â”‚ â”‚
â”‚  â”‚    â€¢ Delete old logs (> 30 days)                                 â”‚ â”‚
â”‚  â”‚    â€¢ Archive completed orders                                    â”‚ â”‚
â”‚  â”‚    â€¢ Purge temporary files                                       â”‚ â”‚
â”‚  â”‚    Schedule: Daily at 2 AM                                       â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚ 2. Report Generation (Rapports)                                  â”‚ â”‚
â”‚  â”‚    â€¢ Daily sales report                                          â”‚ â”‚
â”‚  â”‚    â€¢ Weekly analytics summary                                    â”‚ â”‚
â”‚  â”‚    â€¢ Monthly financial close                                     â”‚ â”‚
â”‚  â”‚    Schedule: Variable selon type                                 â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚ 3. Data Sync (Synchronisation)                                   â”‚ â”‚
â”‚  â”‚    â€¢ Sync to data warehouse                                      â”‚ â”‚
â”‚  â”‚    â€¢ Export to S3/Data Lake                                      â”‚ â”‚
â”‚  â”‚    â€¢ Update external systems                                     â”‚ â”‚
â”‚  â”‚    Schedule: Hourly or continuous                                â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚ 4. Health Checks (Surveillance)                                  â”‚ â”‚
â”‚  â”‚    â€¢ Monitor system metrics                                      â”‚ â”‚
â”‚  â”‚    â€¢ Check service availability                                  â”‚ â”‚
â”‚  â”‚    â€¢ Alert on anomalies                                          â”‚ â”‚
â”‚  â”‚    Schedule: Every 5 minutes                                     â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚ 5. Batch Processing (Traitement par lots)                        â”‚ â”‚
â”‚  â”‚    â€¢ Process pending jobs                                        â”‚ â”‚
â”‚  â”‚    â€¢ Send scheduled notifications                                â”‚ â”‚
â”‚  â”‚    â€¢ Update materialized views                                   â”‚ â”‚
â”‚  â”‚    Schedule: Every 15 minutes                                    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Scheduled Trigger avec Checkpointing

```javascript
// Trigger: Traitement batch incrÃ©mental avec checkpointing

exports = async function() {
  const startTime = Date.now();
  const maxExecutionTime = 80000; // 80 secondes (limite: 90s)

  const db = context.services.get("mongodb-atlas").db("mydb");
  const jobsCollection = db.collection("pending_jobs");
  const checkpointCollection = db.collection("job_checkpoints");

  // RÃ©cupÃ©rer dernier checkpoint
  let checkpoint = await checkpointCollection.findOne({
    jobType: "daily_processing"
  });

  if (!checkpoint) {
    checkpoint = {
      jobType: "daily_processing",
      lastProcessedId: null,
      lastProcessedAt: null,
      processedCount: 0
    };
  }

  let processedCount = 0;
  let lastProcessedId = checkpoint.lastProcessedId;

  try {
    // Query incrÃ©mentale: Traiter jobs aprÃ¨s dernier checkpoint
    const query = lastProcessedId
      ? { _id: { $gt: lastProcessedId }, status: "pending" }
      : { status: "pending" };

    const jobs = await jobsCollection
      .find(query)
      .sort({ _id: 1 })
      .limit(100)
      .toArray();

    console.log(`Found ${jobs.length} pending jobs to process`);

    // Traiter jobs avec time limit
    for (const job of jobs) {
      // Check time limit
      if (Date.now() - startTime > maxExecutionTime) {
        console.log(`Time limit reached. Stopping at job ${job._id}`);
        break;
      }

      try {
        // Process job (votre logique mÃ©tier)
        await processJob(job);

        // Marquer comme traitÃ©
        await jobsCollection.updateOne(
          { _id: job._id },
          {
            $set: {
              status: "completed",
              processedAt: new Date()
            }
          }
        );

        processedCount++;
        lastProcessedId = job._id;

      } catch (error) {
        console.error(`Failed to process job ${job._id}:`, error);

        // Marquer comme failed
        await jobsCollection.updateOne(
          { _id: job._id },
          {
            $set: {
              status: "failed",
              error: error.message,
              failedAt: new Date()
            },
            $inc: { retryCount: 1 }
          }
        );
      }
    }

    // Sauvegarder checkpoint
    await checkpointCollection.updateOne(
      { jobType: "daily_processing" },
      {
        $set: {
          lastProcessedId: lastProcessedId,
          lastProcessedAt: new Date(),
          processedCount: checkpoint.processedCount + processedCount
        }
      },
      { upsert: true }
    );

    console.log(`Processed ${processedCount} jobs. Checkpoint saved.`);

    return {
      success: true,
      processedCount,
      totalProcessed: checkpoint.processedCount + processedCount
    };

  } catch (error) {
    console.error("Batch processing failed:", error);
    throw error;
  }
};

async function processJob(job) {
  // Votre logique mÃ©tier
  // Ex: Envoyer email, appeler API, transformer donnÃ©es, etc.

  // Simuler traitement
  await new Promise(resolve => setTimeout(resolve, 100));

  console.log(`Job ${job._id} processed`);
}
```

---

## ğŸ”— Orchestration de Workflows

### Pattern Chain of Responsibility

```javascript
// Workflow: Order Processing en plusieurs Ã©tapes

// Ã‰TAPE 1: Trigger sur INSERT order
exports = async function(changeEvent) {
  const order = changeEvent.fullDocument;

  if (changeEvent.operationType !== "insert") return;

  console.log(`New order received: ${order._id}`);

  // DÃ©marrer workflow
  await context.functions.execute("processOrderWorkflow", order._id);
};

// FONCTION: Orchestrateur de workflow
exports = async function(orderId) {
  const db = context.services.get("mongodb-atlas").db("mydb");
  const orders = db.collection("orders");

  try {
    // Ã‰tape 1: Validation
    console.log(`Step 1: Validating order ${orderId}`);
    const validationResult = await context.functions.execute(
      "validateOrder",
      orderId
    );

    if (!validationResult.valid) {
      await orders.updateOne(
        { _id: orderId },
        {
          $set: {
            status: "validation_failed",
            validationError: validationResult.error
          }
        }
      );
      return { success: false, step: "validation" };
    }

    // Ã‰tape 2: VÃ©rifier inventaire
    console.log(`Step 2: Checking inventory for order ${orderId}`);
    const inventoryCheck = await context.functions.execute(
      "checkInventory",
      orderId
    );

    if (!inventoryCheck.available) {
      await orders.updateOne(
        { _id: orderId },
        { $set: { status: "out_of_stock" } }
      );

      // Notifier client
      await context.functions.execute("notifyOutOfStock", orderId);
      return { success: false, step: "inventory" };
    }

    // Ã‰tape 3: Traiter paiement
    console.log(`Step 3: Processing payment for order ${orderId}`);
    const paymentResult = await context.functions.execute(
      "processPayment",
      orderId
    );

    if (!paymentResult.success) {
      await orders.updateOne(
        { _id: orderId },
        {
          $set: {
            status: "payment_failed",
            paymentError: paymentResult.error
          }
        }
      );
      return { success: false, step: "payment" };
    }

    // Ã‰tape 4: RÃ©server inventaire
    console.log(`Step 4: Reserving inventory for order ${orderId}`);
    await context.functions.execute("reserveInventory", orderId);

    // Ã‰tape 5: CrÃ©er commande d'expÃ©dition
    console.log(`Step 5: Creating shipment for order ${orderId}`);
    const shipmentId = await context.functions.execute(
      "createShipment",
      orderId
    );

    // Ã‰tape 6: Confirmer commande
    await orders.updateOne(
      { _id: orderId },
      {
        $set: {
          status: "confirmed",
          confirmedAt: new Date(),
          shipmentId: shipmentId,
          paymentTransactionId: paymentResult.transactionId
        }
      }
    );

    // Ã‰tape 7: Notification client
    await context.functions.execute("sendOrderConfirmation", orderId);

    console.log(`Order ${orderId} processed successfully`);
    return { success: true, shipmentId };

  } catch (error) {
    console.error(`Workflow failed for order ${orderId}:`, error);

    // Marquer comme erreur et programmer retry
    await orders.updateOne(
      { _id: orderId },
      {
        $set: {
          status: "processing_error",
          error: error.message,
          retryAt: new Date(Date.now() + 300000) // Retry dans 5 min
        }
      }
    );

    throw error;
  }
};
```

---

## ğŸ›¡ï¸ Error Handling et Retry

### Pattern Circuit Breaker

```javascript
// Circuit Breaker pour appels API externes

class CircuitBreaker {
  constructor(functionName, threshold = 5, timeout = 60000) {
    this.functionName = functionName;
    this.threshold = threshold;
    this.timeout = timeout;
    this.state = "CLOSED"; // CLOSED, OPEN, HALF_OPEN
    this.failureCount = 0;
    this.lastFailureTime = null;
  }

  async execute(apiCall) {
    // Ã‰tat OPEN: Rejeter immÃ©diatement
    if (this.state === "OPEN") {
      if (Date.now() - this.lastFailureTime > this.timeout) {
        console.log(`Circuit breaker: Transitioning to HALF_OPEN`);
        this.state = "HALF_OPEN";
      } else {
        throw new Error(`Circuit breaker OPEN for ${this.functionName}`);
      }
    }

    try {
      const result = await apiCall();

      // SuccÃ¨s: Reset
      if (this.state === "HALF_OPEN") {
        console.log(`Circuit breaker: Transitioning to CLOSED`);
        this.state = "CLOSED";
        this.failureCount = 0;
      }

      return result;

    } catch (error) {
      this.failureCount++;
      this.lastFailureTime = Date.now();

      console.error(`Circuit breaker: Failure ${this.failureCount}/${this.threshold}`);

      // Trop d'Ã©checs: Ouvrir circuit
      if (this.failureCount >= this.threshold) {
        console.error(`Circuit breaker: Opening circuit for ${this.functionName}`);
        this.state = "OPEN";
      }

      throw error;
    }
  }
}

// Usage dans fonction
const paymentApiBreaker = new CircuitBreaker("payment_api", 5, 60000);

exports = async function(orderId) {
  try {
    const result = await paymentApiBreaker.execute(async () => {
      // Appel API paiement
      return await context.http.post({
        url: "https://payment-gateway.com/charge",
        body: { orderId },
        headers: { "Authorization": "Bearer ..." }
      });
    });

    return { success: true, transactionId: result.body.id };

  } catch (error) {
    // Circuit breaker ouvert ou erreur API
    console.error("Payment failed:", error.message);
    return { success: false, error: error.message };
  }
};
```

### Exponential Backoff Retry

```javascript
// Helper: Retry avec exponential backoff

async function retryWithBackoff(
  operation,
  maxRetries = 3,
  initialDelay = 1000,
  maxDelay = 30000
) {
  let lastError;

  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    try {
      return await operation();
    } catch (error) {
      lastError = error;

      if (attempt === maxRetries) {
        console.error(`Max retries (${maxRetries}) reached`);
        throw error;
      }

      // Calculer dÃ©lai: 2^attempt * initialDelay
      const delay = Math.min(
        initialDelay * Math.pow(2, attempt),
        maxDelay
      );

      // Ajouter jitter (Â±20%)
      const jitter = delay * (0.8 + Math.random() * 0.4);

      console.log(`Retry ${attempt + 1}/${maxRetries} after ${Math.round(jitter)}ms`);
      await new Promise(resolve => setTimeout(resolve, jitter));
    }
  }

  throw lastError;
}

// Usage
exports = async function(orderId) {
  const result = await retryWithBackoff(
    async () => {
      // OpÃ©ration potentiellement instable
      return await context.http.post({
        url: "https://unstable-api.com/process",
        body: { orderId }
      });
    },
    3,    // Max 3 retries
    1000, // Initial delay 1s
    10000 // Max delay 10s
  );

  return result;
};
```

---

## ğŸ“Š Monitoring et ObservabilitÃ©

### Structured Logging

```javascript
// Pattern: Structured logging pour observabilitÃ©

class Logger {
  constructor(context, functionName) {
    this.context = context;
    this.functionName = functionName;
    this.correlationId = this.generateCorrelationId();
  }

  generateCorrelationId() {
    return `${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
  }

  log(level, message, metadata = {}) {
    const logEntry = {
      timestamp: new Date().toISOString(),
      level: level,
      function: this.functionName,
      correlationId: this.correlationId,
      message: message,
      userId: this.context.user?.id || null,
      environment: this.context.environment?.values?.environment || "unknown",
      ...metadata
    };

    // Log to console (captured by Atlas)
    console.log(JSON.stringify(logEntry));

    // Optionnel: Log to collection pour analytics
    if (level === "ERROR" || level === "WARN") {
      this.persistLog(logEntry);
    }
  }

  async persistLog(logEntry) {
    try {
      const logs = this.context.services.get("mongodb-atlas")
        .db("logs")
        .collection("function_logs");

      await logs.insertOne(logEntry);
    } catch (error) {
      // Fail silently - ne pas bloquer fonction
      console.error("Failed to persist log:", error);
    }
  }

  info(message, metadata) {
    this.log("INFO", message, metadata);
  }

  warn(message, metadata) {
    this.log("WARN", message, metadata);
  }

  error(message, error, metadata) {
    this.log("ERROR", message, {
      ...metadata,
      error: {
        message: error.message,
        stack: error.stack,
        name: error.name
      }
    });
  }
}

// Usage dans fonction
exports = async function(orderId) {
  const logger = new Logger(context, "processOrder");

  logger.info("Processing order started", { orderId });

  try {
    const order = await fetchOrder(orderId);
    logger.info("Order fetched", { orderId, status: order.status });

    await validateOrder(order);
    logger.info("Order validated", { orderId });

    const result = await processPayment(order);
    logger.info("Payment processed", {
      orderId,
      transactionId: result.transactionId,
      amount: order.total
    });

    return { success: true };

  } catch (error) {
    logger.error("Order processing failed", error, { orderId });
    throw error;
  }
};
```

### MÃ©triques Custom

```javascript
// Pattern: Collecter mÃ©triques custom pour monitoring

exports = async function() {
  const startTime = Date.now();

  const metrics = context.services.get("mongodb-atlas")
    .db("metrics")
    .collection("function_metrics");

  let processedCount = 0;
  let errorCount = 0;

  try {
    // Votre logique
    const jobs = await fetchPendingJobs();

    for (const job of jobs) {
      try {
        await processJob(job);
        processedCount++;
      } catch (error) {
        errorCount++;
      }
    }

  } finally {
    // Enregistrer mÃ©triques
    const duration = Date.now() - startTime;

    await metrics.insertOne({
      functionName: "batchProcessor",
      timestamp: new Date(),
      duration: duration,
      processedCount: processedCount,
      errorCount: errorCount,
      successRate: processedCount / (processedCount + errorCount) || 0,
      environment: context.environment.values.environment
    });

    console.log(JSON.stringify({
      event: "function_completed",
      duration,
      processedCount,
      errorCount
    }));
  }
};

// Query mÃ©triques pour dashboards
db.function_metrics.aggregate([
  {
    $match: {
      timestamp: { $gte: new Date(Date.now() - 86400000) } // Last 24h
    }
  },
  {
    $group: {
      _id: {
        function: "$functionName",
        hour: { $hour: "$timestamp" }
      },
      avgDuration: { $avg: "$duration" },
      totalProcessed: { $sum: "$processedCount" },
      totalErrors: { $sum: "$errorCount" },
      avgSuccessRate: { $avg: "$successRate" }
    }
  }
]);
```

---

## ğŸš€ CI/CD et Infrastructure-as-Code

### DÃ©ploiement avec Atlas CLI

```bash
#!/bin/bash
# deploy-functions.sh - Deploy functions via CI/CD

set -e

PROJECT_ID="your-project-id"
APP_ID="your-app-id"

echo "ğŸ“¦ Deploying Atlas Functions..."

# 1. Pull current configuration
atlas app describe $APP_ID \
  --project $PROJECT_ID \
  --output json > app-config.json

# 2. Update functions directory
cp -r ./functions/* ./atlas-app/functions/

# 3. Deploy (push changes)
atlas app deploy $APP_ID \
  --project $PROJECT_ID \
  --include-node-modules \
  --include-package-json

echo "âœ… Deployment complete"

# 4. Smoke test
echo "ğŸ§ª Running smoke tests..."
atlas app logs tail $APP_ID \
  --project $PROJECT_ID \
  --type function \
  --limit 10

echo "âœ… All done!"
```

### Configuration as Code

```json
// app-config.json - Atlas App Services configuration

{
  "name": "production-app",
  "config_version": 20210101,

  "functions": [
    {
      "name": "processOrder",
      "source": "functions/processOrder.js",
      "can_evaluate": {},
      "run_as_system": true
    }
  ],

  "triggers": [
    {
      "name": "onOrderInsert",
      "type": "DATABASE",
      "config": {
        "operation_types": ["INSERT"],
        "database": "mydb",
        "collection": "orders",
        "full_document": true,
        "full_document_before_change": false,
        "unordered": false
      },
      "function_name": "processOrder",
      "disabled": false
    },
    {
      "name": "dailyCleanup",
      "type": "SCHEDULED",
      "config": {
        "schedule": "0 2 * * *"
      },
      "function_name": "cleanupOldData",
      "disabled": false
    }
  ],

  "values": [
    {
      "name": "apiKey",
      "from_secret": true,
      "value": "secret-api-key"
    },
    {
      "name": "environment",
      "value": "production"
    }
  ]
}
```

---

## ğŸ“‹ Best Practices

### Checklist Production

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           TRIGGERS & FUNCTIONS PRODUCTION CHECKLIST                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚  DESIGN                                                               â”‚
â”‚  â˜ Fonctions idempotentes (safe to retry)                             â”‚
â”‚  â˜ Single Responsibility Principle                                    â”‚
â”‚  â˜ Timeouts appropriÃ©s (< 90s execution)                              â”‚
â”‚  â˜ DÃ©couplage via event-driven patterns                               â”‚
â”‚  â˜ Ã‰viter database triggers en cascade (boucles infinies)             â”‚
â”‚                                                                       â”‚
â”‚  ERROR HANDLING                                                       â”‚
â”‚  â˜ Try/catch sur toutes opÃ©rations externes                           â”‚
â”‚  â˜ Retry logic avec exponential backoff                               â”‚
â”‚  â˜ Circuit breaker pour APIs externes                                 â”‚
â”‚  â˜ Dead letter queue pour Ã©checs critiques                            â”‚
â”‚  â˜ Graceful degradation (fallbacks)                                   â”‚
â”‚                                                                       â”‚
â”‚  PERFORMANCE                                                          â”‚
â”‚  â˜ Limiter itÃ©rations (batch size, time limits)                       â”‚
â”‚  â˜ Utiliser indexes pour queries                                      â”‚
â”‚  â˜ Checkpointing pour scheduled triggers                              â”‚
â”‚  â˜ ParallÃ©lisation si possible (Promise.all)                          â”‚
â”‚  â˜ Ã‰viter N+1 queries                                                 â”‚
â”‚                                                                       â”‚
â”‚  OBSERVABILITY                                                        â”‚
â”‚  â˜ Structured logging (JSON format)                                   â”‚
â”‚  â˜ Correlation IDs pour traÃ§abilitÃ©                                   â”‚
â”‚  â˜ MÃ©triques custom (durÃ©e, counts, errors)                           â”‚
â”‚  â˜ Alerting sur erreurs critiques                                     â”‚
â”‚  â˜ Logs accessibles via Atlas UI                                      â”‚
â”‚                                                                       â”‚
â”‚  SECURITY                                                             â”‚
â”‚  â˜ Secrets dans Values (jamais hardcodÃ©s)                             â”‚
â”‚  â˜ Validation inputs                                                  â”‚
â”‚  â˜ Rate limiting sur fonctions exposÃ©es                               â”‚
â”‚  â˜ Permissions minimales (principle of least privilege)               â”‚
â”‚  â˜ Audit trail pour opÃ©rations sensibles                              â”‚
â”‚                                                                       â”‚
â”‚  CI/CD                                                                â”‚
â”‚  â˜ Version control (Git)                                              â”‚
â”‚  â˜ Automated testing (unit, integration)                              â”‚
â”‚  â˜ Deploy via Atlas CLI                                               â”‚
â”‚  â˜ Staging environment pour tests                                     â”‚
â”‚  â˜ Rollback procedure documentÃ©e                                      â”‚
â”‚                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ RÃ©sumÃ©

### Points ClÃ©s

1. **Event-Driven Architecture**
   - Database triggers (onChange)
   - Scheduled triggers (cron)
   - DÃ©couplage et scalabilitÃ©
   - RÃ©silience built-in

2. **Patterns AvancÃ©s**
   - Audit trail complet
   - Data enrichment
   - Workflow orchestration
   - Materialized views

3. **Error Handling**
   - Retry avec exponential backoff
   - Circuit breaker
   - Dead letter queue
   - Graceful degradation

4. **ObservabilitÃ©**
   - Structured logging
   - Correlation IDs
   - Custom metrics
   - Monitoring dashboards

5. **DevOps**
   - Infrastructure-as-Code
   - CI/CD avec Atlas CLI
   - Automated testing
   - Rollback procedures

### Configuration Minimale Production

```javascript
// Function template avec best practices
exports = async function(changeEvent) {
  const logger = new Logger(context, "myFunction");
  const startTime = Date.now();

  try {
    logger.info("Function started", {
      operationType: changeEvent.operationType,
      documentId: changeEvent.documentKey._id
    });

    // Votre logique avec retry
    const result = await retryWithBackoff(
      () => processEvent(changeEvent),
      3,
      1000
    );

    logger.info("Function completed", {
      duration: Date.now() - startTime,
      result
    });

    return result;

  } catch (error) {
    logger.error("Function failed", error, {
      duration: Date.now() - startTime
    });

    // Dead letter queue
    await sendToDeadLetterQueue(changeEvent, error);

    throw error;
  }
};
```

### Ressources

- [App Services Triggers](https://www.mongodb.com/docs/atlas/app-services/triggers/)
- [Functions Reference](https://www.mongodb.com/docs/atlas/app-services/functions/)
- [Atlas CLI](https://www.mongodb.com/docs/atlas/cli/stable/)

---


â­ï¸ [Data API](/14-mongodb-atlas/15-data-api.md)
