üîù Retour au [Sommaire](/SOMMAIRE.md)

# 9.3.1 Primary

## Introduction

Le **Primary** est le membre central d'un Replica Set MongoDB, occupant le r√¥le de leader unique dans l'architecture single-leader. C'est le seul n≈ìud autoris√© √† accepter les op√©rations d'√©criture, ce qui en fait le point n√©vralgique du syst√®me de r√©plication. Comprendre les m√©canismes internes du Primary, ses responsabilit√©s, ses contraintes et ses modes de d√©faillance est crucial pour op√©rer des syst√®mes MongoDB en production.

Cette section explore en profondeur le fonctionnement du Primary, de l'acceptation des √©critures √† la g√©n√©ration de l'Oplog, en passant par les m√©canismes de step down et les consid√©rations de performance.

## R√¥le et Responsabilit√©s

### Responsabilit√© Principale : Acceptation des √âcritures

Le Primary est l'**unique point d'√©criture** du Replica Set. Cette propri√©t√© fondamentale d√©coule du mod√®le single-leader et garantit :

#### Ordre Total des √âcritures

Toutes les op√©rations d'√©criture passent par un seul n≈ìud, √©tablissant un **ordre total global** :

```
Temps ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>

Client A:  INSERT doc1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>
                           Primary: INSERT doc1 (ts: 1)
                                    ‚Üì
                                    Oplog: [INSERT doc1, ts: 1]

Client B:         UPDATE doc2 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>
                           Primary: UPDATE doc2 (ts: 2)
                                    ‚Üì
                                    Oplog: [INSERT doc1, ts: 1]
                                            [UPDATE doc2, ts: 2]
```

Cet ordre total simplifie consid√©rablement le mod√®le de coh√©rence et √©limine les conflits d'√©criture qui existeraient dans un syst√®me multi-leader.

#### Absence de Conflits d'√âcriture

Contrairement aux syst√®mes multi-master (Cassandra, CouchDB), MongoDB n'a pas besoin de :
- D√©tecter les conflits d'√©criture concurrentes
- R√©soudre les conflits via des strat√©gies (last-write-wins, vector clocks, CRDTs)
- Maintenir des versions multiples pour r√©conciliation

Le Primary s√©rialise toutes les √©critures, √©liminant structurellement les conflits.

#### Atomicit√© au Niveau Document

Le Primary garantit l'atomicit√© de toutes les op√©rations sur un document unique :
- Une op√©ration d'√©criture sur un document r√©ussit ou √©choue enti√®rement
- Aucune lecture ne peut observer un √©tat interm√©diaire
- Applicable m√™me pour des op√©rations complexes (`findAndModify`, mises √† jour multi-champs)

Depuis MongoDB 4.0, cette atomicit√© s'√©tend aux transactions multi-documents.

### G√©n√©ration de l'Oplog

Une responsabilit√© critique du Primary est la **transformation des op√©rations applicatives en entr√©es Oplog**.

#### Processus de Transformation

Lorsqu'une √©criture est effectu√©e :

1. **R√©ception** : Le Primary re√ßoit l'op√©ration du client (insert, update, delete, etc.)

2. **Ex√©cution** : L'op√©ration est ex√©cut√©e sur le dataset local avec le moteur de stockage WiredTiger

3. **Transformation** : L'op√©ration est transform√©e en format idempotent pour l'Oplog

4. **√âcriture Oplog** : L'entr√©e est ajout√©e √† `local.oplog.rs` avec un timestamp unique

5. **Accus√© de r√©ception** : Selon le Write Concern, le Primary peut attendre la r√©plication avant d'ACK

**Exemple de transformation** :

Op√©ration client (non-idempotente) :
```javascript
db.counters.updateOne(
  { _id: "pageviews" },
  { $inc: { count: 1 } }
)
```

Oplog entry (idempotente) :
```javascript
{
  "ts": Timestamp(1638360000, 1),
  "t": NumberLong(5),
  "op": "u",
  "ns": "analytics.counters",
  "ui": UUID("..."),
  "o": {
    "$v": 2,
    "diff": { "u": { "count": 12345 } }  // Valeur finale, pas l'incr√©ment
  },
  "o2": { "_id": "pageviews" }
}
```

La transformation garantit que l'op√©ration peut √™tre appliqu√©e plusieurs fois (idempotence), essentiel pour la r√©plication fiable.

#### OpTime : Horodatage Logique

Chaque op√©ration se voit attribuer un **OpTime**, un tuple `(term, timestamp)` :

```javascript
{
  "ts": Timestamp(1638360000, 42),  // BSON Timestamp
  "t": NumberLong(5)                // Term number
}
```

**Composants** :

- **Timestamp BSON** (8 octets) :
  - 4 octets : Secondes depuis epoch Unix
  - 4 octets : Compteur ordinal (incr√©ment√© pour chaque op√©ration dans la m√™me seconde)
  - Garantit l'ordre total m√™me avec des millions d'ops/sec

- **Term** :
  - Num√©ro de mandat du Primary actuel
  - Incr√©ment√© √† chaque √©lection
  - Permet de d√©tecter les Oplog "obsol√®tes" apr√®s failover

**Propri√©t√©s** :

- **Monotonie stricte** : OpTime(n+1) > OpTime(n) toujours
- **Globalit√©** : Comparable entre tous les membres du Replica Set
- **Causalit√©** : Si OpA < OpB, alors OpA happened-before OpB

### Propagation aux Secondaries

Le Primary ne propage pas activement l'Oplog ; ce sont les **Secondaries qui "tirent" (pull)** les donn√©es :

#### M√©canisme de Pull

1. Chaque Secondary maintient un **tailable cursor** sur `local.oplog.rs` du Primary
2. Le cursor reste ouvert et suit les nouvelles entr√©es au fur et √† mesure
3. Les Secondaries r√©cup√®rent les op√©rations par batches (pour efficacit√©)
4. Les op√©rations sont appliqu√©es localement dans le m√™me ordre

**Avantages du pull** :
- Le Primary n'a pas √† g√©rer N connexions de push vers les Secondaries
- Les Secondaries contr√¥lent leur rythme de r√©plication (back-pressure naturel)
- R√©silience : un Secondary lent n'affecte pas les autres

**Optimisations** :

- **Oplog batching** : R√©cup√©ration de 100-1000 ops par requ√™te (configurable)
- **Parallel replication** : Depuis MongoDB 4.0, application parall√®le des op√©rations non-conflictuelles
- **Compression** : Les donn√©es Oplog peuvent √™tre compress√©es (snappy, zstd)

### Service des Lectures

Bien que les √©critures soient exclusives au Primary, celui-ci peut √©galement servir les lectures :

#### Read Preference "primary"

Configuration par d√©faut : toutes les lectures sont dirig√©es vers le Primary.

**Avantages** :
- **Coh√©rence forte** : Les lectures voient toujours les √©critures les plus r√©centes
- **Pas de replication lag** : Pas de probl√®me de donn√©es obsol√®tes
- **Simplicit√©** : Mod√®le mental direct pour les d√©veloppeurs

**Inconv√©nients** :
- **Charge concentr√©e** : Le Primary g√®re √©critures + lectures
- **Scalabilit√© limit√©e** : Le throughput de lecture est limit√© par un seul n≈ìud
- **Point de contention** : Augmentation de la latence sous charge √©lev√©e

#### Combinaisons avec d'Autres Read Preferences

Le Primary peut servir les lectures m√™me avec d'autres modes :

- **primaryPreferred** : Primary si disponible (fallback sur Secondary)
- **secondaryPreferred** : Secondary pr√©f√©r√© mais Primary en dernier recours
- **nearest** : Le Primary peut √™tre s√©lectionn√© s'il est le plus proche g√©ographiquement

### Heartbeats et Maintien de la Majorit√©

Le Primary doit maintenir une **communication active avec la majorit√©** des membres :

#### Envoi de Heartbeats

Le Primary envoie des heartbeats p√©riodiques (toutes les 2 secondes par d√©faut) √† tous les autres membres, transportant :

- Son √©tat (PRIMARY)
- Son OpTime actuel (position dans l'Oplog)
- Des m√©tadonn√©es de sant√© et de configuration

#### D√©tection de Perte de Quorum

Si le Primary ne peut plus communiquer avec la majorit√© des membres votants, il se d√©grade automatiquement :

**Sc√©nario : Partition R√©seau**

```
Avant partition:
  [Primary] ‚Üê‚Üí [Sec1] ‚Üê‚Üí [Sec2]
     ‚Üë                      ‚Üë
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Apr√®s partition (Primary isol√©):
  [Primary]  X  [Sec1] ‚Üê‚Üí [Sec2]

Action: Primary d√©tecte qu'il ne peut atteindre la majorit√©
‚Üí Ex√©cute step down automatique
‚Üí Devient SECONDARY
‚Üí Rejette toutes les nouvelles √©critures
```

**M√©canisme** :
- Le Primary compte les membres accessibles (heartbeat success)
- Si `membres_accessibles < quorum`, le Primary initie un **step down**
- Transition vers l'√©tat SECONDARY
- Une √©lection d√©marre parmi les membres ayant le quorum (Sec1, Sec2)

Cette auto-d√©gradation √©vite le **split-brain** : deux Primary simultan√©s acceptant des √©critures divergentes.

## M√©canismes Internes

### Architecture du Primary

Le Primary MongoDB s'appuie sur plusieurs composants internes interconnect√©s :

#### Moteur de Stockage (WiredTiger)

**Responsabilit√©s** :
- Persistance des donn√©es sur disque
- Gestion de la m√©moire (cache)
- Transactions MVCC (Multi-Version Concurrency Control)
- Journalisation (WAL - Write-Ahead Log)

**Flux d'√©criture** :

1. **√âcriture en m√©moire** : Modification dans le cache WiredTiger
2. **Journal WiredTiger** : √âcriture dans le journal (si `j: true`)
3. **Checkpoint p√©riodique** : Flush du cache vers disque (toutes les 60s par d√©faut)
4. **Oplog** : √âcriture parall√®le dans `local.oplog.rs`

**Isolation** :
- WiredTiger utilise MVCC avec snapshot isolation
- Plusieurs transactions peuvent lire/√©crire simultan√©ment
- Conflicts r√©solus au moment du commit

#### Oplog Writer

Composant d√©di√© √† la g√©n√©ration et l'√©criture de l'Oplog :

**Pipeline** :
```
Client Write ‚Üí Storage Engine ‚Üí Oplog Transform ‚Üí Oplog Writer ‚Üí local.oplog.rs
                    ‚Üì
               Data Collection
```

**Optimisations** :
- **Batching** : Multiples op√©rations √©crites ensemble dans l'Oplog
- **Compression** : R√©duction de la taille via snappy/zstd
- **Buffering** : Utilisation d'un buffer en m√©moire avant flush disque

#### Replication Coordinator

G√®re l'√©tat de la r√©plication et les interactions avec les Secondaries :

**Fonctions** :
- Suivi de l'OpTime de chaque membre (qui est √† jour, qui est en retard)
- Calcul du commit point (jusqu'o√π les donn√©es sont durable sur la majorit√©)
- Gestion du Write Concern (attente de la r√©plication)
- D√©tection des Secondaries d√©faillants

**Commit Point** :
Le commit point est l'OpTime jusqu'auquel les donn√©es ont √©t√© r√©pliqu√©es sur la majorit√© :

```
Primary:  OpTime = 1000  (derni√®re √©criture)
Sec1:     OpTime = 998   (2 ops en retard)
Sec2:     OpTime = 995   (5 ops en retard)

Commit Point = 995  (min de la majorit√© = Primary, Sec1, Sec2)
                     (OpTime durable sur >= 2 membres)
```

Avec `readConcern: "majority"`, seules les donn√©es jusqu'au commit point sont retourn√©es.

### Write Concern et Durabilit√©

Le Primary g√®re diff√©rents niveaux de Write Concern pour √©quilibrer performance et durabilit√© :

#### w: 1 (ACK Imm√©diat)

**Comportement** :
- Le Primary accuse r√©ception d√®s que l'√©criture est en m√©moire (cache WiredTiger)
- Aucune attente de r√©plication sur les Secondaries
- Si `j: false` (d√©faut pour `w: 1`), pas d'attente du journal

**Performance** : Latence minimale (~1-2 ms)

**Risque** :
- Perte de donn√©es si crash avant flush disque
- Perte de donn√©es si Primary tombe avant r√©plication

**Cas d'usage** :
- Donn√©es non-critiques (logs, m√©triques temporaires)
- Environnements avec r√©plication tr√®s rapide
- Prototypage et d√©veloppement

#### w: "majority" (ACK apr√®s R√©plication)

**Comportement** :
- Le Primary attend que l'op√©ration soit r√©pliqu√©e sur la majorit√© des membres votants
- Garantit la durabilit√© : l'op√©ration survivra √† la perte du Primary
- Depuis MongoDB 5.0, c'est le **d√©faut global**

**Performance** : Latence accrue par la r√©plication (~5-20 ms intra-DC, 50-200 ms inter-DC)

**Impl√©mentation** :

```javascript
// Interne au Primary
function waitForMajority(opTime) {
  let replicatedOn = [this]  // Le Primary lui-m√™me

  while (true) {
    for (secondary in secondaries) {
      if (secondary.lastAppliedOpTime >= opTime) {
        replicatedOn.push(secondary)
      }
    }

    if (replicatedOn.length >= quorum) {
      return SUCCESS
    }

    if (timeout) {
      return ERROR
    }

    sleep(10ms)  // Polling ou notification
  }
}
```

**Garantie** : Les donn√©es committ√©es avec `w: "majority"` ne seront **jamais rollback**.

#### w: \<nombre\> (ACK sur N Membres)

**Comportement** :
- Le Primary attend la r√©plication sur exactement N membres (incluant lui-m√™me)
- `w: 2` = Primary + 1 Secondary
- `w: 3` = Primary + 2 Secondaries

**Cas d'usage** :
```javascript
// Garantir r√©plication sur 3 membres sp√©cifiques
db.collection.insertOne(
  { data: "critical" },
  { writeConcern: { w: 3, wtimeout: 5000 } }
)
```

#### w: \<tag set\> (ACK par Tag)

**Comportement** :
- Attend la r√©plication sur des membres ayant des tags sp√©cifiques
- Utile pour garantir la r√©plication g√©ographique

**Configuration** :
```javascript
// Replica Set config
cfg.settings.getLastErrorModes = {
  multiDC: { dc: 2 }  // Au moins 2 datacenters diff√©rents
}

// √âcriture avec garantie multi-DC
db.collection.insertOne(
  { data: "geo-replicated" },
  { writeConcern: { w: "multiDC", wtimeout: 10000 } }
)
```

#### j: true (Journal)

**Comportement** :
- Attend que l'op√©ration soit √©crite dans le journal WiredTiger (WAL)
- Garantit la durabilit√© m√™me en cas de crash brutal (perte d'alimentation)
- Ajout d'environ 1-3 ms de latence (flush sur disque)

**Recommandation** :
```javascript
// Production critique
{ writeConcern: { w: "majority", j: true } }
```

### Step Down : Transition Ordonn√©e

Le Primary peut se d√©grader volontairement ou forc√©ment, passant de PRIMARY √† SECONDARY.

#### Step Down Automatique

**D√©clencheurs** :

1. **Perte de quorum** :
   - Le Primary ne peut plus communiquer avec la majorit√©
   - Auto-d√©gradation pour √©viter le split-brain

2. **Membre de priorit√© sup√©rieure disponible** :
   - Un Secondary avec `priority` plus √©lev√©e devient disponible
   - Le Primary se d√©grade pour permettre l'√©lection du membre prioritaire
   - Configurable via `settings.electionTimeoutMillis`

3. **Reconfiguration** :
   - Un `rs.reconfig()` modifie les priorit√©s
   - Le Primary actuel n'est plus le membre le plus prioritaire

**Processus** :

```
1. D√©tection de la condition de step down
     ‚Üì
2. Arr√™t de l'acceptation de nouvelles √©critures
     ‚Üì
3. Attente que les Secondaries rattrapent (catch-up period)
     ‚Üì
4. Transition vers SECONDARY
     ‚Üì
5. Annonce du changement d'√©tat (heartbeat)
     ‚Üì
6. Les autres membres initient une √©lection
```

**Catch-up Period** :
- Par d√©faut : illimit√© (`catchUpTimeoutMillis: -1`)
- Le Primary attend que les Secondaries appliquent toutes ses op√©rations
- √âvite la perte de donn√©es lors du failover

**Configuration** :
```javascript
cfg = rs.conf()
cfg.settings.catchUpTimeoutMillis = 20000  // 20 secondes max
rs.reconfig(cfg)
```

Si le timeout est atteint, le Primary se d√©grade quand m√™me (potentielle perte de donn√©es non-r√©pliqu√©es).

#### Step Down Manuel

Un administrateur peut forcer le step down :

```javascript
// Step down avec param√®tres
rs.stepDown(
  60,      // secondsToStepDown: dur√©e pendant laquelle le Primary refuse de redevenir Primary
  30       // catchUpPeriodSecs: temps max d'attente pour catch-up (optionnel)
)
```

**Cas d'usage** :
- Maintenance planifi√©e (red√©marrage, upgrade)
- D√©placement du Primary vers un datacenter sp√©cifique
- Tests de failover

**Comportement** :

1. Le Primary cesse d'accepter les √©critures imm√©diatement
2. Attend que les Secondaries rattrapent (jusqu'√† `catchUpPeriodSecs`)
3. Passe √† l'√©tat SECONDARY
4. Refuse de se pr√©senter aux √©lections pendant `secondsToStepDown`

**Exemple : Maintenance sans interruption**

```javascript
// Sur le Primary actuel
rs.stepDown(120)  // Step down pendant 2 minutes

// Un Secondary est √©lu Primary
// Effectuer la maintenance sur l'ancien Primary
// Apr√®s 2 minutes, il redevient √©ligible
```

#### Rollback apr√®s Step Down

Si le Primary tombe avant que certaines √©critures soient r√©pliqu√©es, ces √©critures peuvent √™tre **rollback** :

**Sc√©nario** :

```
1. Primary √©crit op1, op2, op3
2. R√©plication : op1 r√©pliqu√© sur Sec1, Sec2
                 op2, op3 seulement sur Primary
3. Primary crash
4. Sec1 √©lu nouveau Primary
5. Ancien Primary revient : d√©tecte que op2, op3 ne sont pas sur le nouveau Primary
6. Rollback de op2, op3 ‚Üí sauvegard√©s dans rollback/
```

**Protection** :
- Utiliser `w: "majority"` garantit qu'aucune op√©ration committ√©e ne sera rollback
- MongoDB sauvegarde les op√©rations rollback dans `<dbpath>/rollback/`
- Possibilit√© de r√©appliquer manuellement si n√©cessaire

## Performance et Optimisations

### Facteurs Limitants du Primary

Le Primary est souvent le **goulot d'√©tranglement** d'un Replica Set :

#### CPU

**Charges** :
- Ex√©cution des √©critures (parsing, validation, index updates)
- G√©n√©ration de l'Oplog
- Service des lectures (si Read Preference primary)
- Gestion des connexions client

**Optimisation** :
- Utiliser des Secondaries pour les lectures (Read Preference secondary)
- Optimiser les requ√™tes avec indexes appropri√©s
- Limiter les op√©rations co√ªteuses (large aggregations sur Primary)

#### M√©moire (WiredTiger Cache)

**Allocation** :
- Par d√©faut : 50% de RAM - 1 GB
- Contient les documents actifs (working set) et les indexes

**Optimisation** :
```yaml
# mongod.conf
storage:
  wiredTiger:
    engineConfig:
      cacheSizeGB: 64  # Exemple : 64 GB pour serveur avec 128 GB RAM
```

**Working Set** :
- Id√©alement, le working set doit tenir enti√®rement en cache
- Si working set > cache ‚Üí page faults fr√©quents ‚Üí d√©gradation de performance

#### Disque (IOPS)

**Op√©rations intensives** :
- √âcritures des donn√©es (indexes + documents)
- √âcriture du journal WiredTiger (`j: true`)
- √âcriture de l'Oplog
- Checkpoints p√©riodiques

**Recommandations** :
- **SSD obligatoire** en production (IOPS 10-100x sup√©rieurs √† HDD)
- RAID 10 pour redondance et performance
- Disques d√©di√©s pour le journal si possible (`storage.wiredTiger.engineConfig.journalCompressor`)

#### R√©seau (Bande Passante)

**Trafic sortant** :
- R√©plication vers N-1 Secondaries
- Chaque √©criture dupliqu√©e N-1 fois

**Calcul** :
```
Bande passante requise = Taux_√©criture √ó (N_secondaries) √ó Facteur_overhead

Exemple :
- Taux d'√©criture : 50 MB/s
- 4 Secondaries
- Overhead (protocole, compression 50%) : 0.5
‚Üí BW = 50 √ó 4 √ó 0.5 = 100 MB/s = 800 Mbps
```

**Optimisation** :
- Activer la compression Oplog (snappy, zstd)
- Utiliser replication chaining pour distribuer la charge r√©seau

### Connection Pooling

Le Primary doit g√©rer des milliers de connexions simultan√©es :

#### Param√®tres de Connexion

```yaml
# mongod.conf
net:
  maxIncomingConnections: 10000  # Limite de connexions (d√©faut: 65536)

processManagement:
  fork: true

systemLog:
  destination: file
  path: /var/log/mongodb/mongod.log
```

**Limites syst√®mes** :
- Limites de file descriptors (`ulimit -n`)
- Limites de threads syst√®me
- M√©moire pour g√©rer les connexions (~1 MB par connexion)

#### Connection Pooling C√¥t√© Client

Les drivers MongoDB g√®rent des pools de connexions :

```javascript
// Driver Node.js
const client = new MongoClient(uri, {
  maxPoolSize: 100,        // Max connexions par pool
  minPoolSize: 10,         // Min connexions maintenues
  maxIdleTimeMS: 30000,    // Timeout pour connexions inactives
  waitQueueTimeoutMS: 5000 // Timeout si pool satur√©
})
```

**Bonnes pratiques** :
- R√©utiliser le client MongoClient (ne pas cr√©er un nouveau client par requ√™te)
- Dimensionner le pool selon la charge (100-500 connexions typiques)
- Monitorer l'utilisation du pool (m√©triques `connections.current`)

### Limitations de Throughput

Le Primary a des limites th√©oriques et pratiques :

#### Limites Th√©oriques

**√âcritures** :
- **Single-threaded pour un document** : Une seule thread peut modifier un document donn√©
- **Lock contention** : Les op√©rations concurrentes sur la m√™me collection se bloquent mutuellement

**R√©solution** :
- MongoDB utilise des locks granulaires (document-level locking depuis WiredTiger)
- Les op√©rations sur diff√©rents documents peuvent s'ex√©cuter en parall√®le

#### Limites Pratiques

**Facteurs** :
1. **Hardware** : CPU, RAM, disque IOPS
2. **Sch√©ma de donn√©es** : Nombre d'indexes, taille des documents
3. **Type d'op√©rations** : Inserts simples vs updates complexes
4. **Write Concern** : `w: 1` vs `w: "majority"` (latence r√©seau)

**Ordres de grandeur** :

| Configuration | Throughput √âcritures | Conditions |
|---------------|----------------------|------------|
| Modeste | 1,000-5,000 ops/sec | HDD, indexes multiples |
| Standard | 10,000-50,000 ops/sec | SSD, indexes optimis√©s |
| Haute performance | 100,000-500,000 ops/sec | NVMe, RAM ample, sharding |

**Au-del√† de ces limites** : Envisager le **sharding** (partitionnement horizontal).

## Monitoring du Primary

### M√©triques Critiques

#### √âtat de Sant√©

```javascript
rs.status()

// V√©rifier l'√©tat du Primary
{
  "members": [
    {
      "_id": 0,
      "name": "mongo1.example.com:27017",
      "health": 1,              // 1 = up, 0 = down
      "state": 1,               // 1 = PRIMARY
      "stateStr": "PRIMARY",
      "uptime": 86400,
      "optime": { "ts": Timestamp(...), "t": NumberLong(5) },
      "optimeDate": ISODate("..."),
      "self": true              // C'est le n≈ìud depuis lequel rs.status() est ex√©cut√©
    },
    // ... autres membres
  ]
}
```

**Alertes** :
- √âtat != PRIMARY (failover inattendu)
- Health = 0 (n≈ìud down)

#### Latence d'√âcriture

```javascript
// Via serverStatus
db.serverStatus().opcounters
// Suivre le taux d'op√©rations

db.serverStatus().metrics.operation
// Latences d√©taill√©es
```

**M√©triques** :
- `opcounters.insert` : Nombre d'insertions
- `opcounters.update` : Nombre de mises √† jour
- `opcounters.delete` : Nombre de suppressions
- `metrics.operation.writeConflicts` : Conflits de write (collisions MVCC)

#### Oplog Utilisation

```javascript
db.getReplicationInfo()

{
  "logSizeMB": 10240,           // Taille de l'Oplog (10 GB)
  "usedMB": 5120,                // Espace utilis√©
  "timeDiff": 86400,             // Fen√™tre en secondes (24h)
  "timeDiffHours": 24,
  "tFirst": "Mon Dec 01 2025 00:00:00",
  "tLast": "Tue Dec 02 2025 00:00:00",
  "now": "Tue Dec 02 2025 12:00:00"
}
```

**Alertes** :
- `timeDiff < 6 heures` : Oplog window trop court, risque de resync
- `usedMB / logSizeMB > 90%` : Oplog presque plein

#### Replication Lag des Secondaries

```javascript
db.printSlaveReplicationInfo()

// Affiche le lag de chaque Secondary
source: mongo2.example.com:27017
    syncedTo: Tue Dec 02 2025 12:00:00 GMT
    2 secs (0 hrs) behind the primary

source: mongo3.example.com:27017
    syncedTo: Tue Dec 02 2025 11:59:50 GMT
    12 secs (0 hrs) behind the primary
```

**Alertes** :
- Lag > 60 secondes (selon le contexte)
- Lag croissant de mani√®re monotone (Secondary ne rattrape pas)

#### Write Concern Timeouts

```javascript
db.serverStatus().metrics.getLastError

{
  "wtime": {
    "num": 1234,      // Nombre de Write Concern attentes
    "totalMillis": 5678  // Temps total d'attente
  },
  "wtimeouts": 5      // Nombre de timeouts (IMPORTANT)
}
```

**Alertes** :
- `wtimeouts > 0` : Des √©critures n'ont pas pu √™tre r√©pliqu√©es dans le d√©lai
- Taux de timeout > 1% : Probl√®me de capacit√© ou de r√©seau

### Profiling des Op√©rations

Activer le profiler pour analyser les op√©rations lentes :

```javascript
// Profiler niveau 1 : op√©rations > slowms
db.setProfilingLevel(1, { slowms: 100 })

// Profiler niveau 2 : TOUTES les op√©rations (d√©veloppement uniquement)
db.setProfilingLevel(2)

// Analyser les op√©rations profil√©es
db.system.profile.find().sort({ ts: -1 }).limit(10).pretty()
```

**M√©triques utiles** :
- `millis` : Dur√©e de l'op√©ration
- `planSummary` : Utilisation des indexes
- `locks` : Temps pass√© en locks
- `nreturned` : Nombre de documents retourn√©s

### Outils de Monitoring

#### MongoDB Cloud Manager / Ops Manager

Monitoring complet avec :
- Dashboards en temps r√©el
- Alertes configurables
- Historique des m√©triques
- Analyse des requ√™tes lentes

#### Prometheus + Grafana

```yaml
# mongodb_exporter
- job_name: 'mongodb'
  static_configs:
  - targets: ['mongo1.example.com:9216']

# M√©triques expos√©es
mongodb_up
mongodb_mongod_replset_member_state
mongodb_mongod_op_latencies_latency_microseconds
mongodb_mongod_replset_oplog_tail_lag_seconds
```

**Dashboards Grafana** :
- √âtat du Replica Set
- Latences d'op√©rations
- Throughput (ops/sec)
- Replication lag

#### Scripts Personnalis√©s

```bash
#!/bin/bash
# check_primary.sh

PRIMARY=$(mongo --quiet --eval "rs.isMaster().primary")
CURRENT=$(mongo --quiet --eval "db.serverStatus().host")

if [ "$PRIMARY" != "$CURRENT" ]; then
  echo "ALERT: Node is not PRIMARY"
  exit 2
fi

echo "OK: Node is PRIMARY"
exit 0
```

## Sc√©narios de D√©faillance

### Crash du Primary

**D√©tection** :
- Les Secondaries ne re√ßoivent plus de heartbeats du Primary
- Apr√®s `electionTimeoutMillis` (10s), une √©lection d√©marre

**Processus de Failover** :

```
T+0s : Primary crash
T+2s : Secondaries d√©tectent l'absence de heartbeat
T+10s: Election timeout atteint
T+11s: Un Secondary initie une √©lection
T+12s: Majorit√© des votes obtenus, nouveau Primary
T+13s: Nouveau Primary accepte les √©critures
```

**Temps d'indisponibilit√© typique** : 10-15 secondes

**Impact** :
- √âcritures bloqu√©es pendant le failover
- Lectures possibles sur Secondaries (selon Read Preference)
- Rollback potentiel des √©critures non-r√©pliqu√©es (si `w: 1`)

### Partition R√©seau

**Sc√©nario : Primary Isol√©**

```
Avant :
  [Primary] ‚Üî [Sec1] ‚Üî [Sec2]

Partition :
  [Primary]  X  [Sec1] ‚Üî [Sec2]
```

**Comportement** :

1. **C√¥t√© Primary** :
   - D√©tecte qu'il ne peut atteindre la majorit√©
   - Se d√©grade automatiquement en SECONDARY
   - Rejette toutes les √©critures

2. **C√¥t√© Secondaries** :
   - D√©tectent la perte du Primary
   - Initient une √©lection
   - Sec1 ou Sec2 devient le nouveau Primary

3. **R√©solution de la Partition** :
   - L'ancien Primary rejoint le cluster
   - D√©tecte qu'un nouveau Primary existe
   - Reste en SECONDARY
   - Rattrape son retard via r√©plication

**√âvite le split-brain** : Jamais deux Primary simultan√©s acceptant des √©critures divergentes.

### D√©gradation de Performance

**Sympt√¥mes** :
- Latence d'√©criture √©lev√©e (> 100 ms)
- Timeouts de Write Concern fr√©quents
- Replication lag croissant

**Causes Possibles** :

1. **CPU satur√©** :
   - Requ√™tes inefficaces (scans de collections)
   - Trop de connexions simultan√©es
   - Charge de lecture sur le Primary

2. **Disque satur√© (IOPS)** :
   - Working set trop grand pour la RAM
   - Checkpoints WiredTiger co√ªteux
   - Journal WiredTiger sur disque lent

3. **R√©seau satur√©** :
   - Bande passante insuffisante pour la r√©plication
   - Latence r√©seau √©lev√©e vers les Secondaries

4. **Oplog undersized** :
   - Oplog trop petit, fen√™tre de r√©plication courte
   - Secondaries ne peuvent pas rattraper

**Diagnostic** :

```javascript
// CPU
db.currentOp(true)  // Op√©rations en cours

// Disque
db.serverStatus().wiredTiger.cache
// V√©rifier pageEvictions, pagesRead

// R√©seau
rs.status()  // Replication lag par membre

// Oplog
db.getReplicationInfo()
```

## S√©curit√© et Isolation

### S√©curit√© du Primary

Le Primary √©tant le point d'√©criture unique, sa s√©curit√© est critique :

#### Authentication et Authorization

```yaml
# mongod.conf
security:
  authorization: enabled
  keyFile: /path/to/keyfile  # Authentication inter-membres
```

**Principe du moindre privil√®ge** :
- Comptes applicatifs avec droits lecture/√©criture limit√©s √† leurs bases
- Comptes administrateurs s√©par√©s
- Rotation r√©guli√®re des credentials

#### Encryption

**En transit (TLS/SSL)** :
```yaml
net:
  tls:
    mode: requireTLS
    certificateKeyFile: /path/to/cert.pem
    CAFile: /path/to/ca.pem
```

**Au repos (Encryption at Rest)** :
```yaml
security:
  enableEncryption: true
  encryptionKeyFile: /path/to/keyfile
```

Disponible uniquement dans MongoDB Enterprise.

#### Audit Logging

```yaml
auditLog:
  destination: file
  format: JSON
  path: /var/log/mongodb/audit.json
  filter: '{ atype: { $in: ["createCollection", "dropCollection"] } }'
```

Trace toutes les op√©rations sensibles pour compliance et investigation.

### Isolation et Ressources D√©di√©es

**Bonnes pratiques** :
- **Serveur d√©di√©** : Ne pas co-localiser avec d'autres services
- **R√©seau d√©di√©** : VLAN priv√© pour communication inter-membres
- **Disques d√©di√©s** : Pas de partage avec d'autres applications
- **Limites de ressources** : Utiliser cgroups/systemd pour limiter les ressources

## Bonnes Pratiques

### Dimensionnement du Primary

**Recommandations** :

1. **CPU** : Au moins 4 cores (8-16 cores pour production haute charge)
2. **RAM** : Suffisant pour le working set + WiredTiger cache (64-256 GB typique)
3. **Disque** : SSD/NVMe avec au moins 10,000 IOPS (50,000+ pour haute performance)
4. **R√©seau** : 10 Gbps minimum en production

**Formule de dimensionnement RAM** :
```
RAM = Working_Set + (0.5 √ó Total_Data) + 1 GB + OS_overhead

Exemple :
- Total data : 500 GB
- Working set : 100 GB (20% actif)
- RAM = 100 + (0.5 √ó 500) + 1 + 10 = 361 GB
‚Üí Serveur avec 384 GB RAM recommand√©
```

### Oplog Sizing

**Formule** :
```
OplogSize = Max(
  Taux_√©criture_peak (GB/h) √ó Fen√™tre_souhait√©e (h) √ó 2,
  5% √ó Disque_disponible
)

Exemple :
- Taux d'√©criture peak : 10 GB/h
- Fen√™tre : 48h (2 jours)
‚Üí OplogSize = 10 √ó 48 √ó 2 = 960 GB
```

**Redimensionnement** :
```javascript
// MongoDB 4.0+, sans red√©marrage
db.adminCommand({ replSetResizeOplog: 1, size: 960000 })  // En MB
```

### Maintenance Sans Interruption

**Proc√©dure de Rolling Restart** :

1. **Step down du Primary** :
```javascript
rs.stepDown(120)  // 2 minutes
```

2. **Maintenance sur l'ancien Primary** (maintenant Secondary)

3. **Maintenance sur les Secondaries** (un par un)

4. **Le Primary d'origine redevient √©ligible** apr√®s 2 minutes

Cette approche √©vite toute interruption de service.

### Monitoring Continu

**M√©triques √† surveiller en permanence** :

1. √âtat du Primary (PRIMARY vs autre)
2. Latence d'√©criture (< 10 ms)
3. Write Concern timeouts (= 0)
4. Replication lag des Secondaries (< 10s)
5. Oplog window (> 24h)
6. CPU/RAM/Disque utilization (< 80%)

**Alerting** :
- Alertes critiques : Perte de Primary, lag > 60s
- Alertes warning : Lag > 30s, Oplog window < 12h
- Dashboards : Grafana, MongoDB Cloud Manager

## Conclusion

Le **Primary** est le composant le plus critique d'un Replica Set MongoDB. Sa compr√©hension approfondie est essentielle pour :

1. **Concevoir** des architectures r√©silientes et performantes
2. **Dimensionner** correctement les ressources (CPU, RAM, disque, r√©seau)
3. **Monitorer** efficacement la sant√© et les performances
4. **R√©agir** rapidement aux incidents (failover, d√©gradation)
5. **Optimiser** les param√®tres de Write Concern et de configuration

**Points cl√©s √† retenir** :

- Le Primary est l'**unique point d'√©criture**, garantissant l'ordre total et l'absence de conflits
- Il g√©n√®re l'**Oplog** en transformant les op√©rations en format idempotent
- Le **Write Concern** contr√¥le finement le compromis latence/durabilit√©
- Le **step down** automatique √©vite le split-brain en cas de partition r√©seau
- Le Primary est souvent le **goulot d'√©tranglement** ‚Üí optimisation et sharding n√©cessaires au-del√† d'un certain scale
- Le **monitoring continu** du Primary est imp√©ratif pour garantir la disponibilit√©

La ma√Ætrise du Primary permet de construire des syst√®mes MongoDB capables de g√©rer des millions de transactions par jour avec haute disponibilit√© et durabilit√© des donn√©es.

‚è≠Ô∏è [Secondary](/09-replication/03.2-secondary.md)
