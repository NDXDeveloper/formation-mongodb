üîù Retour au [Sommaire](/SOMMAIRE.md)

# 9.9 Failover et Haute Disponibilit√©

## Introduction

Le **failover** (basculement automatique) est le m√©canisme par lequel MongoDB garantit la haute disponibilit√© en cas de d√©faillance du Primary. Comprendre les subtilit√©s du processus de failover, les diff√©rents types de d√©faillances et les strat√©gies d'optimisation est essentiel pour concevoir et op√©rer des syst√®mes r√©silients en production.

## Architecture de Haute Disponibilit√©

### Principes Fondamentaux

La haute disponibilit√© dans MongoDB repose sur trois piliers :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     Haute Disponibilit√© MongoDB            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                            ‚îÇ
‚îÇ  1. REDONDANCE                             ‚îÇ
‚îÇ     ‚îú‚îÄ Replica Set (‚â•3 membres)            ‚îÇ
‚îÇ     ‚îî‚îÄ Donn√©es r√©pliqu√©es sur tous n≈ìuds   ‚îÇ
‚îÇ                                            ‚îÇ
‚îÇ  2. D√âTECTION AUTOMATIQUE                  ‚îÇ
‚îÇ     ‚îú‚îÄ Heartbeats (2 secondes)             ‚îÇ
‚îÇ     ‚îî‚îÄ Timeout (10 secondes)               ‚îÇ
‚îÇ                                            ‚îÇ
‚îÇ  3. FAILOVER AUTOMATIQUE                   ‚îÇ
‚îÇ     ‚îú‚îÄ √âlection d'un nouveau Primary       ‚îÇ
‚îÇ     ‚îî‚îÄ Reconfiguration automatique         ‚îÇ
‚îÇ                                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Objectifs de Disponibilit√©

| M√©trique | Calcul | Objectif Production |
|----------|--------|---------------------|
| **Availability (%)** | (Uptime / Total Time) √ó 100 | 99.9% - 99.99% |
| **RTO** (Recovery Time Objective) | Temps max pour restaurer | 30-120 secondes |
| **RPO** (Recovery Point Objective) | Perte de donn√©es max acceptable | 0 (w: majority) |
| **MTBF** (Mean Time Between Failures) | Temps moyen entre pannes | Maximiser |
| **MTTR** (Mean Time To Recovery) | Temps moyen de r√©cup√©ration | Minimiser |

**Calcul de disponibilit√©** :

```
Disponibilit√© 99.9%  = ~8.76 heures downtime/an
Disponibilit√© 99.95% = ~4.38 heures downtime/an
Disponibilit√© 99.99% = ~52.6 minutes downtime/an
```

## M√©canisme de Failover

### S√©quence Compl√®te de Failover

```
T0: √âtat Normal
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  Heartbeats  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   PRIMARY   ‚îÇ ‚Üê----------‚Üí ‚îÇ  SECONDARY-1 ‚îÇ
‚îÇ mongodb-01  ‚îÇ              ‚îÇ  mongodb-02  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚Üï
    Heartbeats
       ‚Üï
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  SECONDARY-2 ‚îÇ
‚îÇ  mongodb-03  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

T1: D√©faillance du Primary (crash, r√©seau, etc.)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    DOWN     ‚îÇ      ‚úó       ‚îÇ  SECONDARY-1 ‚îÇ
‚îÇ mongodb-01  ‚îÇ              ‚îÇ  mongodb-02  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò


‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  SECONDARY-2 ‚îÇ
‚îÇ  mongodb-03  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

T2: D√©tection (apr√®s electionTimeoutMillis = 10s)
                             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         Timeout             ‚îÇ  SECONDARY-1   ‚îÇ
         d√©tect√©             ‚îÇ Pas de Primary!‚îÇ
                             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚Üì
                             Initie √©lection

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚Üì
‚îÇ  SECONDARY-2 ‚îÇ ‚Üê‚îÄ‚îÄ‚îÄ Demande vote ‚îÄ‚îò
‚îÇ  mongodb-03  ‚îÇ

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

T3: √âlection (1-2 secondes)
                             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                             ‚îÇ  CANDIDATE   ‚îÇ
                             ‚îÇ  mongodb-02  ‚îÇ
                             ‚îÇ  Term: 43    ‚îÇ
                             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚Üë
                        Vote accord√©‚îÇ
                                    ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îÇ
‚îÇ  SECONDARY-2 ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ  mongodb-03  ‚îÇ
‚îÇ  Vote: OUI   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

T4: Nouveau Primary √âlu
                             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                             ‚îÇ   PRIMARY    ‚îÇ
                             ‚îÇ  mongodb-02  ‚îÇ
                             ‚îÇ  Term: 43    ‚îÇ
                             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚Üï
                               Heartbeats
                                    ‚Üï
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  SECONDARY-2 ‚îÇ
‚îÇ  mongodb-03  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

T5: Ancien Primary Revient
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  SECONDARY  ‚îÇ Heartbeat    ‚îÇ   PRIMARY    ‚îÇ
‚îÇ mongodb-01  ‚îÇ ‚Üê----------‚Üí ‚îÇ  mongodb-02  ‚îÇ
‚îÇ  Term: 42   ‚îÇ              ‚îÇ  Term: 43    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚Üï                              ‚Üï
  Rollback si                  R√©plication
  n√©cessaire                    normale
     ‚Üï                              ‚Üï
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  SECONDARY-2 ‚îÇ
‚îÇ  mongodb-03  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Chronologie D√©taill√©e

**Phase 1 : D√©faillance (T0)**
```
0ms : Primary devient inaccessible
     - Crash syst√®me
     - Panne r√©seau
     - Charge excessive
```

**Phase 2 : D√©tection (T0 + 10s)**
```
10000ms : Les Secondary d√©tectent l'absence de heartbeat
         - Timeout = electionTimeoutMillis (d√©faut: 10s)
         - Chaque Secondary d√©marre un timer ind√©pendant
```

**Phase 3 : Initiation √âlection (T0 + 10s + randomDelay)**
```
10000-11000ms : Un Secondary initie l'√©lection
               - Incr√©mente son term (42 ‚Üí 43)
               - Passe √† l'√©tat CANDIDATE
               - Vote pour lui-m√™me
               - Envoie RequestVote aux autres
```

**Phase 4 : Vote (T0 + 10-12s)**
```
10500-12000ms : Collecte des votes
               - Chaque membre vote pour le premier CANDIDATE valide
               - Validation de l'OpTime (doit √™tre √† jour)
               - V√©rification des priorit√©s
```

**Phase 5 : √âlection (T0 + 11-13s)**
```
11000-13000ms : CANDIDATE obtient la majorit√©
               - Devient PRIMARY
               - Envoie notification aux autres membres
```

**Phase 6 : Catchup (T0 + 13-43s)**
```
13000-43000ms : Nouveau Primary en catchup (optionnel)
               - R√©plique les derni√®res op√©rations manquantes
               - Dur√©e : catchUpTimeoutMillis (d√©faut: -1 = illimit√©)
               - Apr√®s catchup, accepte les √©critures
```

**Temps Total de Failover** :
```
Temps minimal : ~12-15 secondes
Temps typique  : ~20-30 secondes
Temps maximal  : ~40-60 secondes (avec catchup)
```

## Types de D√©faillances

### 1. D√©faillance Mat√©rielle

#### Crash Serveur

```javascript
// Sympt√¥mes
rs.status().members.find(m => m.name === "mongodb-01:27017")
// {
//   name: "mongodb-01:27017",
//   health: 0,
//   state: 8,        // DOWN
//   stateStr: "DOWN (not reachable/healthy)",
//   lastHeartbeat: ISODate("2024-01-15T10:15:23Z")
// }
```

**Causes** :
- Panne mat√©rielle (CPU, RAM, disque)
- Kernel panic
- Alimentation √©lectrique
- Surchauffe

**D√©tection** : Imm√©diate (heartbeat √©choue)

**R√©cup√©ration** :
```bash
# 1. Diagnostiquer le probl√®me
journalctl -u mongod -n 100

# 2. R√©parer/remplacer le hardware

# 3. Red√©marrer MongoDB
systemctl start mongod

# 4. Le membre rejoindra automatiquement comme SECONDARY
```

#### D√©faillance Disque

```bash
# Sympt√¥mes dans les logs
[ERROR] WiredTiger error: disk full
[FATAL] Exception in initAndListen: DBPathInUse

# V√©rification
df -h /data/mongodb
# Filesystem      Size  Used Avail Use% Mounted on
# /dev/sda1       100G  100G    0G 100% /data
```

**Pr√©vention** :
```javascript
// Monitoring de l'espace disque
function checkDiskSpace() {
  var dbStats = db.stats()
  var dataSize = dbStats.dataSize / 1024 / 1024 / 1024  // GB
  var storageSize = dbStats.storageSize / 1024 / 1024 / 1024  // GB

  // Alerter si utilisation > 80%
  if (storageSize > dbStats.fsUsedSize * 0.8) {
    print("WARNING: Disk usage > 80%")
  }
}
```

### 2. D√©faillance R√©seau

#### Partition R√©seau Compl√®te

```
Avant partition :
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Primary  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇSecondary1‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇSecondary2‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Apr√®s partition (exemple split 2-1) :
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚ïë ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Primary  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇSecondary1‚îÇ     ‚ïë ‚îÇSecondary2‚îÇ
‚îÇ (reste)  ‚îÇ     ‚îÇ          ‚îÇ     ‚ïë ‚îÇ (isol√©)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚ïë ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
  Partition A (majorit√©)          ‚ïë  Partition B
  ‚Üí Continue op√©rations           ‚ïë  ‚Üí READ ONLY
```

**Comportement** :
```javascript
// Partition A (2 membres sur 3 - majorit√©)
// Primary reste PRIMARY
// √âcritures continuent normalement

// Partition B (1 membre sur 3 - minorit√©)
// Secondary-2 devient SECONDARY en READ-ONLY
// Erreur sur tentatives d'√©criture :
// "not master and slaveOk=false"
```

**Pr√©vention du Split-Brain** :
```
Gr√¢ce √† l'exigence de majorit√© :
- Seule la partition avec majorit√© peut avoir un Primary
- L'autre partition n'a QUE des Secondary
- Impossible d'avoir 2 Primary simultan√©ment
```

#### Latence R√©seau √âlev√©e

```javascript
// Sympt√¥mes
rs.status().members.forEach(m => {
  if (m.pingMs && m.pingMs > 100) {
    print(`WARNING: High latency to ${m.name}: ${m.pingMs}ms`)
  }
})
```

**Impact** :
- Replication lag augment√©
- √âlections plus fr√©quentes
- Timeout de heartbeat

**Solution** :
```javascript
// Augmenter electionTimeoutMillis pour r√©seaux WAN
cfg = rs.conf()
cfg.settings.electionTimeoutMillis = 30000  // 30 secondes
rs.reconfig(cfg)
```

#### Perte Intermittente de Paquets

```bash
# Diagnostic
ping -c 100 mongodb-secondary
# 100 packets transmitted, 85 received, 15% packet loss

# Impact sur r√©plication
# Logs MongoDB :
# [replication] sync source: mongodb-02:27017 dropped connection
# [replication] changing sync source from mongodb-02:27017 to mongodb-03:27017
```

### 3. D√©faillance Logicielle

#### Out of Memory (OOM)

```bash
# Logs syst√®me
Jan 15 10:15:23 kernel: Out of memory: Kill process 12345 (mongod)

# Logs MongoDB
[ERROR] Fatal Assertion 28561
```

**Pr√©vention** :
```javascript
// Configurer WiredTiger cache correctement
storage:
  wiredTiger:
    engineConfig:
      cacheSizeGB: 8  // ~50% de RAM disponible

// Monitoring
db.serverStatus().wiredTiger.cache["bytes currently in the cache"]
```

#### Deadlock / Blocage

```javascript
// Identifier les op√©rations bloqu√©es
db.currentOp({
  "secs_running": { $gte: 30 },
  "op": { $in: ["query", "update", "remove"] }
})

// Tuer l'op√©ration probl√©matique
db.killOp(opid)
```

#### Corruption de Donn√©es WiredTiger

```bash
# Sympt√¥me
[ERROR] WiredTiger error: WT_PANIC: WiredTiger library panic

# R√©cup√©ration
mongod --repair --dbpath /data/mongodb

# Si √©chec, restaurer depuis backup
```

### 4. D√©faillance Applicative

#### Surcharge de Connexions

```javascript
// Monitoring
db.serverStatus().connections
// {
//   current: 40000,
//   available: 819228,
//   totalCreated: 52341234
// }

// Si current approche de la limite
// Augmenter maxIncomingConnections
net:
  maxIncomingConnections: 65536
```

#### Requ√™tes Lentes Saturant le Syst√®me

```javascript
// Identifier les requ√™tes lentes en cours
db.currentOp({
  "active": true,
  "secs_running": { $gt: 10 },
  "op": "query"
}).inprog.forEach(op => {
  print(`Slow query: ${op.secs_running}s`)
  print(`Query: ${JSON.stringify(op.query)}`)
  print(`OpID: ${op.opid}`)
})

// Tuer si n√©cessaire
db.killOp(opid)
```

## Strat√©gies de Haute Disponibilit√©

### 1. Topologie N+2 (Recommand√©e)

```javascript
// 5 membres au lieu de 3
{
  members: [
    { _id: 0, host: "mongodb-01:27017", priority: 10 },  // Primary pr√©f√©r√©
    { _id: 1, host: "mongodb-02:27017", priority: 9 },
    { _id: 2, host: "mongodb-03:27017", priority: 8 },

    // Membres suppl√©mentaires pour r√©silience
    { _id: 3, host: "mongodb-04:27017", priority: 1 },
    { _id: 4, host: "mongodb-05:27017", priority: 1 }
  ]
}
```

**Avantages** :
- Tol√©rance √† 2 d√©faillances simultan√©es
- Majorit√© : 3 sur 5
- Si 2 membres tombent : 3 restent (majorit√© maintenue)

### 2. D√©ploiement Multi-Datacenter

```javascript
// Configuration g√©o-distribu√©e
{
  members: [
    // DC1 (Principal) - 3 membres
    { _id: 0, host: "dc1-mongodb-01:27017", priority: 10, tags: {dc: "dc1"} },
    { _id: 1, host: "dc1-mongodb-02:27017", priority: 9, tags: {dc: "dc1"} },
    { _id: 2, host: "dc1-mongodb-03:27017", priority: 8, tags: {dc: "dc1"} },

    // DC2 (DR) - 2 membres
    { _id: 3, host: "dc2-mongodb-01:27017", priority: 1, tags: {dc: "dc2"} },
    { _id: 4, host: "dc2-mongodb-02:27017", priority: 1, votes: 0, tags: {dc: "dc2"} }
  ],

  settings: {
    electionTimeoutMillis: 30000,  // Latence WAN
    getLastErrorModes: {
      multiDC: { dc: 2 }  // √âcriture sur au moins 2 DC
    }
  }
}
```

**Sc√©narios de d√©faillance** :

| Sc√©nario | Membres UP | Majorit√© | Primary Possible | √âcritures |
|----------|-----------|----------|------------------|-----------|
| Normal | DC1:3, DC2:2 | 3/4 | ‚úÖ DC1 | ‚úÖ |
| Perte DC2 | DC1:3, DC2:0 | 3/3 | ‚úÖ DC1 | ‚úÖ |
| Perte DC1 | DC1:0, DC2:2 | 2/4 | ‚ùå Pas de majorit√© | ‚ùå |
| 1 down DC1 | DC1:2, DC2:2 | 2/4 | ‚úÖ DC1 | ‚úÖ |
| 2 down DC1 | DC1:1, DC2:2 | 1/4 | ‚ùå Pas de majorit√© | ‚ùå |

### 3. Configuration avec Delayed Member

```javascript
{
  members: [
    // Membres normaux
    { _id: 0, host: "mongodb-01:27017", priority: 2 },
    { _id: 1, host: "mongodb-02:27017", priority: 1 },
    { _id: 2, host: "mongodb-03:27017", priority: 1 },

    // Delayed member (protection contre erreurs humaines)
    {
      _id: 3,
      host: "mongodb-delayed:27017",
      priority: 0,
      hidden: true,
      slaveDelay: 3600,  // 1 heure
      tags: { backup: "delayed" }
    }
  ]
}
```

**R√©cup√©ration apr√®s suppression accidentelle** :
```javascript
// Donn√©es supprim√©es accidentellement √† 14h00
// Le delayed member a encore les donn√©es jusqu'√† 13h00

// 1. Se connecter au delayed member
mongosh --host mongodb-delayed:27017

// 2. Exporter les donn√©es
mongodump --db mydb --collection users --out /backup/recovery

// 3. Restaurer sur le Primary
mongorestore --host mongodb-01:27017 /backup/recovery
```

### 4. Monitoring et Alerting Proactif

```javascript
// Script de monitoring continu
function continuousHealthCheck() {
  setInterval(() => {
    const status = rs.status()
    const alerts = []

    // Check 1 : Pr√©sence du Primary
    const primary = status.members.filter(m => m.state === 1)
    if (primary.length !== 1) {
      alerts.push(`CRITICAL: ${primary.length} PRIMARY members`)
    }

    // Check 2 : Health de tous les membres
    status.members.forEach(m => {
      if (m.health !== 1) {
        alerts.push(`WARNING: ${m.name} health = ${m.health}`)
      }
    })

    // Check 3 : Replication lag
    const now = status.date
    status.members.forEach(m => {
      if (m.state === 2 && m.optimeDate) {  // SECONDARY
        const lag = (now - m.optimeDate) / 1000
        if (lag > 60) {
          alerts.push(`WARNING: ${m.name} lag = ${lag}s`)
        }
      }
    })

    // Check 4 : Oplog window
    const replInfo = db.getReplicationInfo()
    const oplogHours = replInfo.timeDiff / 3600
    if (oplogHours < 24) {
      alerts.push(`WARNING: Oplog window = ${oplogHours}h`)
    }

    // Check 5 : Nombre de membres votants
    const cfg = rs.conf()
    const voting = cfg.members.filter(m => m.votes === 1).length
    if (voting % 2 === 0) {
      alerts.push(`WARNING: Even number of voters (${voting})`)
    }

    if (alerts.length > 0) {
      print(`\n=== ALERTS at ${new Date().toISOString()} ===`)
      alerts.forEach(a => print(a))
      // Envoyer notifications (email, Slack, PagerDuty, etc.)
    }
  }, 30000)  // V√©rifier toutes les 30 secondes
}

// D√©marrer le monitoring
continuousHealthCheck()
```

## Tests de Failover

### Test 1 : Arr√™t Propre du Primary

```bash
# Objectif : V√©rifier le failover contr√¥l√©
# RTO attendu : ~12-20 secondes

# 1. Identifier le Primary
mongosh --eval "rs.isMaster().primary"
# Output: mongodb-01:27017

# 2. Timer de d√©but
START_TIME=$(date +%s)

# 3. Arr√™ter proprement le Primary
ssh mongodb-01 "sudo systemctl stop mongod"

# 4. Observer l'√©lection depuis un Secondary
mongosh --host mongodb-02:27017 --eval "
  while(true) {
    var status = rs.status()
    var primary = status.members.find(m => m.state === 1)
    print(new Date().toISOString() + ' - Primary: ' + (primary ? primary.name : 'NONE'))
    if (primary && primary.name !== 'mongodb-01:27017') {
      print('NEW PRIMARY ELECTED: ' + primary.name)
      break
    }
    sleep(1000)
  }
"

# 5. Calculer le RTO
END_TIME=$(date +%s)
RTO=$((END_TIME - START_TIME))
echo "Recovery Time: ${RTO} seconds"

# 6. Red√©marrer l'ancien Primary
ssh mongodb-01 "sudo systemctl start mongod"

# 7. V√©rifier qu'il rejoint comme SECONDARY
mongosh --host mongodb-01:27017 --eval "rs.isMaster().secondary"
```

### Test 2 : Crash Brutal (kill -9)

```bash
# Objectif : Simuler un crash syst√®me
# RTO attendu : ~20-30 secondes

# 1. Identifier le PID de mongod sur le Primary
ssh mongodb-01 "pgrep mongod"
# Output: 12345

# 2. Timer
START_TIME=$(date +%s)

# 3. Kill brutal
ssh mongodb-01 "sudo kill -9 12345"

# 4. Observer failover...
# (m√™me proc√©dure que Test 1)

# 5. Analyser les logs
ssh mongodb-01 "tail -100 /var/log/mongodb/mongod.log"
# Rechercher : rollback, recovery
```

### Test 3 : Partition R√©seau

```bash
# Objectif : Tester split-brain prevention
# Utilise iptables pour simuler partition r√©seau

# Configuration : 3 membres
# mongodb-01 (Primary)
# mongodb-02 (Secondary)
# mongodb-03 (Secondary)

# Sc√©nario : Isoler mongodb-01

# 1. Sur mongodb-01, bloquer trafic vers autres membres
ssh mongodb-01 "
  sudo iptables -A INPUT -s 10.0.1.11 -j DROP   # mongodb-02
  sudo iptables -A INPUT -s 10.0.1.12 -j DROP   # mongodb-03
  sudo iptables -A OUTPUT -d 10.0.1.11 -j DROP
  sudo iptables -A OUTPUT -d 10.0.1.12 -j DROP
"

# 2. Observer depuis mongodb-02
mongosh --host mongodb-02:27017 --eval "
  // Attendre √©lection
  sleep(15000)

  var status = rs.status()
  print('New Primary: ' + rs.isMaster().primary)

  // mongodb-01 devrait √™tre vu comme DOWN
  var old = status.members.find(m => m.name === 'mongodb-01:27017')
  print('mongodb-01 state: ' + old.stateStr)
"

# 3. Observer depuis mongodb-01 (partition A - minorit√©)
mongosh --host mongodb-01:27017 --eval "
  var status = rs.status()
  var me = status.members.find(m => m.self)
  print('My state: ' + me.stateStr)
  // Devrait √™tre SECONDARY (ne peut pas rester Primary sans majorit√©)
"

# 4. R√©parer la partition
ssh mongodb-01 "
  sudo iptables -F  # Flush toutes les r√®gles
"

# 5. Observer la r√©conciliation
# mongodb-01 rejoint comme SECONDARY
# Possible rollback si des √©critures non r√©pliqu√©es
```

### Test 4 : Failover en Charge

```javascript
// Objectif : Mesurer l'impact du failover sur les applications

// 1. Script de charge continue
const { MongoClient } = require('mongodb')

async function loadTest() {
  const client = new MongoClient('mongodb://mongodb-01,mongodb-02,mongodb-03/?replicaSet=rs0', {
    retryWrites: true,
    w: 'majority'
  })

  await client.connect()
  const db = client.db('test')
  const collection = db.collection('failover_test')

  let successCount = 0
  let errorCount = 0
  let errors = []

  const interval = setInterval(async () => {
    try {
      await collection.insertOne({
        timestamp: new Date(),
        data: Math.random()
      })
      successCount++
    } catch (error) {
      errorCount++
      errors.push({
        time: new Date(),
        error: error.message
      })
    }

    // Afficher stats toutes les 10 √©critures
    if ((successCount + errorCount) % 10 === 0) {
      console.log(`Success: ${successCount}, Errors: ${errorCount}`)
    }
  }, 100)  // 10 √©critures/seconde

  // Arr√™ter apr√®s 5 minutes
  setTimeout(() => {
    clearInterval(interval)
    console.log('\n=== Final Stats ===')
    console.log(`Total Success: ${successCount}`)
    console.log(`Total Errors: ${errorCount}`)
    console.log(`Error Rate: ${(errorCount / (successCount + errorCount) * 100).toFixed(2)}%`)

    if (errors.length > 0) {
      console.log('\n=== Error Timeline ===')
      errors.forEach(e => {
        console.log(`${e.time.toISOString()}: ${e.error}`)
      })
    }

    client.close()
  }, 300000)
}

// 2. Lancer le test
loadTest()

// 3. Pendant l'ex√©cution, d√©clencher failover
// ssh mongodb-01 "sudo systemctl stop mongod"

// 4. Observer :
// - P√©riode d'erreurs pendant failover (~10-30s)
// - Reprise automatique apr√®s √©lection
// - Aucune perte de donn√©es si w: majority
```

### Test 5 : Failover Multiple (Chaos Engineering)

```javascript
// Sc√©nario : D√©faillances en cascade

// Configuration : 5 membres
// Test sur 1 heure avec d√©faillances al√©atoires

function chaosTest() {
  const members = [
    'mongodb-01:27017',
    'mongodb-02:27017',
    'mongodb-03:27017',
    'mongodb-04:27017',
    'mongodb-05:27017'
  ]

  const events = []

  // Toutes les 5-15 minutes, arr√™ter un membre al√©atoire
  function randomFailure() {
    const randomDelay = (Math.random() * 600000) + 300000  // 5-15 min

    setTimeout(() => {
      const target = members[Math.floor(Math.random() * members.length)]
      const timestamp = new Date()

      console.log(`${timestamp.toISOString()}: Failing ${target}`)
      events.push({ time: timestamp, action: 'FAIL', target })

      // Arr√™ter le membre (via SSH ou API)
      // ssh <target> "sudo systemctl stop mongod"

      // Red√©marrer apr√®s 2-5 minutes
      const recoveryDelay = (Math.random() * 180000) + 120000
      setTimeout(() => {
        const recoverTime = new Date()
        console.log(`${recoverTime.toISOString()}: Recovering ${target}`)
        events.push({ time: recoverTime, action: 'RECOVER', target })

        // ssh <target> "sudo systemctl start mongod"
      }, recoveryDelay)

      // Planifier prochaine d√©faillance
      randomFailure()
    }, randomDelay)
  }

  // D√©marrer le chaos
  randomFailure()

  // Arr√™ter apr√®s 1 heure
  setTimeout(() => {
    console.log('\n=== Chaos Test Complete ===')
    console.log(`Total events: ${events.length}`)

    // Analyser la disponibilit√©
    // V√©rifier que le syst√®me est rest√© op√©rationnel
  }, 3600000)
}
```

## R√©cup√©ration et Rollback

### Processus de Rollback

Lorsqu'un ancien Primary red√©marre avec des √©critures non r√©pliqu√©es :

```
Sc√©nario :
1. Primary (mongodb-01) √©crit op√©ration X (non r√©pliqu√©e)
2. Primary tombe avant r√©plication
3. Secondary (mongodb-02) √©lu Primary
4. Nouveau Primary √©crit op√©ration Y
5. Ancien Primary (mongodb-01) red√©marre

R√©sultat :
mongodb-01 : [..., opX]
mongodb-02 : [..., opY]  (divergence)

Action : ROLLBACK
```

#### D√©tection du Rollback

```bash
# Logs MongoDB sur l'ancien Primary
[rollback] rollback started
[rollback] rollback common point: { ts: Timestamp(1705320000, 42), t: 42 }
[rollback] rollback end
[rollback] rollback files created in /data/db/rollback/
```

#### Fichiers de Rollback

```bash
# Emplacement
ls -lh /data/db/rollback/

# Exemple de contenu
2024-01-15T10-30-00.0.bson
2024-01-15T10-30-00.0.metadata.json
2024-01-15T10-30-00.0.removedDocs
```

#### Analyse des Rollbacks

```javascript
// Parser les fichiers rollback
const fs = require('fs')
const BSON = require('bson')

// Lire le fichier .bson
const rollbackData = fs.readFileSync('/data/db/rollback/2024-01-15T10-30-00.0.bson')
const documents = BSON.deserialize(rollbackData)

console.log('Rolled back documents:')
console.log(JSON.stringify(documents, null, 2))

// D√©cider si les donn√©es doivent √™tre r√©appliqu√©es manuellement
```

### Pr√©vention des Rollbacks

#### Write Concern "majority"

```javascript
// ‚úÖ Garantit que l'√©criture est r√©pliqu√©e avant confirmation
db.orders.insertOne(
  { orderId: 12345, amount: 500 },
  { writeConcern: { w: "majority", wtimeout: 5000 } }
)

// Si le Primary tombe avant r√©plication sur majorit√© :
// ‚Üí L'√©criture √©choue (erreur retourn√©e)
// ‚Üí Pas de rollback n√©cessaire
```

#### Configuration par D√©faut

```javascript
// MongoDB 5.0+ : D√©finir w: majority par d√©faut
cfg = rs.conf()
cfg.settings.getLastErrorDefaults = {
  w: "majority",
  wtimeout: 5000
}
rs.reconfig(cfg)

// Toutes les √©critures sans writeConcern explicite
// utiliseront w: majority
```

### R√©cup√©ration apr√®s Rollback

```bash
# 1. Identifier les documents rollback√©s
ls -lh /data/db/rollback/

# 2. Extraire et analyser
bsondump /data/db/rollback/2024-01-15T10-30-00.0.bson > rollback.json

# 3. D√©cision m√©tier
# - Les donn√©es sont-elles critiques ?
# - Doivent-elles √™tre r√©appliqu√©es ?

# 4. Si r√©application n√©cessaire
mongoimport --host mongodb-primary \
  --db mydb \
  --collection orders \
  --file rollback.json

# 5. V√©rifier l'int√©grit√©
mongosh --eval "
  db.orders.find({ orderId: 12345 })
"

# 6. Archiver les fichiers rollback
mv /data/db/rollback/* /backup/rollback-archive/
```

## Optimisation du RTO/RPO

### R√©duire le RTO (Recovery Time Objective)

#### 1. Optimiser electionTimeoutMillis

```javascript
cfg = rs.conf()

// Pour r√©seaux locaux/datacenter
cfg.settings.electionTimeoutMillis = 5000  // 5 secondes

// Pour r√©seaux WAN
cfg.settings.electionTimeoutMillis = 15000  // 15 secondes

rs.reconfig(cfg)
```

**Impact sur RTO** :
```
RTO ‚âà electionTimeoutMillis + 2-3 secondes (√©lection)

electionTimeout = 5s  ‚Üí RTO ‚âà 7-8s
electionTimeout = 10s ‚Üí RTO ‚âà 12-13s
electionTimeout = 30s ‚Üí RTO ‚âà 32-33s
```

#### 2. D√©sactiver la Catchup Phase

```javascript
cfg = rs.conf()
cfg.settings.catchUpTimeoutMillis = 0  // Pas de catchup
rs.reconfig(cfg)
```

**Attention** : Risque de perte des derni√®res √©critures non r√©pliqu√©es.

**Meilleure pratique** : Utiliser w: "majority" + catchupTimeout faible
```javascript
cfg.settings.catchUpTimeoutMillis = 5000  // 5 secondes max
```

#### 3. Priorit√©s Optimis√©es

```javascript
// Membre haute performance comme Primary pr√©f√©r√©
cfg.members[0].priority = 100  // SSD, plus de RAM, CPU
cfg.members[1].priority = 1
cfg.members[2].priority = 1

rs.reconfig(cfg)
```

#### 4. Retry Automatique dans les Drivers

```javascript
// Node.js
const client = new MongoClient(uri, {
  retryWrites: true,      // Retry √©critures automatiquement
  retryReads: true,       // Retry lectures automatiquement
  serverSelectionTimeoutMS: 30000,  // 30s pour trouver un serveur
  socketTimeoutMS: 45000,
  connectTimeoutMS: 10000
})
```

### R√©duire le RPO (Recovery Point Objective)

#### 1. Write Concern Majority

```javascript
// RPO = 0 (aucune perte de donn√©es)
db.collection.insertOne(doc, {
  writeConcern: { w: "majority", wtimeout: 5000 }
})
```

#### 2. Read Concern Majority

```javascript
// Lire uniquement les donn√©es r√©pliqu√©es sur majorit√©
db.collection.find({}, {
  readConcern: { level: "majority" }
})
```

#### 3. Journaling

```yaml
# mongod.conf
storage:
  journal:
    enabled: true
    commitIntervalMs: 100  # Commit journal toutes les 100ms
```

**RPO avec journaling** : ~100-300ms (dur√©e du commit interval)

#### 4. Monitoring de la R√©plication

```javascript
// Alerter si lag > seuil
function monitorReplicationLag(maxLagSeconds) {
  const status = rs.status()
  const alerts = []

  status.members.forEach(m => {
    if (m.state === 2 && m.optimeDate) {  // SECONDARY
      const lag = (status.date - m.optimeDate) / 1000
      if (lag > maxLagSeconds) {
        alerts.push({
          member: m.name,
          lag: lag,
          severity: lag > maxLagSeconds * 2 ? 'CRITICAL' : 'WARNING'
        })
      }
    }
  })

  return alerts
}

// V√©rifier toutes les 30 secondes
setInterval(() => {
  const alerts = monitorReplicationLag(10)  // Seuil: 10s
  if (alerts.length > 0) {
    console.log('REPLICATION LAG ALERTS:', alerts)
    // Envoyer notification
  }
}, 30000)
```

## Bonnes Pratiques

### 1. Architecture

```javascript
// ‚úÖ Nombre impair de votants
// ‚úÖ Minimum 3 membres (id√©alement 5)
// ‚úÖ Distribution g√©ographique si possible
{
  members: [
    { _id: 0, host: "dc1-01:27017", priority: 10, tags: {dc: "dc1"} },
    { _id: 1, host: "dc1-02:27017", priority: 9, tags: {dc: "dc1"} },
    { _id: 2, host: "dc1-03:27017", priority: 8, tags: {dc: "dc1"} },
    { _id: 3, host: "dc2-01:27017", priority: 1, tags: {dc: "dc2"} },
    { _id: 4, host: "dc2-02:27017", priority: 1, tags: {dc: "dc2"} }
  ]
}
```

### 2. Configuration

```javascript
// ‚úÖ Write Concern par d√©faut
cfg.settings.getLastErrorDefaults = {
  w: "majority",
  wtimeout: 5000
}

// ‚úÖ Election timeout adapt√© au r√©seau
cfg.settings.electionTimeoutMillis = 10000  // LAN
cfg.settings.electionTimeoutMillis = 30000  // WAN

// ‚úÖ Oplog suffisant
db.adminCommand({ replSetResizeOplog: 1, size: 10240 })  // 10 GB
```

### 3. Monitoring

```javascript
// M√©triques cl√©s √† surveiller
const metrics = {
  // Disponibilit√©
  'Primary pr√©sent': () => rs.status().members.filter(m => m.state === 1).length === 1,

  // Performance
  'Replication lag': () => {
    const status = rs.status()
    const lags = status.members
      .filter(m => m.state === 2)
      .map(m => (status.date - m.optimeDate) / 1000)
    return Math.max(...lags)
  },

  // R√©silience
  'Oplog window (hours)': () => db.getReplicationInfo().timeDiff / 3600,

  // Sant√©
  'Membres UP': () => rs.status().members.filter(m => m.health === 1).length
}
```

### 4. Tests R√©guliers

```bash
# Planifier des tests de failover trimestriels
# Documenter les r√©sultats
# Mesurer RTO/RPO
# Valider les runbooks

# Exemple de calendrier
# T1 : Test de failover contr√¥l√©
# T2 : Test de partition r√©seau
# T3 : Test de crash brutal
# T4 : Test de failover en charge
```

### 5. Documentation

```yaml
# Runbook Failover
version: 2.1
last_updated: 2024-01-15

scenarios:
  - name: "Primary Down"
    detection: "No primary in rs.status()"
    expected_rto: "15-30 seconds"
    expected_rpo: "0 (with w:majority)"
    actions:
      - "Verify automatic election occurred"
      - "Check application connectivity"
      - "Investigate cause of failure"
      - "Repair/replace failed member"

  - name: "Network Partition"
    detection: "Members showing as DOWN but actually running"
    expected_behavior: "Partition with majority continues"
    actions:
      - "Identify network issue"
      - "Verify no split-brain"
      - "Restore network connectivity"
      - "Verify data consistency"
```

## Conclusion

La haute disponibilit√© dans MongoDB repose sur :

- ‚úÖ **Architecture r√©siliente** : Minimum 3 membres, id√©alement 5+
- ‚úÖ **Configuration optimis√©e** : Write concern majority, timeout adapt√©s
- ‚úÖ **Monitoring proactif** : D√©tection rapide des anomalies
- ‚úÖ **Tests r√©guliers** : Validation des proc√©dures de failover
- ‚úÖ **Documentation** : Runbooks √† jour et test√©s

**M√©triques cl√©s** :
- **RTO** : 15-30 secondes (failover automatique)
- **RPO** : 0 (avec w: "majority")
- **Disponibilit√©** : 99.9% - 99.99%

Le failover automatique de MongoDB garantit la continuit√© de service en cas de d√©faillance, mais n√©cessite une conception architecturale appropri√©e et une validation r√©guli√®re pour assurer la r√©silience en production.

‚è≠Ô∏è [Monitoring d'un Replica Set](/09-replication/10-monitoring-replica-set.md)
