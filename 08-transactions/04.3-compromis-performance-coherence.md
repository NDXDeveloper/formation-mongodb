üîù Retour au [Sommaire](/SOMMAIRE.md)

# 8.4.3 Compromis performance vs coh√©rence

## Introduction : L'in√©vitable √©quation

Dans tout syst√®me distribu√©, et MongoDB ne fait pas exception, il existe une tension fondamentale et in√©vitable entre **performance** et **coh√©rence**. Ce n'est pas un d√©faut d'architecture, mais une cons√©quence math√©matique et physique des syst√®mes distribu√©s : la lumi√®re ne voyage pas instantan√©ment, les r√©seaux ont une latence, et coordonner plusieurs machines prend du temps.

Cette section explore en profondeur comment naviguer dans cet espace de compromis, comment quantifier les co√ªts, et comment prendre des d√©cisions architecturales √©clair√©es qui alignent les garanties techniques avec les besoins m√©tier.

### Le trilemme fondamental revisit√©

Alors que le th√©or√®me CAP nous dit qu'on ne peut avoir que deux des trois propri√©t√©s (Coh√©rence, Disponibilit√©, Tol√©rance aux partitions), dans la pratique, les choix sont plus nuanc√©s :

```
Spectre des compromis MongoDB :

Performance maximale          Coh√©rence stricte
        ‚Üì                             ‚Üì
    w:1, local              w:majority+j, linearizable
        ‚Üì                             ‚Üì
    Latence: ~2ms                 Latence: ~50-100ms
    Risque: Perte <500ms          Risque: Aucun
    Throughput: 50k ops/s         Throughput: 5k ops/s
```

**La question n'est pas "Performance OU Coh√©rence"**, mais plut√¥t :
- Quel niveau de coh√©rence est **suffisant** pour ce cas d'usage ?
- Quel co√ªt de performance suis-je pr√™t √† **payer** pour cette garantie ?
- Comment **mesurer** et **valider** que le compromis choisi est optimal ?

## Quantifier les co√ªts : M√©triques et mesures

### Latence : Le co√ªt temporel de la coh√©rence

La latence est la m√©trique la plus visible et la plus imm√©diate du compromis performance/coh√©rence.

**D√©composition de la latence d'√©criture** :

```javascript
// Anatomie d'une √©criture avec w:majority, j:true

Phase 1: Network ‚Üí Primary                    ~1-2ms
Phase 2: Primary processing                   ~0.5-1ms
Phase 3: Memory write (WiredTiger cache)      ~0.1-0.3ms
Phase 4: Journal write (if j:true)            ~2-5ms
Phase 5: Replication to Secondaries           ~5-50ms (selon topologie)
Phase 6: Secondary acknowledgment             ~1-2ms
Phase 7: Primary ‚Üí Client response            ~1-2ms

Total avec w:majority, j:false:  ~10-60ms
Total avec w:majority, j:true:   ~15-70ms
Total avec w:1, j:false:         ~2-5ms
```

**Benchmark r√©el : Impact des configurations** (Replica Set 3 n≈ìuds, m√™me datacenter) :

```
Configuration               P50      P95      P99      Max
----------------------------------------------------------------
w:0                        0.5ms    1ms      2ms      5ms
w:1, j:false              2ms      5ms      8ms      15ms
w:1, j:true               5ms      10ms     15ms     30ms
w:majority, j:false       12ms     25ms     40ms     80ms
w:majority, j:true        18ms     35ms     60ms     120ms
w:majority+linearizable   45ms     80ms     150ms    300ms

Facteur multiplicatif (vs w:1) :
- majority sans journal : 6x plus lent (P50)
- majority avec journal : 9x plus lent (P50)
- linearizable : 22x plus lent (P50)
```

### Throughput : Le co√ªt volum√©trique de la coh√©rence

Le throughput mesure le nombre d'op√©rations par seconde que le syst√®me peut traiter.

**Mesures empiriques** (MongoDB 7.0, hardware standard) :

```
Configuration                    Write throughput    Read throughput
---------------------------------------------------------------------
w:0 (local reads)               100,000 ops/s       200,000 ops/s
w:1, j:false (local reads)      50,000 ops/s        200,000 ops/s
w:majority, j:false (local)     15,000 ops/s        150,000 ops/s
w:majority, j:true (majority)   8,000 ops/s         80,000 ops/s

Observation cl√© : Le throughput d'√©criture chute drastiquement avec
les garanties de coh√©rence, car chaque op√©ration attend plus longtemps.
```

**Loi d'Amdahl appliqu√©e aux transactions** :

```
Si 20% de vos op√©rations n√©cessitent w:majority+j
et 80% peuvent utiliser w:1 :

Throughput mixte ‚âà 1 / (0.2/8000 + 0.8/50000)
                 ‚âà 1 / (0.000025 + 0.000016)
                 ‚âà 24,400 ops/s

vs tout en w:majority+j : 8,000 ops/s (3x pire)
vs tout en w:1 : 50,000 ops/s (2x mieux mais risqu√©)

Conclusion : La granularit√© du choix de coh√©rence est cruciale
```

### Co√ªt en disponibilit√© : Quand la coh√©rence bloque

Plus le Write Concern est strict, plus il est sensible aux pannes partielles.

**Matrice de disponibilit√©** (Replica Set 3 n≈ìuds) :

```
Situation                        w:1    w:majority    Impact
----------------------------------------------------------------
Tous les n≈ìuds up               ‚úÖ     ‚úÖ            Aucun
1 Secondary down                ‚úÖ     ‚úÖ            Aucun (2/3 OK)
Primary down (√©lection)         ‚ùå     ‚ùå            Indispo ~10-30s
2 Secondaries down              ‚úÖ     ‚ùå            w:maj impossible
Partition r√©seau (1 vs 2)       ‚úÖ*    ‚úÖ/‚ùå         D√©pend du c√¥t√©

* Le n≈ìud isol√© peut accepter w:1 mais ces √©critures seront rollback
```

**Calcul de disponibilit√©** :

```javascript
// Disponibilit√© th√©orique selon configuration

// Hypoth√®ses :
// - Uptime d'un n≈ìud : 99.9% (SLA standard)
// - Replica Set : 3 n≈ìuds

// Avec w:1 : Besoin que le Primary soit up
const availabilityW1 = 0.999; // 99.9%

// Avec w:majority : Besoin de 2+ n≈ìuds up
const availabilityWMaj =
  // 3 n≈ìuds up + 2 n≈ìuds up (avec le Primary)
  Math.pow(0.999, 3) +
  3 * Math.pow(0.999, 2) * 0.001;
  // ‚âà 0.999997 ou 99.9997%

// Paradoxe apparent : w:majority semble plus disponible !
// En r√©alit√©, c'est parce qu'on ignore les partitions r√©seau
// et les d√©lais de failover

// Avec partitions r√©seau (1% du temps) :
const realAvailabilityWMaj = 0.999997 * 0.99; // ‚âà 98.9997%

// Downtime annuel :
// w:1 : ~8.76 heures
// w:majority (avec partitions) : ~52.6 minutes + timeout delays
```

## √âtudes de cas : D√©cisions architecturales r√©elles

### Cas 1 : Plateforme de trading financier

**Contexte** :
- Ordres de bourse en temps r√©el
- Volume : 10,000 ordres/seconde en pic
- Exigence r√©glementaire : Aucune perte d'ordre
- SLA : 99.99% disponibilit√©
- Latence acceptable : < 100ms P99

**Analyse des besoins** :

```javascript
// Caract√©ristiques des op√©rations

const operationProfile = {
  // Placement d'ordre : CRITIQUE
  orderPlacement: {
    frequency: '10,000/sec',
    criticality: 'HIGH',
    regulatoire: true,
    latenceMax: '50ms P99'
  },

  // Consultation du portefeuille : NON CRITIQUE
  portfolioView: {
    frequency: '50,000/sec',
    criticality: 'LOW',
    staleness_tolerance: '1-2s OK',
    latenceMax: '20ms P99'
  },

  // Historique des trades : IMPORTANT mais pas temps r√©el
  tradeHistory: {
    frequency: '5,000/sec',
    criticality: 'MEDIUM',
    staleness_tolerance: '5-10s OK',
    latenceMax: '100ms P99'
  }
};
```

**Solution adopt√©e : Architecture diff√©renci√©e** :

```javascript
// Configuration multi-niveaux

class TradingPlatform {
  constructor(db) {
    this.db = db;

    // Configuration par type d'op√©ration
    this.writeConcerns = {
      critical: { w: "majority", j: true, wtimeout: 5000 },
      important: { w: "majority", j: false, wtimeout: 3000 },
      standard: { w: 1, j: false, wtimeout: 1000 }
    };

    this.readConcerns = {
      critical: { level: "majority" },
      eventual: { level: "local" }
    };
  }

  // Placement d'ordre : Coh√©rence maximale
  async placeOrder(order) {
    const session = this.db.client.startSession();

    try {
      await session.withTransaction(async () => {
        // V√©rifier le solde (lecture coh√©rente)
        const account = await this.db.accounts.findOne(
          { userId: order.userId },
          {
            session,
            readConcern: this.readConcerns.critical
          }
        );

        if (account.balance < order.amount) {
          throw new Error('Solde insuffisant');
        }

        // Cr√©er l'ordre (√©criture durable)
        await this.db.orders.insertOne(
          { ...order, status: 'pending', createdAt: new Date() },
          {
            session,
            writeConcern: this.writeConcerns.critical
          }
        );

        // D√©bit du compte
        await this.db.accounts.updateOne(
          { userId: order.userId },
          { $inc: { balance: -order.amount } },
          {
            session,
            writeConcern: this.writeConcerns.critical
          }
        );

      }, {
        readConcern: this.readConcerns.critical,
        writeConcern: this.writeConcerns.critical,
        maxCommitTimeMS: 5000
      });

      return { success: true };

    } catch (error) {
      console.error('√âchec placement ordre:', error);
      return { success: false, error: error.message };
    } finally {
      await session.endSession();
    }
  }

  // Vue du portefeuille : Performance maximale
  async getPortfolio(userId) {
    // Lecture depuis Secondary le plus proche
    return await this.db.portfolios.findOne(
      { userId },
      {
        readConcern: this.readConcerns.eventual,
        readPreference: 'secondaryPreferred'
      }
    );
    // Un d√©lai de 1-2s est acceptable pour l'affichage
  }

  // Historique : √âquilibre
  async getTradeHistory(userId, filters) {
    return await this.db.trades.find(
      { userId, ...filters },
      {
        readConcern: { level: "majority" },
        readPreference: 'secondaryPreferred'
      }
    ).toArray();
  }
}
```

**R√©sultats mesur√©s** :

```
M√©triques avant optimisation (tout en w:majority+j) :
- Latence ordres P99 : 85ms (limite acceptable)
- Latence portefeuille P99 : 60ms (trop lent)
- Throughput : 8,000 ordres/sec (insuffisant)
- CPU utilization : 85% (satur√©)

M√©triques apr√®s optimisation (configuration diff√©renci√©e) :
- Latence ordres P99 : 45ms (‚úÖ largement sous la limite)
- Latence portefeuille P99 : 12ms (‚úÖ 5x am√©lioration)
- Throughput : 15,000 ordres/sec (‚úÖ suffisant)
- CPU utilization : 55% (‚úÖ marge confortable)

ROI : M√™me niveau de garanties pour les op√©rations critiques,
      mais 5x meilleures performances sur les lectures
```

### Cas 2 : Application SaaS de gestion de projet

**Contexte** :
- 50,000 utilisateurs actifs
- Collaboration en temps r√©el
- Disponibilit√© critique : 99.95%
- Budget limit√© : optimisation des co√ªts cloud

**Analyse des op√©rations** :

```javascript
const operationAnalysis = {
  // Cr√©ation de projet : Peu fr√©quent mais important
  projectCreation: {
    frequency: '100/hour',
    impact: 'Visible par l\'utilisateur',
    decision: 'w:majority (durabilit√© importante)'
  },

  // Mise √† jour de t√¢che : Tr√®s fr√©quent, visible par l'√©quipe
  taskUpdate: {
    frequency: '10,000/hour',
    impact: 'Collaboration temps r√©el',
    conflictRisk: 'High',
    decision: 'w:majority (√©viter conflits)'
  },

  // Commentaires : Tr√®s fr√©quent, moins critique
  comments: {
    frequency: '50,000/hour',
    impact: 'Asynchrone OK',
    staleness_tolerance: '2-3 secondes',
    decision: 'w:1 (performance > coh√©rence stricte)'
  },

  // Activit√©/logs : Volume massif, peu critique
  activityLogs: {
    frequency: '500,000/hour',
    impact: 'Historique seulement',
    staleness_tolerance: 'Minutes',
    decision: 'w:1, batching'
  }
};
```

**Strat√©gie adopt√©e : Compromis progressifs** :

```javascript
class ProjectManagementApp {
  constructor(db) {
    this.db = db;

    // Stratification des guaranties
    this.concerns = {
      tier1: { // Op√©rations structurelles
        write: { w: "majority", j: false, wtimeout: 5000 },
        read: { level: "majority" }
      },
      tier2: { // Collaboration standard
        write: { w: "majority", j: false, wtimeout: 3000 },
        read: { level: "local" }
      },
      tier3: { // Activit√© et logs
        write: { w: 1, j: false, wtimeout: 1000 },
        read: { level: "local" }
      }
    };

    // Buffer pour batching des logs
    this.logBuffer = [];
    this.logBufferSize = 100;
  }

  // Cr√©ation de projet : Tier 1
  async createProject(projectData) {
    return await this.db.projects.insertOne(
      projectData,
      { writeConcern: this.concerns.tier1.write }
    );
  }

  // Mise √† jour de t√¢che : Tier 2
  async updateTask(taskId, updates) {
    // Versioning optimiste pour d√©tecter les conflits
    const result = await this.db.tasks.findOneAndUpdate(
      {
        _id: taskId,
        version: updates.expectedVersion
      },
      {
        $set: updates.data,
        $inc: { version: 1 }
      },
      {
        writeConcern: this.concerns.tier2.write,
        returnDocument: 'after'
      }
    );

    if (!result.value) {
      throw new Error('Conflit de version - rechargez la t√¢che');
    }

    return result.value;
  }

  // Commentaire : Tier 2 mais optimis√©
  async addComment(taskId, comment) {
    // √âcriture rapide sans transaction
    return await this.db.comments.insertOne(
      {
        taskId,
        ...comment,
        createdAt: new Date()
      },
      { writeConcern: this.concerns.tier2.write }
    );
  }

  // Log d'activit√© : Tier 3 avec batching
  async logActivity(activity) {
    this.logBuffer.push({ ...activity, timestamp: new Date() });

    // Flush si le buffer est plein
    if (this.logBuffer.length >= this.logBufferSize) {
      return await this.flushLogs();
    }

    // Sinon, return imm√©diat (fire-and-forget)
    return { queued: true };
  }

  async flushLogs() {
    if (this.logBuffer.length === 0) return;

    const logsToFlush = [...this.logBuffer];
    this.logBuffer = [];

    try {
      await this.db.activity_logs.insertMany(
        logsToFlush,
        {
          writeConcern: this.concerns.tier3.write,
          ordered: false // Continuer m√™me si certains √©chouent
        }
      );
    } catch (error) {
      console.error('Erreur flush logs:', error);
      // Ne pas bloquer l'application
    }
  }
}
```

**Impact financier et technique** :

```
Co√ªt cloud mensuel (estimation AWS/Atlas) :

Approche "tout coh√©rent" (w:majority partout) :
- Instance size: M40 (4 vCPU, 16GB) x3 = $1,200/mois
- IOPS √©lev√©s requis = +$300/mois
- Total : ~$1,500/mois

Approche stratifi√©e :
- Instance size: M30 (2 vCPU, 8GB) x3 = $600/mois
- IOPS standard = inclus
- Total : ~$600/mois

√âconomie : $900/mois = $10,800/an (60% moins cher)

Performance utilisateur :
- Chargement de projet : -30% latence
- Ajout de commentaire : -50% latence
- R√©activit√© g√©n√©rale : Nettement am√©lior√©e
```

### Cas 3 : Plateforme IoT (Internet des Objets)

**Contexte** :
- 1 million de capteurs connect√©s
- 50,000 mesures/seconde
- Alertes critiques rares mais vitales
- Budget de stockage limit√©

**D√©fi sp√©cifique** : Volume massif de donn√©es de faible valeur individuelle, mais certaines donn√©es critiques noy√©es dans le bruit.

**Architecture adopt√©e : Dual-track** :

```javascript
class IoTPlatform {
  constructor(db) {
    this.db = db;

    // Deux chemins d'√©criture distincts
    this.concerns = {
      // Voie rapide : Mesures standard
      fastPath: {
        write: { w: 1, j: false, wtimeout: 500 },
        read: { level: "local" }
      },

      // Voie s√ªre : Alertes critiques
      safePath: {
        write: { w: "majority", j: true, wtimeout: 5000 },
        read: { level: "majority" }
      }
    };

    // Seuils pour classification
    this.thresholds = {
      temperature: { min: -10, max: 60, critical: 80 },
      pressure: { min: 0, max: 1000, critical: 1200 },
      vibration: { min: 0, max: 100, critical: 150 }
    };
  }

  async ingestSensorData(sensorId, readings) {
    // Analyse rapide pour classifier
    const classification = this.classifyReadings(readings);

    if (classification.isCritical) {
      return await this.handleCriticalData(sensorId, readings, classification);
    } else {
      return await this.handleNormalData(sensorId, readings);
    }
  }

  classifyReadings(readings) {
    let isCritical = false;
    const alerts = [];

    for (const [metric, value] of Object.entries(readings)) {
      const threshold = this.thresholds[metric];
      if (threshold && value > threshold.critical) {
        isCritical = true;
        alerts.push({ metric, value, threshold: threshold.critical });
      }
    }

    return { isCritical, alerts };
  }

  // Voie rapide : Volume √©lev√©, faible garanties
  async handleNormalData(sensorId, readings) {
    // Insertion avec garanties minimales
    await this.db.sensor_data.insertOne(
      {
        sensorId,
        readings,
        timestamp: new Date(),
        type: 'normal'
      },
      { writeConcern: this.concerns.fastPath.write }
    );

    // Pas d'attente de confirmation
    return { status: 'queued' };
  }

  // Voie s√ªre : Donn√©es critiques
  async handleCriticalData(sensorId, readings, classification) {
    const session = this.db.client.startSession();

    try {
      await session.withTransaction(async () => {
        // Enregistrer la mesure avec garanties fortes
        await this.db.sensor_data.insertOne(
          {
            sensorId,
            readings,
            timestamp: new Date(),
            type: 'critical',
            alerts: classification.alerts
          },
          {
            session,
            writeConcern: this.concerns.safePath.write
          }
        );

        // Cr√©er une alerte durable
        await this.db.alerts.insertOne(
          {
            sensorId,
            type: 'threshold_exceeded',
            alerts: classification.alerts,
            status: 'active',
            createdAt: new Date()
          },
          {
            session,
            writeConcern: this.concerns.safePath.write
          }
        );

        // Mettre √† jour le statut du capteur
        await this.db.sensors.updateOne(
          { _id: sensorId },
          {
            $set: {
              status: 'alert',
              lastAlert: new Date()
            }
          },
          {
            session,
            writeConcern: this.concerns.safePath.write
          }
        );

      }, {
        readConcern: { level: "majority" },
        writeConcern: this.concerns.safePath.write
      });

      // Notification externe (email, SMS, webhook)
      await this.sendCriticalAlert(sensorId, classification.alerts);

      return { status: 'alert_created', alerts: classification.alerts };

    } finally {
      await session.endSession();
    }
  }

  async sendCriticalAlert(sensorId, alerts) {
    // Impl√©mentation notification externe
    console.log(`üö® ALERTE CRITIQUE - Capteur ${sensorId}:`, alerts);
  }
}
```

**R√©sultats et compromis** :

```
Volum√©trie et performance :

Donn√©es normales (99.5%) :
- Volume : ~49,750 mesures/sec
- Latence √©criture P99 : 8ms
- Garantie : w:1 (risque perte <500ms acceptable)
- Co√ªt : Minimal en compute

Donn√©es critiques (0.5%) :
- Volume : ~250 alertes/sec
- Latence √©criture P99 : 65ms (acceptable pour urgence)
- Garantie : w:majority+j (aucune perte tol√©r√©e)
- Co√ªt : 8x plus cher par op√©ration, mais volume faible

Compromis justifi√© :
- 99.5% des donn√©es : Performance optimale
- 0.5% des donn√©es : Garanties maximales
- Co√ªt global : Optimal
- Fiabilit√© : 100% sur les donn√©es critiques
```

## Strat√©gies d'optimisation : Le meilleur des deux mondes

### Strat√©gie 1 : Lectures asynchrones (Read-your-writes problem)

Un probl√®me classique : Un utilisateur √©crit une donn√©e puis ne la voit pas imm√©diatement lors d'une lecture.

**Probl√®me** :

```javascript
// √âcriture avec w:majority (latence 20ms)
await db.posts.insertOne({ title: "Hello" }, { writeConcern: { w: "majority" } });

// Redirection vers la page du post
// Lecture depuis Secondary (optimisation) avec readConcern:local
const post = await db.posts.findOne(
  { title: "Hello" },
  { readPreference: "secondaryPreferred", readConcern: { level: "local" } }
);

// PROBL√àME : post peut √™tre null si le Secondary n'a pas encore r√©pliqu√© !
// L'utilisateur voit "Post introuvable" alors qu'il vient de le cr√©er
```

**Solution : Sessions causales** :

```javascript
// Utiliser une session causale
const session = client.startSession({ causalConsistency: true });

try {
  // √âcriture avec w:majority
  await db.posts.insertOne(
    { title: "Hello", content: "World" },
    {
      session,
      writeConcern: { w: "majority" }
    }
  );

  // Lecture causalement coh√©rente
  // MongoDB garantit que cette lecture verra l'√©criture pr√©c√©dente
  const post = await db.posts.findOne(
    { title: "Hello" },
    {
      session,
      readPreference: "secondaryPreferred",
      readConcern: { level: "majority" }
    }
  );

  // ‚úÖ post est garanti d'exister
  console.log("Post trouv√©:", post);

} finally {
  await session.endSession();
}

// La coh√©rence causale ajoute ~2-5ms de latence
// mais garantit la coh√©rence read-after-write
```

**Alternative : Sticky sessions avec Primary** :

```javascript
// Pattern : Lire depuis le Primary pendant N secondes apr√®s une √©criture

class CacheWithWritethrough {
  constructor(db) {
    this.db = db;
    this.recentWrites = new Map(); // userId -> timestamp
    this.stickinessDuration = 5000; // 5 secondes
  }

  async write(userId, data) {
    await this.db.collection.insertOne(data, {
      writeConcern: { w: "majority" }
    });

    // Marquer l'utilisateur comme ayant √©crit r√©cemment
    this.recentWrites.set(userId, Date.now());
  }

  async read(userId, filter) {
    const lastWrite = this.recentWrites.get(userId);
    const shouldReadFromPrimary =
      lastWrite && (Date.now() - lastWrite < this.stickinessDuration);

    if (shouldReadFromPrimary) {
      // Lire depuis Primary pour coh√©rence imm√©diate
      return await this.db.collection.findOne(filter, {
        readPreference: "primary",
        readConcern: { level: "local" }
      });
    } else {
      // Lire depuis Secondary pour performance
      return await this.db.collection.findOne(filter, {
        readPreference: "secondaryPreferred",
        readConcern: { level: "local" }
      });
    }
  }

  // Nettoyage p√©riodique
  cleanup() {
    const now = Date.now();
    for (const [userId, timestamp] of this.recentWrites) {
      if (now - timestamp > this.stickinessDuration) {
        this.recentWrites.delete(userId);
      }
    }
  }
}
```

### Strat√©gie 2 : D√©gradation gracieuse (Graceful degradation)

Adapter dynamiquement les garanties selon les conditions du syst√®me.

```javascript
class AdaptiveWriteManager {
  constructor(db) {
    this.db = db;
    this.healthMetrics = {
      replicationLag: 0,
      writeConcernTimeouts: 0,
      lastCheck: Date.now()
    };

    this.thresholds = {
      lagWarning: 1000,      // 1s
      lagCritical: 5000,     // 5s
      timeoutThreshold: 0.05 // 5% de timeouts
    };
  }

  // Mise √† jour p√©riodique de la sant√© du cluster
  async updateHealthMetrics() {
    const status = await this.db.admin().command({ replSetGetStatus: 1 });

    // Calculer le lag max
    let maxLag = 0;
    for (const member of status.members) {
      if (member.state === 2) { // SECONDARY
        const lag = status.date - member.optimeDate;
        maxLag = Math.max(maxLag, lag);
      }
    }

    this.healthMetrics.replicationLag = maxLag;
    this.healthMetrics.lastCheck = Date.now();
  }

  // S√©lectionner le Write Concern selon la sant√©
  getAdaptiveWriteConcern(operationPriority) {
    const lag = this.healthMetrics.replicationLag;
    const timeoutRate = this.healthMetrics.writeConcernTimeouts;

    // Op√©ration critique : Toujours w:majority
    if (operationPriority === 'critical') {
      return {
        w: "majority",
        j: true,
        wtimeout: 10000,
        rationale: "Critique - aucun compromis"
      };
    }

    // Cluster en bonne sant√© : Utiliser w:majority
    if (lag < this.thresholds.lagWarning && timeoutRate < this.thresholds.timeoutThreshold) {
      return {
        w: "majority",
        j: false,
        wtimeout: 5000,
        rationale: "Sant√© OK - garanties normales"
      };
    }

    // Lag mod√©r√© : D√©grader vers w:1 pour les op√©rations non critiques
    if (lag < this.thresholds.lagCritical && operationPriority === 'normal') {
      console.warn(`‚ö†Ô∏è  Replication lag √©lev√© (${lag}ms) - d√©gradation vers w:1`);
      return {
        w: 1,
        j: false,
        wtimeout: 3000,
        rationale: "Lag mod√©r√© - d√©gradation gracieuse"
      };
    }

    // Lag critique : w:1 pour toutes op√©rations non critiques
    console.error(`üö® Replication lag critique (${lag}ms) - mode d√©grad√©`);
    return {
      w: 1,
      j: false,
      wtimeout: 2000,
      rationale: "Mode d√©grad√© - maintenir disponibilit√©"
    };
  }

  // Wrapper pour insertOne avec adaptation
  async insertOneAdaptive(collection, document, priority = 'normal') {
    await this.updateHealthMetrics();
    const writeConcern = this.getAdaptiveWriteConcern(priority);

    console.log(`Write avec ${writeConcern.rationale}`);

    try {
      return await collection.insertOne(document, { writeConcern });
    } catch (error) {
      if (error.code === 64) { // WriteConcernError
        this.healthMetrics.writeConcernTimeouts++;
      }
      throw error;
    }
  }
}

// Utilisation
const manager = new AdaptiveWriteManager(db);

// Op√©ration normale : S'adapte aux conditions
await manager.insertOneAdaptive(
  db.posts,
  { title: "Hello" },
  'normal'
);

// Op√©ration critique : Toujours coh√©rence maximale
await manager.insertOneAdaptive(
  db.payments,
  { amount: 1000, status: "pending" },
  'critical'
);
```

### Strat√©gie 3 : Caching intelligent avec versioning

Combiner un cache applicatif avec MongoDB pour le meilleur des deux mondes.

```javascript
class VersionedCache {
  constructor(db, redis) {
    this.db = db;
    this.redis = redis;
    this.cacheTTL = 60; // 60 secondes
  }

  // √âcriture : Invalide le cache et √©crit en DB
  async set(key, value, options = {}) {
    const priority = options.priority || 'normal';

    // G√©n√©rer une version (timestamp + random)
    const version = `${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
    const documentWithVersion = { ...value, _version: version };

    // √âcrire en DB avec coh√©rence appropri√©e
    const writeConcern = priority === 'critical'
      ? { w: "majority", j: true, wtimeout: 5000 }
      : { w: "majority", j: false, wtimeout: 3000 };

    await this.db.collection(options.collection).updateOne(
      { _id: key },
      { $set: documentWithVersion },
      { upsert: true, writeConcern }
    );

    // Invalider le cache
    await this.redis.del(`cache:${key}`);

    return version;
  }

  // Lecture : Cache-aside avec v√©rification de version
  async get(key, options = {}) {
    const collection = options.collection;

    // Tentative de lecture depuis le cache
    const cached = await this.redis.get(`cache:${key}`);

    if (cached) {
      const data = JSON.parse(cached);

      // Si l'op√©ration est critique, v√©rifier que la version est √† jour
      if (options.ensureFresh) {
        const dbDoc = await this.db.collection(collection).findOne(
          { _id: key },
          {
            projection: { _version: 1 },
            readConcern: { level: "majority" }
          }
        );

        if (dbDoc && dbDoc._version !== data._version) {
          // Version obsol√®te, invalider et recharger
          await this.redis.del(`cache:${key}`);
          return await this.loadFromDB(key, collection);
        }
      }

      return data;
    }

    // Pas en cache, charger depuis DB
    return await this.loadFromDB(key, collection);
  }

  async loadFromDB(key, collection) {
    // Lire depuis MongoDB
    const doc = await this.db.collection(collection).findOne(
      { _id: key },
      {
        readConcern: { level: "local" },
        readPreference: "secondaryPreferred"
      }
    );

    if (doc) {
      // Mettre en cache
      await this.redis.setex(
        `cache:${key}`,
        this.cacheTTL,
        JSON.stringify(doc)
      );
    }

    return doc;
  }
}

// Utilisation
const cache = new VersionedCache(db, redis);

// √âcriture critique : Coh√©rence forte + invalidation cache
await cache.set(
  'user:123',
  { name: "Alice", email: "alice@example.com" },
  { collection: 'users', priority: 'critical' }
);

// Lecture standard : Cache ou DB
const user = await cache.get('user:123', { collection: 'users' });

// Lecture critique : V√©rifier la fra√Æcheur
const userFresh = await cache.get(
  'user:123',
  { collection: 'users', ensureFresh: true }
);
```

## M√©triques de d√©cision : Framework quantitatif

### Calculer le co√ªt total d'une garantie

Pour chaque niveau de coh√©rence, calculer le **co√ªt total** :

```javascript
class ConsistencyCostCalculator {
  constructor(metrics) {
    this.metrics = metrics;
  }

  // Calculer le co√ªt mon√©taire d'une configuration
  calculateCost(config) {
    const { writeConcern, expectedOps, instanceCost } = config;

    // Latence moyenne selon configuration
    const latencyMs = this.getAverageLatency(writeConcern);

    // Op√©rations par seconde par instance
    const opsPerInstance = 1000 / latencyMs;

    // Nombre d'instances n√©cessaires
    const instancesNeeded = Math.ceil(expectedOps / opsPerInstance);

    // Co√ªt mensuel
    const monthlyCost = instancesNeeded * instanceCost * 730; // heures/mois

    return {
      instancesNeeded,
      monthlyCost,
      latencyMs,
      opsPerInstance
    };
  }

  getAverageLatency(writeConcern) {
    // Bas√© sur des benchmarks r√©els
    const latencies = {
      'w:0': 0.5,
      'w:1': 2,
      'w:majority': 15,
      'w:majority+j': 22
    };

    const key = writeConcern.j
      ? `w:${writeConcern.w}+j`
      : `w:${writeConcern.w}`;

    return latencies[key] || 15;
  }

  // Comparer deux configurations
  compare(config1, config2) {
    const cost1 = this.calculateCost(config1);
    const cost2 = this.calculateCost(config2);

    return {
      config1: cost1,
      config2: cost2,
      savings: {
        cost: cost2.monthlyCost - cost1.monthlyCost,
        latency: cost2.latencyMs - cost1.latencyMs,
        instances: cost2.instancesNeeded - cost1.instancesNeeded
      }
    };
  }
}

// Exemple d'utilisation
const calculator = new ConsistencyCostCalculator();

const configOptimized = {
  writeConcern: { w: "majority", j: false },
  expectedOps: 10000,
  instanceCost: 0.15 // $/heure
};

const configMaxConsistency = {
  writeConcern: { w: "majority", j: true },
  expectedOps: 10000,
  instanceCost: 0.15
};

const comparison = calculator.compare(configOptimized, configMaxConsistency);

console.log('Analyse des co√ªts:');
console.log('Optimis√©:', comparison.config1);
console.log('Max consistance:', comparison.config2);
console.log('√âconomies:', comparison.savings);

// Sortie typique:
// Optimis√©: { instancesNeeded: 2, monthlyCost: $219, latencyMs: 15ms }
// Max consistance: { instancesNeeded: 3, monthlyCost: $329, latencyMs: 22ms }
// √âconomies: { cost: -$110, latency: -7ms, instances: -1 }
```

### SLA et disponibilit√© : Calcul d'impact

```javascript
function calculateSLAImpact(config) {
  const {
    replicaSetSize,
    writeTimeout,
    networkPartitionRate,
    nodeFailureRate,
    writeConcern
  } = config;

  // Calcul de disponibilit√© selon le Write Concern
  let availability;

  if (writeConcern === 'w:1') {
    // Besoin du Primary seulement
    availability = 1 - nodeFailureRate;
  } else if (writeConcern === 'w:majority') {
    // Besoin de la majorit√©
    const majority = Math.floor(replicaSetSize / 2) + 1;

    // Probabilit√© qu'au moins 'majority' n≈ìuds soient up
    // Simplification: hypoth√®se d'ind√©pendance
    let probMajorityUp = 0;
    for (let i = majority; i <= replicaSetSize; i++) {
      const prob = binomialProbability(
        replicaSetSize,
        i,
        1 - nodeFailureRate
      );
      probMajorityUp += prob;
    }

    availability = probMajorityUp * (1 - networkPartitionRate);
  }

  // Downtime annuel
  const minutesPerYear = 525600;
  const downtimeMinutes = minutesPerYear * (1 - availability);

  // Nombre d'incidents timeout par an
  const writesPerYear = 365 * 24 * 3600 * config.expectedWriteRate;
  const timeoutIncidents = writesPerYear * (1 - availability);

  return {
    availability: (availability * 100).toFixed(4) + '%',
    downtimeMinutes: downtimeMinutes.toFixed(2),
    timeoutIncidents: Math.round(timeoutIncidents),
    slaClass: availability > 0.9999 ? 'Gold' : availability > 0.999 ? 'Silver' : 'Bronze'
  };
}

function binomialProbability(n, k, p) {
  // Calcul combinatoire C(n,k) * p^k * (1-p)^(n-k)
  const choose = factorial(n) / (factorial(k) * factorial(n - k));
  return choose * Math.pow(p, k) * Math.pow(1 - p, n - k);
}

function factorial(n) {
  if (n <= 1) return 1;
  return n * factorial(n - 1);
}

// Comparaison SLA
const scenarios = [
  {
    name: 'w:1',
    replicaSetSize: 3,
    writeConcern: 'w:1',
    nodeFailureRate: 0.001,
    networkPartitionRate: 0.01,
    expectedWriteRate: 1000
  },
  {
    name: 'w:majority',
    replicaSetSize: 3,
    writeConcern: 'w:majority',
    nodeFailureRate: 0.001,
    networkPartitionRate: 0.01,
    expectedWriteRate: 1000
  }
];

scenarios.forEach(scenario => {
  const impact = calculateSLAImpact(scenario);
  console.log(`\nScenario: ${scenario.name}`);
  console.log('Disponibilit√©:', impact.availability);
  console.log('Downtime annuel:', impact.downtimeMinutes, 'minutes');
  console.log('Incidents timeout/an:', impact.timeoutIncidents);
  console.log('SLA Class:', impact.slaClass);
});
```

## Recommandations et checklist finale

### Arbre de d√©cision pour le compromis optimal

```
√âtape 1: Classifier l'op√©ration
‚îú‚îÄ Financi√®re/R√©glementaire ? ‚Üí Coh√©rence maximale obligatoire
‚îú‚îÄ Modification structurelle ? ‚Üí Coh√©rence forte recommand√©e
‚îú‚îÄ Lecture haute fr√©quence ? ‚Üí Consid√©rer coh√©rence √©ventuelle
‚îî‚îÄ Log/Metric/Analytics ? ‚Üí Performance prioritaire

√âtape 2: √âvaluer les contraintes
‚îú‚îÄ Latence utilisateur ? ‚Üí < 100ms P99 ? ‚Üí Limiter coh√©rence stricte
‚îú‚îÄ Volume d'op√©rations ? ‚Üí > 10k/sec ? ‚Üí Diff√©rencier par type
‚îú‚îÄ Budget cloud ? ‚Üí Limit√© ? ‚Üí Optimiser op√©rations non critiques
‚îî‚îÄ Exigence SLA ? ‚Üí 99.99% ? ‚Üí Planifier d√©gradation gracieuse

√âtape 3: Choisir la configuration
‚îú‚îÄ Critique ‚Üí w:majority, j:true, readConcern:majority
‚îú‚îÄ Important ‚Üí w:majority, j:false, readConcern:majority
‚îú‚îÄ Standard ‚Üí w:majority, j:false, readConcern:local
‚îî‚îÄ Volume ‚Üí w:1, j:false, readConcern:local

√âtape 4: Valider et mesurer
‚îú‚îÄ Benchmark en conditions r√©elles
‚îú‚îÄ Mesurer P50, P95, P99
‚îú‚îÄ Calculer le co√ªt ($/mois)
‚îî‚îÄ Tester en mode d√©grad√©
```

### Checklist de validation

```markdown
## Checklist : Compromis Performance vs Coh√©rence

### Analyse des besoins m√©tier
- [ ] Identifier les op√©rations critiques (conformit√©, finance, s√©curit√©)
- [ ] D√©terminer la tol√©rance √† la perte de donn√©es (RPO)
- [ ] D√©finir les exigences de latence par type d'op√©ration
- [ ] √âvaluer l'impact business d'une incoh√©rence temporaire

### Configuration technique
- [ ] D√©finir Write Concern par type d'op√©ration
- [ ] D√©finir Read Concern align√© avec Write Concern
- [ ] Configurer wtimeout appropri√© (2-3x replication lag P99)
- [ ] Impl√©menter retry logic avec backoff

### Optimisations
- [ ] Utiliser sessions causales pour read-after-write
- [ ] Impl√©menter batching pour op√©rations haute fr√©quence
- [ ] Configurer Read Preference pour distribution de charge
- [ ] Consid√©rer caching avec invalidation intelligente

### R√©silience
- [ ] Impl√©menter d√©gradation gracieuse
- [ ] Configurer circuit breaker pour Write Concern
- [ ] Tester comportement en cas de node failure
- [ ] Tester comportement en cas de partition r√©seau

### Monitoring
- [ ] Alertes sur Replication Lag > seuil
- [ ] Alertes sur Write Concern timeout rate > 1%
- [ ] Dashboard de latence P50/P95/P99 par configuration
- [ ] M√©triques de co√ªt par type d'op√©ration

### Documentation
- [ ] Documenter les choix de coh√©rence et leur rationale
- [ ] Cr√©er un guide de d√©cision pour nouveaux cas d'usage
- [ ] Documenter les sc√©narios de d√©gradation
- [ ] Maintenir un registre des incidents li√©s √† la coh√©rence
```

## Conclusion : L'art du compromis √©clair√©

Les compromis entre performance et coh√©rence ne sont pas des d√©faites techniques, mais des **d√©cisions architecturales strat√©giques**. Les syst√®mes les plus performants et fiables ne sont pas ceux qui maximisent uniform√©ment la coh√©rence, mais ceux qui **diff√©rencient intelligemment** les garanties selon le contexte.

**Principes directeurs** :

1. **Granularit√©** : Diff√©rencier au niveau de l'op√©ration, pas de l'application
2. **Mesure** : Quantifier les co√ªts r√©els (latence, throughput, argent)
3. **Adaptation** : Ajuster dynamiquement selon les conditions
4. **Validation** : Tester les hypoth√®ses avec des benchmarks r√©els
5. **Documentation** : Expliciter les choix pour faciliter la maintenance

**Le compromis optimal** n'est pas un point fixe, mais un **√©quilibre dynamique** qui √©volue avec :
- La croissance de l'application
- Les changements d'exigences m√©tier
- L'√©volution de la topologie (sharding, multi-r√©gion)
- Les le√ßons apprises des incidents

En fin de compte, ma√Ætriser les compromis performance/coh√©rence, c'est **aligner la technique avec le business** pour cr√©er des syst√®mes √† la fois performants, fiables et √©conomiquement viables.

---

**Points cl√©s √† retenir** :

- Performance et coh√©rence sont inversement proportionnelles
- w:majority co√ªte ~6-9x plus cher en latence que w:1
- Diff√©rencier les garanties par type d'op√©ration r√©duit les co√ªts de 40-60%
- Sessions causales r√©solvent le probl√®me read-after-write
- D√©gradation gracieuse maintient la disponibilit√© en conditions d√©grad√©es
- Mesurer et quantifier avant d'optimiser
- Le compromis optimal √©volue avec le syst√®me

‚è≠Ô∏è [Transactions distribu√©es](/08-transactions/05-transactions-distribuees.md)
