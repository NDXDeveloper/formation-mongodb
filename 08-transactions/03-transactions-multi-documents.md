ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 8.3 Transactions Multi-Documents

## Introduction

L'introduction des transactions multi-documents dans MongoDB 4.0 (juin 2018) a marquÃ© un tournant majeur dans l'Ã©volution de MongoDB, reprÃ©sentant l'une des fonctionnalitÃ©s les plus attendues et les plus dÃ©battues de l'histoire de la base de donnÃ©es. Cette capacitÃ© a transformÃ© MongoDB d'une base de donnÃ©es NoSQL privilÃ©giant la performance et la scalabilitÃ© au dÃ©triment de certaines garanties ACID, en un systÃ¨me capable de rivaliser avec les bases relationnelles traditionnelles en termes de garanties transactionnelles, tout en conservant ses avantages natifs de flexibilitÃ© et de scalabilitÃ©.

Comprendre les transactions multi-documents nÃ©cessite d'apprÃ©hender non seulement leur utilisation pratique, mais aussi leur coÃ»t architectural, leurs limites intrinsÃ¨ques, et surtout, de savoir quand leur utilisation est vÃ©ritablement justifiÃ©e.

## Ã‰volution Historique et Contexte

### La GenÃ¨se : Pourquoi MongoDB N'avait Pas de Transactions Multi-Documents

MongoDB a Ã©tÃ© conÃ§u initialement (2009) avec une philosophie claire : **privilÃ©gier la scalabilitÃ© horizontale et la performance au dÃ©triment de certaines garanties transactionnelles**. Ce n'Ã©tait pas un dÃ©faut de conception, mais un choix dÃ©libÃ©rÃ© basÃ© sur plusieurs constats :

```
Philosophie Originale MongoDB (2009-2018)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Principes de Conception :
1. Document comme unitÃ© atomique
   â†’ ModÃ©liser pour que les opÃ©rations atomiques soient mono-document

2. DÃ©normalisation encouragÃ©e
   â†’ Embarquer les donnÃ©es liÃ©es dans un seul document

3. ScalabilitÃ© horizontale native
   â†’ Sharding sans coordination transactionnelle coÃ»teuse

4. Performance avant cohÃ©rence stricte
   â†’ Eventual consistency acceptable pour la plupart des cas

Rationale :
- 80% des applications web n'ont pas besoin de transactions distribuÃ©es
- L'atomicitÃ© document suffit si le schÃ©ma est bien conÃ§u
- Les transactions distribuÃ©es sont intrinsÃ¨quement coÃ»teuses (CAP theorem)
- Le marchÃ© cible (startups web, applications sociales) valorise
  la performance et la facilitÃ© de scaling plus que ACID strict

RÃ©sultat :
âœ“ Performance exceptionnelle (50,000+ ops/sec)
âœ“ Scaling linÃ©aire jusqu'Ã  des centaines de nÅ“uds
âœ“ SimplicitÃ© opÃ©rationnelle (pas de deadlocks, pas de 2PC complexe)
âš  NÃ©cessite discipline de modÃ©lisation
âš  Certains cas d'usage impossibles (systÃ¨mes financiers stricts)
```

### La RÃ©volution : MongoDB 4.0 (Juin 2018)

L'introduction des transactions multi-documents Ã©tait une rÃ©ponse Ã  trois facteurs majeurs :

1. **Pression du marchÃ© entreprise** : Les grandes entreprises voulaient migrer des charges de travail critiques vers MongoDB
2. **CompÃ©tition** : D'autres bases NoSQL (comme CockroachDB) offraient dÃ©jÃ  des transactions distribuÃ©es
3. **MaturitÃ© technique** : L'architecture interne de MongoDB (WiredTiger, Oplog) Ã©tait suffisamment mature

```
Timeline des Transactions MongoDB
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

MongoDB 4.0 (Juin 2018)
â”‚
â”œâ”€ Transactions multi-documents sur Replica Sets
â”œâ”€ Snapshot isolation
â”œâ”€ API sessions et transactions
â””â”€ Limites : Replica Set uniquement (pas de sharded clusters)

         â–¼

MongoDB 4.2 (AoÃ»t 2019)
â”‚
â”œâ”€ Transactions distribuÃ©es sur Sharded Clusters
â”œâ”€ Distributed transactions avec two-phase commit
â”œâ”€ AmÃ©lioration des performances (~30% plus rapide)
â””â”€ Support des transactions dans Atlas

         â–¼

MongoDB 5.0 (Juillet 2021)
â”‚
â”œâ”€ Performances transactionnelles considÃ©rablement amÃ©liorÃ©es
â”œâ”€ Snapshot reads sans transaction
â”œâ”€ RÃ©duction de l'overhead (metadata plus lÃ©ger)
â””â”€ Meilleure gestion de la mÃ©moire

         â–¼

MongoDB 6.0+ (2022-2024)
â”‚
â”œâ”€ Optimisations continues
â”œâ”€ Transactions plus longues supportÃ©es
â”œâ”€ Meilleure gestion des conflits
â””â”€ RÃ©duction du write amplification

Impact :
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MongoDB 4.0+ permet maintenant des cas d'usage impossibles
auparavant, tout en conservant ses avantages de scalabilitÃ©.

Le systÃ¨me offre un spectre complet :
- Performance pure : atomicitÃ© document
- CohÃ©rence stricte : transactions multi-documents
- Compromis : configurable selon les besoins
```

## Architecture des Transactions Multi-Documents

### Composants Fondamentaux

Les transactions multi-documents dans MongoDB reposent sur plusieurs mÃ©canismes architecturaux sophistiquÃ©s :

```
Architecture Transactionnelle MongoDB
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Client Application                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”‚ Driver Connection
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Session Management                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Session State                                 â”‚    â”‚
â”‚  â”‚  - Transaction ID (txnNumber)                  â”‚    â”‚
â”‚  â”‚  - Read timestamp (snapshot)                   â”‚    â”‚
â”‚  â”‚  - Write history                               â”‚    â”‚
â”‚  â”‚  - Transaction options (readConcern, etc.)     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Transaction Coordinator                   â”‚
â”‚                (sur mongos ou primary)                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  - Track active transactions                   â”‚    â”‚
â”‚  â”‚  - Manage transaction lifecycle                â”‚    â”‚
â”‚  â”‚  - Coordinate commit/abort                     â”‚    â”‚
â”‚  â”‚  - Handle two-phase commit (sharded)           â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Storage Layer                        â”‚
â”‚                   (WiredTiger)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  MVCC Engine                                   â”‚    â”‚
â”‚  â”‚  - Document versions                           â”‚    â”‚
â”‚  â”‚  - Snapshot management                         â”‚    â”‚
â”‚  â”‚  - Conflict detection                          â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Transaction Log (Oplog)                       â”‚    â”‚
â”‚  â”‚  - applyOps entries                            â”‚    â”‚
â”‚  â”‚  - Transaction boundaries (start/commit)       â”‚    â”‚
â”‚  â”‚  - Abort markers                               â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Sessions : Le Fondement des Transactions

Toute transaction multi-documents dans MongoDB nÃ©cessite une **session** :

```javascript
// Anatomie d'une session MongoDB

const session = client.startSession({
    // Options de la session
    causalConsistency: true,        // Garantit read-your-writes
    defaultTransactionOptions: {
        readConcern: { level: "snapshot" },
        writeConcern: { w: "majority" },
        readPreference: "primary"
    }
});

// Chaque session a un identifiant unique
console.log(session.id);
// Exemple: { id: Binary(...) }

// La session maintient l'Ã©tat transactionnel :
// - Transaction number (txnNumber)
// - Cluster time (timestamp logique)
// - Transaction state (started, committed, aborted)
// - Read timestamp (pour snapshot isolation)

// Timeline d'une session :

// T=0ms : CrÃ©ation de la session
// â”œâ”€ Allocation d'un session ID unique
// â”œâ”€ Initialisation de l'Ã©tat transactionnel
// â””â”€ Enregistrement cÃ´tÃ© serveur (cache des sessions)

// T=10ms : DÃ©but de transaction
session.startTransaction({
    readConcern: { level: "snapshot" },
    writeConcern: { w: "majority" }
});
// â”œâ”€ txnNumber incrÃ©mentÃ©
// â”œâ”€ Snapshot timestamp capturÃ© (lecture cohÃ©rente)
// â”œâ”€ Transaction state â†’ "in progress"
// â””â”€ Toutes les opÃ©rations suivantes utilisent ce snapshot

// T=20ms-100ms : OpÃ©rations transactionnelles
await collection1.updateOne({...}, {...}, { session });
await collection2.insertOne({...}, { session });
await collection3.deleteOne({...}, { session });
// â”œâ”€ Chaque opÃ©ration porte le session ID et txnNumber
// â”œâ”€ Modifications buffered (pas encore visibles)
// â”œâ”€ Locks acquis (document-level)
// â””â”€ DÃ©tection de conflits (WriteConflict si collision)

// T=150ms : Commit
await session.commitTransaction();
// â”œâ”€ Validation finale (pas de conflits)
// â”œâ”€ Ã‰criture dans l'oplog (applyOps entry atomique)
// â”œâ”€ Application des modifications (visibles)
// â”œâ”€ RelÃ¢chement des locks
// â””â”€ Transaction state â†’ "committed"

// T=160ms : Fin de session
await session.endSession();
// â”œâ”€ Nettoyage de l'Ã©tat transactionnel
// â””â”€ LibÃ©ration des ressources

// PropriÃ©tÃ©s clÃ©s de la session :
// 1. Causal Consistency : Garantit l'ordre des opÃ©rations
// 2. Snapshot Isolation : Vue cohÃ©rente des donnÃ©es
// 3. Server-side tracking : Le serveur sait quelles opÃ©rations
//    font partie de quelle transaction
```

### Oplog et applyOps : Le CÅ“ur de l'AtomicitÃ©

Dans MongoDB, l'oplog (operations log) est le mÃ©canisme de rÃ©plication. Pour les transactions multi-documents, un mÃ©canisme spÃ©cial `applyOps` garantit l'atomicitÃ© :

```javascript
// Structure de l'Oplog pour une transaction

// Transaction simple (sans transaction)
// Chaque opÃ©ration gÃ©nÃ¨re une entrÃ©e oplog sÃ©parÃ©e :
{
    ts: Timestamp(1701963000, 1),
    t: NumberLong(1),
    op: "u",  // update
    ns: "mydb.collection1",
    o: { $set: { status: "active" } },
    o2: { _id: ObjectId("...") }
}

{
    ts: Timestamp(1701963000, 2),
    t: NumberLong(1),
    op: "i",  // insert
    ns: "mydb.collection2",
    o: { _id: ObjectId("..."), data: "..." }
}

// âš  ProblÃ¨me : Entre ces deux entrÃ©es, un crash peut laisser
// la base dans un Ã©tat incohÃ©rent (premiÃ¨re op appliquÃ©e, pas la seconde)

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Transaction multi-documents
// TOUTES les opÃ©rations dans UNE SEULE entrÃ©e applyOps :
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

{
    ts: Timestamp(1701963000, 1),
    t: NumberLong(1),
    op: "c",  // command
    ns: "mydb.$cmd",
    o: {
        applyOps: [
            // â–¼ Toutes les opÃ©rations de la transaction
            {
                op: "u",
                ns: "mydb.collection1",
                o: { $set: { status: "active" } },
                o2: { _id: ObjectId("...") }
            },
            {
                op: "i",
                ns: "mydb.collection2",
                o: { _id: ObjectId("..."), data: "..." }
            },
            {
                op: "d",
                ns: "mydb.collection3",
                o: { _id: ObjectId("...") }
            }
        ],
        // MÃ©tadonnÃ©es transactionnelles
        lsid: { id: UUID("...") },        // Session ID
        txnNumber: NumberLong(1),
        stmtIds: [0, 1, 2],               // Statement IDs
        prevOpTime: { ts: ..., t: ... }   // Previous op timestamp
    },
    wall: ISODate("2024-12-07T10:30:00.000Z")
}

// Garanties de applyOps :
// âœ“ AtomicitÃ© : Toutes les ops appliquÃ©es ensemble ou aucune
// âœ“ Ordre : Les ops sont appliquÃ©es dans l'ordre dÃ©fini
// âœ“ RÃ©plication : L'entrÃ©e applyOps est rÃ©pliquÃ©e atomiquement
// âœ“ DurabilitÃ© : Une fois dans l'oplog, survit aux crashes
// âœ“ Idempotence : Peut Ãªtre rejouÃ©e sans effet de bord

// MÃ©canisme de rÃ©plication avec transactions :

// Primary (Ã©criture)                Secondary (rÃ©plication)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//
// T=0 : BEGIN transaction
// T=10: operation 1 (buffered)
// T=20: operation 2 (buffered)
// T=30: operation 3 (buffered)
// T=40: COMMIT
//       â†“
//       Ã‰criture applyOps dans oplog
//       â†“
//       â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ T=45: Lecture oplog
//                                     T=46: Apply applyOps
//                                           (atomiquement)
//                                     T=47: Ops appliquÃ©es
//
// Si le secondary crash pendant l'apply :
// - Au redÃ©marrage, rejoue le applyOps complet
// - Idempotence garantit le rÃ©sultat correct

// Limite importante de applyOps :
// La taille de l'entrÃ©e applyOps est limitÃ©e Ã  16 MB
// (mÃªme limite qu'un document)
//
// Implication :
// Une transaction avec trop d'opÃ©rations ou trop de donnÃ©es
// peut dÃ©passer cette limite et Ã©chouer
//
// Exemple : Transaction avec 10,000 insertions de documents de 2 KB
// â†’ 20 MB de donnÃ©es â†’ Ã‰CHEC
//
// Solution : Diviser en plusieurs transactions ou utiliser
// des opÃ©rations bulk moins nombreuses
```

### Snapshot Isolation : Le MÃ©canisme de Lecture CohÃ©rente

```javascript
// Snapshot Isolation garantit que toutes les lectures dans une
// transaction voient un Ã©tat cohÃ©rent de la base de donnÃ©es

// Ã‰tat initial de la base :
// Document A : { value: 100 }
// Document B : { value: 200 }

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Timeline avec Snapshot Isolation
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// T1 : Transaction 1 (lecture)
const session1 = client.startSession();
session1.startTransaction({
    readConcern: { level: "snapshot" }
});

// T=0ms : Snapshot crÃ©Ã© au timestamp T0
// session1 voit : A=100, B=200

const docA_t1_read1 = await collectionA.findOne(
    { _id: "A" },
    { session: session1 }
);
console.log(docA_t1_read1.value);  // 100

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// T2 : Pendant ce temps, Transaction 2 modifie les documents
const session2 = client.startSession();
session2.startTransaction();

// T=50ms : T2 modifie A et B
await collectionA.updateOne(
    { _id: "A" },
    { $set: { value: 150 } },
    { session: session2 }
);

await collectionB.updateOne(
    { _id: "B" },
    { $set: { value: 250 } },
    { session: session2 }
);

// T=100ms : T2 committe
await session2.commitTransaction();
await session2.endSession();

// Ã‰tat aprÃ¨s T2 commit :
// Document A : { value: 150 }
// Document B : { value: 250 }

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// T1 continue (toujours sur son snapshot T0)

// T=150ms : T1 relit A
const docA_t1_read2 = await collectionA.findOne(
    { _id: "A" },
    { session: session1 }
);
console.log(docA_t1_read2.value);  // 100 (PAS 150!)

// T=200ms : T1 lit B
const docB_t1_read = await collectionB.findOne(
    { _id: "B" },
    { session: session1 }
);
console.log(docB_t1_read.value);  // 200 (PAS 250!)

// T=250ms : T1 committe
await session1.commitTransaction();
await session1.endSession();

// Garantie Snapshot Isolation :
// âœ“ T1 a vu un Ã©tat cohÃ©rent (snapshot Ã  T0)
// âœ“ Les modifications de T2 n'ont pas "polluÃ©" la vue de T1
// âœ“ Pas de lecture "sale" (dirty read)
// âœ“ Pas de lecture non rÃ©pÃ©table (non-repeatable read)
// âœ“ Pas de lecture fantÃ´me (phantom read)

// MÃ©canisme interne (MVCC dans WiredTiger) :

// Cache WiredTiger maintient plusieurs versions :
// â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
// â”‚ Document A                             â”‚
// â”‚ â”œâ”€ Version @T0: { value: 100 }         â”‚
// â”‚ â”‚  [Visible pour: T1]                  â”‚
// â”‚ â””â”€ Version @T100: { value: 150 }       â”‚
// â”‚    [Visible pour: nouvelles lectures]  â”‚
// â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

// Quand T1 lit A Ã  T=150ms :
// - WiredTiger cherche la version <= snapshot de T1 (T0)
// - Trouve version @T0 : { value: 100 }
// - Retourne cette version (pas la version @T100)

// Nettoyage (eviction) :
// Une fois T1 terminÃ©e, la version @T0 peut Ãªtre supprimÃ©e
// si aucune autre transaction ne l'utilise
```

## DiffÃ©rences Fondamentales : Replica Set vs Sharded Cluster

Les transactions multi-documents se comportent diffÃ©remment selon l'architecture :

### Transactions sur Replica Set

```javascript
// Architecture : 1 Primary + N Secondaries (mÃªme replica set)

// â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
// â”‚   Primary    â”‚  â”‚  Secondary   â”‚  â”‚  Secondary   â”‚
// â”‚              â”‚  â”‚              â”‚  â”‚              â”‚
// â”‚  Collection  â”‚  â”‚  RÃ©plication â”‚  â”‚  RÃ©plication â”‚
// â”‚  A, B, C     â”‚â”€â”€â”¤  oplog       â”‚â”€â”€â”¤  oplog       â”‚
// â”‚              â”‚  â”‚              â”‚  â”‚              â”‚
// â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

const session = client.startSession();

try {
    session.startTransaction({
        readConcern: { level: "snapshot" },
        writeConcern: { w: "majority" },
        readPreference: "primary"
    });

    // Toutes les opÃ©rations sont sur le mÃªme replica set
    await collectionA.updateOne({...}, {...}, { session });
    await collectionB.insertOne({...}, { session });
    await collectionC.deleteOne({...}, { session });

    await session.commitTransaction();

    // MÃ©canisme interne simplifiÃ© :
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // 1. OpÃ©rations exÃ©cutÃ©es sur le Primary
    // 2. Modifications buffered en mÃ©moire
    // 3. COMMIT :
    //    a) Ã‰criture applyOps dans l'oplog du Primary
    //    b) RÃ©plication vers Secondaries (selon writeConcern)
    //    c) Application des modifications
    // 4. Pas de coordination distribuÃ©e nÃ©cessaire

} catch (error) {
    await session.abortTransaction();
    throw error;
} finally {
    await session.endSession();
}

// CaractÃ©ristiques Replica Set :
// âœ“ Relativement simple (pas de 2PC)
// âœ“ Performance acceptable (10-30ms selon writeConcern)
// âœ“ Coordination locale (mÃªme instance logique)
// âœ“ Latence prÃ©dictible
// âš  LimitÃ© Ã  un seul replica set
// âš  Pas de scaling horizontal des transactions
```

### Transactions sur Sharded Cluster

```javascript
// Architecture : Multiple shards + Config servers + Mongos

// â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
// â”‚                     Mongos                          â”‚
// â”‚              (Query Router + Coordinator)           â”‚
// â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
//                 â”‚              â”‚
//       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
//       â”‚                â”‚   â”‚              â”‚
//   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
//   â”‚ Shard 1  â”‚    â”‚ Shard 2  â”‚    â”‚ Shard 3  â”‚
//   â”‚ (RS)     â”‚    â”‚ (RS)     â”‚    â”‚ (RS)     â”‚
//   â”‚ Docs A-H â”‚    â”‚ Docs I-P â”‚    â”‚ Docs Q-Z â”‚
//   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

const session = client.startSession();

try {
    session.startTransaction({
        readConcern: { level: "snapshot" },
        writeConcern: { w: "majority" },
        readPreference: "primary"
    });

    // Ces opÃ©rations touchent diffÃ©rents shards
    await collection.updateOne(
        { userId: "Alice" },    // â†’ Shard 1 (A-H)
        { $inc: { balance: -100 } },
        { session }
    );

    await collection.updateOne(
        { userId: "Zoe" },      // â†’ Shard 3 (Q-Z)
        { $inc: { balance: 100 } },
        { session }
    );

    await session.commitTransaction();

    // MÃ©canisme interne (Two-Phase Commit) :
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // PHASE 1 : PREPARE
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // T=0ms : Mongos (coordinator) envoie PREPARE Ã  tous les shards
    //
    // T=10ms : Shard 1 reÃ§oit PREPARE
    //   â”œâ”€ Applique les modifications localement (buffer)
    //   â”œâ”€ Acquiert les locks
    //   â”œâ”€ Ã‰crit prepare dans son oplog local
    //   â””â”€ RÃ©pond "PREPARED" au coordinator
    //
    // T=15ms : Shard 3 reÃ§oit PREPARE
    //   â”œâ”€ Applique les modifications localement (buffer)
    //   â”œâ”€ Acquiert les locks
    //   â”œâ”€ Ã‰crit prepare dans son oplog local
    //   â””â”€ RÃ©pond "PREPARED" au coordinator
    //
    // T=20ms : Coordinator reÃ§oit tous les PREPARED
    //   â””â”€ DÃ©cision : COMMIT (tous OK) ou ABORT (au moins un Ã©chec)
    //
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // PHASE 2 : COMMIT
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // T=25ms : Coordinator Ã©crit la dÃ©cision dans config servers
    //   â””â”€ Garantit la durabilitÃ© de la dÃ©cision
    //
    // T=30ms : Coordinator envoie COMMIT Ã  tous les shards
    //
    // T=35ms : Shard 1 reÃ§oit COMMIT
    //   â”œâ”€ Applique dÃ©finitivement les modifications
    //   â”œâ”€ Ã‰crit commit dans l'oplog
    //   â”œâ”€ RelÃ¢che les locks
    //   â””â”€ RÃ©pond "COMMITTED"
    //
    // T=40ms : Shard 3 reÃ§oit COMMIT
    //   â”œâ”€ Applique dÃ©finitivement les modifications
    //   â”œâ”€ Ã‰crit commit dans l'oplog
    //   â”œâ”€ RelÃ¢che les locks
    //   â””â”€ RÃ©pond "COMMITTED"
    //
    // T=45ms : Transaction complÃ¨te

} catch (error) {
    await session.abortTransaction();

    // En cas d'ABORT, mÃªme mÃ©canisme 2PC :
    // - Coordinator envoie ABORT Ã  tous les shards
    // - Chaque shard annule ses modifications buffered
    // - Locks relÃ¢chÃ©s

    throw error;
} finally {
    await session.endSession();
}

// CaractÃ©ristiques Sharded Cluster :
// âœ“ Permet transactions cross-shard
// âœ“ ACID complet mÃªme distribuÃ©
// âš  ComplexitÃ© Ã©levÃ©e (2PC)
// âš  Performance dÃ©gradÃ©e (50-200ms typique)
// âš  Plus de risques d'Ã©chec (network, timeouts)
// âš  Overhead de coordination significatif

// Points de dÃ©faillance additionnels :
// 1. Coordinator (mongos) peut crasher
//    â†’ RÃ©cupÃ©ration automatique mais latence accrue
// 2. Shard peut Ãªtre inaccessible pendant PREPARE
//    â†’ Timeout et abort de la transaction
// 3. Network partition entre prepare et commit
//    â†’ Shards en Ã©tat "prepared" (indÃ©cis)
//    â†’ RÃ©solution nÃ©cessaire au recovery
```

## CoÃ»ts et Compromis des Transactions Multi-Documents

### Impact sur la Performance

Les transactions multi-documents ont un coÃ»t mesurable et significatif :

```javascript
// Benchmark comparatif : MÃªme opÃ©ration, diffÃ©rentes approches

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ScÃ©nario 1 : Sans transaction (atomicitÃ© document uniquement)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// Document bien modÃ©lisÃ© (tout est imbriquÃ©)
{
    orderId: "O001",
    customerId: "C001",
    items: [
        { sku: "P001", qty: 2, price: 50 },
        { sku: "P002", qty: 1, price: 100 }
    ],
    total: 200,
    status: "pending"
}

await orders.updateOne(
    { orderId: "O001" },
    {
        $set: {
            status: "confirmed",
            confirmedAt: new Date()
        },
        $inc: { version: 1 }
    }
);

// MÃ©triques mesurÃ©es (Replica Set 3 nÅ“uds, w:1) :
// - Latence P50 : 2.5ms
// - Latence P95 : 6ms
// - Latence P99 : 12ms
// - Throughput : 40,000 ops/sec
// - CPU : 25%
// - Ã‰checs : ~0.01% (network temporaire)

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ScÃ©nario 2 : Avec transaction (modÃ©lisation relationnelle)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// Collections sÃ©parÃ©es
// orders: { orderId, customerId, total, status }
// order_items: { orderItemId, orderId, sku, qty, price }

const session = client.startSession();
session.startTransaction({
    readConcern: { level: "snapshot" },
    writeConcern: { w: "majority" }
});

try {
    await orders.updateOne(
        { orderId: "O001" },
        { $set: { status: "confirmed", confirmedAt: new Date() } },
        { session }
    );

    await orderItems.updateMany(
        { orderId: "O001" },
        { $set: { confirmed: true } },
        { session }
    );

    await session.commitTransaction();
} finally {
    await session.endSession();
}

// MÃ©triques mesurÃ©es (Replica Set 3 nÅ“uds, w:majority) :
// - Latence P50 : 28ms
// - Latence P95 : 65ms
// - Latence P99 : 120ms
// - Throughput : 3,500 ops/sec
// - CPU : 45%
// - Ã‰checs : ~2% (WriteConflict + timeouts)

// Analyse :
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Overhead transactionnel :
// - Latence P50 : 11x plus lent (2.5ms â†’ 28ms)
// - Throughput : 11x plus faible (40k â†’ 3.5k ops/sec)
// - CPU : 1.8x plus Ã©levÃ©
// - Taux d'Ã©chec : 200x plus Ã©levÃ©
//
// Causes :
// 1. Coordination de session (overhead de bookkeeping)
// 2. Snapshot isolation (MVCC overhead)
// 3. WriteConcern majority (attente rÃ©plication)
// 4. Conflict detection (WriteConflict possible)
// 5. Deux-phase commit si sharded (non applicable ici)

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ScÃ©nario 3 : Transaction sur Sharded Cluster (pire cas)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// MÃªme transaction, mais sur un cluster shardÃ©
// oÃ¹ les documents sont sur diffÃ©rents shards

// MÃ©triques mesurÃ©es (Sharded cluster 3 shards, LAN) :
// - Latence P50 : 85ms
// - Latence P95 : 180ms
// - Latence P99 : 350ms
// - Throughput : 800 ops/sec
// - CPU : 60% (mongos)
// - Ã‰checs : ~5% (coordination + network)

// MÃ©triques mesurÃ©es (Sharded cluster multi-rÃ©gion) :
// - Latence P50 : 250ms
// - Latence P95 : 600ms
// - Latence P99 : 1200ms
// - Throughput : 200 ops/sec
// - Ã‰checs : ~8%

// Analyse :
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Overhead additionnel sharded :
// - 2PC coordination (50-100ms)
// - Network round-trips multiples
// - Config servers writes
// - Plus de points de dÃ©faillance

// Comparaison finale :
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Sans transaction (document atomique) : 2.5ms baseline
// Transaction Replica Set : 28ms (11x overhead)
// Transaction Sharded LAN : 85ms (34x overhead)
// Transaction Sharded multi-rÃ©gion : 250ms (100x overhead)
```

### Consommation de Ressources

```javascript
// Impact mÃ©moire et CPU des transactions

// Configuration de test :
// - 1000 transactions concurrentes
// - Chaque transaction : 10 opÃ©rations
// - Duration moyenne : 500ms par transaction

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Sans transactions
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// Consommation mesurÃ©e :
// - RAM : 2 GB (WiredTiger cache)
// - CPU : 35% (4 cores)
// - Connections : 1000 (une par thread applicatif)
// - Disk I/O : 50 MB/s (writes)

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Avec transactions
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// Consommation mesurÃ©e :
// - RAM : 3.8 GB (+90%)
//   â”œâ”€ Session state : +600 MB
//   â”œâ”€ Transaction metadata : +400 MB
//   â”œâ”€ MVCC versions : +800 MB
//   â””â”€ WiredTiger cache : 2 GB (inchangÃ©)
//
// - CPU : 58% (+65%)
//   â”œâ”€ Conflict detection : +10%
//   â”œâ”€ Snapshot management : +8%
//   â””â”€ Transaction coordination : +7%
//
// - Connections : 1000 (inchangÃ©)
//   â””â”€ Mais chaque connection maintient une session active
//
// - Disk I/O : 75 MB/s (+50%)
//   â”œâ”€ Oplog entries plus grandes (applyOps)
//   â””â”€ Transaction metadata writes

// Facteurs aggravants :
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// 1. Transactions longues (> 1s)
//    â†’ Accumulation de versions MVCC
//    â†’ Pression mÃ©moire accrue
//
// 2. Haute contention (mÃªme documents modifiÃ©s)
//    â†’ WriteConflict frÃ©quents
//    â†’ Retries = CPU et latence
//
// 3. Large transactions (1000+ opÃ©rations)
//    â†’ applyOps entry > 16 MB â†’ Ã‰CHEC
//    â†’ Ou trÃ¨s proche limite â†’ performance dÃ©gradÃ©e
//
// 4. Transactions abandonnÃ©es (non endSession)
//    â†’ Fuite de ressources
//    â†’ Sessions zombies

// Recommandations :
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// âœ“ Garder les transactions courtes (< 100ms idÃ©al)
// âœ“ Limiter le nombre d'opÃ©rations (< 100 par transaction)
// âœ“ Toujours appeler endSession() (try/finally)
// âœ“ Configurer des timeouts appropriÃ©s
// âœ“ Monitorer la consommation mÃ©moire
```

## Garanties et Limitations

### Ce que les Transactions Multi-Documents Garantissent

```javascript
// âœ“ GARANTIES FOURNIES

// 1. AtomicitÃ© complÃ¨te
const session = client.startSession();
session.startTransaction();

await collection1.insertOne({ data: "A" }, { session });
await collection2.insertOne({ data: "B" }, { session });
await collection3.insertOne({ data: "C" }, { session });

await session.commitTransaction();
// Garantie : Soit A, B, et C sont insÃ©rÃ©s
//            Soit aucun n'est insÃ©rÃ©
//            Jamais A sans B, ou B sans C, etc.

// 2. Snapshot Isolation
session.startTransaction({ readConcern: { level: "snapshot" } });

const read1 = await collection.findOne({ _id: 1 }, { session });
// Snapshot capturÃ© ici

// [D'autres transactions modifient le doc entre temps]

const read2 = await collection.findOne({ _id: 1 }, { session });
// Garantie : read1 === read2 (mÃªme snapshot)

// 3. DurabilitÃ© configurable
session.startTransaction({
    writeConcern: { w: "majority", j: true }
});

await collection.insertOne({ important: "data" }, { session });
await session.commitTransaction();
// Garantie : DonnÃ©es persistent mÃªme si majoritÃ© des nÅ“uds crashent

// 4. Isolation entre transactions
// T1 et T2 concurrentes ne voient pas les modifications
// non committÃ©es l'une de l'autre

// 5. Ordre des opÃ©rations prÃ©servÃ©
session.startTransaction();
await collection.insertOne({ _id: 1 }, { session });
await collection.updateOne({ _id: 1 }, { $set: { v: 2 } }, { session });
await session.commitTransaction();
// Garantie : Insert avant update, toujours
```

### Ce que les Transactions Multi-Documents NE Garantissent PAS

```javascript
// âœ— LIMITATIONS ET EXCEPTIONS

// 1. Pas de vrai Serializable (anomalies write skew possibles)
// Exemple : Deux mÃ©decins veulent partir, invariant = au moins un prÃ©sent

const session1 = client.startSession();
session1.startTransaction({ readConcern: { level: "snapshot" } });

const session2 = client.startSession();
session2.startTransaction({ readConcern: { level: "snapshot" } });

// T1 : MÃ©decin Smith vÃ©rifie
const count1 = await doctors.countDocuments(
    { onCall: true },
    { session: session1 }
);  // count = 2

// T2 : MÃ©decin Jones vÃ©rifie (snapshot identique)
const count2 = await doctors.countDocuments(
    { onCall: true },
    { session: session2 }
);  // count = 2

// T1 : OK, je peux partir
if (count1 > 1) {
    await doctors.updateOne(
        { doctorId: "Smith" },
        { $set: { onCall: false } },
        { session: session1 }
    );
}
await session1.commitTransaction();

// T2 : OK, je peux partir aussi
if (count2 > 1) {
    await doctors.updateOne(
        { doctorId: "Jones" },
        { $set: { onCall: false } },
        { session: session2 }
    );
}
await session2.commitTransaction();

// RÃ©sultat : count = 0 (VIOLE L'INVARIANT!)
// âš  MongoDB ne dÃ©tecte pas cette anomalie write skew

// 2. Timeout strict (60 secondes par dÃ©faut)
session.startTransaction();

await longRunningOperation();  // Prend 70 secondes

await session.commitTransaction();
// âœ— ERREUR : Transaction aborted (timeout dÃ©passÃ©)

// 3. Limite de taille (16 MB pour applyOps)
session.startTransaction();

for (let i = 0; i < 100000; i++) {
    await collection.insertOne({
        data: "x".repeat(1000)  // 1 KB par document
    }, { session });
}

await session.commitTransaction();
// âœ— ERREUR : Transaction too large
// (100,000 docs Ã— 1 KB = 100 MB > 16 MB limit)

// 4. Pas de DDL dans les transactions
session.startTransaction();

await db.createCollection("newcollection", { session });
// âœ— ERREUR : Cannot create collection in transaction

await collection.createIndex({ field: 1 }, { session });
// âœ— ERREUR : Cannot create index in transaction

// 5. Certaines opÃ©rations non supportÃ©es
session.startTransaction();

await collection.distinct("field", {}, { session });
// âœ— ERREUR : distinct not supported in transactions

await collection.aggregate([
    { $out: "outputCollection" }
], { session });
// âœ— ERREUR : $out not supported in transactions

// 6. Pas de garantie de progression (livelock possible)
// Avec haute contention, des transactions peuvent infiniment
// retry sans jamais rÃ©ussir (nÃ©cessite backoff applicatif)
```

## Quand NE PAS Utiliser les Transactions Multi-Documents

### Anti-Patterns Courants

```javascript
// âŒ ANTI-PATTERN 1 : Transaction pour opÃ©ration unique

const session = client.startSession();
session.startTransaction();

await collection.updateOne(
    { _id: docId },
    { $set: { status: "active" } },
    { session }
);

await session.commitTransaction();
await session.endSession();

// ProblÃ¨me : Overhead transactionnel inutile
// L'atomicitÃ© document suffit largement
//
// âœ“ Solution : OpÃ©ration simple
await collection.updateOne(
    { _id: docId },
    { $set: { status: "active" } }
);

// âŒ ANTI-PATTERN 2 : Transaction pour Ã©viter la modÃ©lisation

// Collections sÃ©parÃ©es par "rÃ©flexe relationnel"
// users: { userId, username }
// profiles: { userId, bio }
// settings: { userId, preferences }

const session = client.startSession();
session.startTransaction();
await users.updateOne({...}, {...}, { session });
await profiles.updateOne({...}, {...}, { session });
await settings.updateOne({...}, {...}, { session });
await session.commitTransaction();

// ProblÃ¨me : ComplexitÃ© et coÃ»t Ã©levÃ©s
//
// âœ“ Solution : Document unique bien modÃ©lisÃ©
{
    userId: "U001",
    username: "jdupont",
    profile: { bio: "..." },
    settings: { preferences: {...} }
}

await users.updateOne(
    { userId: "U001" },
    {
        $set: {
            "profile.bio": "New bio",
            "settings.preferences.theme": "dark"
        }
    }
);

// âŒ ANTI-PATTERN 3 : Transactions longues (> 1 minute)

const session = client.startSession();
session.startTransaction();

for (let i = 0; i < 1000000; i++) {
    await collection.insertOne({ data: i }, { session });

    if (i % 10000 === 0) {
        // Traitement lourd
        await heavyComputation();
    }
}

await session.commitTransaction();
// ProblÃ¨me :
// - Timeout (60s)
// - MÃ©moire (accumulation MVCC)
// - Locks maintenus trop longtemps
//
// âœ“ Solution : Batch processing sans transaction
for (let batch = 0; batch < 100; batch++) {
    const docs = [];
    for (let i = 0; i < 10000; i++) {
        docs.push({ data: batch * 10000 + i });
    }
    await collection.insertMany(docs);
}
```

## Conclusion de l'Introduction

Les transactions multi-documents reprÃ©sentent un ajout majeur aux capacitÃ©s de MongoDB, mais elles ne doivent pas Ãªtre utilisÃ©es par dÃ©faut. Leur introduction Ã©tait nÃ©cessaire pour certains cas d'usage critiques, mais leur coÃ»t en termes de performance, complexitÃ© et ressources est significatif.

### Principes Directeurs

1. **L'atomicitÃ© document devrait Ãªtre votre premiÃ¨re option** : 80-90% des cas d'usage peuvent Ãªtre satisfaits avec une bonne modÃ©lisation
2. **Les transactions multi-documents sont pour les 10-20% restants** : OpÃ©rations cross-document vÃ©ritablement critiques
3. **Mesurer avant de dÃ©ployer** : Benchmarker l'impact rÃ©el sur votre charge de travail
4. **Garder les transactions courtes** : < 100ms idÃ©al, < 1s acceptable, > 1s problÃ©matique
5. **PrÃ©fÃ©rer Replica Set Ã  Sharded pour les transactions** : Si possible, Ã©viter les transactions cross-shard

### Questions Ã  se Poser

Avant d'utiliser une transaction multi-documents :

- Puis-je modÃ©liser diffÃ©remment pour utiliser l'atomicitÃ© document ?
- L'incohÃ©rence temporaire est-elle vraiment inacceptable ?
- Les bÃ©nÃ©fices ACID justifient-ils le coÃ»t de performance ?
- Puis-je utiliser des patterns alternatifs (saga, idempotence) ?
- Mon Ã©quipe est-elle prÃªte Ã  gÃ©rer la complexitÃ© additionnelle ?

Dans les sections suivantes, nous explorerons les cas d'usage lÃ©gitimes des transactions multi-documents, leur implÃ©mentation pratique, et les stratÃ©gies d'optimisation.

---


â­ï¸ [Cas d'usage et nÃ©cessitÃ©](/08-transactions/03.1-cas-usage-necessite.md)
