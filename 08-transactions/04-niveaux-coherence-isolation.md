üîù Retour au [Sommaire](/SOMMAIRE.md)

# 8.4 Niveaux de coh√©rence et d'isolation

## Introduction

Dans un syst√®me distribu√© comme MongoDB, la gestion de la coh√©rence des donn√©es et de l'isolation des op√©rations concurrentes repr√©sente l'un des d√©fis architecturaux les plus complexes. Contrairement aux bases de donn√©es relationnelles traditionnelles qui s'appuient sur des m√©canismes d'isolation stricts (SERIALIZABLE, REPEATABLE READ, etc.), MongoDB adopte une approche plus flexible et configurable √† travers deux concepts fondamentaux : **Read Concern** et **Write Concern**.

Cette flexibilit√© n'est pas un compromis technique, mais une r√©ponse architecturale d√©lib√©r√©e aux contraintes inh√©rentes aux syst√®mes distribu√©s. Elle permet aux d√©veloppeurs de faire des choix √©clair√©s entre coh√©rence, disponibilit√© et performance selon les besoins sp√©cifiques de chaque op√©ration.

## Le d√©fi de la coh√©rence dans les syst√®mes distribu√©s

### Rappel du th√©or√®me CAP dans le contexte transactionnel

Le th√©or√®me CAP (Consistency, Availability, Partition tolerance) prend tout son sens lorsqu'on aborde les transactions dans MongoDB. Dans un Replica Set distribu√© g√©ographiquement, chaque op√©ration de lecture ou d'√©criture doit naviguer dans cet espace de compromis :

**Coh√©rence forte (Strong Consistency)** : Garantit que toutes les lectures retournent la derni√®re √©criture valid√©e. Cela implique une synchronisation entre les n≈ìuds, ce qui augmente la latence et r√©duit la disponibilit√© en cas de partition r√©seau.

**Coh√©rence √©ventuelle (Eventual Consistency)** : Accepte que les lectures puissent temporairement retourner des donn√©es obsol√®tes, en √©change d'une latence r√©duite et d'une meilleure disponibilit√©.

**Exemple concret** :

Consid√©rons une application bancaire avec un Replica Set d√©ploy√© sur trois continents (Am√©rique du Nord, Europe, Asie). Lorsqu'un client √† New York effectue un virement :

- Avec une coh√©rence forte, l'application doit attendre que l'op√©ration soit r√©pliqu√©e sur la majorit√© des n≈ìuds avant de confirmer. Si le n≈ìud en Asie est temporairement indisponible, l'op√©ration peut prendre 300-500ms.
- Avec une coh√©rence √©ventuelle, la confirmation est imm√©diate (10-20ms), mais un client consultant son compte depuis Tokyo pourrait voir son solde mis √† jour avec quelques secondes de d√©lai.

### La notion de "donn√©es sales" (Dirty Reads)

MongoDB permet, selon la configuration, diff√©rents niveaux d'isolation qui d√©terminent si une op√©ration peut voir des donn√©es non encore committ√©es ou non encore r√©pliqu√©es. Cette flexibilit√© est cruciale pour optimiser les performances, mais elle n√©cessite une compr√©hension approfondie des implications.

**Sc√©nario r√©aliste** - Syst√®me de r√©servation de billets d'avion :

```
T0 : Transaction A r√©serve le si√®ge 12A (√©criture sur le Primary)
T1 : La r√©plication vers les Secondaires est en cours (d√©lai r√©seau)
T2 : Transaction B lit depuis un Secondary pour afficher les si√®ges disponibles
```

Si Transaction B utilise un niveau d'isolation faible, elle pourrait voir le si√®ge 12A comme encore disponible, cr√©ant une double r√©servation potentielle. Un niveau d'isolation plus strict forcerait Transaction B √† attendre la r√©plication ou √† lire depuis le Primary.

## Vue d'ensemble des m√©canismes de coh√©rence MongoDB

MongoDB offre deux leviers principaux pour contr√¥ler la coh√©rence et l'isolation :

### Read Concern : Contr√¥ler ce qu'on lit

Le **Read Concern** d√©termine le niveau de garantie sur les donn√©es lues. Il r√©pond √† la question : "Quelle version des donn√©es suis-je autoris√© √† voir ?"

Les niveaux disponibles forment un spectre allant de la performance maximale √† la coh√©rence maximale. Chaque niveau offre un √©quilibre diff√©rent entre :

- **Fra√Æcheur des donn√©es** : √Ä quel point les donn√©es sont r√©centes
- **Durabilit√©** : Le risque que les donn√©es lues soient annul√©es (rollback)
- **Latence** : Le temps d'attente pour obtenir la r√©ponse
- **Disponibilit√©** : La capacit√© √† r√©pondre m√™me en cas de probl√®mes r√©seau

### Write Concern : Contr√¥ler ce qu'on √©crit

Le **Write Concern** d√©finit le niveau d'accus√© de r√©ception requis pour consid√©rer une √©criture comme r√©ussie. Il r√©pond √† : "Combien de n≈ìuds doivent avoir persist√© mes donn√©es avant que je puisse continuer ?"

Ce m√©canisme est fondamental pour √©quilibrer :

- **Durabilit√©** : La probabilit√© que les donn√©es survivent √† une panne
- **Performance d'√©criture** : Le temps n√©cessaire pour confirmer l'op√©ration
- **Disponibilit√© en √©criture** : La capacit√© √† √©crire m√™me si certains n≈ìuds sont indisponibles

### L'interaction critique entre Read et Write Concern

L'aspect le plus subtil de la coh√©rence dans MongoDB est l'interaction entre ces deux m√©canismes. Un Read Concern strict ne garantit rien si le Write Concern est laxiste, et vice-versa.

**Exemple d'interaction probl√©matique** :

```
Configuration A :
- Write Concern: w=1 (confirmation apr√®s √©criture sur le Primary uniquement)
- Read Concern: majority (lecture des donn√©es r√©pliqu√©es sur la majorit√©)

Probl√®me : Une √©criture peut √™tre confirm√©e mais non visible en lecture si le Primary
tombe en panne avant r√©plication.
```

```
Configuration B :
- Write Concern: w=majority (confirmation apr√®s r√©plication sur la majorit√©)
- Read Concern: local (lecture depuis n'importe quel n≈ìud, m√™me non r√©pliqu√©)

Probl√®me : Une lecture peut retourner des donn√©es plus anciennes que des √©critures
d√©j√† confirm√©es.
```

## Compromis fondamentaux et d√©cisions architecturales

### Le trilemme Coh√©rence-Performance-Disponibilit√©

Chaque choix de niveau de coh√©rence implique des compromis qu'il est essentiel de quantifier :

**Cas 1 : Application de trading financier**

Exigences :
- Coh√©rence absolue (aucune transaction ne doit √™tre perdue)
- Isolation stricte (√©viter les conditions de course)
- Audit complet

Configuration appropri√©e :
- Write Concern: `{ w: "majority", j: true, wtimeout: 5000 }`
- Read Concern: `"linearizable"` pour les lectures critiques, `"snapshot"` pour les transactions

Compromis accept√©s :
- Latence d'√©criture : 50-200ms selon la topologie
- Latence de lecture : 20-100ms suppl√©mentaires
- Indisponibilit√© en cas de perte de majorit√© du Replica Set

**Cas 2 : Syst√®me de logs d'application**

Exigences :
- Volume √©lev√© (millions d'√©critures/seconde)
- Tol√©rance √† la perte occasionnelle
- Latence minimale

Configuration appropri√©e :
- Write Concern: `{ w: 1, j: false }` ou m√™me `{ w: 0 }` pour les logs non critiques
- Read Concern: `"local"` ou `"available"`

Compromis accept√©s :
- Risque de perte de donn√©es en cas de crash (fen√™tre de 100ms typiquement)
- Lectures potentiellement obsol√®tes
- Gain : latence d'√©criture < 1ms, throughput maximal

**Cas 3 : R√©seau social - Fil d'actualit√©**

Exigences :
- Scalabilit√© massive en lecture
- Tol√©rance √† la latence √©ventuelle
- Haute disponibilit√©

Configuration appropri√©e :
- Write Concern: `{ w: "majority" }` pour les publications
- Read Concern: `"available"` pour le fil d'actualit√© (accepte la coh√©rence √©ventuelle)

Compromis accept√©s :
- Un utilisateur peut ne pas voir imm√©diatement sa propre publication
- Des utilisateurs diff√©rents peuvent voir le fil dans un ordre l√©g√®rement diff√©rent
- Gain : latence de lecture tr√®s faible, distribution g√©ographique optimale

### Coh√©rence causale : Un mod√®le hybride

MongoDB introduit √©galement la notion de **coh√©rence causale** qui offre un mod√®le interm√©diaire √©l√©gant. Elle garantit que si une op√©ration B lit des donn√©es modifi√©es par une op√©ration A, alors B verra √©galement toutes les modifications ant√©rieures √† A.

**Exemple pratique** - Syst√®me de commentaires :

```
Session causale activ√©e :

1. Alice publie un article (√©criture A)
2. Bob commente l'article (√©criture B, d√©pend de A)
3. Charlie lit les commentaires (lecture C)

Garantie : Si C voit le commentaire de Bob, elle verra forc√©ment l'article d'Alice,
m√™me si la lecture se fait depuis un Secondary avec un l√©ger retard de r√©plication.
```

Sans coh√©rence causale, Charlie pourrait voir un commentaire orphelin r√©f√©ren√ßant un article pas encore visible.

## Consid√©rations pour les architectures modernes

### Microservices et coh√©rence distribu√©e

Dans une architecture microservices, chaque service peut avoir ses propres exigences de coh√©rence :

**Service d'authentification** :
- Write Concern: `majority + journal`
- Read Concern: `majority`
- Rationale : La s√©curit√© prime sur la performance

**Service de recherche/catalogue** :
- Write Concern: `majority`
- Read Concern: `available` ou `local`
- Rationale : La fra√Æcheur imm√©diate n'est pas critique

**Service de panier d'achat** :
- Write Concern: `majority`
- Read Concern: `majority` ou `snapshot` en transaction
- Rationale : √âquilibre entre coh√©rence et exp√©rience utilisateur

### Impact sur les patterns d'architecture

Le choix des niveaux de coh√©rence influence directement les patterns d'architecture applicables :

**Event Sourcing avec MongoDB** :
- N√©cessite `Write Concern: majority` pour garantir la durabilit√© des √©v√©nements
- `Read Concern: majority` ou `snapshot` pour reconstruire l'√©tat de mani√®re coh√©rente

**CQRS (Command Query Responsibility Segregation)** :
- Command side : Write Concern strict (`majority`)
- Query side : Read Concern flexible (`available` ou `local`) depuis des Secondaires optimis√©s

**Cache-aside pattern** :
- L'invalidation du cache doit tenir compte de la coh√©rence √©ventuelle
- Risque de race condition si le cache est invalid√© avant la r√©plication

## M√©triques et observabilit√©

Pour prendre des d√©cisions √©clair√©es, il est crucial de mesurer l'impact r√©el des diff√©rents niveaux :

**M√©triques cl√©s √† surveiller** :

1. **Replication Lag** :
   - Indique le retard entre Primary et Secondaries
   - Impact direct sur `Read Concern: majority`
   - Objectif typique : < 1 seconde en conditions normales

2. **Write Latency P99** :
   - Latence au 99√®me percentile pour les √©critures
   - Compare `w:1` vs `w:majority` sur votre topologie r√©elle
   - Exemple : 5ms vs 45ms sur un Replica Set intercontinental

3. **Read Latency par Read Concern** :
   - Mesure s√©par√©e pour `local`, `majority`, `linearizable`
   - Permet d'identifier les requ√™tes p√©nalisantes

4. **Rollback Events** :
   - Fr√©quence des rollbacks suite √† des √©lections
   - Indique si `w:1` cause des pertes de donn√©es

**Dashboard de d√©cision** :

```
M√©triques actuelles (derni√®res 24h) :
- Replication Lag P99: 850ms
- Write Latency w:1: 12ms (P99)
- Write Latency w:majority: 95ms (P99)
- Read Latency local: 8ms (P99)
- Read Latency majority: 35ms (P99)
- Rollback events: 0

Recommandation : La latence de r√©plication √©lev√©e p√©nalise lourdement
les op√©rations avec Read/Write Concern majority. Envisager :
1. Optimisation r√©seau entre datacenters
2. Topologie avec plus de membres locaux
3. R√©√©valuation des exigences de coh√©rence stricte
```

## √âvolution des exigences dans le temps

Un aspect souvent n√©glig√© : les exigences de coh√©rence √©voluent avec la maturit√© du produit et la croissance de la base utilisateurs.

**Phase 1 : MVP (Minimum Viable Product)**
- Configuration : Coh√©rence forte partout (`w:majority`, `readConcern:majority`)
- Rationale : Simplicit√©, peu d'utilisateurs, debugging facilit√©

**Phase 2 : Croissance**
- Configuration : Diff√©renciation par type d'op√©ration
- Challenge : Identifier les op√©rations qui peuvent tol√©rer la coh√©rence √©ventuelle

**Phase 3 : Scale**
- Configuration : Strat√©gie sophistiqu√©e avec sessions causales, Read Preference, Tagged Read
- Exemple : Lectures depuis Secondaries g√©ographiquement proches, √©critures avec `w:majority`

**Phase 4 : Global Scale**
- Configuration : Sharding avec Zone Awareness, compromis r√©gionaux
- Exemple : Les utilisateurs europ√©ens tol√®rent une coh√©rence √©ventuelle pour voir les contenus am√©ricains

## Antipatterns courants

### Antipattern 1 : "Majority partout par d√©faut"

**Probl√®me** : Appliquer `w:majority` et `readConcern:majority` sans r√©flexion.

**Cons√©quence** : Performance d√©grad√©e inutilement, latence utilisateur √©lev√©e.

**Solution** : Analyse fine par endpoint/op√©ration.

### Antipattern 2 : "Coh√©rence √©ventuelle sans gestion des conflicts"

**Probl√®me** : Utiliser `w:1` et `local` reads sans m√©canisme de r√©conciliation.

**Cons√©quence** : Conditions de course, donn√©es incoh√©rentes visibles par les utilisateurs.

**Solution** : Versioning optimiste, timestamps, ou r√©√©valuation des exigences.

### Antipattern 3 : "Ignorer le Replication Lag"

**Probl√®me** : Ne pas monitorer le d√©lai de r√©plication.

**Cons√©quence** : `readConcern:majority` devient tr√®s lent sans que l'√©quipe ne comprenne pourquoi.

**Solution** : Alertes sur Replication Lag, investigation r√©seau/mat√©riel.

### Antipattern 4 : "M√©langer Write Concern faible et Read Concern fort"

**Probl√®me** : `w:1` avec `readConcern:majority`.

**Cons√©quence** : √âcritures confirm√©es mais invisible aux lectures strictes, confusion sur l'√©tat du syst√®me.

**Solution** : Aligner Write et Read Concern selon les garanties souhait√©es.

## Checklist de d√©cision pour les niveaux de coh√©rence

Avant de choisir vos niveaux de Read et Write Concern, posez-vous ces questions :

**Questions sur les exigences m√©tier** :

- [ ] Quelle est la criticit√© de cette op√©ration pour le business ?
- [ ] Quelle est la tol√©rance √† la perte de donn√©es (RPO) ?
- [ ] Quelle est la tol√©rance √† l'incoh√©rence temporaire ?
- [ ] Les utilisateurs peuvent-ils d√©tecter des incoh√©rences ?
- [ ] Y a-t-il des exigences r√©glementaires (SOX, RGPD, etc.) ?

**Questions sur l'architecture** :

- [ ] Quelle est la topologie du Replica Set (single DC, multi-DC, global) ?
- [ ] Quel est le Replication Lag typique observ√© ?
- [ ] Quelles sont les latences r√©seau entre les membres ?
- [ ] L'application utilise-t-elle des transactions multi-documents ?
- [ ] Y a-t-il des reads depuis les Secondaries ?

**Questions sur la performance** :

- [ ] Quel est le volume d'op√©rations par seconde attendu ?
- [ ] Quelle est la latence maximale acceptable (P99) ?
- [ ] L'application est-elle plus read-heavy ou write-heavy ?
- [ ] Y a-t-il des pics de charge pr√©visibles ?

**Questions sur la r√©silience** :

- [ ] Que se passe-t-il si un membre du Replica Set tombe ?
- [ ] Que se passe-t-il si la majorit√© des membres est indisponible ?
- [ ] L'application peut-elle tol√©rer une indisponibilit√© temporaire en √©criture ?
- [ ] Y a-t-il un m√©canisme de retry dans l'application ?

## Conclusion interm√©diaire

Les niveaux de coh√©rence et d'isolation dans MongoDB ne sont pas de simples param√®tres techniques, mais des leviers architecturaux majeurs qui d√©terminent le comportement de votre syst√®me sous charge, en cas de panne, et lors de la mise √† l'√©chelle. Ils incarnent les compromis fondamentaux des syst√®mes distribu√©s et n√©cessitent une compr√©hension approfondie tant des besoins m√©tier que des contraintes techniques.

Dans les sections suivantes, nous explorerons en d√©tail chaque niveau de Read Concern, Write Concern, et leurs interactions sp√©cifiques, avec des exemples de configuration et des patterns d'utilisation concrets.

---

**Concepts cl√©s √† retenir** :

- Read Concern et Write Concern sont les deux leviers de coh√©rence dans MongoDB
- Chaque niveau repr√©sente un compromis entre coh√©rence, performance et disponibilit√©
- Les exigences varient selon le type d'op√©ration et le contexte m√©tier
- La coh√©rence causale offre un mod√®le hybride int√©ressant pour de nombreux cas d'usage
- Le monitoring est essentiel pour valider et ajuster vos choix
- Les antipatterns sont fr√©quents et co√ªteux : appliquer une r√©flexion syst√©matique

**Prochaines sections** : Nous d√©taillerons les niveaux sp√©cifiques de Read Concern, Write Concern, et leurs compromis performance/coh√©rence avec des exemples de configuration concrets.

‚è≠Ô∏è [Read Concern (local, available, majority, linearizable, snapshot)](/08-transactions/04.1-read-concern.md)
