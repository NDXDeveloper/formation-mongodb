üîù Retour au [Sommaire](/SOMMAIRE.md)

# Partie 4 : Architecture Distribu√©e (Avanc√©)

## üéØ Architecture pour la haute disponibilit√© et la scalabilit√©

Vous ma√Ætrisez maintenant la mod√©lisation, l'optimisation et les garanties transactionnelles de MongoDB. Mais une question cruciale reste en suspens : **comment concevoir une architecture MongoDB qui reste disponible 24/7 malgr√© les pannes mat√©rielles, et qui peut g√©rer des milliards de documents avec des performances constantes ?**

La Partie 4 est d√©di√©e √† l'**architecture distribu√©e de MongoDB**, le fondement qui permet aux applications modernes de scaler globalement et de tol√©rer les pannes. C'est ici que MongoDB r√©v√®le sa vraie puissance en tant que syst√®me distribu√© de classe mondiale.

## üåê Le d√©fi du scale : Vertical vs Horizontal

### Les limites du scale vertical

**Scale vertical** (scale-up) : Ajouter plus de ressources √† un seul serveur
- ‚ûï Simple √† g√©rer (un seul n≈ìud)
- ‚ûï Pas de complexit√© de distribution
- ‚ûñ **Limites physiques** : On ne peut pas augmenter ind√©finiment CPU/RAM/Disque
- ‚ûñ **Single Point of Failure** : Si le serveur tombe, tout tombe
- ‚ûñ **Co√ªt exponentiel** : Les serveurs tr√®s puissants sont disproportionnellement chers
- ‚ûñ **Downtime pour upgrade** : Mise √† jour = interruption de service

**R√©alit√©** : Le scale vertical atteint rapidement ses limites physiques et √©conomiques.

### Le scale horizontal comme solution

**Scale horizontal** (scale-out) : Ajouter plus de serveurs (n≈ìuds)
- ‚ûï **Pas de limite th√©orique** : Ajoutez autant de n≈ìuds que n√©cessaire
- ‚ûï **Tol√©rance aux pannes** : La perte d'un n≈ìud n'affecte pas le syst√®me
- ‚ûï **Co√ªt lin√©aire** : Utilisation de commodity hardware
- ‚ûï **Upgrade sans downtime** : Rolling upgrades n≈ìud par n≈ìud
- ‚ûñ **Complexit√©** : Distribution des donn√©es, coh√©rence, coordination
- ‚ûñ **Latence r√©seau** : Communication entre n≈ìuds

**MongoDB excelle dans le scale horizontal** gr√¢ce √† deux m√©canismes compl√©mentaires :
1. **R√©plication** : Pour la haute disponibilit√© (HA)
2. **Sharding** : Pour la scalabilit√© des donn√©es et du throughput

## üèóÔ∏è Les deux piliers de l'architecture distribu√©e

### R√©plication : La haute disponibilit√©

> **Objectif** : Garantir que votre syst√®me reste op√©rationnel m√™me en cas de panne mat√©rielle ou r√©seau.

**Concept** : Maintenir plusieurs copies identiques de vos donn√©es sur diff√©rents serveurs (Replica Set).

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           Replica Set (3 membres)                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                  ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ   ‚îÇ PRIMARY ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ ‚îÇSECONDARY‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ ‚îÇSECONDARY‚îÇ‚îÇ
‚îÇ   ‚îÇ (write) ‚îÇ       ‚îÇ (read?) ‚îÇ       ‚îÇ (read?) ‚îÇ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îÇ        ‚îÇ                                         ‚îÇ
‚îÇ        ‚îî‚îÄ‚îÄ‚ñ∂ Oplog (operations log)               ‚îÇ
‚îÇ                                                  ‚îÇ
‚îÇ   Si le PRIMARY tombe ‚Üí Election automatique     ‚îÇ
‚îÇ   Un SECONDARY devient PRIMARY en ~10 secondes   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**B√©n√©fices** :
- ‚úÖ **Tol√©rance aux pannes** : Perte d'un ou deux n≈ìuds sans interruption
- ‚úÖ **Zero-downtime maintenance** : Rolling restart pour les upgrades
- ‚úÖ **Durabilit√© des donn√©es** : Plusieurs copies sur diff√©rents serveurs
- ‚úÖ **Disaster recovery** : N≈ìuds dans diff√©rents datacenters
- ‚úÖ **Read scaling** : Possibilit√© de lire depuis les secondaries

**Cas d'usage typiques** :
- Applications critiques n√©cessitant 99.99%+ uptime
- Syst√®mes n√©cessitant des backups automatiques
- Applications multi-r√©gionales

---

### Sharding : La scalabilit√© horizontale

> **Objectif** : Distribuer vos donn√©es sur plusieurs serveurs pour d√©passer les limites d'un seul serveur.

**Concept** : Partitionner horizontalement vos donn√©es sur plusieurs shards (serveurs).

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 Sharded Cluster                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                            ‚îÇ
‚îÇ               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                  ‚îÇ
‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚ñ∂ ‚îÇ Shard 1 ‚îÇ‚îÄ‚îÄ‚îÄ‚îê  (users: id 0-333)           ‚îÇ
‚îÇ         ‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ                              ‚îÇ
‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ                              ‚îÇ
‚îÇ    ‚îÇ mongos ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ ‚îÇ  (users: id 334-666)         ‚îÇ
‚îÇ    ‚îÇ(router)‚îÇ               ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ
‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îå‚îÄ‚îÄ‚îÄ‚ñ∂ ‚îÇ  ‚îÇ Shard 2 ‚îÇ                 ‚îÇ
‚îÇ         ‚îÇ             ‚îÇ     ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ
‚îÇ         ‚îÇ             ‚îÇ     ‚îÇ                              ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚ñ∂ ‚îÇ  (users: id 667-999)         ‚îÇ
‚îÇ                       ‚îÇ     ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ
‚îÇ                       ‚îî‚îÄ‚îÄ‚îÄ‚ñ∂ ‚îÇ  ‚îÇ Shard 3 ‚îÇ                 ‚îÇ
‚îÇ                             ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ
‚îÇ                             ‚îÇ                              ‚îÇ
‚îÇ  Config Servers: M√©tadonn√©es sur la distribution           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**B√©n√©fices** :
- ‚úÖ **Capacit√© de stockage illimit√©e** : Ajoutez des shards pour plus d'espace
- ‚úÖ **Throughput horizontal** : Plus de shards = plus de lectures/√©critures parall√®les
- ‚úÖ **Isolation g√©ographique** : Shards dans diff√©rentes r√©gions
- ‚úÖ **√âvolutivit√© progressive** : Commencez petit, shardez quand n√©cessaire

**Cas d'usage typiques** :
- Datasets > 1 TB
- Applications avec millions d'utilisateurs
- IoT avec millions de capteurs
- SaaS multi-tenant avec isolation des donn√©es

---

### Combinaison : Replica Sets + Sharding

**En production**, chaque shard est lui-m√™me un Replica Set :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        Production Sharded Cluster avec HA                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ Shard 1 Replica Set                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ PRIMARY ‚îÇ  ‚îÇSECONDARY‚îÇ  ‚îÇSECONDARY‚îÇ                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ Shard 2 Replica Set                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ PRIMARY ‚îÇ  ‚îÇSECONDARY‚îÇ  ‚îÇSECONDARY‚îÇ                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ Config Servers Replica Set                             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  Mongos (Query Routers) - Stateless, peuvent √™tre multiples  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**R√©sultat** : Haute disponibilit√© **ET** scalabilit√© illimit√©e.

## üéØ Haute disponibilit√© vs Scalabilit√© : Deux probl√®mes diff√©rents

Il est crucial de comprendre que la r√©plication et le sharding r√©solvent **des probl√®mes diff√©rents** :

| Dimension | R√©plication (Replica Sets) | Sharding |
|-----------|----------------------------|----------|
| **Objectif principal** | Haute disponibilit√© (HA) | Scalabilit√© horizontale |
| **Probl√®me r√©solu** | Tol√©rance aux pannes | Limites de capacit√©/throughput |
| **Copies des donn√©es** | Identiques sur tous les n≈ìuds | Partitionn√©es entre shards |
| **Nombre de datasets** | 1 dataset r√©pliqu√© N fois | 1 dataset distribu√© sur N shards |
| **Lecture** | Peut √™tre distribu√©e (avec compromis) | Automatiquement distribu√©e |
| **√âcriture** | Centralis√©e sur PRIMARY | Distribu√©e entre shards |
| **Capacit√© totale** | Limit√©e par un n≈ìud | N √ó capacit√© d'un shard |
| **Complexit√©** | Faible √† mod√©r√©e | √âlev√©e |
| **Quand l'utiliser** | Toujours (prod) | Quand un serveur ne suffit plus |

**Principe architectural** :
- Utilisez **toujours** un Replica Set en production (m√™me sans sharding)
- N'ajoutez le sharding que **quand n√©cessaire** (> 1 TB ou throughput insuffisant)

## üìã Pr√©requis

Cette partie s'adresse √† des **architectes et ing√©nieurs syst√®me** ayant :

### Connaissances MongoDB requises
- ‚úÖ **Ma√Ætrise compl√®te des Parties 1-3**
- ‚úÖ Mod√©lisation avanc√©e et optimisation
- ‚úÖ Compr√©hension des transactions et de la coh√©rence
- ‚úÖ Exp√©rience avec MongoDB en environnement de d√©veloppement

### Connaissances en syst√®mes distribu√©s
- ‚úÖ **Th√©or√®me CAP** et ses implications pratiques
- ‚úÖ **Consensus distribu√©** : Concepts de base (Raft, Paxos)
- ‚úÖ **Partitionnement** : Strat√©gies de distribution de donn√©es
- ‚úÖ **Coh√©rence √©ventuelle** vs coh√©rence forte
- ‚úÖ **Network partitions** et split-brain scenarios
- ‚úÖ **Quorum** et majorit√©

### Comp√©tences op√©rationnelles
- üõ†Ô∏è Administration Linux/Unix (fichiers, processus, r√©seau)
- üõ†Ô∏è R√©seau : TCP/IP, DNS, firewalls, load balancing
- üõ†Ô∏è Monitoring et observabilit√©
- üõ†Ô∏è Scripting (Bash, Python) pour l'automatisation
- üõ†Ô∏è Exp√©rience avec des environnements de production

### √âtat d'esprit
- üß† Pens√©e architecturale (trade-offs, patterns)
- üß† Approche pragmatique (pas de sur-ing√©nierie)
- üß† Culture DevOps (automatisation, monitoring)
- üß† Gestion de la complexit√©

**Si vous ne ma√Ætrisez pas ces pr√©requis**, prenez le temps de les acqu√©rir. L'architecture distribu√©e est complexe et les erreurs ont un impact direct sur la disponibilit√© et les performances en production.

## üéì Objectifs d'apprentissage

√Ä la fin de cette partie, vous serez capable de :

### Comp√©tences en r√©plication
- ‚úÖ **Comprendre** l'architecture Replica Set en profondeur
- ‚úÖ **D√©ployer** et configurer un Replica Set de production
- ‚úÖ **G√©rer** les diff√©rents types de membres (Primary, Secondary, Arbiter, Hidden, Delayed)
- ‚úÖ **Comprendre** le m√©canisme d'√©lection et le processus de failover
- ‚úÖ **Ma√Ætriser** l'oplog et la r√©plication des op√©rations
- ‚úÖ **Configurer** Read Preference pour optimiser les lectures
- ‚úÖ **Assurer** une haute disponibilit√© avec des SLAs de 99.99%+
- ‚úÖ **Effectuer** une maintenance sans interruption de service
- ‚úÖ **Monitorer** et diagnostiquer les probl√®mes de r√©plication
- ‚úÖ **G√©rer** le replication lag et les situations de split-brain

### Comp√©tences en sharding
- ‚úÖ **Comprendre** l'architecture d'un cluster shard√©
- ‚úÖ **Choisir** la shard key appropri√©e (critique pour la performance)
- ‚úÖ **D√©ployer** un cluster shard√© complet
- ‚úÖ **Comprendre** les diff√©rents types de sharding (Range, Hashed, Zone)
- ‚úÖ **G√©rer** les chunks et le balancing automatique
- ‚úÖ **Optimiser** les requ√™tes pour le sharding (targeted vs broadcast)
- ‚úÖ **R√©soudre** les probl√®mes de jumbo chunks
- ‚úÖ **Monitorer** et maintenir un cluster shard√©
- ‚úÖ **Scaler** horizontalement en ajoutant des shards
- ‚úÖ **Comprendre** l'impact du sharding sur les transactions

### Comp√©tences architecturales
- ‚úÖ **Concevoir** une architecture MongoDB pour la haute disponibilit√©
- ‚úÖ **Dimensionner** les ressources n√©cessaires (CPU, RAM, disque, r√©seau)
- ‚úÖ **Choisir** entre un Replica Set simple ou un cluster shard√©
- ‚úÖ **Planifier** la croissance et la scalabilit√©
- ‚úÖ **√âvaluer** les compromis entre performance, co√ªt et disponibilit√©
- ‚úÖ **Concevoir** des architectures multi-r√©gionales
- ‚úÖ **Impl√©menter** des strat√©gies de disaster recovery

### Comp√©tences op√©rationnelles
- ‚úÖ **Automatiser** le d√©ploiement avec IaC (Infrastructure as Code)
- ‚úÖ **Monitorer** les m√©triques critiques de r√©plication et sharding
- ‚úÖ **Diagnostiquer** et r√©soudre les probl√®mes de production
- ‚úÖ **Effectuer** des rolling upgrades sans downtime
- ‚úÖ **G√©rer** les incidents (failover, panne de shard, etc.)
- ‚úÖ **Optimiser** les performances d'un cluster distribu√©

## üìö Vue d'ensemble des modules

Cette partie contient **2 modules compl√©mentaires** qui forment l'architecture distribu√©e de MongoDB :

### Module 9 : R√©plication
**Dur√©e estim√©e : 16-20 heures**

Le fondement de toute architecture MongoDB en production. La r√©plication garantit que votre syst√®me reste disponible malgr√© les pannes.

#### 9.1 Concepts de r√©plication
**Dur√©e : 2 heures**

Les principes fondamentaux de la r√©plication dans MongoDB.

**Ce que vous ma√Ætriserez :**
- Pourquoi la r√©plication est essentielle
- Architecture logique et physique
- Terminologie (Primary, Secondary, Arbiter, etc.)
- Diff√©rence avec d'autres syst√®mes de r√©plication

**Contexte** : Comprendre les concepts vous permet de prendre les bonnes d√©cisions architecturales.

---

#### 9.2 Architecture Replica Set
**Dur√©e : 2-3 heures**

Structure compl√®te d'un Replica Set et ses composants.

**Ce que vous ma√Ætriserez :**
- Topologie recommand√©e (3, 5, 7 membres)
- R√¥le de chaque membre
- Configuration r√©seau et communication
- Quorum et majorit√©

**Principe cl√©** : Un Replica Set n√©cessite une majorit√© (N/2 + 1) pour √©lire un Primary. D'o√π l'importance d'un nombre impair de membres.

**Topologies courantes :**
```
3 membres : 1 Primary + 2 Secondary (tol√®re 1 panne)
5 membres : 1 Primary + 4 Secondary (tol√®re 2 pannes)
7 membres : 1 Primary + 6 Secondary (tol√®re 3 pannes)
```

---

#### 9.3 Membres d'un Replica Set
**Dur√©e : 3-4 heures**

D√©tail de chaque type de membre et leurs cas d'usage.

**Types de membres :**

**Primary** : Le seul membre acceptant les √©critures
- Point unique d'√©criture
- Peut servir les lectures (par d√©faut)
- Source de v√©rit√© pour l'oplog

**Secondary** : R√©plique le Primary
- R√©plication asynchrone depuis l'oplog
- Peut servir les lectures (avec Read Preference)
- Candidat pour l'√©lection

**Arbiter** : Membre l√©ger pour le quorum
- Ne stocke pas de donn√©es
- Participe uniquement aux √©lections
- Utilis√© pour avoir un nombre impair de votants (controvers√©)

**Hidden** : Secondary cach√©
- Ne peut pas devenir Primary
- Invisible aux clients
- Utilis√© pour les backups ou analytics

**Delayed** : Secondary avec retard temporel
- R√©plique avec un d√©lai intentionnel (ex: 1 heure)
- Protection contre les erreurs humaines (DELETE accidentel)
- Ne peut pas devenir Primary

**Cas d'usage pour chaque type :**
```
Standard: Primary + 2 Secondary
Budget: Primary + Secondary + Arbiter (non recommand√© en prod)
Analytics: Primary + 2 Secondary + 1 Hidden
Protection: Primary + 2 Secondary + 1 Delayed
```

---

#### 9.4 √âlection du Primary
**Dur√©e : 2-3 heures**

Le m√©canisme critique qui assure la haute disponibilit√©.

**Ce que vous ma√Ætriserez :**
- Algorithme d'√©lection (bas√© sur Raft)
- Priorit√©s et votes
- Dur√©e d'√©lection (typiquement 10-12 secondes)
- Situations de split-brain et leur pr√©vention
- Impact sur les applications pendant l'√©lection

**Sc√©nario typique :**
```
t=0s : Primary tombe en panne
t=10s : Heartbeat timeout d√©tect√©
t=12s : √âlection lanc√©e
t=20s : Nouveau Primary √©lu
t=20s : Applications peuvent √©crire √† nouveau
```

**Impact :** 10-20 secondes d'indisponibilit√© en √©criture. Les lectures depuis Secondary peuvent continuer.

---

#### 9.5 Oplog (Operations Log)
**Dur√©e : 2-3 heures**

Le journal des op√©rations qui rend la r√©plication possible.

**Ce que vous ma√Ætriserez :**
- Structure de l'oplog (capped collection)
- Taille de l'oplog et dimensionnement
- Idempotence des op√©rations
- Replication lag et monitoring
- Compaction et truncation

**Principe fondamental** : L'oplog doit √™tre assez grand pour contenir plusieurs heures (voire jours) d'op√©rations, permettant aux Secondary de "rattraper" apr√®s une panne.

**Dimensionnement typique :**
```
Faible activit√© : 5-10 GB (plusieurs jours)
Activit√© moyenne : 20-50 GB (1-2 jours)
Haute activit√© : 100-200 GB (12-24 heures)
```

---

#### 9.6-9.7 Configuration et gestion
**Dur√©e : 3-4 heures**

D√©ploiement pratique et op√©rations courantes.

**Ce que vous ma√Ætriserez :**
- Initialisation d'un Replica Set
- Ajout et suppression de membres
- Modification de la configuration
- Reconfiguration sans downtime
- Validation et tests

---

#### 9.8 Read Preference
**Dur√©e : 2 heures**

Contr√¥le d'o√π les lectures sont effectu√©es.

**Options :**
- `primary` (d√©faut) : Toutes les lectures depuis le Primary
- `primaryPreferred` : Primary si disponible, sinon Secondary
- `secondary` : Lectures uniquement depuis Secondary
- `secondaryPreferred` : Secondary si disponible, sinon Primary
- `nearest` : Le membre le plus proche (latence)

**Compromis :**
```
primary : Coh√©rence forte, charge centralis√©e
secondary : Distribution de charge, coh√©rence √©ventuelle
nearest : Latence minimale, coh√©rence √©ventuelle
```

**Cas d'usage :**
- Analytics : `secondary` (ne pas impacter le Primary)
- Applications critiques : `primary` (coh√©rence forte)
- Multi-r√©gion : `nearest` (latence optimale)

---

#### 9.9 Failover et haute disponibilit√©
**Dur√©e : 2-3 heures**

Gestion automatique des pannes et continuit√© de service.

**Ce que vous ma√Ætriserez :**
- Processus de failover automatique
- Rolling restart sans downtime
- Strat√©gies de disaster recovery
- Tests de r√©silience (chaos engineering)
- RTO et RPO (Recovery Time/Point Objective)

**SLA typiques :**
```
99.9% (3 nines) : ~8.7 heures downtime/an
99.95% : ~4.4 heures downtime/an
99.99% (4 nines) : ~52 minutes downtime/an
99.999% (5 nines) : ~5 minutes downtime/an
```

Un Replica Set bien configur√© peut atteindre 99.99%+.

---

#### 9.10-9.12 Monitoring, maintenance et optimisations
**Dur√©e : 3-4 heures**

Op√©rations avanc√©es et optimisations.

**M√©triques critiques :**
- Replication lag
- Oplog window
- Heartbeat latency
- Member state changes
- Network throughput entre membres

---

**Pourquoi ce module est crucial :** La r√©plication est **non n√©gociable** en production. M√™me une petite application doit utiliser au minimum un Replica Set √† 3 membres.

---

### Module 10 : Sharding (Partitionnement Horizontal)
**Dur√©e estim√©e : 20-25 heures**

Le sharding permet de d√©passer les limites d'un seul serveur en distribuant les donn√©es horizontalement.

#### 10.1 Concepts du sharding
**Dur√©e : 2-3 heures**

Fondements th√©oriques du partitionnement horizontal.

**Ce que vous ma√Ætriserez :**
- Pourquoi sharder (capacit√©, throughput)
- Quand sharder (seuils recommand√©s)
- Partitionnement horizontal vs vertical
- Compromis et complexit√©

**Seuils pour consid√©rer le sharding :**
- Dataset > 1 TB sur un seul serveur
- Throughput > 100K ops/sec
- Croissance > 50% par an
- Besoins de scalabilit√© g√©ographique

---

#### 10.2 Architecture shard√©e
**Dur√©e : 3-4 heures**

Composants d'un cluster shard√© et leurs interactions.

**Composants :**

**Shards** : Serveurs de donn√©es (chacun un Replica Set)
- Stockent une partition des donn√©es
- Traitement local des requ√™tes
- Ind√©pendants les uns des autres

**Config Servers** : M√©tadonn√©es du cluster (Replica Set)
- Stockent la cartographie des chunks
- Information sur la distribution
- Critique : si perdus, cluster inutilisable

**Mongos** : Routeurs de requ√™tes (stateless)
- Point d'entr√©e pour les clients
- Routing des requ√™tes vers les bons shards
- Agr√©gation des r√©sultats
- Peuvent √™tre multiples (load balancing)

**Architecture typique :**
```
Application
     ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Mongos (2-3+ instances)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Config Servers (RS 3 membres) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Shard 1  ‚îÇ Shard 2  ‚îÇ Shard 3  ‚îÇ
‚îÇ(RS 3mbr) ‚îÇ(RS 3mbr) ‚îÇ(RS 3mbr) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Minimum pour un cluster shard√© de production :**
- 2 shards √ó 3 membres = 6 serveurs de donn√©es
- 3 config servers
- 2+ mongos
- **Total : 11+ serveurs** (vs 3 pour un Replica Set simple)

**Conclusion :** Le sharding ajoute une complexit√© significative. Ne le faites que si n√©cessaire.

---

#### 10.3 Shard Key : Choix et strat√©gies
**Dur√©e : 4-5 heures**

**LE** choix le plus important dans le sharding. Une mauvaise shard key peut ruiner les performances.

**Ce que vous ma√Ætriserez :**
- Crit√®res d'une bonne shard key (cardinalit√©, distribution, localit√©)
- Analyse des patterns d'acc√®s
- Exemples de bonnes et mauvaises shard keys
- Impact sur les performances
- Shard key immutable (ne peut √™tre chang√©e facilement)

**Caract√©ristiques d'une bonne shard key :**

1. **Haute cardinalit√©** : Beaucoup de valeurs diff√©rentes
   - ‚úÖ Bon : userId (millions de valeurs)
   - ‚ùå Mauvais : country (quelques centaines de valeurs)

2. **Distribution uniforme** : Donn√©es √©quilibr√©es entre shards
   - ‚úÖ Bon : Hash de userId
   - ‚ùå Mauvais : timestamp (toutes les nouvelles donn√©es sur le m√™me shard)

3. **Localit√© des requ√™tes** : Vos requ√™tes ciblent un seul shard
   - ‚úÖ Bon : tenantId pour SaaS (requ√™tes par tenant)
   - ‚ùå Mauvais : Random hash (requ√™tes broadcast √† tous les shards)

**Exemples :**

```javascript
// ‚ùå MAUVAIS : Timestamp monotone
{ _id: 1 }  // Toutes les insertions vont au m√™me shard (le dernier)

// ‚ùå MAUVAIS : Faible cardinalit√©
{ country: 1 }  // Seulement ~200 valeurs possibles

// ‚úÖ BON : Hash de _id
{ _id: "hashed" }  // Distribution uniforme, mais queries souvent broadcast

// ‚úÖ BON : Identifiant d'entit√© avec haute cardinalit√©
{ userId: 1 }  // Queries isol√©es par user

// ‚úÖ EXCELLENT : Compound key avec localit√©
{ tenantId: 1, timestamp: 1 }  // Isolation par tenant + ordre temporel
```

**R√®gle d'or :** Choisissez votre shard key en fonction de vos requ√™tes les plus fr√©quentes. Si 80% de vos requ√™tes filtrent par `tenantId`, c'est votre shard key.

---

#### 10.4 Types de sharding
**Dur√©e : 3-4 heures**

Diff√©rentes strat√©gies de distribution.

**Range Sharding** : Distribution par plages de valeurs
- Chunks contigus (ex: 0-100, 101-200)
- Bon pour les requ√™tes par range
- Risque de hotspots si les donn√©es sont s√©quentielles

**Hashed Sharding** : Distribution par hash
- Distribution uniforme garantie
- Mauvais pour les range queries
- Pas de hotspots

**Zone Sharding** : Affectation manuelle de ranges √† des shards
- Contr√¥le g√©ographique (EU data en EU, US data aux US)
- Conformit√© r√©glementaire (GDPR, etc.)
- Isolation multi-tenant

---

#### 10.5 Chunks et balancing
**Dur√©e : 3-4 heures**

Unit√© de distribution et √©quilibrage automatique.

**Ce que vous ma√Ætriserez :**
- Concept de chunk (unit√© de migration)
- Taille de chunk (d√©faut 64 MB, configurable)
- Balancer automatique (√©quilibre les chunks entre shards)
- Migration de chunks
- Impact sur la performance

**Probl√®mes courants :**
- Jumbo chunks (> 64 MB, non migrables)
- Balancing pendant les heures de pointe
- Migrations lentes

---

#### 10.6-10.7 D√©ploiement et activation
**Dur√©e : 4-5 heures**

Mise en place pratique d'un cluster shard√©.

**√âtapes :**
1. D√©ployer les config servers (Replica Set)
2. D√©ployer les shards (Replica Sets)
3. D√©ployer les mongos
4. Activer le sharding sur la base
5. Sharder les collections
6. V√©rifier la distribution

---

#### 10.8-10.9 Op√©rations et requ√™tes
**Dur√©e : 3-4 heures**

Op√©rations sur un cluster shard√© et optimisation des requ√™tes.

**Types de requ√™tes :**
- **Targeted queries** : Incluent la shard key ‚Üí rout√©es vers 1 shard
- **Broadcast queries** : Sans shard key ‚Üí envoy√©es √† tous les shards

**Exemple :**
```javascript
// Collection sharded on { userId: 1 }

// ‚úÖ Targeted query (fast)
db.orders.find({ userId: "user123" })

// ‚ùå Broadcast query (slow)
db.orders.find({ productId: "prod456" })
```

**Optimisation :** Incluez toujours la shard key dans vos requ√™tes fr√©quentes.

---

#### 10.10-10.12 Monitoring, jumbo chunks, bonnes pratiques
**Dur√©e : 3-4 heures**

Gestion op√©rationnelle et optimisations avanc√©es.

**M√©triques critiques :**
- Distribution des chunks par shard
- Taille des chunks
- Balancer activity
- Query patterns (targeted vs broadcast)
- Hotspots (shards surcharg√©s)

---

**Pourquoi ce module est optionnel au d√©but :** Le sharding ajoute une complexit√© √©norme. Commencez avec un Replica Set et shardez uniquement quand vous atteignez les limites (> 1 TB, throughput insuffisant).

## üéØ Progression p√©dagogique

Cette partie suit une logique **haute disponibilit√© d'abord, puis scalabilit√©** :

```
Replica Set (HA) ‚Üí Monitoring ‚Üí Sharding (Scale) ‚Üí Optimisation
```

### Semaines 1-3 : Ma√Ætrise de la R√©plication
**Focus : Construire des syst√®mes toujours disponibles**

**Semaine 1 : Concepts et architecture**
- Jours 1-2 : Concepts de r√©plication et architecture Replica Set
- Jours 3-4 : Types de membres et leurs cas d'usage
- Jours 5-7 : √âlection, oplog et coh√©rence

**Semaine 2 : D√©ploiement et configuration**
- Jours 1-3 : D√©ploiement pratique d'un Replica Set
- Jours 4-5 : Read Preference et optimisation des lectures
- Jours 6-7 : Tests de failover et r√©silience

**Semaine 3 : Operations et monitoring**
- Jours 1-3 : Monitoring et m√©triques critiques
- Jours 4-5 : Maintenance sans downtime
- Jours 6-7 : Troubleshooting et optimisations

**Livrables :**
- Replica Set de production (3+ membres)
- Documentation de failover et recovery
- Dashboard de monitoring
- Proc√©dures op√©rationnelles

---

### Semaines 4-7 : Ma√Ætrise du Sharding
**Focus : Scaler horizontalement**

**Semaine 4 : Concepts et architecture**
- Jours 1-2 : Concepts de sharding et composants
- Jours 3-5 : Shard key : analyse et choix
- Jours 6-7 : Types de sharding et strat√©gies

**Semaine 5 : D√©ploiement**
- Jours 1-4 : D√©ploiement d'un cluster shard√© complet
- Jours 5-7 : Activation du sharding et tests

**Semaine 6 : Optimisation**
- Jours 1-3 : Optimisation des requ√™tes (targeted vs broadcast)
- Jours 4-5 : Gestion des chunks et balancing
- Jours 6-7 : R√©solution des jumbo chunks

**Semaine 7 : Production-ready**
- Jours 1-3 : Monitoring et m√©triques avanc√©es
- Jours 4-5 : Bonnes pratiques et anti-patterns
- Jours 6-7 : Consolidation et r√©vision

**Livrables :**
- Cluster shard√© de production (2+ shards, chacun un RS)
- Analyse de shard key pour un cas d'usage r√©el
- Dashboard de monitoring du sharding
- Runbook op√©rationnel

---

**Rythme recommand√© :** 3-5 heures par jour. Le sharding n√©cessite des sessions intensives de pratique.

## üß† Principes architecturaux fondamentaux

### 1. La r√®gle d'or : Haute disponibilit√© d'abord

> **Toujours** d√©ployez un Replica Set, m√™me pour une petite application. Ne d√©ployez **jamais** un seul mongod en production.

**Pourquoi :**
- Un seul serveur = Single Point of Failure
- Maintenance = Downtime
- Panne mat√©rielle = Perte de donn√©es

**Minimum absolu en production :** Replica Set √† 3 membres (1 Primary + 2 Secondary)

### 2. Le sharding est une optimisation, pas un pr√©requis

> Ne shardez que quand vous avez **vraiment** atteint les limites d'un Replica Set simple.

**Shardez si :**
- Dataset > 1 TB
- Throughput > 100K ops/sec sur un serveur
- Working set > RAM disponible
- Croissance rapide (> 50%/an)

**Ne shardez pas si :**
- Dataset < 500 GB
- Vous pouvez scale verticalement
- La complexit√© op√©rationnelle vous fait peur

**R√©alit√© :** 80% des applications n'ont jamais besoin de sharding. Un Replica Set bien configur√© peut g√©rer des TB de donn√©es et des dizaines de milliers d'ops/sec.

### 3. La shard key est immutable (quasi)

> Choisissez votre shard key avec soin. La changer apr√®s coup est extr√™mement co√ªteux.

**Processus de choix :**
1. Analysez vos patterns de requ√™tes (80% de vos queries)
2. Identifiez les champs avec haute cardinalit√©
3. Testez sur des donn√©es r√©elles
4. Simulez la croissance √† 5 ans
5. Validez avec un expert MongoDB

**Erreur courante :** Sharder trop t√¥t avec une mauvaise shard key, puis √™tre coinc√©.

### 4. La localit√© est votre amie

> Concevez pour minimiser les communications entre shards.

**Bon :**
```javascript
// SaaS multi-tenant sharded on { tenantId: 1 }
// Query: db.data.find({ tenantId: "acme", date: ... })
// ‚Üí Targeted √† 1 shard
```

**Mauvais :**
```javascript
// Sharded on { _id: "hashed" }
// Query: db.data.find({ date: ... })
// ‚Üí Broadcast √† tous les shards
```

**Impact :** Queries broadcast sont 10-100x plus lentes.

### 5. Monitoring avant r√©activit√©

> Vous ne pouvez pas g√©rer ce que vous ne mesurez pas.

**M√©triques essentielles :**
- Replication lag
- Oplog window
- Member states
- Query performance (targeted vs broadcast)
- Chunk distribution
- Balancer activity

**Tooling :**
- MongoDB Atlas (monitoring int√©gr√©)
- Ops Manager / Cloud Manager
- Prometheus + Grafana
- Custom dashboards

### 6. Automatisation et Infrastructure as Code

> L'architecture distribu√©e est trop complexe pour des d√©ploiements manuels.

**Outils recommand√©s :**
- Terraform (pour MongoDB Atlas)
- Ansible (pour on-premise)
- Kubernetes Operators (pour conteneurs)
- Scripts de d√©ploiement version√©s

**B√©n√©fice :** Reproductibilit√©, versioning, tests automatis√©s.

## üö¶ Validation des acquis

Avant de passer √† la Partie 5, vous devez ma√Ætriser :

### Checklist R√©plication
- [ ] Je peux expliquer le r√¥le de chaque membre d'un Replica Set
- [ ] Je comprends le processus d'√©lection et de failover
- [ ] Je sais d√©ployer un Replica Set de production
- [ ] Je peux configurer Read Preference selon les cas d'usage
- [ ] Je comprends l'oplog et son dimensionnement
- [ ] Je sais monitorer le replication lag
- [ ] Je peux effectuer une maintenance sans downtime
- [ ] J'ai test√© un failover en conditions r√©elles

### Checklist Sharding
- [ ] Je comprends quand sharder (et quand ne pas sharder)
- [ ] Je peux analyser et choisir une shard key appropri√©e
- [ ] Je connais les diff√©rences entre Range et Hashed sharding
- [ ] Je sais d√©ployer un cluster shard√© complet
- [ ] Je comprends l'architecture (shards, config, mongos)
- [ ] Je peux optimiser les requ√™tes pour le sharding
- [ ] Je sais g√©rer les chunks et le balancing
- [ ] Je peux diagnostiquer et r√©soudre les jumbo chunks

### Checklist Architecture
- [ ] Je peux concevoir une architecture HA pour une application
- [ ] Je sais dimensionner un Replica Set (nombre de membres, ressources)
- [ ] Je peux justifier le choix entre RS simple et cluster shard√©
- [ ] Je comprends les compromis entre co√ªt, complexit√© et performance
- [ ] Je peux concevoir une architecture multi-r√©gion
- [ ] J'ai un plan de disaster recovery document√©

### Checklist Op√©rationnelle
- [ ] Je peux monitorer tous les composants critiques
- [ ] Je sais diagnostiquer les probl√®mes de r√©plication et sharding
- [ ] J'ai des runbooks pour les incidents courants
- [ ] Je peux effectuer un rolling restart sans downtime
- [ ] J'ai test√© mes proc√©dures de recovery

**Objectif :** Cocher 90%+ de ces cases. L'architecture distribu√©e est critique et les erreurs co√ªtent cher.

## üéØ Projets pratiques recommand√©s

### Projet 1 : Replica Set de production
**Dur√©e : 15-20 heures**

**Objectif :** D√©ployer et op√©rer un Replica Set production-ready.

**T√¢ches :**
1. D√©ployer un RS √† 3 membres (Docker ou VMs)
2. Configurer monitoring (Grafana + Prometheus)
3. Tester le failover (kill Primary, observer √©lection)
4. Impl√©menter rolling restart
5. Simuler replication lag et le r√©soudre
6. Documenter les runbooks

**Livrables :**
- Infrastructure as Code (Terraform/Ansible)
- Dashboards de monitoring
- Tests de r√©silience document√©s
- Proc√©dures op√©rationnelles

---

### Projet 2 : Cluster shard√© avec shard key analysis
**Dur√©e : 25-30 heures**

**Objectif :** D√©ployer un cluster shard√© et optimiser la shard key.

**T√¢ches :**
1. Analyser un dataset r√©el (logs, e-commerce, etc.)
2. Choisir et justifier une shard key
3. D√©ployer le cluster (2 shards, config servers, mongos)
4. Sharder les collections
5. Benchmarker targeted vs broadcast queries
6. Monitorer la distribution des chunks
7. Documenter l'architecture et les choix

**Livrables :**
- Document d'analyse de shard key
- Cluster fonctionnel
- Benchmarks de performance
- Monitoring complet
- Recommandations d'optimisation

---

### Projet 3 : Architecture multi-r√©gion
**Dur√©e : 20-25 heures**

**Objectif :** Concevoir une architecture avec contraintes g√©ographiques.

**Contraintes :**
- Donn√©es EU doivent rester en EU (GDPR)
- Latence < 100ms pour les utilisateurs locaux
- Tol√©rance √† la panne d'une r√©gion enti√®re

**Livrables :**
- Design doc de l'architecture
- D√©ploiement sur 3 r√©gions (simul√©)
- Tests de failover inter-r√©gion
- Analyse de latence

---

Ces projets vous donneront une exp√©rience pratique compl√®te et constitueront d'excellents ajouts √† votre portfolio.

## üìä Comparaison des architectures

| Architecture | Co√ªt | Complexit√© | HA | Scalabilit√© | Maintenance | Cas d'usage |
|--------------|------|------------|-----|-------------|-------------|-------------|
| **Standalone** | ‚Ç¨ | ‚≠ê | ‚ùå | ‚ùå | Simple | Dev/test uniquement |
| **Replica Set (3)** | ‚Ç¨‚Ç¨‚Ç¨ | ‚≠ê‚≠ê | ‚úÖ‚úÖ‚úÖ | ‚≠ê | Moyenne | 90% des apps prod |
| **Replica Set (5)** | ‚Ç¨‚Ç¨‚Ç¨‚Ç¨‚Ç¨ | ‚≠ê‚≠ê | ‚úÖ‚úÖ‚úÖ‚úÖ | ‚≠ê | Moyenne | Apps critiques |
| **Sharded (2 shards)** | ‚Ç¨‚Ç¨‚Ç¨‚Ç¨‚Ç¨‚Ç¨ | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ‚úÖ‚úÖ | ‚úÖ‚úÖ | Complexe | > 1 TB |
| **Sharded (5+ shards)** | ‚Ç¨‚Ç¨‚Ç¨‚Ç¨‚Ç¨‚Ç¨‚Ç¨‚Ç¨ | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ‚úÖ‚úÖ | ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ | Tr√®s complexe | Hyper-scale |

**Conseil :** Commencez simple, √©voluez selon les besoins r√©els.

## üåü Conseils d'architecte

### 1. KISS (Keep It Simple, Stupid)
Utilisez l'architecture la plus simple qui r√©pond √† vos besoins. La complexit√© a un co√ªt (op√©rationnel, bugs, maintenance).

### 2. Plan for failure
Tout tombe : hardware, r√©seau, datacenter. Concevez pour la r√©silience d√®s le d√©but.

### 3. Measure twice, cut once
Testez intensivement avant la production. Un failover qui √©choue en production est catastrophique.

### 4. Document everything
Dans 6 mois, vous aurez oubli√© pourquoi vous avez fait certains choix. Documentez votre architecture et vos d√©cisions.

### 5. Automate relentlessly
Tout processus manuel sera oubli√© ou mal ex√©cut√© sous stress. Automatisez les d√©ploiements, les backups, le monitoring.

### 6. Learn from others' mistakes
Lisez les post-mortems publics (MongoDB, GitHub, etc.). Les erreurs d'architecture distribu√©e sont co√ªteuses.

## üìö Ressources compl√©mentaires

### Documentation officielle
- [MongoDB Replication](https://www.mongodb.com/docs/manual/replication/)
- [MongoDB Sharding](https://www.mongodb.com/docs/manual/sharding/)
- [Production Notes](https://www.mongodb.com/docs/manual/administration/production-notes/)

### Livres essentiels
- *Designing Data-Intensive Applications* par Martin Kleppmann
- *Database Internals* par Alex Petrov
- *MongoDB: The Definitive Guide* (3rd ed.)

### Cours et certifications
- MongoDB University (cours M103, M201, M320)
- MongoDB Certified DBA Associate

### Communaut√©
- MongoDB Community Forums
- MongoDB User Groups
- Conf√©rences (MongoDB World, MongoDB.local)

## üöÄ Et apr√®s ?

Une fois cette partie ma√Ætris√©e, vous serez capable de **concevoir et op√©rer des architectures MongoDB distribu√©es** pour des applications de classe mondiale. Vous comprendrez :

- Comment garantir 99.99%+ uptime avec les Replica Sets
- Comment scaler horizontalement avec le sharding
- Les compromis entre disponibilit√©, coh√©rence et performance
- Comment op√©rer des syst√®mes distribu√©s en production

La **Partie 5** vous enseignera la s√©curit√© et l'administration avanc√©e, essentielles pour prot√©ger vos donn√©es et g√©rer vos clusters en production.

La **Partie 6** couvrira MongoDB Atlas et le cloud, vous permettant de d√©ployer des architectures distribu√©es sans g√©rer l'infrastructure.

Mais d'abord, **ma√Ætrisez cette Partie 4**. L'architecture distribu√©e est le fondement de toute application MongoDB √† grande √©chelle. Une architecture bien con√ßue d√®s le d√©part vous fera √©conomiser des ann√©es de probl√®mes.

---

**Pr√™t √† construire des syst√®mes distribu√©s de classe mondiale ? Allons-y ! üåç**

---

**Prochaine √©tape :** [Module 9 - R√©plication ‚Üí](/09-replication/README.md)

---

*üí° Citation du jour : "A distributed system is one in which the failure of a computer you didn't even know existed can render your own computer unusable." - Leslie Lamport (inventeur de Paxos)*

‚è≠Ô∏è [Module 9 - R√©plication ‚Üí](/09-replication/README.md)
