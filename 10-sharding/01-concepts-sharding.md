ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 10.1 Concepts du Sharding

## Introduction

Le **sharding** (partitionnement horizontal) est la mÃ©thode de distribution des donnÃ©es de MongoDB permettant de rÃ©partir un ensemble de donnÃ©es volumineux sur plusieurs machines. Contrairement Ã  la rÃ©plication qui duplique les donnÃ©es pour la haute disponibilitÃ©, le sharding divise les donnÃ©es pour augmenter la capacitÃ© de stockage et le dÃ©bit de traitement.

Cette section explore les concepts fondamentaux qui sous-tendent l'architecture shardÃ©e de MongoDB, nÃ©cessaires pour comprendre, dÃ©ployer et gÃ©rer efficacement un cluster en production.

## Terminologie Essentielle

### Shard

Un **shard** est un sous-ensemble des donnÃ©es d'une collection shardÃ©e. Dans MongoDB, chaque shard est typiquement implÃ©mentÃ© comme un **Replica Set** complet, offrant ainsi :
- Haute disponibilitÃ© au niveau du shard
- TolÃ©rance aux pannes
- PossibilitÃ© de read preference par shard

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Shard A (Replica Set)       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Primary â”‚  â”‚Secondaryâ”‚  â”‚Sec. â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  Contient: user_id 0-999            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Shard B (Replica Set)       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Primary â”‚  â”‚Secondaryâ”‚  â”‚Sec. â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  Contient: user_id 1000-1999        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**CaractÃ©ristiques :**
- Chaque shard ne contient qu'une portion des donnÃ©es totales
- Les shards ne communiquent pas directement entre eux
- L'ajout de shards augmente la capacitÃ© globale du cluster

### Chunk

Un **chunk** est une unitÃ© logique de donnÃ©es contiguÃ«s selon la shard key. MongoDB divise automatiquement les donnÃ©es d'une collection shardÃ©e en chunks.

**PropriÃ©tÃ©s d'un chunk :**
- Taille par dÃ©faut : **128 MB** (configurable entre 1 MB et 1024 MB)
- Bornes : `[minKey, maxKey)` basÃ©es sur la shard key
- Indivisible lors du balancing (sauf splitting)
- Peut rÃ©sider sur un seul shard Ã  la fois

```javascript
// Exemple de structure d'un chunk dans config.chunks
{
  "_id": ObjectId("..."),
  "ns": "ecommerce.orders",
  "min": { "customer_id": 0 },
  "max": { "customer_id": 1000 },
  "shard": "shard-a",
  "lastmod": Timestamp(1, 0),
  "history": [...]
}
```

**ReprÃ©sentation visuelle :**
```
Collection: ecommerce.orders (shard key: customer_id)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Shard A                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Chunk 1         â”‚  Chunk 2         â”‚  Chunk 3       â”‚
â”‚  customer_id:    â”‚  customer_id:    â”‚  customer_id:  â”‚
â”‚  [0, 1000)       â”‚  [1000, 2000)    â”‚  [2000, 3000)  â”‚
â”‚  Size: 120 MB    â”‚  Size: 115 MB    â”‚  Size: 128 MB  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Shard B                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Chunk 4         â”‚  Chunk 5         â”‚  Chunk 6       â”‚
â”‚  customer_id:    â”‚  customer_id:    â”‚  customer_id:  â”‚
â”‚  [3000, 4000)    â”‚  [4000, 5000)    â”‚  [5000, 6000)  â”‚
â”‚  Size: 125 MB    â”‚  Size: 127 MB    â”‚  Size: 118 MB  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Shard Key

La **shard key** est le champ indexÃ© (ou la combinaison de champs) utilisÃ© pour dÃ©terminer la distribution des documents entre les shards.

**RÃ´le critique :**
- DÃ©termine le chunk qui contient chaque document
- Immuable aprÃ¨s la crÃ©ation (avant MongoDB 5.0)
- Impact direct sur les performances et la distribution

```javascript
// Exemples de shard keys
sh.shardCollection("db.collection", { "_id": 1 })                    // Simple
sh.shardCollection("db.collection", { "user_id": 1, "date": 1 })     // ComposÃ©e
sh.shardCollection("db.collection", { "location": "hashed" })        // Hashed
```

**Anatomie d'une shard key composÃ©e :**
```javascript
// Shard key: { "region": 1, "user_id": 1 }

Document 1: { region: "EU", user_id: 12345, name: "Alice" }
            â†“
            Shard Key Value: { region: "EU", user_id: 12345 }
            â†“
            Chunk: [{ region: "EU", user_id: 10000 }, { region: "EU", user_id: 20000 })
            â†“
            Shard: shard-eu-01
```

### Mongos (Query Router)

**Mongos** est le processus de routage qui dirige les requÃªtes des clients vers les shards appropriÃ©s.

**Fonctions principales :**
1. **Routage intelligent** : Analyse les requÃªtes et dÃ©termine les shards cibles
2. **AgrÃ©gation des rÃ©sultats** : Combine les rÃ©sultats de plusieurs shards
3. **Gestion des transactions** : Coordonne les transactions multi-shards
4. **Cache des mÃ©tadonnÃ©es** : Maintient une copie locale de la configuration

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Application                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ Connection String
                       â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Mongos Instance â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚              â”‚              â”‚
Query Analysis    Metadata Cache   Result Merge
        â”‚              â”‚              â”‚
        â–¼              â–¼              â–¼
   Shard A        Config Servers  Shard B
```

**CaractÃ©ristiques importantes :**
- Sans Ã©tat (stateless) : peut Ãªtre arrÃªtÃ©/redÃ©marrÃ© sans perte de donnÃ©es
- Haute disponibilitÃ© : dÃ©ployer plusieurs instances mongos
- LÃ©ger : faible empreinte mÃ©moire (~256 MB typique)
- Scalable : ajouter des mongos pour gÃ©rer plus de connexions

### Config Servers

Les **config servers** stockent les mÃ©tadonnÃ©es et la configuration du cluster shardÃ©.

**DonnÃ©es stockÃ©es :**
- Mapping chunks â†’ shards
- Shard key des collections
- Zones et tags
- Historique des migrations
- Configuration du balancer

```javascript
// Exemple de mÃ©tadonnÃ©es dans config database
use config

// Collections critiques :
db.databases.find()       // Informations sur les databases shardÃ©es
db.collections.find()     // Collections shardÃ©es et leurs shard keys
db.chunks.find()          // Tous les chunks et leur localisation
db.shards.find()          // Liste des shards du cluster
db.version.find()         // Version du cluster metadata
```

**Architecture depuis MongoDB 3.4+ :**
- ImplÃ©mentÃ©s comme un **Replica Set CSRS** (Config Server Replica Set)
- Minimum requis : **3 membres**
- Utilise le protocole de rÃ©plication standard
- Haute disponibilitÃ© critique : si config servers down â†’ cluster en lecture seule

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Config Server Replica Set (CSRS)           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ Primary  â”‚  â”‚Secondary â”‚  â”‚Secondary â”‚      â”‚
â”‚  â”‚  (CSR1)  â”‚  â”‚  (CSR2)  â”‚  â”‚  (CSR3)  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                â”‚
â”‚  Database: config                              â”‚
â”‚  Collections: chunks, databases, collections,  â”‚
â”‚               shards, version, locks...        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## MÃ©canismes Fondamentaux

### 1. Chunk Splitting (Division des Chunks)

Lorsqu'un chunk atteint la taille configurÃ©e (par dÃ©faut 128 MB), MongoDB le divise automatiquement en deux chunks.

**Processus de splitting :**

```
Ã‰tat Initial:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Chunk A                â”‚
â”‚  Range: [0, 10000)             â”‚
â”‚  Size: 140 MB (> 128 MB)       â”‚
â”‚  Shard: shard-a                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

AprÃ¨s Splitting:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Chunk A-1     â”‚    Chunk A-2     â”‚
â”‚ Range: [0, 5000) â”‚Range: [5000,10000â”‚
â”‚ Size: 70 MB      â”‚ Size: 70 MB      â”‚
â”‚ Shard: shard-a   â”‚ Shard: shard-a   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Code interne (simplifiÃ©) :**
```javascript
// MongoDB dÃ©termine le point de split (mÃ©diane de la shard key)
splitPoint = findMedian(chunk.minKey, chunk.maxKey)

// CrÃ©e deux nouveaux chunks
chunk1 = { min: chunk.minKey, max: splitPoint, shard: chunk.shard }
chunk2 = { min: splitPoint, max: chunk.maxKey, shard: chunk.shard }

// Les deux chunks restent sur le mÃªme shard initialement
```

**Points importants :**
- Le split est **local** au shard (pas de transfert de donnÃ©es)
- Le split point est calculÃ© par la **mÃ©diane** de la shard key
- OpÃ©ration rapide (~millisecondes)
- Peut Ãªtre dÃ©clenchÃ© manuellement : `sh.splitAt()` ou `sh.splitFind()`

**Anti-pattern - Jumbo Chunks :**
```javascript
// âŒ MAUVAIS : Shard key avec peu de valeurs distinctes
sh.shardCollection("app.events", { "event_type": 1 })
// event_type a seulement 5 valeurs : "login", "logout", "purchase", "view", "click"

// RÃ©sultat : Chunks de 500 GB car impossible de diviser plus finement
// â†’ Jumbo chunk marquÃ©, balancing bloquÃ©
```

### 2. Balancing (Ã‰quilibrage)

Le **balancer** est un processus automatique qui migre les chunks entre shards pour maintenir une distribution Ã©quilibrÃ©e.

**DÃ©clencheurs du balancing :**
- DiffÃ©rence de nombre de chunks entre shards > seuil de migration
- Seuils configurables selon le nombre total de chunks

```
Seuils de migration par dÃ©faut :
< 20 chunks:     diffÃ©rence de 2 chunks
20-79 chunks:    diffÃ©rence de 4 chunks
â‰¥ 80 chunks:     diffÃ©rence de 8 chunks
```

**Algorithme de balancing (simplifiÃ©) :**

```
Ã‰tape 1: Identifier les shards dÃ©sÃ©quilibrÃ©s
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Shard A â”‚ Shard B â”‚ Shard C â”‚
â”‚ 45 chks â”‚ 38 chks â”‚ 25 chks â”‚ â†’ DiffÃ©rence: 20 chunks (A vs C)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ã‰tape 2: SÃ©lectionner un chunk Ã  migrer de A vers C
Chunk sÃ©lectionnÃ©: chunk_17 (critÃ¨res: taille, activitÃ© rÃ©cente)

Ã‰tape 3: Migration
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Clone chunk_17 de Shard A â†’ Shard C â”‚
â”‚  2. Sync incrementale (oplog)           â”‚
â”‚  3. Update metadata (config servers)    â”‚
â”‚  4. Delete chunk_17 from Shard A        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

RÃ©sultat:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Shard A â”‚ Shard B â”‚ Shard C â”‚
â”‚ 44 chks â”‚ 38 chks â”‚ 26 chks â”‚ â†’ Plus Ã©quilibrÃ©
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**FenÃªtre de balancing :**
```javascript
// Configurer une fenÃªtre pour limiter l'impact
use config
db.settings.updateOne(
  { _id: "balancer" },
  { $set: {
      activeWindow: {
        start: "01:00",  // 1h du matin
        stop: "05:00"    // 5h du matin
      }
    }
  },
  { upsert: true }
)
```

**ContrÃ´le du balancer :**
```javascript
// ArrÃªter temporairement
sh.stopBalancer()

// VÃ©rifier le statut
sh.getBalancerState()
// true = actif, false = inactif

// RedÃ©marrer
sh.startBalancer()

// VÃ©rifier si le balancer est en cours d'exÃ©cution
sh.isBalancerRunning()
```

### 3. Routage des RequÃªtes

Le routage dÃ©termine quels shards doivent Ãªtre interrogÃ©s pour une requÃªte donnÃ©e.

#### Types de Routage

**A. Targeted Query (RequÃªte CiblÃ©e)**

La requÃªte contient la shard key â†’ mongos interroge uniquement le(s) shard(s) pertinent(s).

```javascript
// Shard key: { "user_id": 1 }
db.orders.find({ "user_id": 12345, "status": "pending" })

// Mongos dÃ©termine:
// 1. Chunk contenant user_id=12345 â†’ chunk_42
// 2. Shard hÃ©bergeant chunk_42 â†’ shard-b
// 3. Route la requÃªte uniquement vers shard-b

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Mongos  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚ Query: user_id=12345
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Shard A  â”‚     â”‚Shard B  â”‚     â”‚Shard C  â”‚
â”‚         â”‚     â”‚  âœ“âœ“âœ“âœ“   â”‚     â”‚         â”‚
â”‚         â”‚     â”‚ Queried â”‚     â”‚         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Performance : O(1) shard** - Optimal

**B. Scatter-Gather Query**

La requÃªte ne contient pas (ou partiellement) la shard key â†’ mongos interroge tous les shards.

```javascript
// Shard key: { "user_id": 1 }
db.orders.find({ "product_id": "ABC123" })  // product_id n'est PAS dans la shard key

// Mongos doit interroger TOUS les shards:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Mongos  â”‚
â””â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”˜
  â”‚  â”‚  â”‚ Query: product_id=ABC123
  â–¼  â–¼  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Shard A  â”‚  â”‚Shard B  â”‚  â”‚Shard C  â”‚
â”‚  âœ“âœ“âœ“âœ“   â”‚  â”‚  âœ“âœ“âœ“âœ“   â”‚  â”‚  âœ“âœ“âœ“âœ“   â”‚
â”‚ Queried â”‚  â”‚ Queried â”‚  â”‚ Queried â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚            â”‚            â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Merge Results  â”‚
         â”‚   in Mongos    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Performance : O(N) shards** - Ã€ Ã©viter si possible

**C. Broadcast Query**

RequÃªtes d'administration ou sans filtre â†’ tous les shards.

```javascript
db.orders.find({})  // Pas de filtre
db.orders.count()   // Count global
```

#### Optimisation du Routage avec Shard Key ComposÃ©e

```javascript
// Shard key composÃ©e: { "region": 1, "user_id": 1 }

// âœ… RequÃªte totalement ciblÃ©e (1 shard)
db.users.find({ "region": "EU", "user_id": 12345 })

// âš ï¸ RequÃªte partiellement ciblÃ©e (quelques shards)
db.users.find({ "region": "EU" })
// Mongos interroge uniquement les chunks avec region="EU"
// Mais peut Ãªtre rÃ©parti sur plusieurs shards

// âŒ RequÃªte scatter-gather (tous les shards)
db.users.find({ "user_id": 12345 })
// user_id est dans la shard key MAIS region manque (prÃ©fixe)
```

**RÃ¨gle du prÃ©fixe de shard key :**
Pour une shard key composÃ©e `{ a: 1, b: 1, c: 1 }`, le routage ciblÃ© nÃ©cessite :
- `{ a: ... }` â†’ Partiellement ciblÃ©
- `{ a: ..., b: ... }` â†’ Plus ciblÃ©
- `{ a: ..., b: ..., c: ... }` â†’ Totalement ciblÃ©
- `{ b: ... }` ou `{ c: ... }` â†’ Scatter-gather

### 4. Metadata Management

Les mÃ©tadonnÃ©es du cluster sont stockÃ©es dans la base **config** sur les config servers.

**Collections critiques :**

```javascript
// 1. config.shards - Liste des shards
{
  "_id": "shard-a",
  "host": "shard-a/mongo1:27018,mongo2:27018,mongo3:27018",
  "state": 1,  // 1 = active
  "tags": ["eu", "premium"]
}

// 2. config.databases - Databases et primary shard
{
  "_id": "ecommerce",
  "primary": "shard-a",  // Primary shard pour collections non-shardÃ©es
  "partitioned": true    // Database est shardÃ©e
}

// 3. config.collections - Collections shardÃ©es
{
  "_id": "ecommerce.orders",
  "key": { "customer_id": 1, "order_date": 1 },  // Shard key
  "unique": false,
  "lastmodEpoch": ObjectId("..."),
  "dropped": false
}

// 4. config.chunks - Mapping chunks â†’ shards
{
  "_id": ObjectId("..."),
  "ns": "ecommerce.orders",
  "min": { "customer_id": 0, "order_date": ISODate("2024-01-01") },
  "max": { "customer_id": 1000, "order_date": ISODate("2024-02-01") },
  "shard": "shard-a",
  "lastmod": Timestamp(5, 1),
  "history": [
    { "validAfter": Timestamp(...), "shard": "shard-a" }
  ]
}

// 5. config.locks - Verrous distribuÃ©s
{
  "_id": "ecommerce.orders",
  "state": 2,  // 2 = locked
  "process": "ConfigServer",
  "ts": ObjectId("..."),
  "when": ISODate("2024-12-08T10:30:00Z"),
  "who": "shard-a:Balancer:123456",
  "why": "Migration chunk_42"
}
```

**Synchronisation des mÃ©tadonnÃ©es :**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Config Servers (Source de vÃ©ritÃ©)               â”‚
â”‚  - Chunks mapping                                â”‚
â”‚  - Shard key definitions                         â”‚
â”‚  - Database/collection metadata                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ Replication
               â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  Mongos Instances   â”‚
     â”‚  (Cache des metadataâ”‚
     â”‚   - TTL: 30s        â”‚
     â”‚   - Lazy refresh)   â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Impact du cache mongos :**
- RequÃªtes plus rapides (pas de round-trip vers config servers)
- Risque de stale metadata (30 secondes max)
- RafraÃ®chissement automatique en cas d'erreur de routage

## Flux de DonnÃ©es dans un Cluster ShardÃ©

### Insertion de Document

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Application envoie insert                               â”‚
â”‚     db.orders.insertOne({                                   â”‚
â”‚       customer_id: 12345,                                   â”‚
â”‚       order_date: ISODate("2024-12-08"),                    â”‚
â”‚       total: 99.99                                          â”‚
â”‚     })                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  2. Mongos reÃ§oit                             â”‚
         â”‚     - Extrait shard key:                      â”‚
         â”‚       { customer_id: 12345, order_date: ... } â”‚
         â”‚     - Consulte metadata:                      â”‚
         â”‚       Chunk range â†’ Shard B                   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  3. Route vers   â”‚
              â”‚     Shard B      â”‚
              â”‚     (Primary)    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ 4. Shard B insÃ¨re  â”‚
            â”‚    - Write Concern â”‚
            â”‚    - Oplog entry   â”‚
            â”‚    - Replication   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ 5. Acknowledge   â”‚
            â”‚    Ã  Mongos      â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ 6. Mongos retourne â”‚
          â”‚    Ã  l'application â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### RequÃªte Find avec Shard Key

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Application envoie find                        â”‚
â”‚     db.orders.find({ customer_id: 12345 })         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  2. Mongos analyse      â”‚
         â”‚     - Shard key prÃ©sent â”‚
         â”‚     - Lookup metadata   â”‚
         â”‚     - DÃ©termine: Shard Bâ”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ 3. Query Shard B â”‚
          â”‚    (ciblÃ©e)      â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ 4. Shard B       â”‚
         â”‚    exÃ©cute query â”‚
         â”‚    retourne docs â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ 5. Mongos        â”‚
         â”‚    retourne docs â”‚
         â”‚    (pas de merge)â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ 6. Application     â”‚
         â”‚    reÃ§oit rÃ©sultat â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### RequÃªte Find SANS Shard Key (Scatter-Gather)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Application envoie find                        â”‚
â”‚     db.orders.find({ product_id: "ABC123" })       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  2. Mongos analyse      â”‚
         â”‚     - Shard key ABSENT  â”‚
         â”‚     - DÃ©cision: Scatter â”‚
         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
                â”‚              â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                                â”‚
       â–¼                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚3a. Query   â”‚   â”‚3b. Query   â”‚   â”‚3c. Query   â”‚
â”‚  Shard A   â”‚   â”‚  Shard B   â”‚   â”‚  Shard C   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
       â”‚                â”‚                â”‚
       â”‚   4. Results   â”‚    Results     â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                â”‚
                â–¼                â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ 5. Mongos MERGE          â”‚
         â”‚    - Combine results     â”‚
         â”‚    - Apply sort/limit    â”‚
         â”‚    - Deduplicate (si _id)â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ 6. Application     â”‚
         â”‚    reÃ§oit rÃ©sultat â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Impact performance Scatter-Gather :**
- Latence = max(latence_shardA, latence_shardB, latence_shardC)
- Bande passante Ã— N shards
- Charge CPU mongos pour le merge
- Ã€ Ã©viter autant que possible

## Concepts AvancÃ©s

### Zones (Shard Tags)

Les **zones** permettent de contrÃ´ler la distribution des chunks sur des shards spÃ©cifiques selon des rÃ¨gles mÃ©tier.

**Cas d'usage typiques :**
1. **Localisation gÃ©ographique** : DonnÃ©es EU sur shards EU, US sur shards US
2. **Tiers de service** : Clients premium sur hardware premium
3. **ConformitÃ©** : DonnÃ©es sensibles sur shards dÃ©diÃ©s

```javascript
// Configuration de zones gÃ©ographiques
sh.addShardToZone("shard-eu-01", "EU")
sh.addShardToZone("shard-eu-02", "EU")
sh.addShardToZone("shard-us-01", "US")
sh.addShardToZone("shard-us-02", "US")

// DÃ©finir les plages de shard key pour chaque zone
sh.updateZoneKeyRange(
  "app.users",
  { country: "FR", user_id: MinKey },
  { country: "FR", user_id: MaxKey },
  "EU"
)

sh.updateZoneKeyRange(
  "app.users",
  { country: "DE", user_id: MinKey },
  { country: "DE", user_id: MaxKey },
  "EU"
)

sh.updateZoneKeyRange(
  "app.users",
  { country: "US", user_id: MinKey },
  { country: "US", user_id: MaxKey },
  "US"
)
```

**Visualisation :**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Zone: EU                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚ Shard EU-1 â”‚  â”‚ Shard EU-2 â”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚  Chunks:                                             â”‚
â”‚  - country="FR", user_id [0, 10000)                  â”‚
â”‚  - country="FR", user_id [10000, 20000)              â”‚
â”‚  - country="DE", user_id [0, 15000)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Zone: US                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚ Shard US-1 â”‚  â”‚ Shard US-2 â”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚  Chunks:                                             â”‚
â”‚  - country="US", user_id [0, 20000)                  â”‚
â”‚  - country="US", user_id [20000, 40000)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Jumbo Chunks

Un **jumbo chunk** est un chunk qui dÃ©passe la taille maximale configurÃ©e mais ne peut pas Ãªtre divisÃ©.

**Causes :**
1. **Faible cardinalitÃ©** de la shard key
2. **Distribution dÃ©sÃ©quilibrÃ©e** des valeurs
3. **Shard key avec trop de documents identiques**

```javascript
// Exemple causant jumbo chunks
sh.shardCollection("logs.events", { "severity": 1 })
// severity a 3 valeurs: "INFO", "WARNING", "ERROR"
// Si 90% des logs sont "INFO" â†’ Chunk "INFO" devient jumbo

// Diagnostic
db.chunks.find({ ns: "logs.events", jumbo: true })

// Output:
{
  "_id": ObjectId("..."),
  "ns": "logs.events",
  "min": { "severity": "INFO" },
  "max": { "severity": "WARNING" },
  "shard": "shard-a",
  "jumbo": true,  // âš ï¸ MarquÃ© jumbo
  "lastmod": Timestamp(10, 0)
}
```

**Impact :**
- âŒ Le balancer ne peut pas migrer le chunk
- âŒ Distribution dÃ©sÃ©quilibrÃ©e permanente
- âŒ Hotspot sur le shard contenant le jumbo chunk

**RÃ©solution (dÃ©taillÃ©e en section 10.11) :**
1. Raffiner la shard key (si possible depuis MongoDB 5.0+)
2. Split manuel avec valeur intermÃ©diaire
3. RemodÃ©lisation et migration

### Hashed Shard Keys

Le **hashed sharding** applique une fonction de hachage sur la shard key pour garantir une distribution uniforme.

```javascript
// Activation du hashed sharding
sh.shardCollection("app.users", { "_id": "hashed" })

// MongoDB calcule automatiquement:
hash(user_id) â†’ int64 distribuÃ© uniformÃ©ment

// Exemple de distribution:
user_id: "user_12345" â†’ hash â†’ -4567891234567890123 â†’ Chunk A â†’ Shard 1
user_id: "user_67890" â†’ hash â†’  8901234567890123456 â†’ Chunk B â†’ Shard 2
```

**Distribution garantie :**
```
Sans hashing (monotone):
Shard A: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (100% insertions rÃ©centes)
Shard B: â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ (idle)
Shard C: â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ (idle)

Avec hashing:
Shard A: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ (33% insertions)
Shard B: â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ (33% insertions)
Shard C: â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ (34% insertions)
```

**Trade-off :**
- âœ… Distribution parfaite
- âœ… Pas de hotspots
- âŒ ImpossibilitÃ© de requÃªtes par plage ciblÃ©es
- âŒ Toutes les requÃªtes par plage â†’ scatter-gather

## Anti-Patterns Fondamentaux

### 1. Shard Key Non Incluse dans les RequÃªtes

```javascript
// âŒ ANTI-PATTERN
sh.shardCollection("products.catalog", { "category_id": 1 })

// Mais 90% des requÃªtes sont:
db.catalog.find({ "sku": "ABC123" })
db.catalog.find({ "price": { $lt: 50 } })

// RÃ©sultat: Scatter-gather systÃ©matique sur tous les shards
```

**Solution :**
```javascript
// âœ… PATTERN
// Analyser les patterns de requÃªte AVANT de choisir la shard key
sh.shardCollection("products.catalog", { "sku": 1 })
```

### 2. Shard Key Unique Monotone

```javascript
// âŒ ANTI-PATTERN
sh.shardCollection("events.logs", { "timestamp": 1 })

// ProblÃ¨me: Toutes les insertions vont au chunk le plus rÃ©cent
// Un seul shard actif en Ã©criture â†’ hotspot permanent
```

**Solution :**
```javascript
// âœ… PATTERN 1: Hashed
sh.shardCollection("events.logs", { "timestamp": "hashed" })

// âœ… PATTERN 2: ComposÃ© avec prÃ©fixe non-monotone
sh.shardCollection("events.logs", { "source_id": 1, "timestamp": 1 })
```

### 3. CardinalitÃ© Insuffisante

```javascript
// âŒ ANTI-PATTERN
sh.shardCollection("orders.transactions", { "status": 1 })
// status: "pending", "completed", "cancelled" (3 valeurs)

// RÃ©sultat:
// - Maximum 3 chunks possibles
// - Impossible de distribuer sur plus de 3 shards
// - Jumbo chunks garantis Ã  forte volumÃ©trie
```

**Solution :**
```javascript
// âœ… PATTERN
sh.shardCollection("orders.transactions",
  { "status": 1, "customer_id": 1, "order_id": 1 }
)
// CardinalitÃ©: 3 Ã— millions Ã— millions = suffisante
```

### 4. Shard Key Mutable

```javascript
// âŒ ANTI-PATTERN (avant MongoDB 5.0)
sh.shardCollection("users.profiles", { "email": 1 })

// ProblÃ¨me: Si un utilisateur change d'email
db.profiles.updateOne(
  { _id: userId },
  { $set: { email: "new_email@example.com" } }
)

// Avant MongoDB 5.0: Erreur - Impossible de changer shard key
// Depuis MongoDB 5.0: Possible mais overhead (migration de chunk)
```

**Solution :**
```javascript
// âœ… PATTERN
sh.shardCollection("users.profiles", { "_id": 1 })
// _id est toujours immuable
```

### 5. Sur-Sharding PrÃ©maturÃ©

```javascript
// âŒ ANTI-PATTERN
// DÃ©ployer 20 shards pour une database de 100 GB

// Overhead inutile:
// - 20 Replica Sets Ã  gÃ©rer (60+ serveurs)
// - Balancer actif en permanence
// - Metadata overhead
// - Latence de routage accrue
```

**Solution :**
```javascript
// âœ… PATTERN
// Commencer modeste, scaler progressivement
// RÃ¨gle empirique:
// - DÃ©marrer avec 2-3 shards
// - Ajouter un shard lorsque:
//   * Stockage par shard > 2-3 TB
//   * DÃ©bit par shard > 100k ops/sec
//   * Latence > SLA dÃ©fini
```

## ConsidÃ©rations de Performance

### Latence de Routage

```
RequÃªte non-shardÃ©e (Replica Set):
Application â†’ Primary â†’ RÃ©sultat
Latence typique: 1-5 ms

RequÃªte shardÃ©e ciblÃ©e:
Application â†’ Mongos â†’ Shard Primary â†’ RÃ©sultat
Latence typique: 2-8 ms (+overhead mongos ~1-3 ms)

RequÃªte scatter-gather (4 shards):
Application â†’ Mongos â†’ [4 Shards en parallÃ¨le] â†’ Merge â†’ RÃ©sultat
Latence typique: 10-50 ms (max des 4 + merge)
```

### Throughput d'Ã‰criture

```
Replica Set:
Max throughput â‰ˆ CapacitÃ© du Primary
Exemple: ~50,000 writes/sec sur hardware standard

Cluster ShardÃ© (4 shards):
Max throughput â‰ˆ 4 Ã— CapacitÃ© d'un Primary
Exemple: ~200,000 writes/sec (scaling quasi-linÃ©aire)

Condition: Distribution uniforme des Ã©critures
```

### Consommation MÃ©moire

```
Mongos:
- Cache metadata: 50-200 MB
- Connexion pools: 100 MB par 1000 connexions
- Total typique: 256-512 MB par instance

Config Servers:
- Metadata database: 1-5 GB (pour 1M chunks)
- WiredTiger cache: 1-2 GB minimum
- Total: 2-4 GB par config server

Shards:
- Working set + Indexes (comme un Replica Set standard)
- WiredTiger cache: 50% de la RAM par dÃ©faut
```

## Checklist de Conception

Avant de dÃ©ployer un cluster shardÃ©, validez :

- [ ] **VolumÃ©trie** : DonnÃ©es actuelles et projection 2-5 ans
- [ ] **Patterns de requÃªte** : 80/20 rule - quelles sont les 20% de requÃªtes critiques ?
- [ ] **Shard key** : Satisfait CWT (CardinalitÃ©, Write distribution, Targetability)
- [ ] **Indexes** : Shard key indexÃ©e + indexes secondaires planifiÃ©s
- [ ] **Read/Write ratio** : Majoritairement lecture, Ã©criture, ou mixte ?
- [ ] **Latence acceptable** : SLA dÃ©fini pour P50, P95, P99
- [ ] **Backup strategy** : Compatible avec sharding (backup par shard ou global)
- [ ] **Monitoring** : MÃ©triques spÃ©cifiques sharding dÃ©finies
- [ ] **Expertise** : Ã‰quipe formÃ©e Ã  l'administration d'un cluster shardÃ©
- [ ] **Rollback plan** : StratÃ©gie de retour arriÃ¨re si problÃ¨me

## RÃ©sumÃ©

Le sharding MongoDB repose sur des concepts fondamentaux interconnectÃ©s :

1. **Chunks** : UnitÃ©s logiques de donnÃ©es distribuÃ©es
2. **Shard Key** : DÃ©termine la distribution (choix le plus critique)
3. **Balancer** : Maintient l'Ã©quilibre automatiquement
4. **Mongos** : Route intelligemment les requÃªtes
5. **Config Servers** : Source de vÃ©ritÃ© pour les mÃ©tadonnÃ©es

**Principes de conception :**
- La shard key est **immuable** (ou difficile Ã  changer) â†’ rÃ©flexion approfondie nÃ©cessaire
- Optimiser pour les **requÃªtes ciblÃ©es** (Ã©viter scatter-gather)
- DÃ©marrer **petit** et scaler progressivement
- **Monitorer** constamment la distribution et les performances

**Anti-patterns critiques Ã  Ã©viter :**
- âŒ Shard key Ã  faible cardinalitÃ©
- âŒ Shard key monotone sans distribution
- âŒ Shard key absente des requÃªtes principales
- âŒ Shard key mutable
- âŒ Sur-sharding prÃ©maturÃ©

Le sharding est un outil puissant mais complexe. Une conception soigneuse basÃ©e sur ces concepts fondamentaux est essentielle pour un cluster performant et maintenable en production.

---


â­ï¸ [Architecture shardÃ©e](/10-sharding/02-architecture-shardee.md)
