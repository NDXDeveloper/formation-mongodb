üîù Retour au [Sommaire](/SOMMAIRE.md)

# 10.10 Monitoring et Maintenance

## Introduction

Le monitoring et la maintenance d'un cluster shard√© MongoDB sont des activit√©s critiques qui n√©cessitent une approche proactive et m√©thodique. Contrairement √† un simple Replica Set, un cluster shard√© introduit de multiples points de surveillance : les shards individuels, les config servers, les mongos, et les interactions entre ces composants. Une d√©faillance non d√©tect√©e ou une maintenance mal planifi√©e peut entra√Æner des d√©gradations de performance significatives, voire une indisponibilit√© du service.

Cette section pr√©sente les strat√©gies, outils et bonnes pratiques pour maintenir un cluster shard√© en production dans un √©tat optimal, d√©tecter les probl√®mes avant qu'ils n'impactent les utilisateurs, et effectuer les op√©rations de maintenance avec un minimum d'interruption.

---

## Architecture de Monitoring

### Composants √† Surveiller

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    MONITORING STACK                         ‚îÇ
‚îÇ              (Prometheus + Grafana + Alertmanager)          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ             ‚îÇ             ‚îÇ             ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Config  ‚îÇ   ‚îÇMongos 1‚îÇ   ‚îÇShard A ‚îÇ      ‚îÇShard B ‚îÇ
    ‚îÇServers  ‚îÇ   ‚îÇMongos 2‚îÇ   ‚îÇ (RS)   ‚îÇ      ‚îÇ (RS)   ‚îÇ
    ‚îÇ  (RS)   ‚îÇ   ‚îÇMongos 3‚îÇ   ‚îÇ        ‚îÇ      ‚îÇ        ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ             ‚îÇ             ‚îÇ             ‚îÇ
    Exporter      Exporter      Exporter        Exporter
    :9216         :9216         :9216           :9216
```

**M√©triques par composant** :

| Composant | M√©triques Critiques |
|-----------|-------------------|
| **Config Servers** | √âtat replica set, latence r√©plication, oplog size |
| **Mongos** | Connexions actives, requ√™tes/sec, latence moyenne |
| **Shards** | CPU, RAM, IOPS, distribution chunks, jumbo chunks |
| **Balancer** | Migrations actives, taux d'√©chec, dur√©e moyenne |
| **R√©seau** | Bande passante inter-shards, latence, packet loss |

### Niveaux de Monitoring

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Niveau 1 : Infrastructure (OS/Hardware)                  ‚îÇ
‚îÇ - CPU, RAM, Disque, R√©seau                               ‚îÇ
‚îÇ - Outils : node_exporter, collectd, CloudWatch           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Niveau 2 : MongoDB Internals                             ‚îÇ
‚îÇ - Opcounters, connections, queue depth                   ‚îÇ
‚îÇ - Outils : mongodb_exporter, mongostat                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Niveau 3 : Sharding Specifics                            ‚îÇ
‚îÇ - Distribution chunks, migrations, balancer              ‚îÇ
‚îÇ - Outils : sh.status(), scripts custom                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Niveau 4 : Application Performance                       ‚îÇ
‚îÇ - Query latency, error rate, throughput                  ‚îÇ
‚îÇ - Outils : APM (New Relic, DataDog), logs applicatifs    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## M√©triques Essentielles

### 1. M√©triques de Distribution

#### Distribution des Chunks

```javascript
// Script de monitoring de la distribution
function checkChunkDistribution() {
  print("=== Distribution des Chunks ===\n");

  var collections = db.getSiblingDB("config").collections.find({
    dropped: false
  }).toArray();

  collections.forEach(function(coll) {
    if (coll.key) {  // Collection shard√©e
      var distribution = db.getSiblingDB("config").chunks.aggregate([
        { $match: { ns: coll._id } },
        { $group: {
            _id: "$shard",
            numChunks: { $sum: 1 }
          }
        },
        { $sort: { numChunks: -1 } }
      ]).toArray();

      if (distribution.length > 0) {
        var total = distribution.reduce((sum, d) => sum + d.numChunks, 0);
        var max = Math.max(...distribution.map(d => d.numChunks));
        var min = Math.min(...distribution.map(d => d.numChunks));
        var imbalance = ((max - min) / min) * 100;

        print("Collection : " + coll._id);
        print("  Total chunks : " + total);

        distribution.forEach(function(dist) {
          var percent = ((dist.numChunks / total) * 100).toFixed(1);
          print("  " + dist._id + " : " + dist.numChunks + " chunks (" + percent + "%)");
        });

        if (imbalance > 20) {
          print("  ‚ö†Ô∏è  ALERTE : D√©s√©quilibre de " + imbalance.toFixed(1) + "%");
        } else {
          print("  ‚úÖ Distribution √©quilibr√©e (" + imbalance.toFixed(1) + "%)");
        }
        print("");
      }
    }
  });
}

// Ex√©cuter
checkChunkDistribution();
```

**Seuils recommand√©s** :

```javascript
// Indicateurs de sant√© de la distribution
var healthMetrics = {
  balanceThreshold: 20,      // % de d√©s√©quilibre acceptable
  minChunksPerShard: 10,     // Minimum de chunks par shard
  maxJumboChunks: 0,         // Nombre acceptable de jumbo chunks
  migrationSuccessRate: 95   // % de succ√®s des migrations
};
```

#### Jumbo Chunks

```javascript
// D√©tection et analyse des jumbo chunks
function analyzeJumboChunks() {
  print("=== Analyse des Jumbo Chunks ===\n");

  var jumboChunks = db.getSiblingDB("config").chunks.aggregate([
    { $match: { jumbo: true } },
    { $group: {
        _id: "$ns",
        count: { $sum: 1 },
        shards: { $addToSet: "$shard" }
      }
    },
    { $sort: { count: -1 } }
  ]).toArray();

  if (jumboChunks.length === 0) {
    print("‚úÖ Aucun jumbo chunk d√©tect√©\n");
    return;
  }

  print("‚ö†Ô∏è  " + jumboChunks.length + " collection(s) avec jumbo chunks :\n");

  jumboChunks.forEach(function(jc) {
    print("Collection : " + jc._id);
    print("  Nombre : " + jc.count);
    print("  Shards affect√©s : " + jc.shards.join(", "));

    // Analyser la shard key de la collection
    var collInfo = db.getSiblingDB("config").collections.findOne({ _id: jc._id });
    print("  Shard key : " + JSON.stringify(collInfo.key));

    // Recommandations
    print("  Recommandation :");
    print("    1. V√©rifier la cardinalit√© de la shard key");
    print("    2. Consid√©rer refineCollectionShardKey (MongoDB 5.0+)");
    print("    3. Ou forcer migration avec attemptToBalanceJumboChunks");
    print("");
  });
}

// Ex√©cuter
analyzeJumboChunks();
```

### 2. M√©triques du Balancer

#### √âtat et Performance du Balancer

```javascript
// Monitoring complet du balancer
function monitorBalancer() {
  print("=== Monitoring du Balancer ===\n");

  // 1. √âtat global
  var isEnabled = sh.getBalancerState();
  var isRunning = sh.isBalancerRunning();

  print("√âtat :");
  print("  Activ√© : " + isEnabled);
  print("  En cours : " + isRunning);

  // 2. Fen√™tre active
  var balancerConfig = db.getSiblingDB("config").settings.findOne({ _id: "balancer" });

  if (balancerConfig && balancerConfig.activeWindow) {
    print("  Fen√™tre : " + balancerConfig.activeWindow.start + " - " + balancerConfig.activeWindow.stop);
  } else {
    print("  Fen√™tre : Actif 24/7");
  }
  print("");

  // 3. Statistiques (derni√®res 24h)
  var last24h = new Date(Date.now() - 86400000);

  var migrations = db.getSiblingDB("config").changelog.aggregate([
    {
      $match: {
        time: { $gte: last24h },
        what: { $in: ["moveChunk.start", "moveChunk.commit", "moveChunk.error"] }
      }
    },
    {
      $group: {
        _id: "$what",
        count: { $sum: 1 }
      }
    }
  ]).toArray();

  print("Statistiques (24h) :");

  var stats = {
    started: 0,
    committed: 0,
    errors: 0
  };

  migrations.forEach(function(m) {
    if (m._id === "moveChunk.start") stats.started = m.count;
    if (m._id === "moveChunk.commit") stats.committed = m.count;
    if (m._id === "moveChunk.error") stats.errors = m.count;
  });

  print("  Migrations initi√©es : " + stats.started);
  print("  Migrations r√©ussies : " + stats.committed);
  print("  Migrations √©chou√©es : " + stats.errors);

  if (stats.committed > 0) {
    var successRate = ((stats.committed / (stats.committed + stats.errors)) * 100).toFixed(2);
    print("  Taux de succ√®s : " + successRate + "%");

    if (successRate < 95) {
      print("  ‚ö†Ô∏è  ALERTE : Taux de succ√®s faible (< 95%)");
    }
  }
  print("");

  // 4. Dur√©e moyenne des migrations
  var avgDuration = db.getSiblingDB("config").changelog.aggregate([
    {
      $match: {
        what: "moveChunk.commit",
        time: { $gte: last24h }
      }
    },
    {
      $project: {
        duration: {
          $subtract: ["$time", "$details.step1of6"]
        }
      }
    },
    {
      $group: {
        _id: null,
        avgDurationMs: { $avg: "$duration" },
        maxDurationMs: { $max: "$duration" },
        count: { $sum: 1 }
      }
    }
  ]).toArray();

  if (avgDuration.length > 0) {
    var avg = avgDuration[0];
    print("Dur√©e des migrations :");
    print("  Moyenne : " + (avg.avgDurationMs / 1000).toFixed(2) + "s");
    print("  Maximum : " + (avg.maxDurationMs / 1000).toFixed(2) + "s");
    print("  √âchantillon : " + avg.count + " migrations");

    if (avg.avgDurationMs > 60000) {  // > 1 minute
      print("  ‚ö†Ô∏è  ATTENTION : Dur√©e moyenne √©lev√©e (> 1min)");
    }
  }
  print("");

  // 5. Migrations en cours
  var activeMigrations = db.currentOp({
    $or: [
      { op: "command", "command.moveChunk": { $exists: true } },
      { desc: /^migrateThread/ }
    ]
  }).inprog;

  print("Migrations actives : " + activeMigrations.length);

  activeMigrations.forEach(function(mig) {
    print("  Collection : " + mig.ns);
    print("  Dur√©e : " + (mig.microsecs_running / 1000000).toFixed(2) + "s");
    if (mig.progress) {
      var percent = ((mig.progress.done / mig.progress.total) * 100).toFixed(1);
      print("  Progression : " + percent + "%");
    }
    print("");
  });
}

// Ex√©cuter
monitorBalancer();
```

### 3. M√©triques de Performance

#### Latence des Requ√™tes

```javascript
// Analyse des performances par type de requ√™te
function analyzeQueryPerformance() {
  print("=== Analyse des Performances des Requ√™tes ===\n");

  // 1. Requ√™tes lentes en cours
  var slowQueries = db.currentOp({
    "secs_running": { $gte: 3 },
    "op": { $in: ["query", "update", "remove", "command"] }
  }).inprog;

  print("Requ√™tes lentes (>3s) : " + slowQueries.length + "\n");

  if (slowQueries.length > 0) {
    slowQueries.forEach(function(query) {
      print("Namespace : " + query.ns);
      print("Op√©ration : " + query.op);
      print("Dur√©e : " + query.secs_running + "s");

      if (query.command) {
        // D√©terminer si c'est une requ√™te targeted ou broadcast
        var filter = query.command.filter || query.command.query || {};
        print("Filtre : " + JSON.stringify(filter));
      }

      print("");
    });
  }

  // 2. Statistiques du profiler (si activ√©)
  // Activer le profiler : db.setProfilingLevel(1, { slowms: 100 })

  try {
    var profileStats = db.system.profile.aggregate([
      { $match: { ts: { $gte: new Date(Date.now() - 3600000) } } },  // 1h
      {
        $group: {
          _id: "$op",
          count: { $sum: 1 },
          avgDuration: { $avg: "$millis" },
          maxDuration: { $max: "$millis" }
        }
      },
      { $sort: { avgDuration: -1 } }
    ]).toArray();

    if (profileStats.length > 0) {
      print("Statistiques Profiler (1h) :");
      profileStats.forEach(function(stat) {
        print("  " + stat._id + " :");
        print("    Count : " + stat.count);
        print("    Avg : " + stat.avgDuration.toFixed(2) + "ms");
        print("    Max : " + stat.maxDuration.toFixed(2) + "ms");
      });
      print("");
    }
  } catch (e) {
    print("Profiler non activ√© ou non accessible\n");
  }
}

// Ex√©cuter
analyzeQueryPerformance();
```

#### M√©triques par Shard

```javascript
// Collecte de m√©triques d√©taill√©es par shard
function collectShardMetrics() {
  print("=== M√©triques par Shard ===\n");

  var shards = db.getSiblingDB("config").shards.find().toArray();

  shards.forEach(function(shard) {
    print("Shard : " + shard._id);

    try {
      // Connexion au primary du shard
      var shardHost = shard.host.split("/")[1].split(",")[0];
      var shardConn = new Mongo(shardHost);

      // 1. √âtat du replica set
      var rsStatus = shardConn.getDB("admin").adminCommand({ replSetGetStatus: 1 });
      var primary = rsStatus.members.find(m => m.state === 1);
      var secondaries = rsStatus.members.filter(m => m.state === 2);

      print("  Replica Set :");
      print("    Primary : " + primary.name);
      print("    Secondaries : " + secondaries.length);

      // Lag de r√©plication
      if (secondaries.length > 0) {
        var maxLag = 0;
        secondaries.forEach(function(sec) {
          var lag = (primary.optimeDate - sec.optimeDate) / 1000;
          maxLag = Math.max(maxLag, lag);
        });
        print("    Replication lag (max) : " + maxLag.toFixed(2) + "s");

        if (maxLag > 10) {
          print("    ‚ö†Ô∏è  ATTENTION : Lag √©lev√© (> 10s)");
        }
      }

      // 2. Statistiques du serveur
      var serverStatus = shardConn.getDB("admin").serverStatus();

      print("  Performance :");
      print("    Connexions : " + serverStatus.connections.current + "/" + serverStatus.connections.available);
      print("    Ops/sec : ");
      print("      Insert : " + serverStatus.opcounters.insert);
      print("      Query : " + serverStatus.opcounters.query);
      print("      Update : " + serverStatus.opcounters.update);
      print("      Delete : " + serverStatus.opcounters.delete);

      // 3. M√©moire WiredTiger
      var wtMem = serverStatus.wiredTiger.cache;
      var cachePct = ((wtMem["bytes currently in the cache"] / wtMem["maximum bytes configured"]) * 100).toFixed(1);

      print("  M√©moire (WiredTiger Cache) :");
      print("    Taille : " + (wtMem["bytes currently in the cache"] / 1024 / 1024 / 1024).toFixed(2) + " GB");
      print("    Max : " + (wtMem["maximum bytes configured"] / 1024 / 1024 / 1024).toFixed(2) + " GB");
      print("    Utilisation : " + cachePct + "%");

      if (cachePct > 90) {
        print("    ‚ö†Ô∏è  ATTENTION : Cache presque plein (> 90%)");
      }

      // 4. Stockage
      var dbStats = shardConn.getDB("admin").adminCommand({
        listDatabases: 1,
        nameOnly: false
      });

      var totalSize = dbStats.databases.reduce((sum, db) => sum + (db.sizeOnDisk || 0), 0);

      print("  Stockage :");
      print("    Taille totale : " + (totalSize / 1024 / 1024 / 1024).toFixed(2) + " GB");

    } catch (e) {
      print("  ‚ùå Erreur de connexion : " + e.message);
    }

    print("");
  });
}

// Ex√©cuter
collectShardMetrics();
```

### 4. M√©triques des Config Servers

```javascript
// Monitoring sp√©cifique des config servers
function monitorConfigServers() {
  print("=== Monitoring Config Servers ===\n");

  // R√©cup√©rer les config servers depuis la connection string de mongos
  var adminDB = db.getSiblingDB("admin");
  var cmdLineOpts = adminDB.adminCommand({ getCmdLineOpts: 1 });
  var configDBString = cmdLineOpts.parsed.sharding.configDB;

  var configServers = configDBString.split("/")[1].split(",");

  print("Config Servers : " + configServers.length + "\n");

  configServers.forEach(function(cs) {
    print("Config Server : " + cs);

    try {
      var csConn = new Mongo(cs);

      // 1. √âtat du membre
      var isMaster = csConn.getDB("admin").isMaster();
      print("  √âtat : " + (isMaster.ismaster ? "PRIMARY" : isMaster.secondary ? "SECONDARY" : "OTHER"));
      print("  Replica Set : " + isMaster.setName);

      // 2. Statistiques des m√©tadonn√©es
      var configDB = csConn.getDB("config");

      var chunksCount = configDB.chunks.countDocuments({});
      var shardsCount = configDB.shards.countDocuments({});
      var collectionsCount = configDB.collections.countDocuments({ dropped: false });

      print("  M√©tadonn√©es :");
      print("    Chunks : " + chunksCount);
      print("    Shards : " + shardsCount);
      print("    Collections shard√©es : " + collectionsCount);

      // 3. Taille de l'oplog
      var localDB = csConn.getDB("local");
      var oplogStats = localDB.oplog.rs.stats();

      var oplogSizeGB = (oplogStats.maxSize / 1024 / 1024 / 1024).toFixed(2);
      var oplogUsedGB = (oplogStats.size / 1024 / 1024 / 1024).toFixed(2);
      var oplogPct = ((oplogStats.size / oplogStats.maxSize) * 100).toFixed(1);

      print("  Oplog :");
      print("    Taille : " + oplogUsedGB + " GB / " + oplogSizeGB + " GB (" + oplogPct + "%)");

      // Dur√©e couverte par l'oplog
      var firstOplog = localDB.oplog.rs.find().sort({ $natural: 1 }).limit(1).toArray()[0];
      var lastOplog = localDB.oplog.rs.find().sort({ $natural: -1 }).limit(1).toArray()[0];

      if (firstOplog && lastOplog) {
        var oplogDurationHours = ((lastOplog.ts.getTime() - firstOplog.ts.getTime()) / 1000 / 3600).toFixed(1);
        print("    Dur√©e couverte : " + oplogDurationHours + " heures");

        if (oplogDurationHours < 24) {
          print("    ‚ö†Ô∏è  ATTENTION : Oplog couvre moins de 24h");
        }
      }

    } catch (e) {
      print("  ‚ùå Erreur : " + e.message);
    }

    print("");
  });
}

// Ex√©cuter
monitorConfigServers();
```

---

## Outils de Monitoring

### 1. MongoDB Native Tools

#### mongostat

```bash
# Monitoring en temps r√©el via mongos
mongostat --host mongos1.example.com:27017 -u admin -p password --authenticationDatabase admin

# Output :
# insert query update delete getmore command dirty used flushes vsize   res qrw arw net_in net_out conn                time
#   *456   789   *234    12       0   1567  3.4% 80.2%       0  8.3G  4.2G 0|0 1|0  157mb   89mb  128 Dec  8 10:30:15.123

# Colonnes importantes :
# - insert, query, update, delete : Opcounters par seconde
# - command : Commandes par seconde
# - dirty : % de donn√©es modifi√©es en cache
# - used : % d'utilisation du cache WiredTiger
# - qrw : Queue depth (read|write)
# - conn : Nombre de connexions actives
```

#### mongotop

```bash
# Identifier les collections les plus actives
mongotop --host mongos1.example.com:27017 -u admin -p password --authenticationDatabase admin 30

# Output :
#                     ns    total    read    write
# mydb.orders           450ms   120ms    330ms
# mydb.users            230ms   230ms      0ms
# mydb.analytics       1200ms  1200ms      0ms

# Utile pour :
# - Identifier les collections "hot"
# - D√©tecter les patterns d'acc√®s anormaux
# - Valider la distribution de charge
```

### 2. MongoDB Exporter + Prometheus + Grafana

#### Installation de mongodb_exporter

```bash
# Installer mongodb_exporter sur chaque shard et config server

# 1. T√©l√©charger
wget https://github.com/percona/mongodb_exporter/releases/download/v0.40.0/mongodb_exporter-0.40.0.linux-amd64.tar.gz
tar xvzf mongodb_exporter-0.40.0.linux-amd64.tar.gz

# 2. Cr√©er un utilisateur de monitoring
mongosh --host localhost:27018
use admin
db.createUser({
  user: "mongodb_exporter",
  pwd: "SecureExporterPassword",
  roles: [
    { role: "clusterMonitor", db: "admin" },
    { role: "read", db: "local" }
  ]
})

# 3. Configurer le exporter
cat > /etc/systemd/system/mongodb_exporter.service <<EOF
[Unit]
Description=MongoDB Exporter
After=network.target

[Service]
Type=simple
User=mongodb_exporter
Environment="MONGODB_URI=mongodb://mongodb_exporter:SecureExporterPassword@localhost:27018/admin"
ExecStart=/usr/local/bin/mongodb_exporter
Restart=always

[Install]
WantedBy=multi-user.target
EOF

# 4. D√©marrer
sudo systemctl daemon-reload
sudo systemctl start mongodb_exporter
sudo systemctl enable mongodb_exporter

# V√©rifier
curl http://localhost:9216/metrics | grep mongodb_up
# mongodb_up 1
```

#### Configuration Prometheus

```yaml
# /etc/prometheus/prometheus.yml

global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  # Config Servers
  - job_name: 'mongodb-config'
    static_configs:
      - targets:
        - 'cfg1.example.com:9216'
        - 'cfg2.example.com:9216'
        - 'cfg3.example.com:9216'
        labels:
          cluster: 'production'
          component: 'config-server'

  # Mongos
  - job_name: 'mongodb-mongos'
    static_configs:
      - targets:
        - 'mongos1.example.com:9216'
        - 'mongos2.example.com:9216'
        - 'mongos3.example.com:9216'
        labels:
          cluster: 'production'
          component: 'mongos'

  # Shards
  - job_name: 'mongodb-shards'
    static_configs:
      - targets:
        - 'shardA1.example.com:9216'
        - 'shardA2.example.com:9216'
        - 'shardA3.example.com:9216'
        labels:
          cluster: 'production'
          component: 'shard'
          shard: 'shardA'

      - targets:
        - 'shardB1.example.com:9216'
        - 'shardB2.example.com:9216'
        - 'shardB3.example.com:9216'
        labels:
          cluster: 'production'
          component: 'shard'
          shard: 'shardB'
```

#### Requ√™tes PromQL Essentielles

```promql
# 1. Connexions actives (par composant)
mongodb_connections{state="current", component="mongos"}

# 2. Opcounters (taux par seconde)
rate(mongodb_op_counters_total[5m])

# 3. Lag de r√©plication (maximum)
max(mongodb_mongod_replset_member_replication_lag) by (set)

# 4. Utilisation du cache WiredTiger
(mongodb_wiredtiger_cache_bytes{type="total"} / mongodb_wiredtiger_cache_max_bytes) * 100

# 5. Queue depth (lectures + √©critures)
mongodb_mongod_global_lock_current_queue{type="reader"} +
mongodb_mongod_global_lock_current_queue{type="writer"}

# 6. Distribution des chunks (n√©cessite custom exporter)
# Voir section "Custom Exporters" ci-dessous

# 7. Dur√©e moyenne des requ√™tes
rate(mongodb_mongod_op_latencies_latency_total[5m]) /
rate(mongodb_mongod_op_latencies_ops_total[5m])

# 8. Taux d'erreur des commandes
rate(mongodb_mongod_metrics_commands_failed_total[5m]) /
rate(mongodb_mongod_metrics_commands_total[5m]) * 100
```

#### Dashboard Grafana pour Cluster Shard√©

```json
{
  "dashboard": {
    "title": "MongoDB Sharded Cluster Overview",
    "panels": [
      {
        "title": "Cluster Health",
        "targets": [
          {
            "expr": "mongodb_up{component=\"config-server\"}",
            "legendFormat": "Config: {{instance}}"
          },
          {
            "expr": "mongodb_up{component=\"mongos\"}",
            "legendFormat": "Mongos: {{instance}}"
          },
          {
            "expr": "mongodb_up{component=\"shard\"}",
            "legendFormat": "Shard: {{shard}} - {{instance}}"
          }
        ]
      },
      {
        "title": "Operations per Second",
        "targets": [
          {
            "expr": "sum(rate(mongodb_op_counters_total[5m])) by (type)",
            "legendFormat": "{{type}}"
          }
        ]
      },
      {
        "title": "Replication Lag",
        "targets": [
          {
            "expr": "max(mongodb_mongod_replset_member_replication_lag) by (set)",
            "legendFormat": "{{set}}"
          }
        ],
        "thresholds": [
          { "value": 10, "color": "orange" },
          { "value": 30, "color": "red" }
        ]
      },
      {
        "title": "WiredTiger Cache Usage",
        "targets": [
          {
            "expr": "(mongodb_wiredtiger_cache_bytes{type=\"total\"} / mongodb_wiredtiger_cache_max_bytes) * 100",
            "legendFormat": "{{instance}}"
          }
        ]
      },
      {
        "title": "Connections",
        "targets": [
          {
            "expr": "mongodb_connections{state=\"current\"}",
            "legendFormat": "{{instance}} - {{component}}"
          }
        ]
      },
      {
        "title": "Slow Queries (>100ms)",
        "targets": [
          {
            "expr": "rate(mongodb_mongod_metrics_query_executor_total{state=\"scanned\"}[5m])",
            "legendFormat": "{{instance}}"
          }
        ]
      }
    ]
  }
}
```

### 3. Custom Exporters pour M√©triques Sharding

```python
# custom_sharding_exporter.py
# Exporter personnalis√© pour m√©triques de sharding

from prometheus_client import start_http_server, Gauge
from pymongo import MongoClient
import time

# M√©triques Prometheus
chunk_distribution = Gauge('mongodb_chunk_distribution', 'Number of chunks per shard', ['namespace', 'shard'])
jumbo_chunks = Gauge('mongodb_jumbo_chunks', 'Number of jumbo chunks', ['namespace'])
migration_success_rate = Gauge('mongodb_migration_success_rate', 'Migration success rate (24h)', [])
balancer_state = Gauge('mongodb_balancer_state', 'Balancer state (1=enabled, 0=disabled)', [])

def collect_sharding_metrics(mongos_uri):
    client = MongoClient(mongos_uri)
    config_db = client['config']

    # 1. Distribution des chunks
    chunk_dist = config_db.chunks.aggregate([
        {'$group': {
            '_id': {'ns': '$ns', 'shard': '$shard'},
            'count': {'$sum': 1}
        }}
    ])

    for doc in chunk_dist:
        chunk_distribution.labels(
            namespace=doc['_id']['ns'],
            shard=doc['_id']['shard']
        ).set(doc['count'])

    # 2. Jumbo chunks
    jumbo_dist = config_db.chunks.aggregate([
        {'$match': {'jumbo': True}},
        {'$group': {
            '_id': '$ns',
            'count': {'$sum': 1}
        }}
    ])

    for doc in jumbo_dist:
        jumbo_chunks.labels(namespace=doc['_id']).set(doc['count'])

    # 3. Taux de succ√®s des migrations (24h)
    last_24h = time.time() - 86400

    success = config_db.changelog.count_documents({
        'what': 'moveChunk.commit',
        'time': {'$gte': last_24h}
    })

    errors = config_db.changelog.count_documents({
        'what': 'moveChunk.error',
        'time': {'$gte': last_24h}
    })

    if success + errors > 0:
        rate = (success / (success + errors)) * 100
        migration_success_rate.set(rate)

    # 4. √âtat du balancer
    admin_db = client['admin']
    balancer_status = admin_db.command('balancerStatus')
    balancer_state.set(1 if balancer_status['mode'] == 'full' else 0)

if __name__ == '__main__':
    MONGOS_URI = 'mongodb://monitor_user:password@mongos1.example.com:27017/admin'

    # D√©marrer le serveur HTTP pour Prometheus
    start_http_server(9217)

    print("Custom sharding exporter started on port 9217")

    # Boucle de collecte
    while True:
        try:
            collect_sharding_metrics(MONGOS_URI)
        except Exception as e:
            print(f"Error collecting metrics: {e}")

        time.sleep(60)  # Collecter toutes les minutes
```

```bash
# D√©ployer le custom exporter

# 1. Installer d√©pendances
pip3 install prometheus_client pymongo

# 2. Cr√©er un service systemd
cat > /etc/systemd/system/mongodb-sharding-exporter.service <<EOF
[Unit]
Description=MongoDB Sharding Custom Exporter
After=network.target

[Service]
Type=simple
User=prometheus
ExecStart=/usr/bin/python3 /opt/custom_sharding_exporter.py
Restart=always

[Install]
WantedBy=multi-user.target
EOF

# 3. D√©marrer
sudo systemctl daemon-reload
sudo systemctl start mongodb-sharding-exporter
sudo systemctl enable mongodb-sharding-exporter

# 4. Ajouter √† Prometheus
# scrape_configs:
#   - job_name: 'mongodb-sharding-metrics'
#     static_configs:
#       - targets: ['localhost:9217']
```

---

## Alerting : R√®gles Critiques

### Configuration Alertmanager

```yaml
# /etc/alertmanager/alertmanager.yml

route:
  receiver: 'team-database'
  group_by: ['alertname', 'cluster']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h

  routes:
    - match:
        severity: critical
      receiver: 'pagerduty'
      continue: true

    - match:
        severity: warning
      receiver: 'slack'

receivers:
  - name: 'team-database'
    email_configs:
      - to: 'dba-team@example.com'

  - name: 'pagerduty'
    pagerduty_configs:
      - service_key: 'your-pagerduty-key'

  - name: 'slack'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/YOUR/WEBHOOK/URL'
        channel: '#mongodb-alerts'
```

### R√®gles d'Alerte Prometheus

```yaml
# /etc/prometheus/rules/mongodb-sharded.yml

groups:
  - name: mongodb_sharded_cluster
    interval: 30s
    rules:

      # === Alertes Critiques ===

      - alert: ConfigServerDown
        expr: mongodb_up{component="config-server"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Config Server down: {{ $labels.instance }}"
          description: "Config server {{ $labels.instance }} is unreachable. Cluster may become read-only."

      - alert: MajorityConfigServersDown
        expr: count(mongodb_up{component="config-server"} == 0) >= 2
        for: 30s
        labels:
          severity: critical
        annotations:
          summary: "Majority of Config Servers down"
          description: "{{ $value }} config servers are down. Cluster is READ-ONLY!"

      - alert: ShardDown
        expr: mongodb_up{component="shard"} == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Shard node down: {{ $labels.shard }} - {{ $labels.instance }}"
          description: "Shard member {{ $labels.instance }} of {{ $labels.shard }} is down."

      - alert: HighReplicationLag
        expr: mongodb_mongod_replset_member_replication_lag > 30
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High replication lag: {{ $labels.set }}"
          description: "Replication lag on {{ $labels.set }} is {{ $value }}s (threshold: 30s)"

      - alert: MigrationFailureRateHigh
        expr: |
          (
            rate(mongodb_changelog_count{what="moveChunk.error"}[1h]) /
            (rate(mongodb_changelog_count{what="moveChunk.commit"}[1h]) +
             rate(mongodb_changelog_count{what="moveChunk.error"}[1h]))
          ) * 100 > 20
        for: 30m
        labels:
          severity: critical
        annotations:
          summary: "High migration failure rate"
          description: "Migration failure rate is {{ $value }}% (threshold: 20%)"

      # === Alertes Warning ===

      - alert: WiredTigerCacheHighUsage
        expr: |
          (mongodb_wiredtiger_cache_bytes{type="total"} /
           mongodb_wiredtiger_cache_max_bytes) * 100 > 90
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "WiredTiger cache high usage: {{ $labels.instance }}"
          description: "Cache usage is {{ $value }}% on {{ $labels.instance }}"

      - alert: HighConnectionCount
        expr: |
          (mongodb_connections{state="current"} /
           mongodb_connections{state="available"}) * 100 > 80
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "High connection count: {{ $labels.instance }}"
          description: "Connection usage is {{ $value }}% on {{ $labels.instance }}"

      - alert: JumboChunksDetected
        expr: mongodb_jumbo_chunks > 0
        for: 1h
        labels:
          severity: warning
        annotations:
          summary: "Jumbo chunks detected: {{ $labels.namespace }}"
          description: "{{ $value }} jumbo chunks on {{ $labels.namespace }}"

      - alert: ClusterImbalance
        expr: |
          (
            max(mongodb_chunk_distribution) by (namespace) -
            min(mongodb_chunk_distribution) by (namespace)
          ) / min(mongodb_chunk_distribution) by (namespace) * 100 > 30
        for: 4h
        labels:
          severity: warning
        annotations:
          summary: "Cluster imbalance: {{ $labels.namespace }}"
          description: "Chunk distribution imbalance is {{ $value }}%"

      - alert: SlowQueries
        expr: rate(mongodb_mongod_metrics_query_executor_total{state="scanned"}[5m]) > 100
        for: 15m
        labels:
          severity: warning
        annotations:
          summary: "High rate of slow queries: {{ $labels.instance }}"
          description: "{{ $value }} slow queries/sec on {{ $labels.instance }}"

      - alert: LongRunningMigration
        expr: mongodb_current_op_duration_seconds{op="command", command="moveChunk"} > 1800
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Long-running migration detected"
          description: "Migration running for {{ $value }}s (>30min)"
```

---

## Strat√©gies de Maintenance

### 1. Maintenance Planifi√©e : Rolling Restart

```bash
# Proc√©dure de rolling restart sans downtime

# ========================================
# PHASE 1 : Pr√©paration
# ========================================

# 1. Notification
echo "MAINTENANCE : Rolling restart pr√©vu le 2024-01-15 02:00-06:00 UTC"

# 2. D√©sactiver le balancer
mongosh --host mongos1.example.com --eval "sh.stopBalancer()"

# Attendre que les migrations en cours se terminent
while mongosh --host mongos1.example.com --eval "sh.isBalancerRunning()" | grep -q "true"; do
  echo "Attente fin migrations..."
  sleep 10
done

echo "Balancer arr√™t√©, aucune migration en cours"

# 3. Sauvegarde de pr√©caution
./backup-cluster.sh

# ========================================
# PHASE 2 : Restart des Mongos
# ========================================

# Pour chaque mongos (mongos1, mongos2, mongos3)

for MONGOS in mongos1 mongos2 mongos3; do
  echo "Restart de $MONGOS..."

  # Retirer du load balancer (si applicable)
  # aws elb deregister-instances-from-load-balancer --load-balancer-name my-lb --instances $MONGOS

  # Attendre drain des connexions
  sleep 30

  # Restart
  ssh $MONGOS.example.com "sudo systemctl restart mongos"

  # V√©rifier
  sleep 10
  mongosh --host $MONGOS.example.com --eval "db.adminCommand('ping')"

  if [ $? -eq 0 ]; then
    echo "‚úÖ $MONGOS red√©marr√© avec succ√®s"
  else
    echo "‚ùå ERREUR : $MONGOS ne r√©pond pas !"
    exit 1
  fi

  # R√©int√©grer au load balancer
  # aws elb register-instances-with-load-balancer --load-balancer-name my-lb --instances $MONGOS

  sleep 60  # Pause entre chaque mongos
done

# ========================================
# PHASE 3 : Restart des Config Servers
# ========================================

# Ordre : SECONDARIES d'abord, PRIMARY en dernier

for CFG in cfg2 cfg3 cfg1; do
  echo "Restart de $CFG..."

  # V√©rifier le r√¥le
  ROLE=$(mongosh --host $CFG.example.com:27019 --quiet --eval "rs.isMaster().ismaster")

  if [ "$ROLE" == "true" ] && [ "$CFG" != "cfg1" ]; then
    echo "‚ö†Ô∏è  $CFG est PRIMARY, step down..."
    mongosh --host $CFG.example.com:27019 --eval "rs.stepDown(60)"
    sleep 10
  fi

  # Restart
  ssh $CFG.example.com "sudo systemctl restart mongod-configsvr"

  # Attendre r√©int√©gration au replica set
  sleep 30

  # V√©rifier
  mongosh --host $CFG.example.com:27019 --eval "rs.status()"

  if [ $? -eq 0 ]; then
    echo "‚úÖ $CFG red√©marr√© avec succ√®s"
  else
    echo "‚ùå ERREUR : $CFG ne r√©pond pas !"
    exit 1
  fi

  sleep 60
done

# ========================================
# PHASE 4 : Restart des Shards (un √† un)
# ========================================

for SHARD in shardA shardB; do
  echo "Restart du shard $SHARD..."

  # Membres du shard
  MEMBERS=("${SHARD}1" "${SHARD}2" "${SHARD}3")

  # Secondaries d'abord
  for MEMBER in "${MEMBERS[@]}"; do
    echo "  Restart de $MEMBER..."

    ROLE=$(mongosh --host $MEMBER.example.com:27018 --quiet --eval "rs.isMaster().ismaster")

    if [ "$ROLE" == "true" ]; then
      echo "  $MEMBER est PRIMARY, skip pour l'instant"
      PRIMARY=$MEMBER
      continue
    fi

    # Restart secondary
    ssh $MEMBER.example.com "sudo systemctl restart mongod-shard"
    sleep 30

    # V√©rifier r√©int√©gration
    mongosh --host $MEMBER.example.com:27018 --eval "rs.status()"

    if [ $? -eq 0 ]; then
      echo "  ‚úÖ $MEMBER red√©marr√©"
    else
      echo "  ‚ùå ERREUR : $MEMBER ne r√©pond pas !"
      exit 1
    fi

    sleep 30
  done

  # Primary en dernier
  echo "  Restart du PRIMARY : $PRIMARY..."

  # Step down
  mongosh --host $PRIMARY.example.com:27018 --eval "rs.stepDown(60)"
  sleep 15

  # Restart
  ssh $PRIMARY.example.com "sudo systemctl restart mongod-shard"
  sleep 30

  # V√©rifier
  mongosh --host $PRIMARY.example.com:27018 --eval "rs.status()"

  if [ $? -eq 0 ]; then
    echo "  ‚úÖ $PRIMARY red√©marr√©"
  else
    echo "  ‚ùå ERREUR : $PRIMARY ne r√©pond pas !"
    exit 1
  fi

  sleep 60
done

# ========================================
# PHASE 5 : Validation et R√©activation
# ========================================

echo "Validation du cluster..."

# 1. V√©rifier la sant√© globale
mongosh --host mongos1.example.com --eval "sh.status()"

# 2. R√©activer le balancer
mongosh --host mongos1.example.com --eval "sh.startBalancer()"

echo "‚úÖ Rolling restart termin√© avec succ√®s"
echo "Balancer r√©activ√©, cluster op√©rationnel"
```

### 2. Maintenance Non Planifi√©e : Gestion d'Incident

```bash
# Proc√©dure d'urgence : Shard Primary down

# ========================================
# DIAGNOSTIC
# ========================================

# 1. Identifier le probl√®me
mongosh --host mongos1.example.com --eval "sh.status()"

# Output montre :
# shardA: "PRIMARY : UNKNOWN"

# 2. Connexion au replica set du shard
mongosh --host shardA1.example.com:27018 --eval "rs.status()"

# Primary est down, une √©lection devrait avoir lieu

# ========================================
# ACTIONS
# ========================================

# Si √©lection bloqu√©e (pas de majorit√©) :

# Option 1 : Red√©marrer le primary
ssh shardA1.example.com "sudo systemctl start mongod-shard"

# Attendre et v√©rifier
sleep 30
mongosh --host shardA1.example.com:27018 --eval "rs.status()"

# Option 2 : Si hardware HS, forcer √©lection sur secondary
mongosh --host shardA2.example.com:27018

# Reconfig pour retirer le membre HS
cfg = rs.conf()
cfg.members = cfg.members.filter(m => m.host !== "shardA1.example.com:27018")
rs.reconfig(cfg, {force: true})

# Option 3 : Promouvoir un secondary manuellement
mongosh --host shardA2.example.com:27018
rs.stepDown(0)  # Sur le current primary (si accessible)

# Ou forcer la priorit√©
cfg = rs.conf()
cfg.members[1].priority = 10  # shardA2
rs.reconfig(cfg)

# ========================================
# VALIDATION
# ========================================

# V√©rifier que le shard a un primary
mongosh --host mongos1.example.com --eval "sh.status()"

# Tester une op√©ration CRUD sur le shard
mongosh --host mongos1.example.com
use mydb
db.test_collection.insertOne({test: "recovery", timestamp: new Date()})

# Si succ√®s, cluster recovered

# ========================================
# POST-INCIDENT
# ========================================

# 1. Analyser les logs pour comprendre la cause
ssh shardA1.example.com "sudo tail -n 500 /var/log/mongodb/shard.log"

# 2. Documenter l'incident
# - Heure de d√©but
# - Cause identifi√©e
# - Actions prises
# - Dur√©e d'impact
# - Le√ßons apprises

# 3. Am√©liorer le monitoring/alerting
# Ajouter une alerte pour ce sc√©nario sp√©cifique
```

### 3. Maintenance Pr√©ventive : Nettoyage et Optimisation

```javascript
// Script de maintenance pr√©ventive (√† ex√©cuter mensuellement)

function preventiveMaintenance() {
  print("=== MAINTENANCE PR√âVENTIVE ===\n");

  // 1. Nettoyer les collections syst√®me obsol√®tes
  print("1. Nettoyage des logs syst√®me\n");

  // Config changelog (garder 30 jours)
  var cutoffDate = new Date(Date.now() - 30 * 86400000);

  var deletedChangelog = db.getSiblingDB("config").changelog.deleteMany({
    time: { $lt: cutoffDate }
  });

  print("  Entr√©es changelog supprim√©es : " + deletedChangelog.deletedCount);

  // 2. Compacter les collections (si espace disque faible)
  print("\n2. V√©rification de l'espace disque\n");

  var shards = db.getSiblingDB("config").shards.find().toArray();

  shards.forEach(function(shard) {
    try {
      var shardConn = new Mongo(shard.host.split("/")[1].split(",")[0]);
      var dbStats = shardConn.getDB("admin").adminCommand({
        listDatabases: 1,
        nameOnly: false
      });

      dbStats.databases.forEach(function(dbInfo) {
        if (dbInfo.name !== "admin" && dbInfo.name !== "local" && dbInfo.name !== "config") {
          var sizeGB = (dbInfo.sizeOnDisk / 1024 / 1024 / 1024).toFixed(2);
          print("  " + shard._id + " - " + dbInfo.name + " : " + sizeGB + " GB");

          // Si plus de 500 GB, consid√©rer compact
          if (dbInfo.sizeOnDisk > 500 * 1024 * 1024 * 1024) {
            print("    ‚ö†Ô∏è  Consid√©rer compact pour " + dbInfo.name);
          }
        }
      });

    } catch (e) {
      print("  ‚ùå Erreur sur " + shard._id + " : " + e.message);
    }
  });

  // 3. V√©rifier les index inutilis√©s
  print("\n3. Analyse des index inutilis√©s\n");

  var collections = db.getSiblingDB("config").collections.find({
    dropped: false
  }).toArray();

  collections.forEach(function(coll) {
    if (coll.key) {
      print("  Collection : " + coll._id);

      try {
        // Obtenir les stats d'index
        var dbName = coll._id.split(".")[0];
        var collName = coll._id.split(".")[1];

        var indexStats = db.getSiblingDB(dbName)[collName].aggregate([
          { $indexStats: {} }
        ]).toArray();

        indexStats.forEach(function(idx) {
          if (idx.accesses && idx.accesses.ops === 0) {
            print("    ‚ö†Ô∏è  Index inutilis√© : " + idx.name);
            print("       Envisager suppression avec : db." + collName + ".dropIndex(\"" + idx.name + "\")");
          }
        });

      } catch (e) {
        // $indexStats non disponible sur toutes les versions
      }
    }
  });

  // 4. V√©rifier la fragmentation
  print("\n4. V√©rification de la fragmentation\n");

  shards.forEach(function(shard) {
    try {
      var shardConn = new Mongo(shard.host.split("/")[1].split(",")[0]);
      var serverStatus = shardConn.getDB("admin").serverStatus();

      if (serverStatus.wiredTiger && serverStatus.wiredTiger.block) {
        var bytesRead = serverStatus.wiredTiger.block["bytes read"];
        var bytesWritten = serverStatus.wiredTiger.block["bytes written"];

        print("  " + shard._id + " :");
        print("    Bytes lus : " + (bytesRead / 1024 / 1024 / 1024).toFixed(2) + " GB");
        print("    Bytes √©crits : " + (bytesWritten / 1024 / 1024 / 1024).toFixed(2) + " GB");
      }

    } catch (e) {
      print("  ‚ùå Erreur sur " + shard._id);
    }
  });

  // 5. V√©rifier l'√©tat des connexions
  print("\n5. √âtat des connexions\n");

  var mongosConnections = db.serverStatus().connections;
  print("  Mongos :");
  print("    Actives : " + mongosConnections.current);
  print("    Disponibles : " + mongosConnections.available);

  var pct = (mongosConnections.current / (mongosConnections.current + mongosConnections.available) * 100).toFixed(1);
  print("    Utilisation : " + pct + "%");

  if (pct > 80) {
    print("    ‚ö†Ô∏è  ATTENTION : Utilisation √©lev√©e des connexions (> 80%)");
  }

  print("\n=== FIN MAINTENANCE PR√âVENTIVE ===");
}

// Ex√©cuter
preventiveMaintenance();
```

---

## Anti-Patterns de Monitoring et Maintenance

### ‚ùå Anti-Pattern 1 : Monitoring Insuffisant

**Probl√®me** :

```javascript
// Uniquement v√©rifier que les serveurs r√©pondent au ping
// Pas de monitoring des m√©triques MongoDB sp√©cifiques
```

**Cons√©quence** :
- Probl√®mes d√©tect√©s trop tard (apr√®s impact utilisateurs)
- Pas de visibilit√© sur les tendances
- Impossible de faire du capacity planning

**Solution** :

```yaml
# Stack de monitoring compl√®te
monitoring:
  niveau_1_infrastructure:
    - CPU, RAM, Disque, R√©seau
    - Outils: node_exporter, CloudWatch

  niveau_2_mongodb:
    - Opcounters, connections, cache
    - Outils: mongodb_exporter

  niveau_3_sharding:
    - Distribution chunks, migrations
    - Outils: custom exporter

  niveau_4_application:
    - Latence requ√™tes, taux d'erreur
    - Outils: APM (New Relic, DataDog)
```

### ‚ùå Anti-Pattern 2 : Alertes Sans Action

**Probl√®me** :

```yaml
# Des dizaines d'alertes configur√©es
# Mais personne ne les traite
# ‚Üí Alerte fatigue, vraies alertes ignor√©es
```

**Cons√©quence** :
- D√©sensibilisation aux alertes
- Incidents critiques pass√©s inaper√ßus
- Perte de confiance dans le syst√®me d'alerting

**Solution** :

```yaml
# Principe : Chaque alerte doit avoir un runbook

alertes:
  critiques:
    - nom: "ConfigServerDown"
      runbook: "docs/runbooks/config-server-down.md"
      responsable: "√©quipe-dba"
      escalation: "30 minutes ‚Üí manager"

    - nom: "HighReplicationLag"
      runbook: "docs/runbooks/replication-lag.md"
      responsable: "√©quipe-dba"
      escalation: "1 heure ‚Üí CTO"

  warnings:
    - nom: "JumboChunksDetected"
      runbook: "docs/runbooks/jumbo-chunks.md"
      responsable: "√©quipe-dba"
      review: "hebdomadaire"
```

### ‚ùå Anti-Pattern 3 : Maintenance Sans Test

**Probl√®me** :

```bash
# Effectuer une maintenance majeure directement en production
# Sans l'avoir test√©e en staging
# Exemple : Upgrade MongoDB 5.0 ‚Üí 7.0 sans test
```

**Cons√©quence** :
- Incompatibilit√©s d√©couvertes en production
- Rollback complexe
- Downtime prolong√©

**Solution** :

```bash
# Pipeline de test rigoureux

# 1. DEV : Test sur cluster minimal
#    - 1 config server
#    - 1 shard (3 membres)
#    - 1 mongos
#    - R√©sultat : OK

# 2. STAGING : Test sur cluster identique √† prod
#    - Restauration snapshot prod
#    - Upgrade complet
#    - Tests fonctionnels
#    - Tests de charge
#    - R√©sultat : OK, dur√©e estim√©e: 4h

# 3. PRODUCTION : Ex√©cution planifi√©e
#    - Fen√™tre de maintenance: 02:00-06:00
#    - √âquipe compl√®te disponible
#    - Plan de rollback pr√©par√©
```

### ‚ùå Anti-Pattern 4 : Pas de Documentation

**Probl√®me** :

```bash
# Connaissances uniquement dans la t√™te des admins
# Pas de runbooks
# Pas de documentation des incidents pass√©s
```

**Cons√©quence** :
- D√©pendance aux individus (single point of failure humain)
- Onboarding difficile des nouveaux membres
- R√©solution d'incidents plus lente

**Solution** :

```markdown
# Structure de documentation recommand√©e

docs/
‚îú‚îÄ‚îÄ architecture/
‚îÇ   ‚îú‚îÄ‚îÄ cluster-topology.md
‚îÇ   ‚îú‚îÄ‚îÄ shard-key-decisions.md
‚îÇ   ‚îî‚îÄ‚îÄ network-diagram.png
‚îÇ
‚îú‚îÄ‚îÄ runbooks/
‚îÇ   ‚îú‚îÄ‚îÄ config-server-down.md
‚îÇ   ‚îú‚îÄ‚îÄ shard-failover.md
‚îÇ   ‚îú‚îÄ‚îÄ migration-failure.md
‚îÇ   ‚îî‚îÄ‚îÄ balancer-issues.md
‚îÇ
‚îú‚îÄ‚îÄ procedures/
‚îÇ   ‚îú‚îÄ‚îÄ rolling-restart.md
‚îÇ   ‚îú‚îÄ‚îÄ add-shard.md
‚îÇ   ‚îú‚îÄ‚îÄ backup-restore.md
‚îÇ   ‚îî‚îÄ‚îÄ upgrade-cluster.md
‚îÇ
‚îî‚îÄ‚îÄ incidents/
    ‚îú‚îÄ‚îÄ 2024-01-15-replication-lag.md
    ‚îú‚îÄ‚îÄ 2024-02-03-jumbo-chunks.md
    ‚îî‚îÄ‚îÄ template-incident-report.md
```

### ‚ùå Anti-Pattern 5 : Maintenance Pendant les Heures de Pointe

**Probl√®me** :

```bash
# Effectuer un rolling restart √† 14h
# Pendant le pic de charge quotidien
```

**Cons√©quence** :
- D√©gradation de performance visible par les utilisateurs
- Timeout applicatifs
- Exp√©rience utilisateur d√©grad√©e

**Solution** :

```bash
# Fen√™tres de maintenance d√©finies

# Production : 02:00-06:00 UTC (charge minimale)
# Staging : Flexible
# Dev : Flexible

# Exceptions : Incidents critiques uniquement

# Planification :
# - Notification 7 jours avant
# - Fen√™tre de 4 heures
# - √âquipe compl√®te en standby
# - Rollback plan pr√©par√©
```

---

## Checklist de Monitoring

```yaml
checklist_monitoring:

  quotidien:
    - titre: "Sant√© du cluster"
      commande: "sh.status()"
      fr√©quence: "Matin et soir"

    - titre: "Distribution des chunks"
      commande: "checkChunkDistribution()"
      fr√©quence: "Matin"

    - titre: "√âtat du balancer"
      commande: "monitorBalancer()"
      fr√©quence: "Matin"

    - titre: "V√©rification des alertes"
      action: "Review Grafana + Alertmanager"
      fr√©quence: "Matin"

  hebdomadaire:
    - titre: "Analyse des performances"
      action: "Review slow queries logs"
      fr√©quence: "Lundi matin"

    - titre: "Jumbo chunks"
      commande: "analyzeJumboChunks()"
      fr√©quence: "Lundi"

    - titre: "Capacity planning"
      action: "Projection croissance donn√©es"
      fr√©quence: "Lundi"

    - titre: "Review des incidents"
      action: "Analyse incidents de la semaine"
      fr√©quence: "Vendredi"

  mensuel:
    - titre: "Maintenance pr√©ventive"
      commande: "preventiveMaintenance()"
      fr√©quence: "1er du mois"

    - titre: "Test de restauration"
      action: "Restaurer backup en staging"
      fr√©quence: "15 du mois"

    - titre: "Audit s√©curit√©"
      action: "Review users, roles, network"
      fr√©quence: "Dernier vendredi"

    - titre: "Update documentation"
      action: "Mise √† jour runbooks et proc√©dures"
      fr√©quence: "Dernier vendredi"

  trimestriel:
    - titre: "Disaster recovery drill"
      action: "Simulation panne compl√®te"
      fr√©quence: "T1, T2, T3, T4"

    - titre: "Performance benchmark"
      action: "Tests de charge"
      fr√©quence: "T1, T2, T3, T4"
```

---

## Conclusion

Le monitoring et la maintenance d'un cluster shard√© MongoDB sont des activit√©s continues qui n√©cessitent rigueur et proactivit√©. Les points cl√©s √† retenir :

- ‚úÖ **Monitoring multi-niveaux** : Infrastructure, MongoDB, Sharding, Application
- ‚úÖ **Alerting intelligent** : Chaque alerte avec runbook et responsable
- ‚úÖ **Maintenance planifi√©e** : Proc√©dures document√©es et test√©es
- ‚úÖ **R√©activit√© aux incidents** : Diagnostic rapide et actions document√©es
- ‚úÖ **Am√©lioration continue** : Post-mortems et optimisations
- ‚úÖ **Documentation vivante** : Runbooks, proc√©dures, incidents
- ‚úÖ **Tests r√©guliers** : DR drills, restaurations, benchmarks

Un cluster bien monitor√© et maintenu proactivement pr√©sente :
- **Moins d'incidents** gr√¢ce √† la d√©tection pr√©coce
- **R√©solution plus rapide** gr√¢ce aux runbooks
- **Meilleure disponibilit√©** gr√¢ce aux maintenances planifi√©es
- **Performance optimale** gr√¢ce au tuning continu

**Investissez dans le monitoring et la maintenance : c'est la cl√© d'un cluster shard√© fiable en production.**

---

## Ressources

- [MongoDB Monitoring Best Practices](https://docs.mongodb.com/manual/administration/monitoring/)
- [Prometheus MongoDB Exporter](https://github.com/percona/mongodb_exporter)
- [MongoDB Ops Manager](https://www.mongodb.com/products/ops-manager)
- [MongoDB Cloud Manager](https://www.mongodb.com/cloud/cloud-manager)

---


‚è≠Ô∏è [Jumbo Chunks et r√©solution](/10-sharding/11-jumbo-chunks-resolution.md)
