ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 10.2.3 Mongos (Query Routers)

## Introduction

Les instances **mongos** (MongoDB Shard Router) sont les points d'entrÃ©e du cluster shardÃ© pour toutes les applications clientes. Contrairement aux shards et config servers qui stockent des donnÃ©es, mongos est un processus **stateless** (sans Ã©tat) dont le rÃ´le exclusif est de **router intelligemment** les requÃªtes vers les shards appropriÃ©s et d'agrÃ©ger les rÃ©sultats.

Cette section explore en profondeur l'architecture interne des mongos, leurs stratÃ©gies de routage, les mÃ©canismes de cache, et les bonnes pratiques de dÃ©ploiement en production.

## RÃ´le et Positionnement

### Vue d'Ensemble

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          POSITIONNEMENT DE MONGOS                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Couche Application
    â”‚
    â”‚ Connection String:
    â”‚ mongodb://mongos1:27017,mongos2:27017,mongos3:27017
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    MONGOS (Query Router Layer)     â”‚  â† STATELESS
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ Mongos 1 â”‚  â”‚ Mongos 2 â”‚  ...   â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚             â”‚
        â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   â”‚                  â”‚
        â–¼   â–¼                  â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Config    â”‚      â”‚  Shards  â”‚  â† STATEFUL
    â”‚  Servers   â”‚      â”‚  (Data)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ResponsabilitÃ©s Principales

**1. Routage de RequÃªtes**
```javascript
// Application envoie une requÃªte
db.orders.find({ customer_id: 12345 })

// Mongos:
// 1. Parse la requÃªte
// 2. Identifie la shard key (customer_id)
// 3. Consulte metadata cache
// 4. DÃ©termine: Chunk 42 â†’ Shard B
// 5. Route UNIQUEMENT vers Shard B
// 6. Retourne rÃ©sultat Ã  l'application
```

**2. AgrÃ©gation de RÃ©sultats**
```javascript
// RequÃªte sans shard key (scatter-gather)
db.orders.find({ status: "pending" })

// Mongos:
// 1. Broadcast vers TOUS les shards
// 2. ReÃ§oit rÃ©sultats partiels de chaque shard
// 3. MERGE les rÃ©sultats:
//    - Combine les documents
//    - Apply sort global (si nÃ©cessaire)
//    - Apply limit global
// 4. Retourne rÃ©sultat unifiÃ©
```

**3. Gestion des Transactions Multi-Shards**
```javascript
// Transaction touchant plusieurs shards
const session = client.startSession()
session.startTransaction()

try {
  // Write sur Shard A (customer_id: 1000)
  db.orders.insertOne({ customer_id: 1000, ... }, { session })

  // Write sur Shard B (customer_id: 5000)
  db.orders.insertOne({ customer_id: 5000, ... }, { session })

  // Mongos coordonne 2PC (Two-Phase Commit)
  await session.commitTransaction()
} catch(e) {
  await session.abortTransaction()
}
```

**4. Gestion du Balancer**
```javascript
// Le balancer s'exÃ©cute dans un mongos Ã©lu

// Processus:
// 1. Analyse distribution chunks
// 2. Identifie dÃ©sÃ©quilibres
// 3. Initie migrations
// 4. Update metadata
// 5. VÃ©rifie complÃ©tion
```

## Architecture Interne

### Composants d'un Mongos

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              MONGOS INTERNAL ARCHITECTURE           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚     Connection Pool Manager                    â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚ Config Servers Pool                      â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  Connections: 1-10 per config server     â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚ Shards Pool                              â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  Connections: Dynamic (50-1000 per shard)â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  - minPoolSize: 1                        â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  - maxPoolSize: 1000 (configurable)      â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚     Metadata Cache (In-Memory)                 â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚ Database â†’ Primary Shard Map             â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  Size: ~1 KB per database                â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚ Collection â†’ Shard Key Map               â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  Size: ~500 bytes per collection         â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚ Chunk â†’ Shard Mapping (Routing Table)    â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  Size: ~200 bytes per chunk              â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  Example: 100k chunks = 20 MB            â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚                                                â”‚ â”‚
â”‚  â”‚  Cache TTL: 30 seconds (configurable)          â”‚ â”‚
â”‚  â”‚  Refresh: Lazy (on-demand) + background        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚     Query Router & Optimizer                   â”‚ â”‚
â”‚  â”‚  - Parse incoming queries                      â”‚ â”‚
â”‚  â”‚  - Extract shard key if present                â”‚ â”‚
â”‚  â”‚  - Determine target shards (targeted/scatter)  â”‚ â”‚
â”‚  â”‚  - Build execution plan                        â”‚ â”‚
â”‚  â”‚  - Optimize aggregation pipelines              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚     Result Merger & Sorter                     â”‚ â”‚
â”‚  â”‚  - Receive partial results from shards         â”‚ â”‚
â”‚  â”‚  - Streaming merge (if sorted)                 â”‚ â”‚
â”‚  â”‚  - In-memory sort (if unsorted)                â”‚ â”‚
â”‚  â”‚  - Apply global limit/skip                     â”‚ â”‚
â”‚  â”‚  - Cursor management                           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚     Transaction Coordinator (MongoDB 4.2+)     â”‚ â”‚
â”‚  â”‚  - Two-Phase Commit protocol                   â”‚ â”‚
â”‚  â”‚  - Participant tracking                        â”‚ â”‚
â”‚  â”‚  - Abort/commit coordination                   â”‚ â”‚
â”‚  â”‚  - Transaction timeout management              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚     Balancer (if elected as balancer)          â”‚ â”‚
â”‚  â”‚  - Only ONE mongos acts as balancer            â”‚ â”‚
â”‚  â”‚  - Monitors chunk distribution                 â”‚ â”‚
â”‚  â”‚  - Initiates chunk migrations                  â”‚ â”‚
â”‚  â”‚  - Respects balancing windows                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                     â”‚
â”‚  Resource Usage (Typical):                          â”‚
â”‚  - RAM: 256 MB - 2 GB                               â”‚
â”‚  - CPU: 1-4 cores (I/O bound, not CPU intensive)    â”‚
â”‚  - Network: High bandwidth required                 â”‚
â”‚  - Disk: Minimal (logs only, ~10 GB)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Stateless vs Stateful

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MONGOS = STATELESS (Sans Ã‰tat)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  Pas de donnÃ©es persistantes:                      â”‚
â”‚  âœ… Pas de dbPath                                  â”‚
â”‚  âœ… Pas de storage engine                          â”‚
â”‚  âœ… Pas d'oplog                                    â”‚
â”‚  âœ… Pas de rÃ©plication                             â”‚
â”‚                                                    â”‚
â”‚  Tout en mÃ©moire (cache):                          â”‚
â”‚  - Metadata cache (refresh depuis config servers)  â”‚
â”‚  - Connection pools (rebuild au redÃ©marrage)       â”‚
â”‚  - Query execution state (volatile)                â”‚
â”‚                                                    â”‚
â”‚  ConsÃ©quences:                                     â”‚
â”‚  âœ… ArrÃªt/redÃ©marrage sans impact donnÃ©es          â”‚
â”‚  âœ… Scaling horizontal trivial (ajouter instances) â”‚
â”‚  âœ… Aucun backup nÃ©cessaire                        â”‚
â”‚  âœ… Rolling restart sans downtime                  â”‚
â”‚  âŒ Cache perdu au redÃ©marrage (cold start)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Comparaison:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Component â”‚ Stateless â”‚  Data Storageâ”‚ Replication â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Mongos   â”‚    âœ…     â”‚      âŒ      â”‚     âŒ      â”‚
â”‚ Config   â”‚    âŒ     â”‚      âœ…      â”‚     âœ…      â”‚
â”‚ Shard    â”‚    âŒ     â”‚      âœ…      â”‚     âœ…      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## MÃ©canisme de Routage

### Algorithme de Routage de RequÃªtes

```javascript
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ALGORITHME DE ROUTAGE MONGOS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

function routeQuery(query, collection) {
  // Ã‰tape 1: RÃ©cupÃ©rer metadata de la collection
  const metadata = getCollectionMetadata(collection)

  if (!metadata.sharded) {
    // Collection non-shardÃ©e â†’ Primary shard de la DB
    const primaryShard = getDatabasePrimaryShard(collection.db)
    return [primaryShard]  // Un seul shard
  }

  // Ã‰tape 2: Extraire shard key du query
  const shardKey = metadata.key
  const shardKeyValues = extractShardKeyFromQuery(query, shardKey)

  if (shardKeyValues.isComplete()) {
    // Ã‰tape 3a: TARGETED QUERY (shard key complet)
    const chunk = findChunkByShardKey(collection, shardKeyValues)
    return [chunk.shard]  // Un seul shard

  } else if (shardKeyValues.isPartial()) {
    // Ã‰tape 3b: PARTIALLY TARGETED (prÃ©fixe de shard key)
    const chunks = findChunksByPartialKey(collection, shardKeyValues)
    const shards = [...new Set(chunks.map(c => c.shard))]
    return shards  // Quelques shards

  } else {
    // Ã‰tape 3c: SCATTER-GATHER (pas de shard key)
    const allShards = getAllActiveShards()
    return allShards  // TOUS les shards
  }
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// EXEMPLES CONCRETS
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// Collection: orders
// Shard key: { customer_id: 1, order_date: 1 }

// Exemple 1: TARGETED (1 shard)
db.orders.find({
  customer_id: 12345,           // â† shard key complet
  order_date: ISODate("2024-12-08")
})
// â†’ Route vers 1 shard (chunk contenant cette combinaison)

// Exemple 2: PARTIALLY TARGETED (quelques shards)
db.orders.find({
  customer_id: 12345            // â† prÃ©fixe de shard key
})
// â†’ Route vers N shards (tous chunks avec customer_id=12345)
// â†’ Peut Ãªtre 1-N shards selon distribution

// Exemple 3: SCATTER-GATHER (tous shards)
db.orders.find({
  total: { $gt: 1000 }          // â† pas de shard key
})
// â†’ Route vers TOUS les shards
// â†’ Performance: O(N) shards

// Exemple 4: Range query sur shard key
db.orders.find({
  customer_id: { $gte: 10000, $lte: 20000 }
})
// â†’ Route vers shards contenant chunks dans cette plage
// â†’ Peut Ãªtre quelques shards (si range sharding)
```

### Types de RequÃªtes et Performance

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TYPE DE REQUÃŠTE VS PERFORMANCE                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚
â”‚  1. TARGETED QUERY (Optimal)
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     â”‚ Mongos   â”‚
â”‚     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
â”‚          â”‚ Query avec shard key complet
â”‚          â–¼
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     â”‚Shard A  â”‚  â”‚Shard B  â”‚  â”‚Shard C  â”‚
â”‚     â”‚         â”‚  â”‚  âœ“âœ“âœ“âœ“   â”‚  â”‚         â”‚
â”‚     â”‚         â”‚  â”‚ QUERIED â”‚  â”‚         â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â”‚     Latence: ~5-10 ms (1 shard)
â”‚     Throughput: LimitÃ© par 1 shard
â”‚     Network: Minimal
â”‚     âœ… IDÃ‰AL
â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚
â”‚  2. SCATTER-GATHER (Ã€ Ã©viter si possible)
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     â”‚ Mongos   â”‚
â”‚     â””â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”˜
â”‚       â”‚  â”‚  â”‚ Broadcast Ã  tous shards
â”‚       â–¼  â–¼  â–¼
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     â”‚Shard A  â”‚  â”‚Shard B  â”‚  â”‚Shard C  â”‚
â”‚     â”‚  âœ“âœ“âœ“âœ“   â”‚  â”‚  âœ“âœ“âœ“âœ“   â”‚  â”‚  âœ“âœ“âœ“âœ“   â”‚
â”‚     â”‚ QUERIED â”‚  â”‚ QUERIED â”‚  â”‚ QUERIED â”‚
â”‚     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
â”‚          â”‚            â”‚            â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚                       â–¼
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  â”‚ MERGE   â”‚
â”‚                  â”‚ Results â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â”‚     Latence: ~50-200 ms (max des N shards + merge)
â”‚     Throughput: Somme des shards (mais overhead merge)
â”‚     Network: Ã— N shards
â”‚     âš ï¸  ACCEPTABLE si rare
â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚
â”‚  3. AGGREGATION PIPELINE
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     â”‚ Mongos   â”‚
â”‚     â””â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”˜
â”‚       â”‚  â”‚  â”‚ Pipeline distribuÃ©
â”‚       â–¼  â–¼  â–¼
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     â”‚Shard A  â”‚  â”‚Shard B  â”‚  â”‚Shard C  â”‚
â”‚     â”‚ $match  â”‚  â”‚ $match  â”‚  â”‚ $match  â”‚
â”‚     â”‚ $group  â”‚  â”‚ $group  â”‚  â”‚ $group  â”‚
â”‚     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
â”‚          â”‚            â”‚            â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚                       â–¼
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  â”‚ Mongos  â”‚
â”‚                  â”‚ $group  â”‚ â† Merge stage
â”‚                  â”‚ $sort   â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â”‚     Optimisation: Stages pushdown vers shards
â”‚     âœ… Performance peut Ãªtre excellente
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Cache de MÃ©tadonnÃ©es

```javascript
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// GESTION DU CACHE METADATA DANS MONGOS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// Structure du cache (simplifiÃ©)
const metadataCache = {
  databases: {
    "ecommerce": {
      primary: "shard-a-replica-set",
      partitioned: true,
      lastRefresh: ISODate("2024-12-08T10:30:00Z")
    }
  },

  collections: {
    "ecommerce.orders": {
      sharded: true,
      key: { customer_id: 1, order_date: 1 },
      unique: false,
      lastRefresh: ISODate("2024-12-08T10:30:05Z")
    }
  },

  chunks: {
    "ecommerce.orders": [
      {
        min: { customer_id: 0, order_date: MinKey },
        max: { customer_id: 1000, order_date: MaxKey },
        shard: "shard-a-replica-set",
        version: Timestamp(1701456789, 5)
      },
      {
        min: { customer_id: 1000, order_date: MinKey },
        max: { customer_id: 2000, order_date: MaxKey },
        shard: "shard-b-replica-set",
        version: Timestamp(1701456789, 6)
      }
      // ... 100k+ chunks possibles
    ]
  }
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// STRATÃ‰GIES DE REFRESH
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// 1. LAZY REFRESH (on-demand)
// DÃ©clenchÃ© par:
// - Cache miss
// - StaleConfigError (version mismatch)
// - RequÃªte Ã©chouÃ©e

function routeQueryWithLazyRefresh(query) {
  try {
    return routeQuery(query)
  } catch (StaleConfigError) {
    // Metadata obsolÃ¨te dÃ©tectÃ©e
    refreshMetadata(query.collection)
    return routeQuery(query)  // Retry
  }
}

// 2. PERIODIC REFRESH (background)
// Par dÃ©faut: Toutes les 30 secondes

setInterval(() => {
  // Refresh collections "hot" (frÃ©quemment accÃ©dÃ©es)
  const hotCollections = getHotCollections()
  hotCollections.forEach(coll => {
    refreshMetadata(coll)
  })
}, 30000)  // 30 secondes

// 3. PUSH NOTIFICATION (MongoDB 4.4+)
// Config servers notifient mongos des changements

// Ã‰vÃ©nements dÃ©clenchant notification:
// - Split de chunk
// - Migration de chunk
// - addShard / removeShard
// - Changement de shard key (refine)

// Avantages:
// âœ… Latence rÃ©duite (pas d'attente StaleConfigError)
// âœ… Moins de retries

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// CONFIGURATION DU CACHE
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// Pas de paramÃ¨tres configurables directement
// Mais comportement influencÃ© par:

// 1. Nombre de chunks
// - Plus de chunks = cache plus gros
// - 1M chunks â‰ˆ 200 MB de cache

// 2. FrÃ©quence des changements
// - Balancer actif = refreshes frÃ©quents
// - Cluster stable = cache rarement invalidÃ©

// 3. Nombre de collections
// - 1000 collections = ~500 KB metadata
```

## StratÃ©gies de DÃ©ploiement

### Option 1 : Mongos Co-LocalisÃ©s avec Applications

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ARCHITECTURE: MONGOS CO-LOCALISÃ‰S                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  App Server 1    â”‚  â”‚  App Server 2    â”‚  â”‚  App Server N    â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ â”‚ Application â”‚  â”‚  â”‚ â”‚ Application â”‚  â”‚  â”‚ â”‚ Application â”‚  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚        â”‚localhostâ”‚  â”‚        â”‚localhostâ”‚  â”‚        â”‚localhostâ”‚
â”‚        â”‚:27017   â”‚  â”‚        â”‚:27017   â”‚  â”‚        â”‚:27017   â”‚
â”‚        â–¼         â”‚  â”‚        â–¼         â”‚  â”‚        â–¼         â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ â”‚   Mongos    â”‚  â”‚  â”‚ â”‚   Mongos    â”‚  â”‚  â”‚ â”‚   Mongos    â”‚  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                     â”‚                     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚ Network
                               â–¼
                     Config Servers + Shards

Avantages:
âœ… Latence minimale (connexion localhost)
âœ… Pas de hop rÃ©seau supplÃ©mentaire
âœ… Scaling horizontal naturel (mongos scale avec apps)
âœ… Isolation des ressources par app
âœ… SimplicitÃ© de connection string: localhost:27017

InconvÃ©nients:
âŒ Duplication des processus mongos (N instances)
âŒ RAM Ã— N serveurs (~256-512 MB par mongos)
âŒ Gestion dÃ©centralisÃ©e (N processus Ã  monitorer)
âŒ ComplexitÃ© des rolling upgrades

Cas d'usage:
- Applications distribuÃ©es (microservices)
- Containerized deployments (Kubernetes)
- > 10 app servers
- Latence critique (< 1ms required)
```

### Option 2 : Mongos DÃ©diÃ©s Standalone

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ARCHITECTURE: MONGOS DÃ‰DIÃ‰S                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ App Srv 1 â”‚  â”‚ App Srv 2 â”‚  â”‚ App Srv N â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
      â”‚              â”‚              â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ Network (1-5ms)
                     â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚     Load Balancer (HAProxy)  â”‚
      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”˜
           â”‚                      â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚  Mongos 1   â”‚        â”‚  Mongos 2   â”‚
    â”‚  (Dedicated)â”‚        â”‚  (Dedicated)â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â”‚                      â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
            Config Servers + Shards

Avantages:
âœ… Gestion centralisÃ©e (2-3 instances seulement)
âœ… Ressources dÃ©diÃ©es pour routage
âœ… Monitoring simplifiÃ©
âœ… Upgrades plus faciles
âœ… Scaling indÃ©pendant apps/mongos

InconvÃ©nients:
âŒ Latence rÃ©seau supplÃ©mentaire (~1-5ms)
âŒ Infrastructure additionnelle (serveurs mongos)
âŒ Load balancer = SPOF potentiel
âŒ CoÃ»t serveurs dÃ©diÃ©s

Cas d'usage:
- Petite Ã©chelle (< 10 app servers)
- Applications monolithiques
- Besoin de contrÃ´le centralisÃ©
- Budget infrastructure limitÃ©
```

### Option 3 : Hybrid (Mix Co-LocalisÃ©s + DÃ©diÃ©s)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ARCHITECTURE: HYBRID                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Hot Path (critique):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Server 1    â”‚  â”‚  API Server 2    â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ â”‚     API     â”‚  â”‚  â”‚ â”‚     API     â”‚  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚        â”‚localhostâ”‚  â”‚        â”‚localhostâ”‚
â”‚        â–¼         â”‚  â”‚        â–¼         â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ â”‚   Mongos    â”‚  â”‚  â”‚ â”‚   Mongos    â”‚  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
Cold Path (batch, analytics):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  Batch Workers  â”‚   â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚ â”‚   Worker    â”‚ â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
         â”‚ Network    â”‚
         â–¼            â”‚
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
  â”‚ Mongos Pool â”‚     â”‚
  â”‚  (Dedicated)â”‚     â”‚
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â”‚
         â”‚            â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â–º
                                â”‚
                                â–¼
                    Config Servers + Shards

Avantages:
âœ… Meilleur des deux mondes
âœ… Latence optimale pour API
âœ… Ressources dÃ©diÃ©es pour batch

Cas d'usage:
- Workloads mixtes (API + batch)
- > 20 app servers
```

## Configuration et Optimisation

### Fichier de Configuration Mongos

```yaml
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# mongos.conf - Configuration Production
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Network
net:
  port: 27017
  bindIp: 0.0.0.0  # Production: IP spÃ©cifique
  maxIncomingConnections: 65536  # Par dÃ©faut: 65536
  # âš ï¸  Mongos peut gÃ©rer beaucoup de connexions (stateless)

  compression:
    compressors: snappy,zstd,zlib

  # TLS/SSL (Production)
  tls:
    mode: requireTLS
    certificateKeyFile: /etc/ssl/mongos.pem
    CAFile: /etc/ssl/ca.pem
    allowConnectionsWithoutCertificates: false

# Sharding
sharding:
  configDB: configReplSet/configsvr-1:27019,configsvr-2:27019,configsvr-3:27019
  # âš ï¸  CRITIQUE: Connection string vers config servers

# Security
security:
  keyFile: /etc/mongodb-keyfile  # Inter-cluster auth
  clusterAuthMode: keyFile

  # RBAC
  authorization: enabled

# Logging
systemLog:
  destination: file
  path: /var/log/mongodb/mongos.log
  logAppend: true
  logRotate: reopen

  # Verbosity (DEBUG)
  verbosity: 0
  component:
    sharding:
      verbosity: 1  # Augmenter pour debug routage
    network:
      verbosity: 0

# Process Management
processManagement:
  fork: true
  pidFilePath: /var/run/mongodb/mongos.pid

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PARAMÃˆTRES AVANCÃ‰S (via setParameter)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Peut Ãªtre dÃ©fini dans config ou au runtime:
setParameter:
  # Connection Pool vers Shards
  ShardingTaskExecutorPoolMinSize: 1
  ShardingTaskExecutorPoolMaxSize: 1000
  ShardingTaskExecutorPoolMaxConnecting: 2

  # Timeout
  defaultConfigCommandTimeoutMS: 60000  # 60 secondes

  # Transaction
  transactionLifetimeLimitSeconds: 60
  maxTransactionLockRequestTimeoutMillis: 5

  # Balancer
  balancerMigrationsThrottleMs: 100  # Pause entre migrations

  # Metadata refresh
  # (Pas de paramÃ¨tre direct, gestion interne automatique)
```

### Dimensionnement Mongos

```javascript
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// FORMULE DE DIMENSIONNEMENT MONGOS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// Facteurs Ã  considÃ©rer:

// 1. NOMBRE DE CONNEXIONS APPLICATIONS
connexions_apps = nb_app_servers Ã— connexions_par_app

// 2. THROUGHPUT REQUÃŠTES
requetes_sec = charge_totale_ops_sec

// 3. LATENCE CIBLE
latence_p99_ms = SLA_dÃ©fini  // Ex: < 50ms

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// CALCUL NOMBRE DE MONGOS
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

nb_mongos = MAX(
  // Minimum HA
  2,

  // BasÃ© sur connexions (1 mongos par 10k connexions)
  CEIL(connexions_apps / 10000),

  // BasÃ© sur throughput (1 mongos par 100k ops/sec)
  CEIL(requetes_sec / 100000),

  // BasÃ© sur CPU (si CPU-bound, rare)
  CEIL(cpu_utilisÃ© / 0.8)  // 80% max CPU par mongos
)

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// EXEMPLE CONCRET
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// ScÃ©nario:
// - 50 app servers
// - 200 connexions par app = 10,000 connexions totales
// - 150,000 requÃªtes/sec
// - P99 latency target: < 30ms

nb_mongos = MAX(
  2,
  CEIL(10000 / 10000) = 1,
  CEIL(150000 / 100000) = 2,
  CEIL(cpu_utilisÃ© / 0.8)  // Supposons CPU OK
)

nb_mongos = 2

// Recommandation finale: 3 mongos
// (2 minimum calculÃ© + 1 pour tolÃ©rance pannes)

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// RESSOURCES PAR MONGOS
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// RAM par mongos:
ram_mongos_gb = (
  256 MB  // Base
  + metadata_cache_mb
  + (connexions_apps / nb_mongos Ã— 0.01 MB)  // ~10 KB par connexion
  + merge_buffer_mb  // Variable, ~100-500 MB
)

// Exemple avec 10k connexions, 100k chunks:
ram_mongos = 256 MB + 20 MB + (10000 Ã— 0.01) + 200 MB
           = 256 + 20 + 100 + 200
           = 576 MB â‰ˆ 1 GB recommandÃ©

// CPU par mongos:
// GÃ©nÃ©ralement pas CPU-bound
// 2-4 cores suffisants (I/O bound)

// Network:
// CRITIQUE: Mongos est proxy de toutes les donnÃ©es
// 10 Gbps minimum en production haute charge
```

## Connection Pooling

### Gestion des Pools de Connexions

```javascript
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// CONNECTION POOLING DANS MONGOS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// Architecture des pools:
//
// Application (1000 connexions)
//     â†“
// Mongos (1 pool par shard)
//     â”œâ”€â†’ Pool Shard A (50 connexions)
//     â”œâ”€â†’ Pool Shard B (50 connexions)
//     â””â”€â†’ Pool Shard C (50 connexions)

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// CONFIGURATION DES POOLS
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// setParameter (au dÃ©marrage ou runtime)
db.adminCommand({
  setParameter: 1,

  // Taille minimale du pool par shard
  ShardingTaskExecutorPoolMinSize: 1,

  // Taille maximale du pool par shard
  ShardingTaskExecutorPoolMaxSize: 1000,

  // Connexions simultanÃ©es en Ã©tablissement
  ShardingTaskExecutorPoolMaxConnecting: 2,

  // Idle timeout (connexions inactives)
  ShardingTaskExecutorPoolHostTimeoutMS: 300000  // 5 minutes
})

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// CALCUL DU POOL SIZE PAR SHARD
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// Formule empirique:
pool_size_per_shard = MIN(
  // BasÃ© sur throughput
  CEIL(operations_per_sec_to_shard / 100),

  // BasÃ© sur connexions apps
  CEIL(connexions_apps / nb_shards Ã— 0.5),

  // Maximum configurÃ©
  ShardingTaskExecutorPoolMaxSize
)

// Exemple:
// - 10,000 connexions apps
// - 3 shards
// - 50,000 ops/sec total (16,666 ops/sec par shard)

pool_size = MIN(
  CEIL(16666 / 100) = 167,
  CEIL(10000 / 3 Ã— 0.5) = 1667,
  1000
)
= 167 connexions par shard

// Total connexions mongosâ†’shards: 167 Ã— 3 = 501 connexions

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// MONITORING DES POOLS
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// Commande connPoolStats
db.adminCommand({ connPoolStats: 1 })

// Output (exemple):
{
  "numClientConnections": 1000,  // Apps â†’ mongos

  "numAScopedConnections": 0,

  "totalInUse": 150,      // Connexions actives vers shards
  "totalAvailable": 351,  // Connexions idle dans pools
  "totalCreated": 501,    // Total connexions crÃ©Ã©es
  "totalRefreshing": 0,

  "pools": {
    "shard-a-replica-set/mongo-a1:27018,mongo-a2:27018,mongo-a3:27018": {
      "inUse": 50,
      "available": 117,
      "created": 167,
      "refreshing": 0
    },
    "shard-b-replica-set/...": {
      "inUse": 50,
      "available": 117,
      "created": 167,
      "refreshing": 0
    },
    "shard-c-replica-set/...": {
      "inUse": 50,
      "available": 117,
      "created": 167,
      "refreshing": 0
    }
  },

  "hosts": {
    "mongo-a1:27018": {
      "inUse": 17,
      "available": 38,
      "created": 55
    }
    // ... par membre du RS
  }
}

// Alertes Ã  configurer:
// - totalInUse / totalCreated > 0.9 â†’ Pool saturation
// - created > maxPoolSize Ã— nb_shards â†’ Leak potentiel
```

## Anti-Patterns Critiques

### ğŸš« Anti-Pattern 1 : Mongos Unique (SPOF)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âŒ ANTI-PATTERN: 1 seul mongos         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ Toutes les Apps  â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚           â”‚                            â”‚
â”‚           â–¼                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚  Mongos UNIQUE   â”‚  â† SPOF!         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚           â”‚                            â”‚
â”‚           â–¼                            â”‚
â”‚    Config + Shards                     â”‚
â”‚                                        â”‚
â”‚  ProblÃ¨mes:                            â”‚
â”‚  - Si mongos down â†’ TOUT down          â”‚
â”‚  - Bottleneck performance              â”‚
â”‚  - Impossible rolling upgrade          â”‚
â”‚  - Pas de maintenance sans downtime    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Impact Production :**
```
17:30:00 - Mongos crash (OOM, bug, etc.)
17:30:01 - TOUTES les applications perdent connexion
17:30:05 - Alertes flood (500+ apps)
17:31:00 - RedÃ©marrage mongos
17:31:30 - Cold start (cache vide)
17:32:00 - Apps reconnect (thundering herd)
17:35:00 - Service rÃ©tabli

Downtime total: 5 minutes
Impact: 100% des utilisateurs
CoÃ»t: $$$$ (SLA breach)
```

**Solution :**
```
âœ… MINIMUM ABSOLU: 2 mongos
âœ… Production: 3+ mongos
âœ… Connection string avec multiple hosts:
mongodb://mongos1:27017,mongos2:27017,mongos3:27017/db
```

### ğŸš« Anti-Pattern 2 : Ignorer la Latence RÃ©seau

```javascript
// âŒ ANTI-PATTERN: Mongos gÃ©ographiquement distant

// Topologie:
// - Applications: Europe (Paris)
// - Mongos: US-East (Virginie)
// - Shards: Europe (Paris)

// Flux d'une requÃªte:
// App (Paris)
//   â†’ [100ms Atlantic] â†’
// Mongos (Virginie)
//   â†’ [100ms Atlantic] â†’
// Shard (Paris)
//   â†’ [100ms Atlantic] â†’
// Mongos (Virginie)
//   â†’ [100ms Atlantic] â†’
// App (Paris)

// Latence totale: 400ms (4 Ã— 100ms)
// vs
// App â†’ Mongos â†’ Shard (tous Paris): 5ms

// Impact:
// - P99 latency: 500-1000ms (inacceptable)
// - Throughput divisÃ© par 10
// - CoÃ»ts rÃ©seau inter-rÃ©gion Ã©levÃ©s
```

**Solution :**
```
âœ… PATTERN: Mongos proche des applications

Option 1: Mongos co-localisÃ©s (mÃªme DC que apps)
Option 2: Mongos multi-rÃ©gion
  - EU apps â†’ EU mongos â†’ EU shards (zone sharding)
  - US apps â†’ US mongos â†’ US shards
```

### ğŸš« Anti-Pattern 3 : Sur-Provisionnement Mongos

```javascript
// âŒ ANTI-PATTERN: 50 mongos pour 5 app servers

// Configuration inutile:
// - 50 instances mongos
// - 5 app servers (100 connexions chacun = 500 total)

// RÃ©sultat:
// - Mongos: ~10 connexions par instance (sous-utilisÃ©)
// - RAM gaspillÃ©e: 50 Ã— 512 MB = 25 GB
// - ComplexitÃ© monitoring: 50 processus
// - CoÃ»t: $$$ (50 serveurs ou containers)

// RÃ¨gle empirique:
// nb_mongos â‰ˆ nb_app_servers / 5
// (pour apps co-localisÃ©es)

// Exemple:
// - 5 app servers â†’ 1-2 mongos suffisent
// - 50 app servers â†’ 3-5 mongos co-localisÃ©s
```

**Solution :**
```
âœ… PATTERN: Dimensionnement appropriÃ©

Petit dÃ©ploiement (< 10 apps):
  â†’ 2-3 mongos dÃ©diÃ©s

Moyen dÃ©ploiement (10-50 apps):
  â†’ 3-5 mongos (dÃ©diÃ©s ou mix)

Grand dÃ©ploiement (> 50 apps):
  â†’ Mongos co-localisÃ©s + quelques dÃ©diÃ©s
```

### ğŸš« Anti-Pattern 4 : Scatter-Gather SystÃ©matique

```javascript
// âŒ ANTI-PATTERN: Shard key jamais dans les requÃªtes

// Shard key: { customer_id: 1 }

// Mais 90% des requÃªtes:
db.orders.find({ status: "pending" })        // Scatter
db.orders.find({ product_id: "ABC" })        // Scatter
db.orders.find({ created_at: { $gte: ... } })  // Scatter

// Impact sur mongos:
// - Broadcast Ã  tous shards (ex: 10 shards)
// - 10Ã— connexions utilisÃ©es
// - 10Ã— network traffic
// - Merge CPU intensive
// - Latency = max(shard_latencies) + merge_time

// Exemple avec 10 shards:
// - Latence individuelle: 10ms
// - Latence max shard: 50ms (P99)
// - Merge time: 20ms
// â†’ Latence totale: 70ms

// vs requÃªte ciblÃ©e:
// - 1 shard: 10ms
// - Pas de merge: 0ms
// â†’ Latence totale: 10ms

// AmÃ©lioration: 7Ã— plus rapide
```

**Solution :**
```javascript
// âœ… PATTERN: Aligner shard key sur requÃªtes

// Option 1: Changer shard key pour correspondre
sh.shardCollection("orders", { status: 1, customer_id: 1 })

// Option 2: Inclure shard key dans requÃªtes
db.orders.find({
  customer_id: currentUser.id,  // â† shard key
  status: "pending"
})

// Option 3: Index secondaire optimisÃ©
db.orders.createIndex({ status: 1, created_at: 1 })
// Scatter-gather reste, mais accÃ©lÃ©rÃ© par index
```

### ğŸš« Anti-Pattern 5 : NÃ©gliger le Monitoring Mongos

```javascript
// âŒ ANTI-PATTERN: Monitoring uniquement shards/config

// "Mongos est stateless, pas besoin de monitoring"

// FAUX! ProblÃ¨mes silencieux possibles:

// 1. Pool saturation
db.adminCommand({ connPoolStats: 1 })
// "totalInUse" / "totalCreated" = 0.95  // 95% utilisÃ©!
// â†’ Nouvelles requÃªtes attendent connexion disponible
// â†’ Latence augmente

// 2. Cache thrashing
// - Metadata refresh constant (StaleConfigError en boucle)
// - CPU 100% sur metadata parsing
// - Logs flooded: "Refreshing metadata for collection X"

// 3. Memory leak
// - Cursors non-fermÃ©s s'accumulent
// - RAM mongos: 512 MB â†’ 4 GB â†’ 8 GB â†’ OOM crash

// 4. Network saturation
// - Scatter-gather massif
// - Bandwidth mongosâ†’shards saturÃ© (1 Gbps)
// - Packets dropped

// 5. Transaction coordinator overload
// - 1000+ transactions concurrentes
// - 2PC coordination CPU intensive
// - Timeouts en cascade
```

**Solution :**
```javascript
// âœ… PATTERN: Monitoring complet mongos

// MÃ©triques critiques Ã  surveiller:

// 1. Connection pool stats
db.adminCommand({ connPoolStats: 1 })
// Alerter: totalInUse / totalCreated > 0.8

// 2. Server status
db.adminCommand({ serverStatus: 1 })

// MÃ©triques clÃ©s:
// - connections.current / connections.available
// - network.bytesIn / network.bytesOut
// - opcounters (command, query, update, insert, delete)
// - mem.resident (RAM usage)

// 3. Current operations
db.currentOp({ secs_running: { $gte: 5 } })
// Identifier requÃªtes lentes

// 4. Logs
// tail -f /var/log/mongodb/mongos.log | grep -E "StaleConfigError|slow query"

// 5. Custom metrics
// - % requÃªtes targeted vs scatter-gather
// - Latence P50, P95, P99 par type requÃªte
// - Erreur rate
```

## Troubleshooting AvancÃ©

### Diagnostics Communs

```javascript
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// TROUBLESHOOTING MONGOS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// ProblÃ¨me 1: Latence Ã©levÃ©e soudaine
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// SymptÃ´me:
// - P99 latency: 10ms â†’ 500ms
// - Pas d'erreur visible

// Diagnostic:
// 1. VÃ©rifier pool saturation
db.adminCommand({ connPoolStats: 1 })
// Si totalInUse â‰ˆ totalCreated â†’ Pool full

// 2. Identifier requÃªtes lentes
db.currentOp({
  secs_running: { $gte: 1 },
  "$or": [
    { op: "query" },
    { op: "command" }
  ]
}).inprog.forEach(op => {
  print("Op: " + op.op)
  print("NS: " + op.ns)
  print("Running: " + op.secs_running + "s")
  print("Command: " + tojson(op.command))
  print("---")
})

// 3. VÃ©rifier scatter-gather ratio
// (NÃ©cessite monitoring custom, pas de commande native)

// Solution selon la cause:
// - Pool full â†’ Augmenter maxPoolSize
// - Scatter-gather Ã©levÃ© â†’ Optimiser requÃªtes
// - Shard lent â†’ Investiguer shard spÃ©cifique

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// ProblÃ¨me 2: StaleConfigError en boucle
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// SymptÃ´me:
// - Logs mongos flooded: "StaleConfigError"
// - RequÃªtes rÃ©essayÃ©es en permanence
// - CPU mongos: 100%

// Causes possibles:
// 1. Balancer trÃ¨s actif (migrations continues)
// 2. Bug metadata (corruption)
// 3. Network issues config servers â†” mongos

// Diagnostic:
// 1. VÃ©rifier activitÃ© balancer
sh.isBalancerRunning()
db.getSiblingDB("config").changelog.find({
  time: { $gte: ISODate("2024-12-08T10:00:00Z") }
}).count()
// > 100 migrations dans derniÃ¨re heure â†’ Balancer trop actif

// 2. VÃ©rifier latence config servers
// Sur mongos:
db.adminCommand({ ping: 1 })  // Vers config servers
// > 100ms â†’ ProblÃ¨me rÃ©seau

// Solution:
// - Balancer trop actif â†’ Ajuster fenÃªtre ou throttle
// - Network issues â†’ Investiguer infrastructure
// - Corruption metadata â†’ Restore config servers

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// ProblÃ¨me 3: Mongos OOM (Out of Memory)
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// SymptÃ´me:
// - Mongos crash pÃ©riodiquement
// - Logs: "Insufficient memory"
// - RAM mongos: Croissance continue

// Causes frÃ©quentes:
// 1. Cursors non-fermÃ©s (leak)
// 2. Merge buffers trop gros (sort/aggregate massif)
// 3. Metadata cache explosion (1M+ chunks)

// Diagnostic:
// 1. VÃ©rifier cursors ouverts
db.serverStatus().metrics.cursor
// "open.total" > 10,000 â†’ Probable leak

// 2. VÃ©rifier taille metadata cache
// (Pas d'API directe, estimation)
nb_chunks = db.getSiblingDB("config").chunks.count()
estimated_cache_mb = nb_chunks Ã— 0.2 / 1024
// > 500 MB â†’ Cache trÃ¨s gros

// 3. Identifier requÃªtes gourmandes
db.currentOp({
  op: { $in: ["query", "getmore"] }
}).inprog.sort({ "mem": -1 }).limit(10)

// Solution:
// - Cursors: Forcer timeout agressif (cursorTimeoutMillis)
// - Merge: Limiter taille sorts (allowDiskUse sur shards)
// - Cache: Sharding trop granulaire â†’ Augmenter chunk size

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// ProblÃ¨me 4: Connection storm aprÃ¨s restart
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// SymptÃ´me:
// - Mongos restart
// - Toutes apps reconnect simultanÃ©ment (10k connexions)
// - Mongos freeze pendant 30s-1min
// - "Connection timeout" errors

// Cause:
// - Thundering herd problem
// - Pool reconstruction simultanÃ©e
// - Cache metadata vide (cold start)

// Solution:
// - Connection retry avec backoff exponentiel (driver)
// - Staged rollout (restart apps progressivement)
// - Pre-warm cache (script curl API avant mise en prod)

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// ProblÃ¨me 5: Transaction timeout
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// SymptÃ´me:
// - TransactionExceededTimeLimit errors
// - Transactions abort aprÃ¨s 60s

// Diagnostic:
db.serverStatus().transactions
// - "currentActive" > 100 â†’ Beaucoup de txns actives
// - "totalAborted" croissant â†’ Aborts frÃ©quents

// Causes:
// 1. Transaction trop longue (lock contention)
// 2. Timeout trop court
// 3. Network latency (multi-shard txn)

// Solution:
db.adminCommand({
  setParameter: 1,
  transactionLifetimeLimitSeconds: 120  // Augmenter Ã  120s
})

// Ou: Optimiser transactions (moins d'opÃ©rations)
```

## Monitoring et MÃ©triques

### MÃ©triques Essentielles

```javascript
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// DASHBOARD MONITORING MONGOS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// 1. CONNEXIONS
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

db.serverStatus().connections
// {
//   "current": 1000,      // Connexions apps actuelles
//   "available": 64536,   // Disponibles (max - current)
//   "totalCreated": 5000, // Total crÃ©Ã© depuis dÃ©marrage
//   "active": 150         // Actuellement en exÃ©cution
// }

// MÃ©triques Ã  grapher:
// - current (gauge)
// - current / (current + available) ratio (%)

// Alertes:
// - current / max > 0.8 â†’ Pool saturation imminent
// - active / current > 0.5 â†’ Beaucoup d'opÃ©rations actives

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// 2. OPÃ‰RATIONS
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

db.serverStatus().opcounters
// {
//   "insert": 50000,
//   "query": 1000000,
//   "update": 30000,
//   "delete": 5000,
//   "getmore": 20000,
//   "command": 500000
// }

// DÃ©river pour obtenir ops/sec:
// (valeur_actuelle - valeur_prÃ©cÃ©dente) / intervalle_secondes

// MÃ©triques Ã  grapher:
// - query/sec
// - insert/sec
// - update/sec
// - command/sec (total)

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// 3. LATENCE (P50, P95, P99)
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// MongoDB 4.4+: Latence par type opÃ©ration
db.serverStatus().opLatencies
// {
//   "reads": {
//     "latency": 123456789,  // Microseconds total
//     "ops": 1000000,
//     "hist": [ ... ]  // Histogram
//   },
//   "writes": { ... },
//   "commands": { ... }
// }

// Calcul latence moyenne:
// latency_avg_ms = (latency_micros / ops) / 1000

// Pour P99, utiliser histogram ou APM driver-side

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// 4. RÃ‰SEAU
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

db.serverStatus().network
// {
//   "bytesIn": 5368709120,      // 5 GB reÃ§u
//   "bytesOut": 10737418240,    // 10 GB envoyÃ©
//   "numRequests": 1000000
// }

// DÃ©river pour bandwidth:
// (bytesIn_now - bytesIn_prev) / intervalle = bytes/sec

// MÃ©triques Ã  grapher:
// - Network In (MB/sec)
// - Network Out (MB/sec)
// - Ratio Out/In (mongos envoie souvent 2-5Ã— ce qu'il reÃ§oit)

// Alertes:
// - Bandwidth > 80% de la carte rÃ©seau (ex: 8 Gbps sur 10 Gbps)

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// 5. MÃ‰MOIRE
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

db.serverStatus().mem
// {
//   "bits": 64,
//   "resident": 512,   // RAM utilisÃ©e (MB)
//   "virtual": 1024,   // Virtual memory (MB)
//   "supported": true
// }

// MÃ©triques Ã  grapher:
// - resident (gauge, MB)

// Alertes:
// - resident > 80% de RAM allouÃ©e
// - Croissance continue (leak potentiel)

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// 6. POOL DE CONNEXIONS (vers shards)
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

db.adminCommand({ connPoolStats: 1 })

// MÃ©triques par shard:
// - totalInUse / totalCreated ratio (%)
// - created (gauge)

// Alertes:
// - Ratio > 0.9 â†’ Pool proche saturation
// - created > maxPoolSize Ã— nb_shards â†’ Anormal
```

## RÃ©sumÃ©

Les **mongos** sont les routeurs intelligents du cluster shardÃ© :

**RÃ´le :**
- Point d'entrÃ©e unique pour applications
- Routage intelligent (targeted vs scatter-gather)
- AgrÃ©gation des rÃ©sultats multi-shards
- Coordination des transactions distribuÃ©es

**Architecture :**
- Processus stateless (sans stockage)
- Cache metadata en mÃ©moire (refresh 30s)
- Connection pools vers shards
- LÃ©ger (256 MB - 2 GB RAM typique)

**DÃ©ploiement :**
- Minimum : 2 mongos (HA)
- Production : 3+ mongos
- Options : Co-localisÃ©s / DÃ©diÃ©s / Hybrid

**Anti-patterns critiques :**
- âŒ Mongos unique (SPOF)
- âŒ Latence rÃ©seau ignorÃ©e
- âŒ Sur-provisionnement
- âŒ Scatter-gather systÃ©matique
- âŒ Monitoring nÃ©gligÃ©

**Optimisations :**
- Dimensionnement appropriÃ© (formule)
- Pool sizing adaptÃ© au workload
- ProximitÃ© gÃ©ographique apps
- Monitoring proactif

**MÃ©triques essentielles :**
- Connexions (current/max ratio)
- Ops/sec par type
- Latence P99
- Pool saturation
- RAM usage

Les mongos, bien que stateless et lÃ©gers, sont critiques pour les performances et la disponibilitÃ© du cluster. Leur bon dimensionnement et monitoring sont essentiels.

---


â­ï¸ [Shard Key : Choix et stratÃ©gies](/10-sharding/03-shard-key-choix-strategies.md)
