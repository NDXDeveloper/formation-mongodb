ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 12.12 Bonnes Pratiques

## Introduction

Les bonnes pratiques de sauvegarde et restauration ne sont pas simplement une liste de recommandations techniques - elles constituent le **fondement mÃªme de la continuitÃ© d'activitÃ©** d'une organisation. Une stratÃ©gie de backup mal conÃ§ue ou mal exÃ©cutÃ©e peut conduire Ã  des pertes de donnÃ©es catastrophiques, des interruptions prolongÃ©es et, dans les cas extrÃªmes, Ã  la fermeture d'une entreprise.

Cette section synthÃ©tise les enseignements des chapitres prÃ©cÃ©dents en un ensemble cohÃ©rent de principes, procÃ©dures et recommandations Ã©prouvÃ©es pour garantir la rÃ©silience de vos donnÃ©es MongoDB dans tous les scÃ©narios possibles.

## Principes Fondamentaux

### La RÃ¨gle 3-2-1-1-0

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              RÃ¨gle 3-2-1-1-0 de Backup                       â”‚
â”‚                                                              â”‚
â”‚  3ï¸âƒ£  TROIS copies de vos donnÃ©es                             â”‚
â”‚     â€¢ Original (production)                                  â”‚
â”‚     â€¢ Backup local                                           â”‚
â”‚     â€¢ Backup distant                                         â”‚
â”‚                                                              â”‚
â”‚  2ï¸âƒ£  DEUX types de mÃ©dia diffÃ©rents                          â”‚
â”‚     â€¢ Disk (SSD/HDD local)                                   â”‚
â”‚     â€¢ Cloud/Tape/Remote storage                              â”‚
â”‚                                                              â”‚
â”‚  1ï¸âƒ£  UNE copie off-site (hors site)                          â”‚
â”‚     â€¢ Protection contre sinistres locaux                     â”‚
â”‚     â€¢ RÃ©gion cloud diffÃ©rente                                â”‚
â”‚     â€¢ Data center gÃ©ographiquement distant                   â”‚
â”‚                                                              â”‚
â”‚  1ï¸âƒ£  UNE copie offline/immutable                             â”‚
â”‚     â€¢ Protection contre ransomware                           â”‚
â”‚     â€¢ S3 Object Lock / Azure Immutable Blob                  â”‚
â”‚     â€¢ Air-gapped storage                                     â”‚
â”‚                                                              â”‚
â”‚  0ï¸âƒ£  ZÃ‰RO erreur de restauration                             â”‚
â”‚     â€¢ Tests rÃ©guliers obligatoires                           â”‚
â”‚     â€¢ Validation automatisÃ©e                                 â”‚
â”‚     â€¢ ProcÃ©dures documentÃ©es et testÃ©es                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Architecture de RÃ©fÃ©rence

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Architecture de Backup ComplÃ¨te                   â”‚
â”‚                                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              PRODUCTION (Site Primaire)                    â”‚    â”‚
â”‚  â”‚                                                            â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  â”‚  MongoDB Replica Set                                 â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ Primary + 2 Secondaries                           â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ Oplog: 72h minimum                                â”‚  â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â”‚                          â”‚                                 â”‚    â”‚
â”‚  â”‚                          v                                 â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  â”‚  Backup Local (mÃªme DC)                              â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ Full backup: quotidien 2h                         â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ Snapshot: toutes les 6h                           â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ Oplog streaming: continu                          â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ RÃ©tention: 7 jours                                â”‚  â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â”‚                                        â”‚
â”‚                           v                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚           BACKUP DISTANT (RÃ©gion diffÃ©rente)               â”‚    â”‚
â”‚  â”‚                                                            â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  â”‚  Object Storage (S3/Azure/GCS)                       â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ RÃ©plication: quotidienne                          â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ Encryption: AES-256                               â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ Versioning: enabled                               â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ RÃ©tention GFS: 7j/4w/6m/7y                        â”‚  â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â”‚                          â”‚                                 â”‚    â”‚
â”‚  â”‚                          v                                 â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  â”‚  Immutable Storage                                   â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ S3 Object Lock / Glacier                          â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ Write-Once-Read-Many (WORM)                       â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ Protection ransomware                             â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ RÃ©tention lÃ©gale: selon compliance                â”‚  â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â”‚                                        â”‚
â”‚                           v                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              DISASTER RECOVERY SITE                        â”‚    â”‚
â”‚  â”‚                                                            â”‚    â”‚
â”‚  â”‚  â€¢ Standby cluster (warm/hot)                              â”‚    â”‚
â”‚  â”‚  â€¢ Continuous replication                                  â”‚    â”‚
â”‚  â”‚  â€¢ Automatic/Manual failover                               â”‚    â”‚
â”‚  â”‚  â€¢ RTO: < 1h, RPO: < 15min                                 â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## StratÃ©gie par Environnement

### Development / Testing

```yaml
Environnement: Development / Testing
CriticitÃ©: Faible
RPO: 24 heures
RTO: 4-8 heures

Configuration Backup:
  mÃ©thode: mongodump
  frÃ©quence: quotidien
  rÃ©tention: 7 jours
  stockage: local uniquement
  compression: gzip
  chiffrement: non requis

Oplog:
  taille: 5-10 GB
  fenÃªtre: 24 heures

Tests:
  frÃ©quence: mensuel
  type: basique
  automatisation: optionnel

CoÃ»t estimÃ©: $50-200/mois

Justification:
  - DonnÃ©es non critiques
  - Facilement recrÃ©ables
  - Focus sur rapiditÃ© de setup
  - CoÃ»t minimal

ImplÃ©mentation:
  ```bash
  # Cron simple
  0 2 * * * mongodump --uri=mongodb://localhost:27017 \
    --out=/backup/dev/$(date +\%Y\%m\%d) --gzip

  # Cleanup 7 jours
  find /backup/dev -type d -mtime +7 -exec rm -rf {} \;
  ```
```

### Staging / Pre-Production

```yaml
Environnement: Staging / Pre-Production
CriticitÃ©: Moyenne
RPO: 6 heures
RTO: 2-4 heures

Configuration Backup:
  mÃ©thode: mongodump + snapshots
  frÃ©quence:
    - Full: quotidien
    - Snapshot: toutes les 6h
  rÃ©tention:
    - Daily: 14 jours
    - Weekly: 4 semaines
  stockage: local + cloud
  compression: gzip
  chiffrement: recommandÃ© (AES-256)

Oplog:
  taille: 20-50 GB
  fenÃªtre: 48 heures
  export_continu: recommandÃ©

Tests:
  frÃ©quence: hebdomadaire
  type: standard
  automatisation: obligatoire

Monitoring:
  - Alertes sur Ã©chec
  - Dashboard basique
  - MÃ©triques rÃ©tention

CoÃ»t estimÃ©: $200-500/mois

Justification:
  - Environnement de validation
  - Tests prÃ©-production
  - DonnÃ©es similaires Ã  production
  - Besoin de restauration rapide

ImplÃ©mentation:
  - Systemd timers
  - Upload S3 automatique
  - Rotation GFS basique
  - Notifications Slack
```

### Production Standard

```yaml
Environnement: Production Standard
CriticitÃ©: Ã‰levÃ©e
RPO: 1 heure
RTO: 1-2 heures

Configuration Backup:
  mÃ©thode: mongodump + snapshots + oplog streaming
  frÃ©quence:
    - Full: quotidien 2h
    - Snapshot: toutes les 4h
    - Oplog: continu
  rÃ©tention:
    - Hourly: 24 heures
    - Daily: 7 jours
    - Weekly: 4 semaines
    - Monthly: 6 mois
  stockage: local + cloud multi-rÃ©gion
  compression: zstd (meilleur ratio)
  chiffrement: AES-256 (obligatoire)

Oplog:
  taille: 100-200 GB
  fenÃªtre: 72 heures minimum
  export_continu: obligatoire

PITR:
  activÃ©: true
  fenÃªtre: 48 heures

Tests:
  frÃ©quence:
    - Basique: hebdomadaire (automatisÃ©)
    - Standard: mensuel (automatisÃ©)
    - Complet: trimestriel
    - PITR: mensuel
  validation: complÃ¨te
  documentation: obligatoire

Monitoring:
  - Alertes temps rÃ©el
  - Dashboard Grafana
  - MÃ©triques complÃ¨tes
  - SLA tracking
  - PagerDuty intÃ©gration

DR:
  site_secondaire: warm standby
  rÃ©plication: continue
  failover: manuel (< 1h)
  tests: semestriels

CoÃ»t estimÃ©: $1,000-3,000/mois

Justification:
  - DonnÃ©es business critiques
  - Impact financier modÃ©rÃ©
  - SLA client standard
  - Compliance de base

ImplÃ©mentation ClÃ©:
  - Kubernetes CronJobs
  - Automation complÃ¨te
  - Multi-rÃ©gion S3
  - ImmutabilitÃ© partielle
  - Tests automatisÃ©s
```

### Production Critique / Mission-Critical

```yaml
Environnement: Production Mission-Critical
CriticitÃ©: Critique
RPO: 15 minutes ou moins
RTO: 30 minutes ou moins

Configuration Backup:
  mÃ©thode:
    - Continuous replication (DR site)
    - Snapshots (hourly)
    - mongodump (daily)
    - Oplog streaming (real-time)
  frÃ©quence:
    - Snapshot: horaire
    - Full: quotidien
    - Oplog: temps rÃ©el
  rÃ©tention:
    - Hourly: 48 heures
    - Daily: 30 jours
    - Weekly: 12 semaines
    - Monthly: 12 mois
    - Yearly: 7 ans
  stockage:
    - Local: triple rÃ©pliquÃ©
    - Cloud: multi-rÃ©gion (3+)
    - Air-gapped: mensuel
  compression: zstd niveau 9
  chiffrement: AES-256 + HSM

Oplog:
  taille: 500+ GB
  fenÃªtre: 168 heures (7 jours)
  export_continu: obligatoire redondant

PITR:
  activÃ©: true
  fenÃªtre: 7 jours
  prÃ©cision: seconde

Tests:
  frÃ©quence:
    - Basique: quotidien (automatisÃ©)
    - Standard: hebdomadaire (automatisÃ©)
    - Complet: mensuel
    - PITR: hebdomadaire
    - DR drill: trimestriel
  validation: exhaustive
  documentation: obligatoire + audit trail

Monitoring:
  - Alertes temps rÃ©el multi-canal
  - Dashboard 24/7
  - MÃ©triques prÃ©dictives
  - Anomaly detection
  - War room protocol

DR:
  site_secondaire: hot standby (actif)
  rÃ©plication: synchrone/quasi-synchrone
  failover: automatique (< 30min)
  tests: mensuels
  multi_region: 3+ rÃ©gions

SÃ©curitÃ©:
  - Chiffrement bout-en-bout
  - RBAC strict
  - Audit complet
  - ImmutabilitÃ© obligatoire
  - Air-gap backups
  - Ransomware protection

Compliance:
  - SOC 2 Type II
  - ISO 27001
  - GDPR / HIPAA si applicable
  - Retention lÃ©gale
  - Audit trail complet

CoÃ»t estimÃ©: $5,000-20,000+/mois

Justification:
  - DonnÃ©es mission-critical
  - Impact financier majeur (>$10k/heure)
  - SLA client strict (99.99%+)
  - Compliance rÃ©glementaire
  - RÃ©putation entreprise

ImplÃ©mentation ClÃ©:
  - MongoDB Atlas (recommandÃ©) ou
  - Ops Manager + DR complet
  - GitOps pour IaC
  - Chaos engineering
  - Automation maximale
  - Ã‰quipe dÃ©diÃ©e 24/7
```

## SÃ©curitÃ© des Backups

### Chiffrement

```bash
#!/bin/bash
# encryption_best_practices.sh

# ============================================================================
# CHIFFREMENT AT-REST
# ============================================================================

# MÃ©thode 1: Chiffrement avec GPG (simple)
backup_with_gpg() {
  local backup_file=$1
  local recipient="backup@company.com"

  # Compression puis chiffrement
  tar -czf - "$backup_file" | \
    gpg --encrypt --recipient "$recipient" \
    > "${backup_file}.tar.gz.gpg"

  # VÃ©rification
  gpg --list-packets "${backup_file}.tar.gz.gpg" >/dev/null 2>&1

  echo "âœ“ Backup encrypted with GPG"
}

# MÃ©thode 2: Chiffrement avec OpenSSL (sans clÃ© publique)
backup_with_openssl() {
  local backup_file=$1
  local password_file="/etc/mongodb-backup/encryption.key"

  # GÃ©nÃ©rer clÃ© si n'existe pas
  if [ ! -f "$password_file" ]; then
    openssl rand -base64 32 > "$password_file"
    chmod 600 "$password_file"
  fi

  # Compression et chiffrement AES-256-CBC
  tar -czf - "$backup_file" | \
    openssl enc -aes-256-cbc -salt \
    -pass file:"$password_file" \
    -out "${backup_file}.tar.gz.enc"

  # Checksum
  sha256sum "${backup_file}.tar.gz.enc" > "${backup_file}.tar.gz.enc.sha256"

  echo "âœ“ Backup encrypted with OpenSSL AES-256"
}

# MÃ©thode 3: AWS S3 avec KMS (recommandÃ© cloud)
backup_to_s3_encrypted() {
  local backup_file=$1
  local s3_bucket="s3://company-backups"
  local kms_key="arn:aws:kms:us-east-1:123456789:key/abc-def-123"

  # Upload avec chiffrement cÃ´tÃ© serveur via KMS
  aws s3 cp "$backup_file" "$s3_bucket/" \
    --sse aws:kms \
    --sse-kms-key-id "$kms_key" \
    --storage-class STANDARD_IA

  echo "âœ“ Backup uploaded to S3 with KMS encryption"
}

# MÃ©thode 4: Chiffrement MongoDB natif (WiredTiger)
enable_mongodb_encryption() {
  # Note: NÃ©cessite MongoDB Enterprise

  cat > /etc/mongod-encryption.conf <<'EOF'
security:
  enableEncryption: true
  encryptionKeyFile: /etc/mongodb/encryption-key
  encryptionCipherMode: AES256-CBC

# GÃ©nÃ©rer la clÃ© (une seule fois)
# openssl rand -base64 32 > /etc/mongodb/encryption-key
# chmod 600 /etc/mongodb/encryption-key
# chown mongodb:mongodb /etc/mongodb/encryption-key
EOF

  echo "âœ“ MongoDB encryption-at-rest configured"
  echo "âš ï¸  Restart MongoDB to apply changes"
}
```

### ContrÃ´le d'AccÃ¨s

```yaml
# Matrice RBAC pour les Backups

RÃ´le: backup-operator (quotidien)
  permissions:
    - ExÃ©cuter backups automatisÃ©s
    - Lire configurations backup
    - Ã‰crire dans rÃ©pertoire backup local
    - Upload vers stockage distant
  restrictions:
    - Pas d'accÃ¨s restauration
    - Pas de suppression backups
    - Pas de modification rÃ©tention

RÃ´le: backup-validator (tests)
  permissions:
    - backup-operator permissions +
    - Lire backups
    - CrÃ©er instances de test
    - ExÃ©cuter tests restauration
    - Ã‰crire rapports de test
  restrictions:
    - Pas d'accÃ¨s production
    - Pas de suppression backups

RÃ´le: restore-operator (incidents)
  permissions:
    - backup-validator permissions +
    - Restaurer vers production
    - Modifier configurations restauration
  restrictions:
    - NÃ©cessite approbation manager
    - Actions auditÃ©es
    - MFA obligatoire

RÃ´le: backup-admin
  permissions:
    - Toutes permissions backup/restore
    - Modifier politiques rÃ©tention
    - Supprimer backups (avec justification)
    - AccÃ¨s air-gap backups
  restrictions:
    - Actions auditÃ©es
    - MFA obligatoire
    - Require 2-person rule pour suppressions

ImplÃ©mentation MongoDB:
  ```javascript
  // CrÃ©er les rÃ´les
  use admin

  // Backup Operator
  db.createRole({
    role: "backupOperator",
    privileges: [
      { resource: { cluster: true }, actions: ["listDatabases"] },
      { resource: { db: "", collection: "" }, actions: ["find"] }
    ],
    roles: []
  });

  // Restore Operator
  db.createRole({
    role: "restoreOperator",
    privileges: [
      { resource: { cluster: true }, actions: ["listDatabases"] },
      { resource: { db: "", collection: "" }, actions: ["insert", "createIndex"] }
    ],
    roles: ["backupOperator"]
  });

  // CrÃ©er utilisateurs
  db.createUser({
    user: "backup-bot",
    pwd: "SecurePassword",
    roles: ["backupOperator"]
  });
  ```
```

### Protection Ransomware

```bash
#!/bin/bash
# ransomware_protection.sh

# ============================================================================
# STRATÃ‰GIE DE PROTECTION CONTRE RANSOMWARE
# ============================================================================

# 1. ImmutabilitÃ© S3 Object Lock
configure_s3_immutability() {
  local bucket="company-backups"

  # Activer versioning (prÃ©requis)
  aws s3api put-bucket-versioning \
    --bucket "$bucket" \
    --versioning-configuration Status=Enabled

  # Activer Object Lock (compliance mode)
  aws s3api put-object-lock-configuration \
    --bucket "$bucket" \
    --object-lock-configuration '{
      "ObjectLockEnabled": "Enabled",
      "Rule": {
        "DefaultRetention": {
          "Mode": "COMPLIANCE",
          "Days": 90
        }
      }
    }'

  echo "âœ“ S3 Object Lock configured (90 days retention)"
  echo "âš ï¸  Objects cannot be deleted even by root for 90 days"
}

# 2. Azure Immutable Blob Storage
configure_azure_immutability() {
  local resource_group="backups-rg"
  local storage_account="companybackups"
  local container="mongodb-backups"

  # CrÃ©er policy d'immutabilitÃ©
  az storage container immutability-policy create \
    --account-name "$storage_account" \
    --container-name "$container" \
    --period 90 \
    --resource-group "$resource_group"

  # Verrouiller la policy
  az storage container immutability-policy lock \
    --account-name "$storage_account" \
    --container-name "$container" \
    --resource-group "$resource_group"

  echo "âœ“ Azure Immutable Blob configured"
}

# 3. Air-Gap Backups
setup_air_gap_backup() {
  local source_backup=$1
  local air_gap_mount="/mnt/air-gap"

  # VÃ©rifier que le mÃ©dia air-gap est montÃ©
  if ! mountpoint -q "$air_gap_mount"; then
    echo "âœ— Air-gap storage not mounted"
    return 1
  fi

  # Copier avec vÃ©rification
  rsync -av --checksum "$source_backup" "$air_gap_mount/"

  # CrÃ©er manifeste
  find "$air_gap_mount" -type f -exec sha256sum {} \; > \
    "$air_gap_mount/CHECKSUMS_$(date +%Y%m%d).txt"

  # CrÃ©er read-only snapshot (si ZFS/Btrfs)
  # zfs snapshot tank/air-gap@$(date +%Y%m%d)

  echo "âœ“ Air-gap backup completed"
  echo "âš ï¸  Unmount and physically disconnect storage"
}

# 4. DÃ©tection d'anomalies
detect_backup_anomalies() {
  local backup_dir="/backup/mongodb"
  local alert_threshold=50  # % de variation

  # Obtenir taille actuelle
  local current_size=$(du -sb "$backup_dir/latest" | cut -f1)

  # Obtenir taille prÃ©cÃ©dente
  local previous_size=$(cat "$backup_dir/.last_size" 2>/dev/null || echo "$current_size")

  # Calculer variation
  local variation=$(echo "scale=2; ($current_size - $previous_size) / $previous_size * 100" | bc)

  # Alerter si variation anormale
  if (( $(echo "$variation > $alert_threshold || $variation < -$alert_threshold" | bc -l) )); then
    echo "ğŸš¨ ANOMALY DETECTED: Backup size variation: ${variation}%"
    echo "  Previous: $(numfmt --to=iec-i --suffix=B $previous_size)"
    echo "  Current: $(numfmt --to=iec-i --suffix=B $current_size)"

    # Notifier Ã©quipe sÃ©curitÃ©
    alert_security_team "Backup size anomaly detected: ${variation}%"

    return 1
  fi

  # Sauvegarder la taille pour prochaine comparaison
  echo "$current_size" > "$backup_dir/.last_size"

  echo "âœ“ Backup size within normal range (${variation}%)"
}

# 5. Backup Segregation (network isolation)
configure_backup_network_isolation() {
  # RÃ©seau dÃ©diÃ© aux backups avec rÃ¨gles strictes

  cat > /etc/nftables/backup-isolation.nft <<'EOF'
# Backup Network Isolation Rules

table inet backup_isolation {
  chain input {
    type filter hook input priority 0; policy drop;

    # Autoriser uniquement backup node
    ip saddr 10.0.backup.0/24 tcp dport 27017 accept

    # SSH admin uniquement
    ip saddr 10.0.admin.0/24 tcp dport 22 accept

    # Drop tout le reste
    log prefix "BACKUP_BLOCKED: " drop
  }

  chain output {
    type filter hook output priority 0; policy accept;

    # Autoriser seulement vers stockage backup
    ip daddr 10.0.storage.0/24 accept

    # Bloquer accÃ¨s Internet (sauf backup cloud)
    # ip daddr backup-cloud.com accept
  }
}
EOF

  nft -f /etc/nftables/backup-isolation.nft

  echo "âœ“ Backup network isolation configured"
}
```

## Gestion du Cycle de Vie

### Politique de RÃ©tention GFS

```python
#!/usr/bin/env python3
# gfs_retention_manager.py

"""
Grandfather-Father-Son (GFS) Retention Policy Manager
"""

import os
import datetime
import json
from pathlib import Path
from typing import List, Dict
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class GFSRetentionManager:
    """Gestionnaire de rÃ©tention GFS pour backups MongoDB"""

    def __init__(self, backup_root: str, config: Dict):
        self.backup_root = Path(backup_root)
        self.config = config

        # Politique par dÃ©faut (jours)
        self.retention = {
            'hourly': config.get('hourly', 24),
            'daily': config.get('daily', 7),
            'weekly': config.get('weekly', 28),
            'monthly': config.get('monthly', 180),
            'yearly': config.get('yearly', 2555)
        }

    def classify_backup(self, backup_path: Path) -> str:
        """Classifier un backup selon GFS"""

        # Extraire timestamp du nom
        # Format: backup_YYYYMMDD_HHMMSS
        try:
            timestamp_str = backup_path.name.split('_')[1] + backup_path.name.split('_')[2]
            timestamp = datetime.datetime.strptime(timestamp_str, '%Y%m%d%H%M%S')
        except (IndexError, ValueError):
            return 'unknown'

        now = datetime.datetime.now()
        age_hours = (now - timestamp).total_seconds() / 3600

        # Classification
        if age_hours <= self.retention['hourly']:
            return 'hourly'
        elif timestamp.hour == 2:  # Backup quotidien Ã  2h
            age_days = (now - timestamp).days

            if age_days <= self.retention['daily']:
                return 'daily'
            elif timestamp.weekday() == 6:  # Dimanche
                age_weeks = age_days / 7

                if age_weeks <= (self.retention['weekly'] / 7):
                    return 'weekly'
                elif timestamp.day == 1:  # Premier du mois
                    age_months = (now.year - timestamp.year) * 12 + (now.month - timestamp.month)

                    if age_months <= (self.retention['monthly'] / 30):
                        return 'monthly'
                    elif timestamp.month == 1 and timestamp.day == 1:  # 1er janvier
                        return 'yearly'

        return 'expired'

    def apply_retention(self, dry_run: bool = False) -> Dict:
        """Appliquer la politique de rÃ©tention"""

        stats = {
            'hourly': 0,
            'daily': 0,
            'weekly': 0,
            'monthly': 0,
            'yearly': 0,
            'expired': 0,
            'deleted': 0
        }

        logger.info("=== Applying GFS Retention Policy ===")
        logger.info(f"Backup root: {self.backup_root}")
        logger.info(f"Dry run: {dry_run}")

        # Scanner tous les backups
        for backup_path in sorted(self.backup_root.glob('backup_*')):
            if not backup_path.is_dir():
                continue

            classification = self.classify_backup(backup_path)
            stats[classification] += 1

            logger.debug(f"{backup_path.name}: {classification}")

            # Supprimer si expirÃ©
            if classification == 'expired':
                if dry_run:
                    logger.info(f"[DRY-RUN] Would delete: {backup_path}")
                else:
                    logger.info(f"Deleting expired backup: {backup_path}")
                    # shutil.rmtree(backup_path)
                    stats['deleted'] += 1

        # Rapport
        logger.info("")
        logger.info("=== Retention Summary ===")
        for category, count in stats.items():
            if category != 'deleted':
                logger.info(f"  {category.capitalize()}: {count} backup(s)")

        if not dry_run:
            logger.info(f"  Deleted: {stats['deleted']} backup(s)")

        return stats

    def promote_backups(self):
        """Promouvoir les backups selon GFS"""

        logger.info("=== Promoting Backups ===")

        now = datetime.datetime.now()

        # Promouvoir vers weekly (dimanche)
        if now.weekday() == 6:
            latest = self._get_latest_backup('daily')
            if latest:
                weekly_link = latest.parent / f"{latest.name}_weekly_{now.strftime('%Y%W')}"
                weekly_link.symlink_to(latest.name)
                logger.info(f"âœ“ Promoted to weekly: {weekly_link.name}")

        # Promouvoir vers monthly (1er du mois)
        if now.day == 1:
            latest = self._get_latest_backup('weekly')
            if latest:
                monthly_link = latest.parent / f"{latest.name}_monthly_{now.strftime('%Y%m')}"
                monthly_link.symlink_to(latest.name)
                logger.info(f"âœ“ Promoted to monthly: {monthly_link.name}")

        # Promouvoir vers yearly (1er janvier)
        if now.month == 1 and now.day == 1:
            latest = self._get_latest_backup('monthly')
            if latest:
                yearly_link = latest.parent / f"{latest.name}_yearly_{now.year}"
                yearly_link.symlink_to(latest.name)
                logger.info(f"âœ“ Promoted to yearly: {yearly_link.name}")

    def _get_latest_backup(self, category: str) -> Path:
        """Obtenir le dernier backup d'une catÃ©gorie"""

        backups = [
            p for p in self.backup_root.glob('backup_*')
            if self.classify_backup(p) == category
        ]

        return max(backups, key=lambda p: p.stat().st_mtime) if backups else None

    def generate_report(self, output_file: str = None):
        """GÃ©nÃ©rer rapport de rÃ©tention"""

        stats = {
            'timestamp': datetime.datetime.now().isoformat(),
            'policy': self.retention,
            'backups': {}
        }

        for backup_path in sorted(self.backup_root.glob('backup_*')):
            if not backup_path.is_dir():
                continue

            classification = self.classify_backup(backup_path)
            size = sum(f.stat().st_size for f in backup_path.rglob('*') if f.is_file())

            stats['backups'][backup_path.name] = {
                'classification': classification,
                'size_bytes': size,
                'modified': backup_path.stat().st_mtime
            }

        if output_file:
            with open(output_file, 'w') as f:
                json.dump(stats, f, indent=2)
            logger.info(f"âœ“ Report saved to: {output_file}")

        return stats


if __name__ == '__main__':
    # Configuration
    config = {
        'hourly': 24,      # 24 heures
        'daily': 7,        # 7 jours
        'weekly': 28,      # 4 semaines
        'monthly': 180,    # 6 mois
        'yearly': 2555     # 7 ans
    }

    manager = GFSRetentionManager('/backup/mongodb', config)

    # Dry run
    manager.apply_retention(dry_run=True)

    # Promouvoir
    manager.promote_backups()

    # Rapport
    manager.generate_report('/backup/mongodb/retention_report.json')
```

## Documentation Obligatoire

### Runbook de Restauration

```markdown
# MongoDB Restoration Runbook

## Document Information

**Version:** 2.1.0
**Last Updated:** 2024-12-08
**Owner:** Database Team
**Reviewers:** DevOps, Security, Management
**Next Review:** 2025-03-08

## Purpose

This runbook provides step-by-step procedures for restoring MongoDB databases
in various disaster scenarios.

## Prerequisites

- [ ] Access to backup storage (credentials in 1Password vault "DB-Backups")
- [ ] SSH access to production servers (bastion host required)
- [ ] MongoDB credentials (stored in AWS Secrets Manager)
- [ ] Approval from manager (for production restores)
- [ ] Communication channel open (#incident-response Slack)

## Scenarios

### Scenario 1: Complete Database Loss

**RTO:** 2 hours
**RPO:** 1 hour (latest backup)

**Detection:**
- MongoDB cluster completely unavailable
- All replica set members down
- Data directory corrupted/lost

**Procedure:**

1. **Assess & Communicate** (5 minutes)
   ```bash
   # Verify cluster is truly down
   mongo mongodb://primary:27017 --eval "db.adminCommand('ping')"

   # Alert stakeholders
   python3 /scripts/alert_incident.py --severity=critical \
     --title="MongoDB Complete Outage" \
     --channel="#incidents"
   ```

2. **Identify Latest Valid Backup** (10 minutes)
   ```bash
   # List recent backups
   aws s3 ls s3://company-backups/prod/mongodb/ --recursive | tail -20

   # Download manifest of latest
   aws s3 cp s3://company-backups/prod/mongodb/latest/MANIFEST.json /tmp/

   # Verify integrity
   jq . /tmp/MANIFEST.json
   ```

3. **Provision Infrastructure** (30 minutes)
   ```bash
   # If infrastructure lost, provision new cluster
   cd /infrastructure/mongodb-prod
   terraform apply -var="restore_mode=true"
   ```

4. **Download Backup** (20 minutes)
   ```bash
   # Download to restoration server
   aws s3 sync s3://company-backups/prod/mongodb/20241208_020000 \
     /restore/backup --no-progress

   # Verify checksums
   cd /restore/backup
   sha256sum -c SHA256SUMS
   ```

5. **Restore Data** (45 minutes)
   ```bash
   # Stop MongoDB if running
   systemctl stop mongod

   # Clean data directory
   rm -rf /var/lib/mongodb/*

   # Restore
   mongorestore \
     --uri="mongodb://localhost:27017" \
     --drop \
     --oplogReplay \
     --gzip \
     --numParallelCollections=8 \
     --dir=/restore/backup

   # Start MongoDB
   systemctl start mongod
   ```

6. **Validate** (15 minutes)
   ```bash
   # Run validation script
   /scripts/validate_restore.sh

   # Check key metrics
   mongo mongodb://localhost:27017 --eval "
     db.adminCommand({ listDatabases: 1 }).databases.forEach(printjson);
   "
   ```

7. **Reconnect Application** (5 minutes)
   ```bash
   # Update application configuration
   kubectl set env deployment/app MONGO_URI="mongodb://restored-cluster"

   # Monitor errors
   kubectl logs -f deployment/app
   ```

8. **Post-Restore** (ongoing)
   - Monitor database performance
   - Validate data integrity with business team
   - Document incident and lessons learned
   - Update runbook if procedures changed

### Scenario 2: Accidental Data Deletion

[Detailed procedure similar to above]

### Scenario 3: Ransomware Attack

[Detailed procedure similar to above]

## Contacts

**Primary On-Call:** +1-555-0100 (PagerDuty)
**Database Team Lead:** john.doe@company.com
**Security Team:** security@company.com
**Management (Critical):** cto@company.com

## Tools & Access

- Backup Storage: AWS S3 (us-east-1, us-west-2, eu-west-1)
- Credentials: 1Password vault "DB-Backups"
- Monitoring: https://grafana.company.com/mongodb
- Incident Channel: #incident-response
- Documentation: https://wiki.company.com/mongodb

## Post-Incident

- [ ] Complete incident report
- [ ] Update runbook with learnings
- [ ] Review backup strategy
- [ ] Test restore procedures
- [ ] Conduct post-mortem
```

## Checklists OpÃ©rationnelles

### Checklist Quotidienne

```markdown
# MongoDB Backup - Daily Checklist

Date: ___________
Operator: ___________

## Morning (9:00 AM)

- [ ] Verify last night's backup completed successfully
      Log: /var/log/mongodb-backup/latest.log
      Expected completion: 02:30 AM Â± 15 min

- [ ] Check backup size is within expected range
      Previous: _______ GB
      Current: _______ GB
      Variation: _______ % (alert if > Â±30%)

- [ ] Verify upload to S3 completed
      Command: aws s3 ls s3://company-backups/prod/mongodb/ | tail -1

- [ ] Review monitoring dashboard
      URL: https://grafana.company.com/mongodb-backups
      All metrics green: YES / NO

- [ ] Check disk space on backup servers
      Backup server 1: _______ % used (alert if > 80%)
      Backup server 2: _______ % used (alert if > 80%)

## Issues Found

_______________________________________________________________________
_______________________________________________________________________

## Actions Taken

_______________________________________________________________________
_______________________________________________________________________

## Escalations

_______________________________________________________________________
_______________________________________________________________________

Signature: ___________________
```

### Checklist Hebdomadaire

```markdown
# MongoDB Backup - Weekly Checklist

Week of: ___________
Operator: ___________

## Sunday Evening

- [ ] Weekly full backup completed
- [ ] Backup promoted to "weekly" tier (GFS)
- [ ] Test restore executed automatically
      Result: PASS / FAIL
      Log: /var/log/mongodb-restore-tests/latest.log

- [ ] Review test restore results
      Databases restored: _______ (expected: _______)
      Collections restored: _______ (expected: _______)
      Validation errors: _______ (expected: 0)

- [ ] Review backup retention
      Daily backups: _______ (expected: 7)
      Weekly backups: _______ (expected: 4)
      Monthly backups: _______ (expected: varies)

- [ ] Check oplog window
      Current window: _______ hours
      Target: â‰¥ 72 hours
      Status: OK / WARNING / CRITICAL

- [ ] Review backup failures log
      Failures this week: _______
      Root causes identified: YES / NO

- [ ] Update documentation if procedures changed
      Changes made: _______________________________________

## Actions Required

_______________________________________________________________________
_______________________________________________________________________
```

## MÃ©triques et KPIs

### Dashboard de MÃ©triques

```yaml
MongoDB Backup & Restore - Key Performance Indicators

MÃ©triques de DisponibilitÃ©:
  backup_success_rate:
    calcul: "successful_backups / total_backups * 100"
    target: "> 99%"
    alerte: "< 95%"

  restore_test_success_rate:
    calcul: "successful_restore_tests / total_tests * 100"
    target: "100%"
    alerte: "< 100%"

  backup_window_compliance:
    description: "Backups complÃ©tÃ©s dans fenÃªtre planifiÃ©e"
    target: "> 95%"
    alerte: "< 90%"

MÃ©triques de Performance:
  backup_duration:
    description: "DurÃ©e moyenne backup full"
    target: "< 2 heures"
    alerte: "> 3 heures"

  restore_duration:
    description: "DurÃ©e restauration (RTO rÃ©el)"
    target: "< objectif RTO"
    alerte: "> objectif RTO"

  backup_size_growth:
    description: "Croissance mensuelle taille backups"
    target: "< 20% par mois"
    alerte: "> 30% par mois"

MÃ©triques de Couverture:
  oplog_window:
    description: "FenÃªtre temporelle oplog"
    target: "> 72 heures"
    alerte: "< 48 heures"

  pitr_capability:
    description: "FenÃªtre PITR disponible"
    target: "> 48 heures"
    alerte: "< 24 heures"

  backup_coverage:
    description: "% donnÃ©es couvertes par backup"
    target: "100%"
    alerte: "< 100%"

MÃ©triques de CoÃ»t:
  cost_per_gb:
    description: "CoÃ»t par GB stockÃ©"
    target: "< $0.03/GB/mois"
    monitoring: "mensuel"

  total_storage_cost:
    description: "CoÃ»t total stockage backups"
    budget: "[selon environment]"
    monitoring: "mensuel"

MÃ©triques de QualitÃ©:
  validation_errors:
    description: "Erreurs validation backups"
    target: "0"
    alerte: "> 0"

  data_loss_incidents:
    description: "Incidents perte de donnÃ©es"
    target: "0"
    monitoring: "continu"

  mttr_restore:
    description: "Mean Time To Restore"
    target: "< RTO"
    monitoring: "par incident"
```

## Erreurs Communes Ã  Ã‰viter

### Top 10 des Erreurs Critiques

```markdown
# Top 10 MongoDB Backup Mistakes (& Solutions)

## 1. âŒ Backups Jamais TestÃ©s
**SymptÃ´me:** Backups rÃ©guliers mais aucun test de restauration
**Impact:** DÃ©couverte que les backups sont inutilisables lors d'un incident rÃ©el
**Solution:**
- Tests automatisÃ©s hebdomadaires minimum
- DR drills trimestriels
- Documentation des rÃ©sultats

## 2. âŒ Oplog DimensionnÃ© Insuffisamment
**SymptÃ´me:** FenÃªtre oplog < 24 heures
**Impact:** PITR impossible, pertes de donnÃ©es
**Solution:**
```bash
# Calculer taille nÃ©cessaire
use local
db.oplog.rs.stats().maxSize / 1024 / 1024 / 1024  # GB

# Redimensionner
db.adminCommand({ replSetResizeOplog: 1, size: 204800 })  # 200 GB
```

## 3. âŒ Backup Sans --oplog
**SymptÃ´me:** mongodump sans option --oplog
**Impact:** Backups inconsistants, PITR impossible
**Solution:**
```bash
# Toujours inclure --oplog
mongodump --uri="..." --oplog --out=/backup
```

## 4. âŒ Tous les Backups Au MÃªme Endroit
**SymptÃ´me:** Backups uniquement locaux ou dans une seule rÃ©gion
**Impact:** Perte complÃ¨te lors d'un sinistre du data center
**Solution:**
- RÃ¨gle 3-2-1-1-0
- Multi-rÃ©gion obligatoire
- Air-gap pour donnÃ©es critiques

## 5. âŒ Pas de Chiffrement
**SymptÃ´me:** Backups en clair
**Impact:** Violation GDPR, fuite de donnÃ©es
**Solution:**
```bash
# Chiffrement systÃ©matique
tar -czf - /backup | openssl enc -aes-256-cbc -out backup.enc
```

## 6. âŒ Credentials en Dur dans Scripts
**SymptÃ´me:** Mots de passe en clair dans scripts
**Impact:** SÃ©curitÃ© compromise
**Solution:**
- Variables d'environnement
- Secrets managers (AWS Secrets Manager, Vault)
- Fichiers credentials avec permissions 600

## 7. âŒ Pas de Monitoring des Backups
**SymptÃ´me:** Ã‰checs de backup non dÃ©tectÃ©s
**Impact:** DÃ©couverte tardive, perte de donnÃ©es
**Solution:**
- Alertes temps rÃ©el
- Dashboard dÃ©diÃ©
- PagerDuty pour production

## 8. âŒ Ignorer les Sharded Clusters
**SymptÃ´me:** Backup de shards sans coordination
**Impact:** IncohÃ©rence entre shards
**Solution:**
- ArrÃªter balancer
- Backup coordonnÃ© de config + tous shards
- Documenter topologie

## 9. âŒ Pas de Rotation/Retention
**SymptÃ´me:** Backups s'accumulent infiniment
**Impact:** CoÃ»ts explosifs, disque plein
**Solution:**
- Politique GFS claire
- Automation de la rotation
- Monitoring de l'utilisation

## 10. âŒ Documentation ObsolÃ¨te
**SymptÃ´me:** ProcÃ©dures non Ã  jour
**Impact:** Confusion lors d'incident, RTO dÃ©passÃ©
**Solution:**
- Mise Ã  jour aprÃ¨s chaque changement
- Review mensuelle
- Versioning des runbooks
```

## Matrice de DÃ©cision

### Choisir sa StratÃ©gie de Backup

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Arbre de DÃ©cision - StratÃ©gie de Backup               â”‚
â”‚                                                               â”‚
â”‚  Quelle est la criticitÃ© de vos donnÃ©es?                      â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Faible     â”‚   â”‚   Moyenne    â”‚   â”‚   Critique        â”‚  â”‚
â”‚  â”‚  (Dev/Test)  â”‚   â”‚  (Prod Std)  â”‚   â”‚ (Mission-Critical)â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                  â”‚                    â”‚             â”‚
â”‚         v                  v                    v             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ mongodump    â”‚   â”‚ mongodump +  â”‚   â”‚ Atlas / Ops Mgr + â”‚  â”‚
â”‚  â”‚ quotidien    â”‚   â”‚ snapshots +  â”‚   â”‚ Continuous Backup â”‚  â”‚
â”‚  â”‚ local        â”‚   â”‚ oplog stream â”‚   â”‚ + Multi-rÃ©gion    â”‚  â”‚
â”‚  â”‚              â”‚   â”‚ S3           â”‚   â”‚ + Immutable       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                               â”‚
â”‚  Quel est votre RTO acceptable?                               â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   > 4h       â”‚   â”‚  1-4h        â”‚   â”‚   < 1h            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                  â”‚                    â”‚             â”‚
â”‚         v                  v                    v             â”‚
â”‚  Daily backups      Hourly snapshots     Hot standby + PITR   â”‚
â”‚  Test restore       + PITR window        + Automated failover â”‚
â”‚  monthly            Test restore          Test restore weekly â”‚
â”‚                     weekly                                    â”‚
â”‚                                                               â”‚
â”‚  Quel est votre budget?                                       â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  < $500/m    â”‚   â”‚ $500-3k/m    â”‚   â”‚   > $3k/m         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                  â”‚                    â”‚             â”‚
â”‚         v                  v                    v             â”‚
â”‚  Self-managed       Self-managed        MongoDB Atlas         â”‚
â”‚  Basic automation   Full automation     Fully managed         â”‚
â”‚  Local + S3         Multi-rÃ©gion        Enterprise support    â”‚
â”‚                     Monitoring                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ConformitÃ© et Audit

### Checklist de ConformitÃ©

```yaml
GDPR Compliance (Europe):
  - [ ] DonnÃ©es personnelles chiffrÃ©es at-rest et in-transit
  - [ ] AccÃ¨s aux backups auditÃ© et tracÃ©
  - [ ] CapacitÃ© de suppression (droit Ã  l'oubli)
  - [ ] RÃ©tention max 7 ans (sauf obligation lÃ©gale)
  - [ ] Transferts hors UE documentÃ©s et conformes
  - [ ] DPO informÃ© de la stratÃ©gie backup
  - [ ] Incident response plan documentÃ©

HIPAA Compliance (US Healthcare):
  - [ ] Chiffrement AES-256 minimum
  - [ ] AccÃ¨s restreint (minimum necessary)
  - [ ] Audit trail complet (tous accÃ¨s tracÃ©s)
  - [ ] Backups testÃ©s annuellement minimum
  - [ ] BAA (Business Associate Agreement) avec providers
  - [ ] Integrity controls (checksums)
  - [ ] Disaster recovery plan testÃ©

SOC 2 Type II:
  - [ ] Politiques backup documentÃ©es
  - [ ] Tests de restauration rÃ©guliers
  - [ ] Monitoring et alerting actifs
  - [ ] Gestion des changements documentÃ©e
  - [ ] Revue des accÃ¨s trimestrielle
  - [ ] Documentation des incidents
  - [ ] Audit trail complet

PCI-DSS (Payment Card Data):
  - [ ] Chiffrement fort (AES-256)
  - [ ] Backups isolÃ©s du rÃ©seau production
  - [ ] Tests de restauration trimestriels
  - [ ] RÃ©tention max 3 mois (cardholder data)
  - [ ] Secure deletion (overwrite)
  - [ ] AccÃ¨s strictement contrÃ´lÃ©
  - [ ] Logging de tous les accÃ¨s

ISO 27001:
  - [ ] Politique de backup formelle
  - [ ] Risk assessment documentÃ©
  - [ ] ProcÃ©dures de restauration testÃ©es
  - [ ] Gestion des incidents
  - [ ] Formation du personnel
  - [ ] Revues management rÃ©guliÃ¨res
  - [ ] AmÃ©lioration continue documentÃ©e
```

### Audit Trail

```javascript
// audit_backup_access.js
// Script pour tracker tous les accÃ¨s aux backups

use admin

// Activer l'audit
db.adminCommand({
  setParameter: 1,
  auditLog: {
    destination: "file",
    path: "/var/log/mongodb/audit.json",
    filter: {
      // Auditer tous les accÃ¨s aux backups
      "atype": { "$in": ["authenticate", "authCheck"] },
      "param.db": { "$in": ["admin", "config"] }
    },
    format: "JSON"
  }
});

// Query pour analyser les accÃ¨s backups
db.getSiblingDB("audit").log.aggregate([
  {
    $match: {
      "users.user": "backup-operator",
      "ts": {
        $gte: new Date(Date.now() - 30*24*60*60*1000)  // 30 derniers jours
      }
    }
  },
  {
    $group: {
      _id: {
        user: "$users.user",
        operation: "$param.command"
      },
      count: { $sum: 1 },
      lastAccess: { $max: "$ts" }
    }
  },
  {
    $sort: { count: -1 }
  }
]);
```

## Framework de ContinuitÃ© d'ActivitÃ©

### Business Continuity Plan (BCP)

```markdown
# MongoDB Business Continuity Plan

## 1. Business Impact Analysis

### DonnÃ©es Critiques
| Database | CriticitÃ© | RPO | RTO | Impact Financier |
|----------|-----------|-----|-----|------------------|
| Orders   | Critique  | 15min | 30min | $10k/heure |
| Users    | Haute     | 1h  | 1h  | $2k/heure |
| Logs     | Moyenne   | 24h | 4h  | $200/heure |

### ScÃ©narios de Disaster

**Scenario 1: Panne Data Center**
- ProbabilitÃ©: Faible (1/10 ans)
- Impact: TrÃ¨s Ã©levÃ©
- Mitigation: Multi-rÃ©gion actif

**Scenario 2: Corruption de DonnÃ©es**
- ProbabilitÃ©: Moyenne (1/an)
- Impact: Moyen
- Mitigation: PITR + Backups frÃ©quents

**Scenario 3: Ransomware**
- ProbabilitÃ©: Ã‰levÃ©e (secteur cible)
- Impact: TrÃ¨s Ã©levÃ©
- Mitigation: ImmutabilitÃ© + Air-gap

## 2. Recovery Strategies

### Tier 1 (Critique)
- **Strategy:** Hot standby multi-rÃ©gion
- **Failover:** Automatique (< 5 min)
- **Testing:** Mensuel

### Tier 2 (Haute)
- **Strategy:** Warm standby + PITR
- **Failover:** Manuel (< 1h)
- **Testing:** Trimestriel

### Tier 3 (Moyenne)
- **Strategy:** Backups + Snapshots
- **Recovery:** Best effort (< 4h)
- **Testing:** Semestriel

## 3. Team Responsibilities

### Database Team (Primary)
- Monitoring 24/7
- Incident response
- Backup execution & validation
- Documentation

### DevOps Team (Support)
- Infrastructure provisioning
- Automation
- Deployment recovery

### Security Team
- Access control
- Encryption
- Audit compliance

## 4. Communication Plan

### Escalation Path
1. On-Call DBA (0-15 min)
2. Database Team Lead (15-30 min)
3. CTO (30-60 min)
4. CEO (if business impact > $50k)

### Stakeholder Notifications
- **Internal:** #incidents Slack (immediate)
- **Customers:** Status page (< 30 min)
- **Management:** Email summary (< 1h)

## 5. Post-Incident

- [ ] Root cause analysis (48h)
- [ ] Post-mortem (1 week)
- [ ] Action items tracking
- [ ] BCP update if needed
- [ ] Team debrief
```

## Conclusion

Les bonnes pratiques de sauvegarde et restauration ne sont pas statiques - elles Ã©voluent avec votre organisation, vos technologies et les menaces. Un programme de backup mature repose sur trois piliers :

### 1. **Excellence Technique**
- Architecture rÃ©siliente (3-2-1-1-0)
- Automation maximale
- Monitoring proactif
- Tests rÃ©guliers obligatoires

### 2. **Excellence OpÃ©rationnelle**
- ProcÃ©dures documentÃ©es et testÃ©es
- Ã‰quipe formÃ©e et prÃªte
- Communication claire
- AmÃ©lioration continue

### 3. **Excellence Organisationnelle**
- Alignement business-IT
- Budget appropriÃ©
- Compliance garantie
- Culture de la rÃ©silience

### Minimum Viable pour Production

**Must-Have absolu** :
- âœ… Backups quotidiens automatisÃ©s
- âœ… Stockage multi-rÃ©gion
- âœ… Tests mensuels minimum
- âœ… Monitoring avec alertes
- âœ… Documentation Ã  jour
- âœ… Chiffrement des backups
- âœ… Plan de restoration testÃ©

**Nice-to-Have recommandÃ©** :
- â­ PITR (48h minimum)
- â­ ImmutabilitÃ© (ransomware protection)
- â­ DR site (warm/hot standby)
- â­ Automation complÃ¨te
- â­ Tests hebdomadaires
- â­ Dashboards temps rÃ©el

**Excellence (Mission-Critical)** :
- ğŸ† MongoDB Atlas / Ops Manager
- ğŸ† Multi-rÃ©gion actif-actif
- ğŸ† RTO < 30 minutes
- ğŸ† RPO < 15 minutes
- ğŸ† Tests quotidiens automatisÃ©s
- ğŸ† Ã‰quipe dÃ©diÃ©e 24/7

### Le Test Ultime

**Votre stratÃ©gie de backup est-elle vraiment solide ?**

Posez-vous ces questions :
1. âœ… Pouvez-vous restaurer en production **maintenant** avec confiance ?
2. âœ… Votre Ã©quipe peut-elle restaurer **sans vous** ?
3. âœ… Vos backups survivraient-ils Ã  un **ransomware** ?
4. âœ… Respectez-vous votre **RTO/RPO promis** ?
5. âœ… Votre derniÃ¨re restauration remonte Ã  **quand** ? (doit Ãªtre < 1 mois)

Si vous avez rÃ©pondu **OUI** Ã  tout : Bravo ! ğŸ‰

Sinon : Ce chapitre vous donne tous les outils pour y arriver.

**Remember:** *Un backup non testÃ© n'est qu'une illusion de sÃ©curitÃ©.*

---


â­ï¸ [Monitoring et Administration](/13-monitoring-administration/README.md)
